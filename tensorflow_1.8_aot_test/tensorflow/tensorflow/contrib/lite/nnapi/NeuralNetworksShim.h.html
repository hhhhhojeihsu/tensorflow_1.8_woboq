<!doctype html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0"><title>NeuralNetworksShim.h source code [tensorflow/tensorflow/contrib/lite/nnapi/NeuralNetworksShim.h] - Woboq Code Browser</title>
<meta name="woboq:interestingDefinitions" content="ANeuralNetworksOperandType "/>
<link rel="stylesheet" href="https://code.woboq.org/data/qtcreator.css" title="QtCreator"/>
<link rel="alternate stylesheet" href="https://code.woboq.org/data/kdevelop.css" title="KDevelop"/>
<script type="text/javascript" src="https://code.woboq.org/data/jquery/jquery.min.js"></script>
<script type="text/javascript" src="https://code.woboq.org/data/jquery/jquery-ui.min.js"></script>
<script>var file = 'tensorflow/tensorflow/contrib/lite/nnapi/NeuralNetworksShim.h'; var root_path = '../../../../..'; var data_path = 'https://code.woboq.org/data';</script>
<script src='https://code.woboq.org/data/codebrowser.js'></script>
</head>
<body><div id='header'><h1 id='breadcrumb'><span>Browse the source code of </span><a href='../../../..'>tensorflow</a>/<a href='../../..'>tensorflow</a>/<a href='../..'>contrib</a>/<a href='..'>lite</a>/<a href='./'>nnapi</a>/<a href='NeuralNetworksShim.h.html'>NeuralNetworksShim.h</a></h1></div>
<hr/><div id='content'><table class="code">
<tr><th id="1">1</th><td><i>/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.</i></td></tr>
<tr><th id="2">2</th><td><i></i></td></tr>
<tr><th id="3">3</th><td><i>Licensed under the Apache License, Version 2.0 (the "License");</i></td></tr>
<tr><th id="4">4</th><td><i>you may not use this file except in compliance with the License.</i></td></tr>
<tr><th id="5">5</th><td><i>You may obtain a copy of the License at</i></td></tr>
<tr><th id="6">6</th><td><i></i></td></tr>
<tr><th id="7">7</th><td><i>    <a href="http://www.apache.org/licenses/LICENSE-2.0">http://www.apache.org/licenses/LICENSE-2.0</a></i></td></tr>
<tr><th id="8">8</th><td><i></i></td></tr>
<tr><th id="9">9</th><td><i>Unless required by applicable law or agreed to in writing, software</i></td></tr>
<tr><th id="10">10</th><td><i>distributed under the License is distributed on an "AS IS" BASIS,</i></td></tr>
<tr><th id="11">11</th><td><i>WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</i></td></tr>
<tr><th id="12">12</th><td><i>See the License for the specific language governing permissions and</i></td></tr>
<tr><th id="13">13</th><td><i>limitations under the License.</i></td></tr>
<tr><th id="14">14</th><td><i>==============================================================================*/</i></td></tr>
<tr><th id="15">15</th><td><u>#<span data-ppcond="15">ifndef</span> <span class="macro" data-ref="_M/NN_API_SHIM_H0">NN_API_SHIM_H0</span></u></td></tr>
<tr><th id="16">16</th><td><u>#define <dfn class="macro" id="_M/NN_API_SHIM_H0" data-ref="_M/NN_API_SHIM_H0">NN_API_SHIM_H0</dfn></u></td></tr>
<tr><th id="17">17</th><td></td></tr>
<tr><th id="18">18</th><td><u>#include <a href="../../../../../include/dlfcn.h.html">&lt;dlfcn.h&gt;</a></u></td></tr>
<tr><th id="19">19</th><td><u>#include &lt;stdint.h&gt;</u></td></tr>
<tr><th id="20">20</th><td><u>#include <a href="../../../../../include/stdio.h.html">&lt;stdio.h&gt;</a></u></td></tr>
<tr><th id="21">21</th><td><u>#include <a href="../../../../../include/stdlib.h.html">&lt;stdlib.h&gt;</a></u></td></tr>
<tr><th id="22">22</th><td></td></tr>
<tr><th id="23">23</th><td><i>// helpers</i></td></tr>
<tr><th id="24">24</th><td></td></tr>
<tr><th id="25">25</th><td><u>#define <dfn class="macro" id="_M/NNAPI_LOG" data-ref="_M/NNAPI_LOG">NNAPI_LOG</dfn>(format, ...) <a class="ref" href="../../../../../include/stdio.h.html#fprintf" title='fprintf' data-ref="fprintf">fprintf</a>(stderr, format "\n", __VA_ARGS__);</u></td></tr>
<tr><th id="26">26</th><td><u>#define <dfn class="macro" id="_M/LOAD_FUNCTION" data-ref="_M/LOAD_FUNCTION">LOAD_FUNCTION</dfn>(name) \</u></td></tr>
<tr><th id="27">27</th><td><u>  static name##_fn <dfn class="local col8 decl" id="318fn" title='fn' data-type='ANeuralNetworksMemory_createFromFd_fn' data-ref="318fn"><dfn class="local col0 decl" id="320fn" title='fn' data-type='ANeuralNetworksMemory_free_fn' data-ref="320fn"><dfn class="local col2 decl" id="322fn" title='fn' data-type='ANeuralNetworksModel_create_fn' data-ref="322fn"><dfn class="local col4 decl" id="324fn" title='fn' data-type='ANeuralNetworksModel_free_fn' data-ref="324fn"><dfn class="local col6 decl" id="326fn" title='fn' data-type='ANeuralNetworksModel_finish_fn' data-ref="326fn"><dfn class="local col9 decl" id="329fn" title='fn' data-type='ANeuralNetworksModel_addOperand_fn' data-ref="329fn"><dfn class="local col4 decl" id="334fn" title='fn' data-type='ANeuralNetworksModel_setOperandValue_fn' data-ref="334fn"><dfn class="local col0 decl" id="340fn" title='fn' data-type='ANeuralNetworksModel_setOperandValueFromMemory_fn' data-ref="340fn"><dfn class="local col7 decl" id="347fn" title='fn' data-type='ANeuralNetworksModel_addOperation_fn' data-ref="347fn"><dfn class="local col3 decl" id="353fn" title='fn' data-type='ANeuralNetworksModel_identifyInputsAndOutputs_fn' data-ref="353fn"><dfn class="local col6 decl" id="356fn" title='fn' data-type='ANeuralNetworksCompilation_create_fn' data-ref="356fn"><dfn class="local col8 decl" id="358fn" title='fn' data-type='ANeuralNetworksCompilation_free_fn' data-ref="358fn"><dfn class="local col1 decl" id="361fn" title='fn' data-type='ANeuralNetworksCompilation_setPreference_fn' data-ref="361fn"><dfn class="local col3 decl" id="363fn" title='fn' data-type='ANeuralNetworksCompilation_finish_fn' data-ref="363fn"><dfn class="local col6 decl" id="366fn" title='fn' data-type='ANeuralNetworksExecution_create_fn' data-ref="366fn"><dfn class="local col8 decl" id="368fn" title='fn' data-type='ANeuralNetworksExecution_free_fn' data-ref="368fn"><dfn class="local col4 decl" id="374fn" title='fn' data-type='ANeuralNetworksExecution_setInput_fn' data-ref="374fn"><dfn class="local col1 decl" id="381fn" title='fn' data-type='ANeuralNetworksExecution_setInputFromMemory_fn' data-ref="381fn"><dfn class="local col7 decl" id="387fn" title='fn' data-type='ANeuralNetworksExecution_setOutput_fn' data-ref="387fn"><dfn class="local col4 decl" id="394fn" title='fn' data-type='ANeuralNetworksExecution_setOutputFromMemory_fn' data-ref="394fn"><dfn class="local col7 decl" id="397fn" title='fn' data-type='ANeuralNetworksExecution_startCompute_fn' data-ref="397fn"><dfn class="local col9 decl" id="399fn" title='fn' data-type='ANeuralNetworksEvent_wait_fn' data-ref="399fn"><dfn class="local col1 decl" id="401fn" title='fn' data-type='ANeuralNetworksEvent_free_fn' data-ref="401fn">fn</dfn></dfn></dfn></dfn></dfn></dfn></dfn></dfn></dfn></dfn></dfn></dfn></dfn></dfn></dfn></dfn></dfn></dfn></dfn></dfn></dfn></dfn></dfn> = reinterpret_cast&lt;name##_fn&gt;(<a class="ref" href="#_Z12loadFunctionPKc" title='loadFunction' data-ref="_Z12loadFunctionPKc">loadFunction</a>(#name));</u></td></tr>
<tr><th id="28">28</th><td><u>#define <dfn class="macro" id="_M/EXECUTE_FUNCTION" data-ref="_M/EXECUTE_FUNCTION">EXECUTE_FUNCTION</dfn>(...) \</u></td></tr>
<tr><th id="29">29</th><td><u>  if (<a class="local col0 ref" href="#1381" title='fn' data-ref="320fn"><a class="local col4 ref" href="#1423" title='fn' data-ref="324fn"><a class="local col8 ref" href="#1643" title='fn' data-ref="358fn"><a class="local col8 ref" href="#1721" title='fn' data-ref="368fn"><a class="local col1 ref" href="#1910" title='fn' data-ref="401fn">fn</a></a></a></a></a> != nullptr) {        \</u></td></tr>
<tr><th id="30">30</th><td><u>    <a class="local col0 ref" href="#1381" title='fn' data-ref="320fn"><a class="local col4 ref" href="#1423" title='fn' data-ref="324fn"><a class="local col8 ref" href="#1643" title='fn' data-ref="358fn"><a class="local col8 ref" href="#1721" title='fn' data-ref="368fn"><a class="local col1 ref" href="#1910" title='fn' data-ref="401fn">fn</a></a></a></a></a>(__VA_ARGS__);          \</u></td></tr>
<tr><th id="31">31</th><td><u>  }</u></td></tr>
<tr><th id="32">32</th><td><u>#define <dfn class="macro" id="_M/EXECUTE_FUNCTION_RETURN" data-ref="_M/EXECUTE_FUNCTION_RETURN">EXECUTE_FUNCTION_RETURN</dfn>(...) return <a class="local col8 ref" href="#1367" title='fn' data-ref="318fn"><a class="local col2 ref" href="#1407" title='fn' data-ref="322fn"><a class="local col6 ref" href="#1441" title='fn' data-ref="326fn"><a class="local col9 ref" href="#1476" title='fn' data-ref="329fn"><a class="local col4 ref" href="#1507" title='fn' data-ref="334fn"><a class="local col0 ref" href="#1538" title='fn' data-ref="340fn"><a class="local col7 ref" href="#1568" title='fn' data-ref="347fn"><a class="local col3 ref" href="#1597" title='fn' data-ref="353fn"><a class="local col6 ref" href="#1622" title='fn' data-ref="356fn"><a class="local col1 ref" href="#1664" title='fn' data-ref="361fn"><a class="local col3 ref" href="#1681" title='fn' data-ref="363fn"><a class="local col6 ref" href="#1702" title='fn' data-ref="366fn"><a class="local col4 ref" href="#1753" title='fn' data-ref="374fn"><a class="local col1 ref" href="#1788" title='fn' data-ref="381fn"><a class="local col7 ref" href="#1820" title='fn' data-ref="387fn"><a class="local col4 ref" href="#1855" title='fn' data-ref="394fn"><a class="local col7 ref" href="#1885" title='fn' data-ref="397fn"><a class="local col9 ref" href="#1900" title='fn' data-ref="399fn">fn</a></a></a></a></a></a></a></a></a></a></a></a></a></a></a></a></a></a> != nullptr ? <a class="local col8 ref" href="#1367" title='fn' data-ref="318fn"><a class="local col2 ref" href="#1407" title='fn' data-ref="322fn"><a class="local col6 ref" href="#1441" title='fn' data-ref="326fn"><a class="local col9 ref" href="#1476" title='fn' data-ref="329fn"><a class="local col4 ref" href="#1507" title='fn' data-ref="334fn"><a class="local col0 ref" href="#1538" title='fn' data-ref="340fn"><a class="local col7 ref" href="#1568" title='fn' data-ref="347fn"><a class="local col3 ref" href="#1597" title='fn' data-ref="353fn"><a class="local col6 ref" href="#1622" title='fn' data-ref="356fn"><a class="local col1 ref" href="#1664" title='fn' data-ref="361fn"><a class="local col3 ref" href="#1681" title='fn' data-ref="363fn"><a class="local col6 ref" href="#1702" title='fn' data-ref="366fn"><a class="local col4 ref" href="#1753" title='fn' data-ref="374fn"><a class="local col1 ref" href="#1788" title='fn' data-ref="381fn"><a class="local col7 ref" href="#1820" title='fn' data-ref="387fn"><a class="local col4 ref" href="#1855" title='fn' data-ref="394fn"><a class="local col7 ref" href="#1885" title='fn' data-ref="397fn"><a class="local col9 ref" href="#1900" title='fn' data-ref="399fn">fn</a></a></a></a></a></a></a></a></a></a></a></a></a></a></a></a></a></a>(__VA_ARGS__) : 0;</u></td></tr>
<tr><th id="33">33</th><td></td></tr>
<tr><th id="34">34</th><td><b>inline</b> <em>void</em>* <dfn class="decl def" id="_Z11loadLibraryPKc" title='loadLibrary' data-ref="_Z11loadLibraryPKc">loadLibrary</dfn>(<em>const</em> <em>char</em>* <dfn class="local col1 decl" id="241name" title='name' data-type='const char *' data-ref="241name">name</dfn>) {</td></tr>
<tr><th id="35">35</th><td>  <i>// TODO: change RTLD_LOCAL? Assumes there can be multiple instances of nn</i></td></tr>
<tr><th id="36">36</th><td><i>  // api RT</i></td></tr>
<tr><th id="37">37</th><td>  <em>void</em>* <dfn class="local col2 decl" id="242handle" title='handle' data-type='void *' data-ref="242handle">handle</dfn> = <a class="ref" href="../../../../../include/dlfcn.h.html#dlopen" title='dlopen' data-ref="dlopen">dlopen</a>(<a class="local col1 ref" href="#241name" title='name' data-ref="241name">name</a>, <a class="macro" href="../../../../../include/x86_64-linux-gnu/bits/dlfcn.h.html#24" title="0x00001" data-ref="_M/RTLD_LAZY">RTLD_LAZY</a> | <a class="macro" href="../../../../../include/x86_64-linux-gnu/bits/dlfcn.h.html#38" title="0" data-ref="_M/RTLD_LOCAL">RTLD_LOCAL</a>);</td></tr>
<tr><th id="38">38</th><td>  <b>if</b> (<a class="local col2 ref" href="#242handle" title='handle' data-ref="242handle">handle</a> == <b>nullptr</b>) {</td></tr>
<tr><th id="39">39</th><td>    <a class="macro" href="#25" title="fprintf(stderr, &quot;nnapi error: unable to open library %s&quot; &quot;\n&quot;, name);" data-ref="_M/NNAPI_LOG">NNAPI_LOG</a>(<q>"nnapi error: unable to open library %s"</q>, <a class="local col1 ref" href="#241name" title='name' data-ref="241name">name</a>);</td></tr>
<tr><th id="40">40</th><td>  }</td></tr>
<tr><th id="41">41</th><td>  <b>return</b> <a class="local col2 ref" href="#242handle" title='handle' data-ref="242handle">handle</a>;</td></tr>
<tr><th id="42">42</th><td>}</td></tr>
<tr><th id="43">43</th><td></td></tr>
<tr><th id="44">44</th><td><b>inline</b> <em>void</em>* <dfn class="decl def" id="_Z16getLibraryHandlev" title='getLibraryHandle' data-ref="_Z16getLibraryHandlev">getLibraryHandle</dfn>() {</td></tr>
<tr><th id="45">45</th><td>  <em>static</em> <em>void</em>* <dfn class="local col3 decl" id="243handle" title='handle' data-type='void *' data-ref="243handle">handle</dfn> = <a class="ref" href="#_Z11loadLibraryPKc" title='loadLibrary' data-ref="_Z11loadLibraryPKc">loadLibrary</a>(<q>"libneuralnetworks.so"</q>);</td></tr>
<tr><th id="46">46</th><td>  <b>return</b> <a class="local col3 ref" href="#243handle" title='handle' data-ref="243handle">handle</a>;</td></tr>
<tr><th id="47">47</th><td>}</td></tr>
<tr><th id="48">48</th><td></td></tr>
<tr><th id="49">49</th><td><b>inline</b> <em>void</em>* <dfn class="decl def" id="_Z12loadFunctionPKc" title='loadFunction' data-ref="_Z12loadFunctionPKc">loadFunction</dfn>(<em>const</em> <em>char</em>* <dfn class="local col4 decl" id="244name" title='name' data-type='const char *' data-ref="244name">name</dfn>) {</td></tr>
<tr><th id="50">50</th><td>  <em>void</em>* <dfn class="local col5 decl" id="245fn" title='fn' data-type='void *' data-ref="245fn">fn</dfn> = <b>nullptr</b>;</td></tr>
<tr><th id="51">51</th><td>  <b>if</b> (<a class="ref" href="#_Z16getLibraryHandlev" title='getLibraryHandle' data-ref="_Z16getLibraryHandlev">getLibraryHandle</a>() != <b>nullptr</b>) {</td></tr>
<tr><th id="52">52</th><td>    <a class="local col5 ref" href="#245fn" title='fn' data-ref="245fn">fn</a> = <a class="ref" href="../../../../../include/dlfcn.h.html#dlsym" title='dlsym' data-ref="dlsym">dlsym</a>(<a class="ref" href="#_Z16getLibraryHandlev" title='getLibraryHandle' data-ref="_Z16getLibraryHandlev">getLibraryHandle</a>(), <a class="local col4 ref" href="#244name" title='name' data-ref="244name">name</a>);</td></tr>
<tr><th id="53">53</th><td>  }</td></tr>
<tr><th id="54">54</th><td>  <b>if</b> (<a class="local col5 ref" href="#245fn" title='fn' data-ref="245fn">fn</a> == <b>nullptr</b>) {</td></tr>
<tr><th id="55">55</th><td>    <a class="macro" href="#25" title="fprintf(stderr, &quot;nnapi error: unable to open function %s&quot; &quot;\n&quot;, name);" data-ref="_M/NNAPI_LOG">NNAPI_LOG</a>(<q>"nnapi error: unable to open function %s"</q>, <a class="local col4 ref" href="#244name" title='name' data-ref="244name">name</a>);</td></tr>
<tr><th id="56">56</th><td>  }</td></tr>
<tr><th id="57">57</th><td>  <b>return</b> <a class="local col5 ref" href="#245fn" title='fn' data-ref="245fn">fn</a>;</td></tr>
<tr><th id="58">58</th><td>}</td></tr>
<tr><th id="59">59</th><td></td></tr>
<tr><th id="60">60</th><td><b>inline</b> <em>bool</em> <dfn class="decl def" id="_Z11NNAPIExistsv" title='NNAPIExists' data-ref="_Z11NNAPIExistsv">NNAPIExists</dfn>() {</td></tr>
<tr><th id="61">61</th><td>  <em>static</em> <em>bool</em> <dfn class="local col6 decl" id="246nnapi_is_available" title='nnapi_is_available' data-type='bool' data-ref="246nnapi_is_available">nnapi_is_available</dfn> = <a class="ref" href="#_Z16getLibraryHandlev" title='getLibraryHandle' data-ref="_Z16getLibraryHandlev">getLibraryHandle</a>();</td></tr>
<tr><th id="62">62</th><td>  <b>return</b> <a class="local col6 ref" href="#246nnapi_is_available" title='nnapi_is_available' data-ref="246nnapi_is_available">nnapi_is_available</a>;</td></tr>
<tr><th id="63">63</th><td>}</td></tr>
<tr><th id="64">64</th><td></td></tr>
<tr><th id="65">65</th><td><i>// nn api types</i></td></tr>
<tr><th id="66">66</th><td></td></tr>
<tr><th id="67">67</th><td><i class="doc">/**</i></td></tr>
<tr><th id="68">68</th><td><i class="doc"> * Operand types.</i></td></tr>
<tr><th id="69">69</th><td><i class="doc"> *</i></td></tr>
<tr><th id="70">70</th><td><i class="doc"> * The type of operands that can be added to a model.</i></td></tr>
<tr><th id="71">71</th><td><i class="doc"> *</i></td></tr>
<tr><th id="72">72</th><td><i class="doc"> * Although we define many types, most operators accept just a few</i></td></tr>
<tr><th id="73">73</th><td><i class="doc"> * types.  Most used are ANEURALNETWORKS_TENSOR_FLOAT32,</i></td></tr>
<tr><th id="74">74</th><td><i class="doc"> * ANEURALNETWORKS_TENSOR_QUANT8_ASYMM, and ANEURALNETWORKS_INT32.</i></td></tr>
<tr><th id="75">75</th><td><i class="doc"> */</i></td></tr>
<tr><th id="76">76</th><td><b>enum</b> {</td></tr>
<tr><th id="77">77</th><td>  <i class="doc">/** The following entries are used to declare scalars. */</i></td></tr>
<tr><th id="78">78</th><td></td></tr>
<tr><th id="79">79</th><td>  <i class="doc">/** A 32 bit floating point scalar value. */</i></td></tr>
<tr><th id="80">80</th><td>  <dfn class="enum" id="ANEURALNETWORKS_FLOAT32" title='ANEURALNETWORKS_FLOAT32' data-ref="ANEURALNETWORKS_FLOAT32">ANEURALNETWORKS_FLOAT32</dfn> = <var>0</var>,</td></tr>
<tr><th id="81">81</th><td>  <i class="doc">/** A signed 32 bit integer scalar value. */</i></td></tr>
<tr><th id="82">82</th><td>  <dfn class="enum" id="ANEURALNETWORKS_INT32" title='ANEURALNETWORKS_INT32' data-ref="ANEURALNETWORKS_INT32">ANEURALNETWORKS_INT32</dfn> = <var>1</var>,</td></tr>
<tr><th id="83">83</th><td>  <i class="doc">/** An unsigned 32 bit integer scalar value. */</i></td></tr>
<tr><th id="84">84</th><td>  <dfn class="enum" id="ANEURALNETWORKS_UINT32" title='ANEURALNETWORKS_UINT32' data-ref="ANEURALNETWORKS_UINT32">ANEURALNETWORKS_UINT32</dfn> = <var>2</var>,</td></tr>
<tr><th id="85">85</th><td></td></tr>
<tr><th id="86">86</th><td>  <i class="doc">/** The following entries are used to declare tensors. */</i></td></tr>
<tr><th id="87">87</th><td></td></tr>
<tr><th id="88">88</th><td>  <i class="doc">/** A tensor of 32 bit floating point values. */</i></td></tr>
<tr><th id="89">89</th><td>  <dfn class="enum" id="ANEURALNETWORKS_TENSOR_FLOAT32" title='ANEURALNETWORKS_TENSOR_FLOAT32' data-ref="ANEURALNETWORKS_TENSOR_FLOAT32">ANEURALNETWORKS_TENSOR_FLOAT32</dfn> = <var>3</var>,</td></tr>
<tr><th id="90">90</th><td>  <i class="doc">/** A tensor of 32 bit integer values. */</i></td></tr>
<tr><th id="91">91</th><td>  <dfn class="enum" id="ANEURALNETWORKS_TENSOR_INT32" title='ANEURALNETWORKS_TENSOR_INT32' data-ref="ANEURALNETWORKS_TENSOR_INT32">ANEURALNETWORKS_TENSOR_INT32</dfn> = <var>4</var>,</td></tr>
<tr><th id="92">92</th><td>  <i class="doc">/** A tensor of 8 bit integers that represent real numbers.</i></td></tr>
<tr><th id="93">93</th><td><i class="doc">   *</i></td></tr>
<tr><th id="94">94</th><td><i class="doc">   * Attached to this tensor are two numbers that can be used to convert</i></td></tr>
<tr><th id="95">95</th><td><i class="doc">   * the 8 bit integer to the real value and vice versa.  These two numbers are:</i></td></tr>
<tr><th id="96">96</th><td><i class="doc">   * - scale: a 32 bit floating point value</i></td></tr>
<tr><th id="97">97</th><td><i class="doc">   * - zero_value: an 32 bit integer</i></td></tr>
<tr><th id="98">98</th><td><i class="doc">   *</i></td></tr>
<tr><th id="99">99</th><td><i class="doc">   * The formula is:</i></td></tr>
<tr><th id="100">100</th><td><i class="doc">   * real_value = (integer_value - zero_value) * scale.</i></td></tr>
<tr><th id="101">101</th><td><i class="doc">   */</i></td></tr>
<tr><th id="102">102</th><td>  <dfn class="enum" id="ANEURALNETWORKS_TENSOR_QUANT8_ASYMM" title='ANEURALNETWORKS_TENSOR_QUANT8_ASYMM' data-ref="ANEURALNETWORKS_TENSOR_QUANT8_ASYMM">ANEURALNETWORKS_TENSOR_QUANT8_ASYMM</dfn> = <var>5</var>,</td></tr>
<tr><th id="103">103</th><td>};</td></tr>
<tr><th id="104">104</th><td></td></tr>
<tr><th id="105">105</th><td><i class="doc">/**</i></td></tr>
<tr><th id="106">106</th><td><i class="doc"> * Operation types.</i></td></tr>
<tr><th id="107">107</th><td><i class="doc"> *</i></td></tr>
<tr><th id="108">108</th><td><i class="doc"> * The type of operations that can be added to a model.</i></td></tr>
<tr><th id="109">109</th><td><i class="doc"> */</i></td></tr>
<tr><th id="110">110</th><td><b>enum</b> {</td></tr>
<tr><th id="111">111</th><td>  <i class="doc">/** Adds two tensors, element-wise.</i></td></tr>
<tr><th id="112">112</th><td><i class="doc">   *</i></td></tr>
<tr><th id="113">113</th><td><i class="doc">   * Takes two input tensors of identical type and compatible dimensions. The</i></td></tr>
<tr><th id="114">114</th><td><i class="doc">   * output is the sum of both input tensors, optionally modified by an</i></td></tr>
<tr><th id="115">115</th><td><i class="doc">   * activation function.</i></td></tr>
<tr><th id="116">116</th><td><i class="doc">   *</i></td></tr>
<tr><th id="117">117</th><td><i class="doc">   * Two dimensions are compatible when:</i></td></tr>
<tr><th id="118">118</th><td><i class="doc">   *     1. they are equal, or</i></td></tr>
<tr><th id="119">119</th><td><i class="doc">   *     2. one of them is 1</i></td></tr>
<tr><th id="120">120</th><td><i class="doc">   *</i></td></tr>
<tr><th id="121">121</th><td><i class="doc">   * The size of the output is the maximum size along each dimension of the</i></td></tr>
<tr><th id="122">122</th><td><i class="doc">   * input operands. It starts with the trailing dimensions, and works its way</i></td></tr>
<tr><th id="123">123</th><td><i class="doc">   * forward.</i></td></tr>
<tr><th id="124">124</th><td><i class="doc">   *</i></td></tr>
<tr><th id="125">125</th><td><i class="doc">   * Example:</i></td></tr>
<tr><th id="126">126</th><td><i class="doc">   *</i></td></tr>
<tr><th id="127">127</th><td><i class="doc">   *     input1.dimension = {4, 1, 2}</i></td></tr>
<tr><th id="128">128</th><td><i class="doc">   *     input2.dimension = {5, 4, 3, 1}</i></td></tr>
<tr><th id="129">129</th><td><i class="doc">   *     output.dimension = {5, 4, 3, 2}</i></td></tr>
<tr><th id="130">130</th><td><i class="doc">   *</i></td></tr>
<tr><th id="131">131</th><td><i class="doc">   * Supported tensor types:</i></td></tr>
<tr><th id="132">132</th><td><i class="doc">   * * {<span class="command">@link</span><span class="verb"> ANEURALNETWORKS_TENSOR_FLOAT32}</span></i></td></tr>
<tr><th id="133">133</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="134">134</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Supported tensor rank: up to 4</span></i></td></tr>
<tr><th id="135">135</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="136">136</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Inputs:</span></i></td></tr>
<tr><th id="137">137</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: A tensor.</span></i></td></tr>
<tr><th id="138">138</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 1: A tensor of the same type, and compatible dimensions as input0.</span></i></td></tr>
<tr><th id="139">139</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 2: An INT32 value, and has to be one of the {@link FuseCode} values.</span></i></td></tr>
<tr><th id="140">140</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      Specifies the activation to invoke on the result of each addition.</span></i></td></tr>
<tr><th id="141">141</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="142">142</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Outputs:</span></i></td></tr>
<tr><th id="143">143</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: The sum, a tensor of the same type as input0.</span></i></td></tr>
<tr><th id="144">144</th><td><i class="doc"><span class="verb"></span><span class="verb">   *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="145">145</th><td><span class="verb"></span>  <dfn class="enum" id="ANEURALNETWORKS_ADD" title='ANEURALNETWORKS_ADD' data-ref="ANEURALNETWORKS_ADD">ANEURALNETWORKS_ADD</dfn> = <var>0</var>,</td></tr>
<tr><th id="146">146</th><td>  <i class="doc">/** Performs a 2-D average pooling operation.</i></td></tr>
<tr><th id="147">147</th><td><i class="doc">   *</i></td></tr>
<tr><th id="148">148</th><td><i class="doc">   * The output dimensions are functions of the filter dimensions, stride, and</i></td></tr>
<tr><th id="149">149</th><td><i class="doc">   * padding.</i></td></tr>
<tr><th id="150">150</th><td><i class="doc">   *</i></td></tr>
<tr><th id="151">151</th><td><i class="doc">   * The values in the output tensor are computed as:</i></td></tr>
<tr><th id="152">152</th><td><i class="doc">   *</i></td></tr>
<tr><th id="153">153</th><td><i class="doc">   *     output[batch, row, col, channel] =</i></td></tr>
<tr><th id="154">154</th><td><i class="doc">   *         sum_{i, j}(input[batch, row + i, col + j, channel]) / sum(1)</i></td></tr>
<tr><th id="155">155</th><td><i class="doc">   *</i></td></tr>
<tr><th id="156">156</th><td><i class="doc">   * Supported tensor types:</i></td></tr>
<tr><th id="157">157</th><td><i class="doc">   * * {<span class="command">@link</span><span class="verb"> ANEURALNETWORKS_TENSOR_FLOAT32}</span></i></td></tr>
<tr><th id="158">158</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * {@link ANEURALNETWORKS_TENSOR_QUANT8_ASYMM}</span></i></td></tr>
<tr><th id="159">159</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="160">160</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Supported tensor rank: 4, with "NHWC" data layout.</span></i></td></tr>
<tr><th id="161">161</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="162">162</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Inputs:</span></i></td></tr>
<tr><th id="163">163</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: A 4-D tensor, of shape [batches, height, width, depth], specifying the</span></i></td></tr>
<tr><th id="164">164</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> input.</span></i></td></tr>
<tr><th id="165">165</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 1: An INT32 value, specifying the padding on the left, in the ‘width’</span></i></td></tr>
<tr><th id="166">166</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> dimension.</span></i></td></tr>
<tr><th id="167">167</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 2: An INT32 value, specifying the padding on the right,in the ‘width’</span></i></td></tr>
<tr><th id="168">168</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> dimension.</span></i></td></tr>
<tr><th id="169">169</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 3: An INT32 value, specifying the padding on the top, in the ‘height’</span></i></td></tr>
<tr><th id="170">170</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> dimension.</span></i></td></tr>
<tr><th id="171">171</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 4: An INT32 value, specifying the padding on the bottom, in the ‘height’</span></i></td></tr>
<tr><th id="172">172</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> dimension.</span></i></td></tr>
<tr><th id="173">173</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 5: An INT32 value, specifying the output stride in the ‘width’ dimension.</span></i></td></tr>
<tr><th id="174">174</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 6: An INT32 value, specifying the output stride in the ‘height’</span></i></td></tr>
<tr><th id="175">175</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> dimension.</span></i></td></tr>
<tr><th id="176">176</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 7: An INT32 value, specifying the filter width.</span></i></td></tr>
<tr><th id="177">177</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 8: An INT32 value, specifying the filter height.</span></i></td></tr>
<tr><th id="178">178</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 9: An INT32 value, and has to be one of the {@link FuseCode} values.</span></i></td></tr>
<tr><th id="179">179</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      Specifies the activation to invoke on the result of each addition.</span></i></td></tr>
<tr><th id="180">180</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="181">181</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Outputs:</span></i></td></tr>
<tr><th id="182">182</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: The output 4-D tensor, of shape [batches, out_height, out_width,</span></i></td></tr>
<tr><th id="183">183</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> depth].</span></i></td></tr>
<tr><th id="184">184</th><td><i class="doc"><span class="verb"></span><span class="verb">   *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="185">185</th><td><span class="verb"></span>  <dfn class="enum" id="ANEURALNETWORKS_AVERAGE_POOL_2D" title='ANEURALNETWORKS_AVERAGE_POOL_2D' data-ref="ANEURALNETWORKS_AVERAGE_POOL_2D">ANEURALNETWORKS_AVERAGE_POOL_2D</dfn> = <var>1</var>,</td></tr>
<tr><th id="186">186</th><td>  <i class="doc">/** Concatenates the input tensors along the given dimension.</i></td></tr>
<tr><th id="187">187</th><td><i class="doc">   *</i></td></tr>
<tr><th id="188">188</th><td><i class="doc">   * The input tensors must have identical type and the same dimensions except</i></td></tr>
<tr><th id="189">189</th><td><i class="doc">   * the dimension along the concatenation axis.</i></td></tr>
<tr><th id="190">190</th><td><i class="doc">   *</i></td></tr>
<tr><th id="191">191</th><td><i class="doc">   * Supported tensor types:</i></td></tr>
<tr><th id="192">192</th><td><i class="doc">   * * {<span class="command">@link</span><span class="verb"> ANEURALNETWORKS_TENSOR_FLOAT32}</span></i></td></tr>
<tr><th id="193">193</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * {@link ANEURALNETWORKS_TENSOR_QUANT8_ASYMM}</span></i></td></tr>
<tr><th id="194">194</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="195">195</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Supported tensor rank: up to 4</span></i></td></tr>
<tr><th id="196">196</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="197">197</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Inputs:</span></i></td></tr>
<tr><th id="198">198</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> 0 ~ n: The list on n input tensors, of shape [D0, D1, ..., Daxis(i), ...,</span></i></td></tr>
<tr><th id="199">199</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Dm] n+1: An INT32 value, specifying the concatenation axis. n+2: An INT32</span></i></td></tr>
<tr><th id="200">200</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> value, and has to be one of the {@link FuseCode} values. Specifies the</span></i></td></tr>
<tr><th id="201">201</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> activation to invoke on the result of each addition.</span></i></td></tr>
<tr><th id="202">202</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="203">203</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Outputs:</span></i></td></tr>
<tr><th id="204">204</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: The output, a tensor of the same type as the input tensors.</span></i></td></tr>
<tr><th id="205">205</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      The output shape is [D0, D1, ..., sum(Daxis(i)), ..., Dm].</span></i></td></tr>
<tr><th id="206">206</th><td><i class="doc"><span class="verb"></span><span class="verb">   *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="207">207</th><td><span class="verb"></span>  <dfn class="enum" id="ANEURALNETWORKS_CONCATENATION" title='ANEURALNETWORKS_CONCATENATION' data-ref="ANEURALNETWORKS_CONCATENATION">ANEURALNETWORKS_CONCATENATION</dfn> = <var>2</var>,</td></tr>
<tr><th id="208">208</th><td>  <i class="doc">/** Performs an 2-D convolution operation.</i></td></tr>
<tr><th id="209">209</th><td><i class="doc">   *</i></td></tr>
<tr><th id="210">210</th><td><i class="doc">   * The CONV_2D op sweeps a 2-D filter that can mix channels together over a</i></td></tr>
<tr><th id="211">211</th><td><i class="doc">   * batch of images, applying the filter to each window of each image of the</i></td></tr>
<tr><th id="212">212</th><td><i class="doc">   * appropriate size.</i></td></tr>
<tr><th id="213">213</th><td><i class="doc">   *</i></td></tr>
<tr><th id="214">214</th><td><i class="doc">   * The output dimensions are functions of the filter dimensions, stride, and</i></td></tr>
<tr><th id="215">215</th><td><i class="doc">   * padding.</i></td></tr>
<tr><th id="216">216</th><td><i class="doc">   *</i></td></tr>
<tr><th id="217">217</th><td><i class="doc">   * The values in the output tensor are computed as:</i></td></tr>
<tr><th id="218">218</th><td><i class="doc">   *</i></td></tr>
<tr><th id="219">219</th><td><i class="doc">   *     output[batch, row, col, channel] =</i></td></tr>
<tr><th id="220">220</th><td><i class="doc">   *         sum_{i, j} (</i></td></tr>
<tr><th id="221">221</th><td><i class="doc">   *             input[batch, row + i, col + j, k] *</i></td></tr>
<tr><th id="222">222</th><td><i class="doc">   *             filter[channel, row + i, col + j, k] +</i></td></tr>
<tr><th id="223">223</th><td><i class="doc">   *             bias[channel]</i></td></tr>
<tr><th id="224">224</th><td><i class="doc">   *         )</i></td></tr>
<tr><th id="225">225</th><td><i class="doc">   *</i></td></tr>
<tr><th id="226">226</th><td><i class="doc">   * Supported tensor types:</i></td></tr>
<tr><th id="227">227</th><td><i class="doc">   * * {<span class="command">@link</span><span class="verb"> ANEURALNETWORKS_TENSOR_FLOAT32}</span></i></td></tr>
<tr><th id="228">228</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * {@link ANEURALNETWORKS_TENSOR_QUANT8_ASYMM}</span></i></td></tr>
<tr><th id="229">229</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="230">230</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Supported tensor rank: 4, with "NHWC" data layout.</span></i></td></tr>
<tr><th id="231">231</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="232">232</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Inputs:</span></i></td></tr>
<tr><th id="233">233</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: A 4-D tensor, of shape [batches, height, width, depth_in], specifying</span></i></td></tr>
<tr><th id="234">234</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> the input.</span></i></td></tr>
<tr><th id="235">235</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 1: A 4-D tensor, of shape [depth_out, filter_height, filter_width,</span></i></td></tr>
<tr><th id="236">236</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> depth_in], specifying the filter.</span></i></td></tr>
<tr><th id="237">237</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 2: A 1-D tensor, of shape [depth_out], specifying the bias.</span></i></td></tr>
<tr><th id="238">238</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      For input tensor of {@link ANEURALNETWORKS_TENSOR_FLOAT32} type, the</span></i></td></tr>
<tr><th id="239">239</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> bias should also be of {@link ANEURALNETWORKS_TENSOR_FLOAT32}. For input</span></i></td></tr>
<tr><th id="240">240</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> tensor of {@link ANEURALNETWORKS_TENSOR_QUANT8_ASYMM} type, the bias should</span></i></td></tr>
<tr><th id="241">241</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> be of {@link ANEURALNETWORKS_TENSOR_INT32}.</span></i></td></tr>
<tr><th id="242">242</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 3: An INT32 value, specifying the padding on the left, in the ‘width’</span></i></td></tr>
<tr><th id="243">243</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> dimension.</span></i></td></tr>
<tr><th id="244">244</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 4: An INT32 value, specifying the padding on the right,in the ‘width’</span></i></td></tr>
<tr><th id="245">245</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> dimension.</span></i></td></tr>
<tr><th id="246">246</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 5: An INT32 value, specifying the padding on the top, in the ‘height’</span></i></td></tr>
<tr><th id="247">247</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> dimension.</span></i></td></tr>
<tr><th id="248">248</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 6: An INT32 value, specifying the padding on the bottom, in the ‘height’</span></i></td></tr>
<tr><th id="249">249</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> dimension.</span></i></td></tr>
<tr><th id="250">250</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 7: An INT32 value, specifying the output stride in the ‘width’ dimension.</span></i></td></tr>
<tr><th id="251">251</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 8: An INT32 value, specifying the output stride in the ‘height’</span></i></td></tr>
<tr><th id="252">252</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> dimension.</span></i></td></tr>
<tr><th id="253">253</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 9: An INT32 value, and has to be one of the {@link FuseCode} values.</span></i></td></tr>
<tr><th id="254">254</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      Specifies the activation to invoke on the result of each addition.</span></i></td></tr>
<tr><th id="255">255</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="256">256</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Outputs:</span></i></td></tr>
<tr><th id="257">257</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: The output 4-D tensor, of shape [batches, out_height, out_width,</span></i></td></tr>
<tr><th id="258">258</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> depth_out].</span></i></td></tr>
<tr><th id="259">259</th><td><i class="doc"><span class="verb"></span><span class="verb">   *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="260">260</th><td><span class="verb"></span>  <dfn class="enum" id="ANEURALNETWORKS_CONV_2D" title='ANEURALNETWORKS_CONV_2D' data-ref="ANEURALNETWORKS_CONV_2D">ANEURALNETWORKS_CONV_2D</dfn> = <var>3</var>,</td></tr>
<tr><th id="261">261</th><td>  <i class="doc">/** Performs a depthwise 2-D convolution operation.</i></td></tr>
<tr><th id="262">262</th><td><i class="doc">   *</i></td></tr>
<tr><th id="263">263</th><td><i class="doc">   * Given an input tensor of shape [batches, height, width, depth_in] and a</i></td></tr>
<tr><th id="264">264</th><td><i class="doc">   * filter tensor of shape [depth_out, filter_height, filter_width, depth_in]</i></td></tr>
<tr><th id="265">265</th><td><i class="doc">   * containing in_channels convolutional filters of depth 1, DEPTHWISE_CONV</i></td></tr>
<tr><th id="266">266</th><td><i class="doc">   * applies a different filter to each input channel (expanding from 1 channel</i></td></tr>
<tr><th id="267">267</th><td><i class="doc">   * to channel_multiplier channels for each), then concatenates the results</i></td></tr>
<tr><th id="268">268</th><td><i class="doc">   * together.</i></td></tr>
<tr><th id="269">269</th><td><i class="doc">   *</i></td></tr>
<tr><th id="270">270</th><td><i class="doc">   * The output has depth_out = depth_in * depth_multiplier channels.</i></td></tr>
<tr><th id="271">271</th><td><i class="doc">   * The output dimensions are functions of the filter dimensions, stride, and</i></td></tr>
<tr><th id="272">272</th><td><i class="doc">   * padding.</i></td></tr>
<tr><th id="273">273</th><td><i class="doc">   *</i></td></tr>
<tr><th id="274">274</th><td><i class="doc">   * The values in the output tensor are computed as:</i></td></tr>
<tr><th id="275">275</th><td><i class="doc">   *</i></td></tr>
<tr><th id="276">276</th><td><i class="doc">   *     output[b, i, j, k * channel_multiplier + q] =</i></td></tr>
<tr><th id="277">277</th><td><i class="doc">   *         sum_{di, dj} (</i></td></tr>
<tr><th id="278">278</th><td><i class="doc">   *             input[b, strides[1] * i + di, strides[2] * j + dj, k] *</i></td></tr>
<tr><th id="279">279</th><td><i class="doc">   *             filter[di, dj, k, q]</i></td></tr>
<tr><th id="280">280</th><td><i class="doc">   *         )</i></td></tr>
<tr><th id="281">281</th><td><i class="doc">   *</i></td></tr>
<tr><th id="282">282</th><td><i class="doc">   * Supported tensor types:</i></td></tr>
<tr><th id="283">283</th><td><i class="doc">   * * {<span class="command">@link</span><span class="verb"> ANEURALNETWORKS_TENSOR_FLOAT32}</span></i></td></tr>
<tr><th id="284">284</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * {@link ANEURALNETWORKS_TENSOR_QUANT8_ASYMM}</span></i></td></tr>
<tr><th id="285">285</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="286">286</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Supported tensor rank: 4, with "NHWC" data layout.</span></i></td></tr>
<tr><th id="287">287</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="288">288</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Inputs:</span></i></td></tr>
<tr><th id="289">289</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: A 4-D tensor, of shape [batches, height, width, depth_in], specifying</span></i></td></tr>
<tr><th id="290">290</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> the input.</span></i></td></tr>
<tr><th id="291">291</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 1: A 4-D tensor, of shape [depth_out, filter_height, filter_width,</span></i></td></tr>
<tr><th id="292">292</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> depth_in], specifying the filter.</span></i></td></tr>
<tr><th id="293">293</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 2: A 1-D tensor, of shape [depth_out], specifying the bias.</span></i></td></tr>
<tr><th id="294">294</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      For input tensor of {@link ANEURALNETWORKS_TENSOR_FLOAT32} type, the</span></i></td></tr>
<tr><th id="295">295</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> bias should also be of {@link ANEURALNETWORKS_TENSOR_FLOAT32}. For input</span></i></td></tr>
<tr><th id="296">296</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> tensor of {@link ANEURALNETWORKS_TENSOR_QUANT8_ASYMM} type, the bias should</span></i></td></tr>
<tr><th id="297">297</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> be of {@link ANEURALNETWORKS_TENSOR_INT32}.</span></i></td></tr>
<tr><th id="298">298</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 3: An INT32 value, specifying the padding on the left, in the ‘width’</span></i></td></tr>
<tr><th id="299">299</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> dimension.</span></i></td></tr>
<tr><th id="300">300</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 4: An INT32 value, specifying the padding on the right,in the ‘width’</span></i></td></tr>
<tr><th id="301">301</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> dimension.</span></i></td></tr>
<tr><th id="302">302</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 5: An INT32 value, specifying the padding on the top, in the ‘height’</span></i></td></tr>
<tr><th id="303">303</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> dimension.</span></i></td></tr>
<tr><th id="304">304</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 6: An INT32 value, specifying the padding on the bottom, in the ‘height’</span></i></td></tr>
<tr><th id="305">305</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> dimension.</span></i></td></tr>
<tr><th id="306">306</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 7: An INT32 value, specifying the output stride in the ‘width’ dimension.</span></i></td></tr>
<tr><th id="307">307</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 8: An INT32 value, specifying the output stride in the ‘height’</span></i></td></tr>
<tr><th id="308">308</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> dimension.</span></i></td></tr>
<tr><th id="309">309</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 9: An INT32 value, specifying the depthwise multiplier.</span></i></td></tr>
<tr><th id="310">310</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 10: An INT32 value, and has to be one of the {@link FuseCode} values.</span></i></td></tr>
<tr><th id="311">311</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">       Specifies the activation to invoke on the result of each addition.</span></i></td></tr>
<tr><th id="312">312</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="313">313</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Outputs:</span></i></td></tr>
<tr><th id="314">314</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: The output 4-D tensor, of shape [batches, out_height, out_width,</span></i></td></tr>
<tr><th id="315">315</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> depth_out].</span></i></td></tr>
<tr><th id="316">316</th><td><i class="doc"><span class="verb"></span><span class="verb">   *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="317">317</th><td><span class="verb"></span>  <dfn class="enum" id="ANEURALNETWORKS_DEPTHWISE_CONV_2D" title='ANEURALNETWORKS_DEPTHWISE_CONV_2D' data-ref="ANEURALNETWORKS_DEPTHWISE_CONV_2D">ANEURALNETWORKS_DEPTHWISE_CONV_2D</dfn> = <var>4</var>,</td></tr>
<tr><th id="318">318</th><td>  <i class="doc">/** Rearranges data from depth into blocks of spatial data.</i></td></tr>
<tr><th id="319">319</th><td><i class="doc">   *</i></td></tr>
<tr><th id="320">320</th><td><i class="doc">   * More specifically, this op outputs a copy of the input tensor where values</i></td></tr>
<tr><th id="321">321</th><td><i class="doc">   * from the depth dimension are moved in spatial blocks to the height and</i></td></tr>
<tr><th id="322">322</th><td><i class="doc">   * width dimensions. The value block_size indicates the input block size and</i></td></tr>
<tr><th id="323">323</th><td><i class="doc">   * how the data is moved.</i></td></tr>
<tr><th id="324">324</th><td><i class="doc">   *</i></td></tr>
<tr><th id="325">325</th><td><i class="doc">   * Chunks of data of size block_size * block_size from depth are rearranged</i></td></tr>
<tr><th id="326">326</th><td><i class="doc">   * into non-overlapping blocks of size block_size x block_size.</i></td></tr>
<tr><th id="327">327</th><td><i class="doc">   *</i></td></tr>
<tr><th id="328">328</th><td><i class="doc">   * The width of the output tensor is input_depth * block_size, whereas the</i></td></tr>
<tr><th id="329">329</th><td><i class="doc">   * height is input_height * block_size. The depth of the input tensor must be</i></td></tr>
<tr><th id="330">330</th><td><i class="doc">   * divisible by block_size * block_size</i></td></tr>
<tr><th id="331">331</th><td><i class="doc">   *</i></td></tr>
<tr><th id="332">332</th><td><i class="doc">   * Supported tensor types:</i></td></tr>
<tr><th id="333">333</th><td><i class="doc">   * * {<span class="command">@link</span><span class="verb"> ANEURALNETWORKS_TENSOR_FLOAT32}</span></i></td></tr>
<tr><th id="334">334</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * {@link ANEURALNETWORKS_TENSOR_QUANT8_ASYMM}</span></i></td></tr>
<tr><th id="335">335</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="336">336</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Supported tensor rank: 4, with "NHWC" data layout.</span></i></td></tr>
<tr><th id="337">337</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="338">338</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Inputs:</span></i></td></tr>
<tr><th id="339">339</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: A 4-D tensor, of shape [batches, height, width, depth_in], specifying</span></i></td></tr>
<tr><th id="340">340</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> the input.</span></i></td></tr>
<tr><th id="341">341</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 1: An INT32 value, specifying the block_size. block_size must be &gt;=1 and</span></i></td></tr>
<tr><th id="342">342</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      block_size * block_size must be a divisor of the input depth.</span></i></td></tr>
<tr><th id="343">343</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="344">344</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Outputs:</span></i></td></tr>
<tr><th id="345">345</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: The output 4-D tensor, of shape [batch, height*block_size,</span></i></td></tr>
<tr><th id="346">346</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> width*block_size, depth/(block_size*block_size)].</span></i></td></tr>
<tr><th id="347">347</th><td><i class="doc"><span class="verb"></span><span class="verb">   *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="348">348</th><td><span class="verb"></span>  <dfn class="enum" id="ANEURALNETWORKS_DEPTH_TO_SPACE" title='ANEURALNETWORKS_DEPTH_TO_SPACE' data-ref="ANEURALNETWORKS_DEPTH_TO_SPACE">ANEURALNETWORKS_DEPTH_TO_SPACE</dfn> = <var>5</var>,</td></tr>
<tr><th id="349">349</th><td>  <i class="doc">/** Dequantizes the input tensor.</i></td></tr>
<tr><th id="350">350</th><td><i class="doc">   *</i></td></tr>
<tr><th id="351">351</th><td><i class="doc">   * The formula is:</i></td></tr>
<tr><th id="352">352</th><td><i class="doc">   *</i></td></tr>
<tr><th id="353">353</th><td><i class="doc">   *     output = (input - zero_value) * scale.</i></td></tr>
<tr><th id="354">354</th><td><i class="doc">   *</i></td></tr>
<tr><th id="355">355</th><td><i class="doc">   * Supported tensor types:</i></td></tr>
<tr><th id="356">356</th><td><i class="doc">   * * {<span class="command">@link</span><span class="verb"> ANEURALNETWORKS_TENSOR_QUANT8_ASYMM}</span></i></td></tr>
<tr><th id="357">357</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="358">358</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Supported tensor rank: up to 4</span></i></td></tr>
<tr><th id="359">359</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="360">360</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Inputs:</span></i></td></tr>
<tr><th id="361">361</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: A tensor of type {@link ANEURALNETWORKS_TENSOR_QUANT8_ASYMM}.</span></i></td></tr>
<tr><th id="362">362</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="363">363</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Outputs:</span></i></td></tr>
<tr><th id="364">364</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: The output tensor of same shape as input0, but with type</span></i></td></tr>
<tr><th id="365">365</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      {@link ANEURALNETWORKS_TENSOR_FLOAT32}.</span></i></td></tr>
<tr><th id="366">366</th><td><i class="doc"><span class="verb"></span><span class="verb">   *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="367">367</th><td><span class="verb"></span>  <dfn class="enum" id="ANEURALNETWORKS_DEQUANTIZE" title='ANEURALNETWORKS_DEQUANTIZE' data-ref="ANEURALNETWORKS_DEQUANTIZE">ANEURALNETWORKS_DEQUANTIZE</dfn> = <var>6</var>,</td></tr>
<tr><th id="368">368</th><td></td></tr>
<tr><th id="369">369</th><td>  <i class="doc">/**</i></td></tr>
<tr><th id="370">370</th><td><i class="doc">   * Looks up items from a given tensor.</i></td></tr>
<tr><th id="371">371</th><td><i class="doc">   *</i></td></tr>
<tr><th id="372">372</th><td><i class="doc">   * Each item in the output is a raw copy of the corresponding item in</i></td></tr>
<tr><th id="373">373</th><td><i class="doc">   * the input “values”. If the given “lookup” indices are out of bounds,</i></td></tr>
<tr><th id="374">374</th><td><i class="doc">   * the op will fail and an error will be reported.</i></td></tr>
<tr><th id="375">375</th><td><i class="doc">   *</i></td></tr>
<tr><th id="376">376</th><td><i class="doc">   * Inputs:</i></td></tr>
<tr><th id="377">377</th><td><i class="doc">   * * 0: Values. An n-D tensor of any type X (where n &gt;= 2). E.g., if n is 2,</i></td></tr>
<tr><th id="378">378</th><td><i class="doc">   *      then the shape would be [lookup_dimension, values_dimension], where</i></td></tr>
<tr><th id="379">379</th><td><i class="doc">   *      “lookup_dimension” corresponds to the indexing dimension in the lookup</i></td></tr>
<tr><th id="380">380</th><td><i class="doc">   *      table, and “values_dimension” to the contents.</i></td></tr>
<tr><th id="381">381</th><td><i class="doc">   * * 1: Lookups. An 1-D tensor of type T, of shape [lookup_size], where</i></td></tr>
<tr><th id="382">382</th><td><i class="doc">   *      “lookup_size” is the number of elements to look for, and each entry</i></td></tr>
<tr><th id="383">383</th><td><i class="doc">   *      corresponds to the first dimension of the “values” tensor.</i></td></tr>
<tr><th id="384">384</th><td><i class="doc">   *</i></td></tr>
<tr><th id="385">385</th><td><i class="doc">   * Output:</i></td></tr>
<tr><th id="386">386</th><td><i class="doc">   * * 0: A n-D tensor of type X and the same rank and shape as the “values”</i></td></tr>
<tr><th id="387">387</th><td><i class="doc">   *      tensor, except for the first dimension which has size “lookup_size”.</i></td></tr>
<tr><th id="388">388</th><td><i class="doc">   */</i></td></tr>
<tr><th id="389">389</th><td>  <dfn class="enum" id="ANEURALNETWORKS_EMBEDDING_LOOKUP" title='ANEURALNETWORKS_EMBEDDING_LOOKUP' data-ref="ANEURALNETWORKS_EMBEDDING_LOOKUP">ANEURALNETWORKS_EMBEDDING_LOOKUP</dfn> = <var>7</var>,</td></tr>
<tr><th id="390">390</th><td></td></tr>
<tr><th id="391">391</th><td>  <i class="doc">/** Computes element-wise floor() on the input tensor.</i></td></tr>
<tr><th id="392">392</th><td><i class="doc">   *</i></td></tr>
<tr><th id="393">393</th><td><i class="doc">   * Supported tensor types:</i></td></tr>
<tr><th id="394">394</th><td><i class="doc">   * * {<span class="command">@link</span><span class="verb"> ANEURALNETWORKS_TENSOR_FLOAT32}</span></i></td></tr>
<tr><th id="395">395</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="396">396</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Supported tensor rank: up to 4</span></i></td></tr>
<tr><th id="397">397</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="398">398</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Inputs:</span></i></td></tr>
<tr><th id="399">399</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: A tensor.</span></i></td></tr>
<tr><th id="400">400</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="401">401</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Outputs:</span></i></td></tr>
<tr><th id="402">402</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: The output, a tensor of the same type and dimensions as input0.</span></i></td></tr>
<tr><th id="403">403</th><td><i class="doc"><span class="verb"></span><span class="verb">   *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="404">404</th><td><span class="verb"></span>  <dfn class="enum" id="ANEURALNETWORKS_FLOOR" title='ANEURALNETWORKS_FLOOR' data-ref="ANEURALNETWORKS_FLOOR">ANEURALNETWORKS_FLOOR</dfn> = <var>8</var>,</td></tr>
<tr><th id="405">405</th><td>  <i class="doc">/** Denotes a fully (densely) connected layer, which connects all elements in</i></td></tr>
<tr><th id="406">406</th><td><i class="doc">   * the input tensor with each element in the output tensor.</i></td></tr>
<tr><th id="407">407</th><td><i class="doc">   *</i></td></tr>
<tr><th id="408">408</th><td><i class="doc">   * This layer implements the operation:</i></td></tr>
<tr><th id="409">409</th><td><i class="doc">   *</i></td></tr>
<tr><th id="410">410</th><td><i class="doc">   *     outputs = activation(inputs * weights’ + bias)</i></td></tr>
<tr><th id="411">411</th><td><i class="doc">   *</i></td></tr>
<tr><th id="412">412</th><td><i class="doc">   * Supported tensor types:</i></td></tr>
<tr><th id="413">413</th><td><i class="doc">   * * {<span class="command">@link</span><span class="verb"> ANEURALNETWORKS_TENSOR_FLOAT32}</span></i></td></tr>
<tr><th id="414">414</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * {@link ANEURALNETWORKS_TENSOR_QUANT8_ASYMM}</span></i></td></tr>
<tr><th id="415">415</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="416">416</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Supported tensor rank: up to 4.</span></i></td></tr>
<tr><th id="417">417</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="418">418</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Inputs:</span></i></td></tr>
<tr><th id="419">419</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: A tensor, specifying the input. If rank is greater than 2, then it</span></i></td></tr>
<tr><th id="420">420</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> gets flattened to a 2-D Tensor. The 2-D Tensor is handled as if dimensions</span></i></td></tr>
<tr><th id="421">421</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> corresponded to shape [batch_size, input_size], where “batch_size”</span></i></td></tr>
<tr><th id="422">422</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> corresponds to the batching dimension, and “input_size” is the size of the</span></i></td></tr>
<tr><th id="423">423</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> input.</span></i></td></tr>
<tr><th id="424">424</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 1: A 2-D tensor, specifying the weights, of shape [num_units,</span></i></td></tr>
<tr><th id="425">425</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> input_size], where "num_units" corresponds to the number of output nodes.</span></i></td></tr>
<tr><th id="426">426</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 2: A 1-D tensor, of shape [num_units], specifying the bias.</span></i></td></tr>
<tr><th id="427">427</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      For input tensor of {@link ANEURALNETWORKS_TENSOR_FLOAT32} type, the</span></i></td></tr>
<tr><th id="428">428</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> bias should also be of {@link ANEURALNETWORKS_TENSOR_FLOAT32}. For input</span></i></td></tr>
<tr><th id="429">429</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> tensor of {@link ANEURALNETWORKS_TENSOR_QUANT8_ASYMM} type, the bias should</span></i></td></tr>
<tr><th id="430">430</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> be of {@link ANEURALNETWORKS_TENSOR_INT32}.</span></i></td></tr>
<tr><th id="431">431</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 3: An INT32 value, and has to be one of the {@link FuseCode} values.</span></i></td></tr>
<tr><th id="432">432</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      Specifies the activation to invoke on the result of each addition.</span></i></td></tr>
<tr><th id="433">433</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="434">434</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Outputs:</span></i></td></tr>
<tr><th id="435">435</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: The output tensor, of shape [batch_size, num_units].</span></i></td></tr>
<tr><th id="436">436</th><td><i class="doc"><span class="verb"></span><span class="verb">   *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="437">437</th><td><span class="verb"></span>  <dfn class="enum" id="ANEURALNETWORKS_FULLY_CONNECTED" title='ANEURALNETWORKS_FULLY_CONNECTED' data-ref="ANEURALNETWORKS_FULLY_CONNECTED">ANEURALNETWORKS_FULLY_CONNECTED</dfn> = <var>9</var>,</td></tr>
<tr><th id="438">438</th><td></td></tr>
<tr><th id="439">439</th><td>  <i class="doc">/**</i></td></tr>
<tr><th id="440">440</th><td><i class="doc">   * Looks up values of a hash table with given keys.</i></td></tr>
<tr><th id="441">441</th><td><i class="doc">   *</i></td></tr>
<tr><th id="442">442</th><td><i class="doc">   * Inputs:</i></td></tr>
<tr><th id="443">443</th><td><i class="doc">   * * 0: Lookups. A 1-D int32 tensor with shape [ k ].</i></td></tr>
<tr><th id="444">444</th><td><i class="doc">   * * 1: Keys. A 1-D int32 tensor with shape [ n ], *MUST* be sorted in</i></td></tr>
<tr><th id="445">445</th><td><i class="doc">   *      ascending order.</i></td></tr>
<tr><th id="446">446</th><td><i class="doc">   * * 2: Values. A tensor with shape [ n … ].</i></td></tr>
<tr><th id="447">447</th><td><i class="doc">   *</i></td></tr>
<tr><th id="448">448</th><td><i class="doc">   * Outputs:</i></td></tr>
<tr><th id="449">449</th><td><i class="doc">   * * 0: Output. A tensor with shape [ k …].</i></td></tr>
<tr><th id="450">450</th><td><i class="doc">   * * 1: Hits. A uint8 tensor with shape [ k ] indicates whether the lookup</i></td></tr>
<tr><th id="451">451</th><td><i class="doc">   *      hits or not.</i></td></tr>
<tr><th id="452">452</th><td><i class="doc">   */</i></td></tr>
<tr><th id="453">453</th><td>  <dfn class="enum" id="ANEURALNETWORKS_HASHTABLE_LOOKUP" title='ANEURALNETWORKS_HASHTABLE_LOOKUP' data-ref="ANEURALNETWORKS_HASHTABLE_LOOKUP">ANEURALNETWORKS_HASHTABLE_LOOKUP</dfn> = <var>10</var>,</td></tr>
<tr><th id="454">454</th><td></td></tr>
<tr><th id="455">455</th><td>  <i class="doc">/** Applies L2 normalization along the depth dimension.</i></td></tr>
<tr><th id="456">456</th><td><i class="doc">   *</i></td></tr>
<tr><th id="457">457</th><td><i class="doc">   * The values in the output tensor are computed as:</i></td></tr>
<tr><th id="458">458</th><td><i class="doc">   *</i></td></tr>
<tr><th id="459">459</th><td><i class="doc">   *     output[batch, row, col, channel] =</i></td></tr>
<tr><th id="460">460</th><td><i class="doc">   *         input[batch, row, col, channel] /</i></td></tr>
<tr><th id="461">461</th><td><i class="doc">   *         sqrt(sum_{c} pow(input[batch, row, col, c], 2))</i></td></tr>
<tr><th id="462">462</th><td><i class="doc">   *</i></td></tr>
<tr><th id="463">463</th><td><i class="doc">   * For x with more dimensions, independently normalizes each 1-D slice along</i></td></tr>
<tr><th id="464">464</th><td><i class="doc">   * dimension dim.</i></td></tr>
<tr><th id="465">465</th><td><i class="doc">   *</i></td></tr>
<tr><th id="466">466</th><td><i class="doc">   * Supported tensor types:</i></td></tr>
<tr><th id="467">467</th><td><i class="doc">   * * {<span class="command">@link</span><span class="verb"> ANEURALNETWORKS_TENSOR_FLOAT32}</span></i></td></tr>
<tr><th id="468">468</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="469">469</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Supported tensor rank: 4, with "NHWC" data layout.</span></i></td></tr>
<tr><th id="470">470</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="471">471</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Inputs:</span></i></td></tr>
<tr><th id="472">472</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: A 4-D tensor, of shape [batches, height, width, depth], specifying the</span></i></td></tr>
<tr><th id="473">473</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> input.</span></i></td></tr>
<tr><th id="474">474</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="475">475</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Outputs:</span></i></td></tr>
<tr><th id="476">476</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: The output 4-D tensor, of shape [batches, out_height, out_width,</span></i></td></tr>
<tr><th id="477">477</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> depth].</span></i></td></tr>
<tr><th id="478">478</th><td><i class="doc"><span class="verb"></span><span class="verb">   *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="479">479</th><td><span class="verb"></span>  <dfn class="enum" id="ANEURALNETWORKS_L2_NORMALIZATION" title='ANEURALNETWORKS_L2_NORMALIZATION' data-ref="ANEURALNETWORKS_L2_NORMALIZATION">ANEURALNETWORKS_L2_NORMALIZATION</dfn> = <var>11</var>,</td></tr>
<tr><th id="480">480</th><td></td></tr>
<tr><th id="481">481</th><td>  <i class="doc">/** Performs an 2-D L2 pooling operation.</i></td></tr>
<tr><th id="482">482</th><td><i class="doc">   *</i></td></tr>
<tr><th id="483">483</th><td><i class="doc">   * The output dimensions are functions of the filter dimensions, stride, and</i></td></tr>
<tr><th id="484">484</th><td><i class="doc">   * padding.</i></td></tr>
<tr><th id="485">485</th><td><i class="doc">   *</i></td></tr>
<tr><th id="486">486</th><td><i class="doc">   * The values in the output tensor are computed as:</i></td></tr>
<tr><th id="487">487</th><td><i class="doc">   *</i></td></tr>
<tr><th id="488">488</th><td><i class="doc">   *     output[batch, row, col, channel] =</i></td></tr>
<tr><th id="489">489</th><td><i class="doc">   *         sqrt(sum_{i, j} pow(input[batch, row + i, col + j, channel], 2) /</i></td></tr>
<tr><th id="490">490</th><td><i class="doc">   * sum(1))</i></td></tr>
<tr><th id="491">491</th><td><i class="doc">   *</i></td></tr>
<tr><th id="492">492</th><td><i class="doc">   * Supported tensor types:</i></td></tr>
<tr><th id="493">493</th><td><i class="doc">   * * {<span class="command">@link</span><span class="verb"> ANEURALNETWORKS_TENSOR_FLOAT32}</span></i></td></tr>
<tr><th id="494">494</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="495">495</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Supported tensor rank: 4, with "NHWC" data layout.</span></i></td></tr>
<tr><th id="496">496</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="497">497</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Inputs:</span></i></td></tr>
<tr><th id="498">498</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: A 4-D tensor, of shape [batches, height, width, depth], specifying the</span></i></td></tr>
<tr><th id="499">499</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> input.</span></i></td></tr>
<tr><th id="500">500</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 1: An INT32 value, specifying the padding on the left, in the ‘width’</span></i></td></tr>
<tr><th id="501">501</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> dimension.</span></i></td></tr>
<tr><th id="502">502</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 2: An INT32 value, specifying the padding on the right,in the ‘width’</span></i></td></tr>
<tr><th id="503">503</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> dimension.</span></i></td></tr>
<tr><th id="504">504</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 3: An INT32 value, specifying the padding on the top, in the ‘height’</span></i></td></tr>
<tr><th id="505">505</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> dimension.</span></i></td></tr>
<tr><th id="506">506</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 4: An INT32 value, specifying the padding on the bottom, in the ‘height’</span></i></td></tr>
<tr><th id="507">507</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> dimension.</span></i></td></tr>
<tr><th id="508">508</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 5: An INT32 value, specifying the output stride in the ‘width’ dimension.</span></i></td></tr>
<tr><th id="509">509</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 6: An INT32 value, specifying the output stride in the ‘height’</span></i></td></tr>
<tr><th id="510">510</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> dimension.</span></i></td></tr>
<tr><th id="511">511</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 7: An INT32 value, specifying the filter width.</span></i></td></tr>
<tr><th id="512">512</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 8: An INT32 value, specifying the filter height.</span></i></td></tr>
<tr><th id="513">513</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 9: An INT32 value, and has to be one of the {@link FuseCode} values.</span></i></td></tr>
<tr><th id="514">514</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      Specifies the activation to invoke on the result of each addition.</span></i></td></tr>
<tr><th id="515">515</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="516">516</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Outputs:</span></i></td></tr>
<tr><th id="517">517</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: The output 4-D tensor, of shape [batches, out_height, out_width,</span></i></td></tr>
<tr><th id="518">518</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> depth].</span></i></td></tr>
<tr><th id="519">519</th><td><i class="doc"><span class="verb"></span><span class="verb">   *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="520">520</th><td><span class="verb"></span>  <dfn class="enum" id="ANEURALNETWORKS_L2_POOL_2D" title='ANEURALNETWORKS_L2_POOL_2D' data-ref="ANEURALNETWORKS_L2_POOL_2D">ANEURALNETWORKS_L2_POOL_2D</dfn> = <var>12</var>,</td></tr>
<tr><th id="521">521</th><td>  <i class="doc">/** Applies Local Response Normalization along the depth dimension.</i></td></tr>
<tr><th id="522">522</th><td><i class="doc">   *</i></td></tr>
<tr><th id="523">523</th><td><i class="doc">   * The 4-D input tensor is treated as a 3-D array of 1-D vectors (along the</i></td></tr>
<tr><th id="524">524</th><td><i class="doc">   * last dimension), and each vector is normalized independently. Within a</i></td></tr>
<tr><th id="525">525</th><td><i class="doc">   * given vector, each component is divided by the weighted, squared sum of</i></td></tr>
<tr><th id="526">526</th><td><i class="doc">   * inputs within depth_radius.</i></td></tr>
<tr><th id="527">527</th><td><i class="doc">   *</i></td></tr>
<tr><th id="528">528</th><td><i class="doc">   * The output is calculated using this formula:</i></td></tr>
<tr><th id="529">529</th><td><i class="doc">   *</i></td></tr>
<tr><th id="530">530</th><td><i class="doc">   *     sqr_sum[a, b, c, d] =</i></td></tr>
<tr><th id="531">531</th><td><i class="doc">   *         sum(pow(input[a, b, c, d - depth_radius : d + depth_radius + 1], 2)</i></td></tr>
<tr><th id="532">532</th><td><i class="doc">   *     output = input / pow((bias + alpha * sqr_sum), beta)</i></td></tr>
<tr><th id="533">533</th><td><i class="doc">   *</i></td></tr>
<tr><th id="534">534</th><td><i class="doc">   * Supported tensor types:</i></td></tr>
<tr><th id="535">535</th><td><i class="doc">   * * {<span class="command">@link</span><span class="verb"> ANEURALNETWORKS_TENSOR_FLOAT32}</span></i></td></tr>
<tr><th id="536">536</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="537">537</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Supported tensor rank: 4, with "NHWC" data layout.</span></i></td></tr>
<tr><th id="538">538</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="539">539</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Inputs:</span></i></td></tr>
<tr><th id="540">540</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: A 4-D tensor, of shape [batches, height, width, depth], specifying the</span></i></td></tr>
<tr><th id="541">541</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> input.</span></i></td></tr>
<tr><th id="542">542</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 1: An INT32 value, specifying the radius of the normalization window.</span></i></td></tr>
<tr><th id="543">543</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 2: A FLOAT32 value, specifying the bias, must not be zero.</span></i></td></tr>
<tr><th id="544">544</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 3: A FLOAT32 value, specifying the scale factor, alpha.</span></i></td></tr>
<tr><th id="545">545</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 4: A FLOAT32 value, specifying the exponent, beta.</span></i></td></tr>
<tr><th id="546">546</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="547">547</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Outputs:</span></i></td></tr>
<tr><th id="548">548</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: The output tensor of same shape as input0.</span></i></td></tr>
<tr><th id="549">549</th><td><i class="doc"><span class="verb"></span><span class="verb">   *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="550">550</th><td><span class="verb"></span>  <dfn class="enum" id="ANEURALNETWORKS_LOCAL_RESPONSE_NORMALIZATION" title='ANEURALNETWORKS_LOCAL_RESPONSE_NORMALIZATION' data-ref="ANEURALNETWORKS_LOCAL_RESPONSE_NORMALIZATION">ANEURALNETWORKS_LOCAL_RESPONSE_NORMALIZATION</dfn> = <var>13</var>,</td></tr>
<tr><th id="551">551</th><td>  <i class="doc">/** Computes sigmoid activation on the input tensor element-wise.</i></td></tr>
<tr><th id="552">552</th><td><i class="doc">   *</i></td></tr>
<tr><th id="553">553</th><td><i class="doc">   * The output is calculated using this formula:</i></td></tr>
<tr><th id="554">554</th><td><i class="doc">   *</i></td></tr>
<tr><th id="555">555</th><td><i class="doc">   *     output = 1 / (1 + exp(-input))</i></td></tr>
<tr><th id="556">556</th><td><i class="doc">   *</i></td></tr>
<tr><th id="557">557</th><td><i class="doc">   * Supported tensor types:</i></td></tr>
<tr><th id="558">558</th><td><i class="doc">   * * {<span class="command">@link</span><span class="verb"> ANEURALNETWORKS_TENSOR_FLOAT32}</span></i></td></tr>
<tr><th id="559">559</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * {@link ANEURALNETWORKS_TENSOR_QUANT8_ASYMM}</span></i></td></tr>
<tr><th id="560">560</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="561">561</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Supported tensor rank: up to 4.</span></i></td></tr>
<tr><th id="562">562</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="563">563</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Inputs:</span></i></td></tr>
<tr><th id="564">564</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: A tensor, specifying the input.</span></i></td></tr>
<tr><th id="565">565</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="566">566</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Outputs:</span></i></td></tr>
<tr><th id="567">567</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: The output tensor of same shape as input0.</span></i></td></tr>
<tr><th id="568">568</th><td><i class="doc"><span class="verb"></span><span class="verb">   *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="569">569</th><td><span class="verb"></span>  <dfn class="enum" id="ANEURALNETWORKS_LOGISTIC" title='ANEURALNETWORKS_LOGISTIC' data-ref="ANEURALNETWORKS_LOGISTIC">ANEURALNETWORKS_LOGISTIC</dfn> = <var>14</var>,</td></tr>
<tr><th id="570">570</th><td></td></tr>
<tr><th id="571">571</th><td>  <i class="doc">/**</i></td></tr>
<tr><th id="572">572</th><td><i class="doc">   * Projects an input to a bit vector via locality sensitive hashing.</i></td></tr>
<tr><th id="573">573</th><td><i class="doc">   *</i></td></tr>
<tr><th id="574">574</th><td><i class="doc">   * Inputs:</i></td></tr>
<tr><th id="575">575</th><td><i class="doc">   * * 0: Hash functions. Dim.size == 2, DataType: Float.</i></td></tr>
<tr><th id="576">576</th><td><i class="doc">   *            Tensor[0].Dim[0]: Number of hash functions.</i></td></tr>
<tr><th id="577">577</th><td><i class="doc">   *            Tensor[0].Dim[1]: Number of seeds per hash functions.</i></td></tr>
<tr><th id="578">578</th><td><i class="doc">   *            Tensor[0].Dim[1] &lt;= 32 in sparse case.</i></td></tr>
<tr><th id="579">579</th><td><i class="doc">   *</i></td></tr>
<tr><th id="580">580</th><td><i class="doc">   * * 1: Input. Dim.size &gt;= 1, no restriction on DataType.</i></td></tr>
<tr><th id="581">581</th><td><i class="doc">   * * 2: Weight. Optional. Dim.size == 1, DataType: Float.</i></td></tr>
<tr><th id="582">582</th><td><i class="doc">   *     If not set, each input element is considered to have the same weight of</i></td></tr>
<tr><th id="583">583</th><td><i class="doc">   *     1.0.</i></td></tr>
<tr><th id="584">584</th><td><i class="doc">   *     Tensor[1].Dim[0] == Tensor[2].Dim[0]</i></td></tr>
<tr><th id="585">585</th><td><i class="doc">   * * 3: Type:</i></td></tr>
<tr><th id="586">586</th><td><i class="doc">   *        Sparse: Value LSHProjectionType_SPARSE(=1).</i></td></tr>
<tr><th id="587">587</th><td><i class="doc">   *          Computed bit vector is considered to be sparse.</i></td></tr>
<tr><th id="588">588</th><td><i class="doc">   *          Each output element is an int32 made up of multiple bits computed</i></td></tr>
<tr><th id="589">589</th><td><i class="doc">   * from hash functions.</i></td></tr>
<tr><th id="590">590</th><td><i class="doc">   *</i></td></tr>
<tr><th id="591">591</th><td><i class="doc">   *        Dense: Value LSHProjectionType_DENSE(=2).</i></td></tr>
<tr><th id="592">592</th><td><i class="doc">   *          Computed bit vector is considered to be dense. Each output element</i></td></tr>
<tr><th id="593">593</th><td><i class="doc">   *          represents a bit and can take the value of either 0 or 1.</i></td></tr>
<tr><th id="594">594</th><td><i class="doc">   *</i></td></tr>
<tr><th id="595">595</th><td><i class="doc">   * Outputs:</i></td></tr>
<tr><th id="596">596</th><td><i class="doc">   * * 0: If the projection type is sparse:</i></td></tr>
<tr><th id="597">597</th><td><i class="doc">   *        Output.Dim == { Tensor[0].Dim[0] }</i></td></tr>
<tr><th id="598">598</th><td><i class="doc">   *        A tensor of int32 that represents hash signatures.</i></td></tr>
<tr><th id="599">599</th><td><i class="doc">   *      If the projection type is Dense:</i></td></tr>
<tr><th id="600">600</th><td><i class="doc">   *        Output.Dim == { Tensor[0].Dim[0] * Tensor[0].Dim[1] }</i></td></tr>
<tr><th id="601">601</th><td><i class="doc">   *        A flattened tensor that represents projected bit vectors.</i></td></tr>
<tr><th id="602">602</th><td><i class="doc">   */</i></td></tr>
<tr><th id="603">603</th><td>  <dfn class="enum" id="ANEURALNETWORKS_LSH_PROJECTION" title='ANEURALNETWORKS_LSH_PROJECTION' data-ref="ANEURALNETWORKS_LSH_PROJECTION">ANEURALNETWORKS_LSH_PROJECTION</dfn> = <var>15</var>,</td></tr>
<tr><th id="604">604</th><td></td></tr>
<tr><th id="605">605</th><td>  <i class="doc">/**</i></td></tr>
<tr><th id="606">606</th><td><i class="doc">   * Long short-term memory unit (LSTM) recurrent network layer.</i></td></tr>
<tr><th id="607">607</th><td><i class="doc">   *</i></td></tr>
<tr><th id="608">608</th><td><i class="doc">   * The default non-peephole implementation is based on:</i></td></tr>
<tr><th id="609">609</th><td><i class="doc">   * <a href="http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf">http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf</a></i></td></tr>
<tr><th id="610">610</th><td><i class="doc">   * S. Hochreiter and J. Schmidhuber. "Long Short-Term Memory". Neural</i></td></tr>
<tr><th id="611">611</th><td><i class="doc">   * Computation, 9(8):1735-1780, 1997.</i></td></tr>
<tr><th id="612">612</th><td><i class="doc">   *</i></td></tr>
<tr><th id="613">613</th><td><i class="doc">   * The peephole implementation is based on:</i></td></tr>
<tr><th id="614">614</th><td><i class="doc">   * <a href="https://research.google.com/pubs/archive/43905.pdf">https://research.google.com/pubs/archive/43905.pdf</a></i></td></tr>
<tr><th id="615">615</th><td><i class="doc">   * Hasim Sak, Andrew Senior, and Francoise Beaufays. "Long short-term memory</i></td></tr>
<tr><th id="616">616</th><td><i class="doc">   * recurrent neural network architectures for large scale acoustic modeling."</i></td></tr>
<tr><th id="617">617</th><td><i class="doc">   * INTERSPEECH, 2014.</i></td></tr>
<tr><th id="618">618</th><td><i class="doc">   *</i></td></tr>
<tr><th id="619">619</th><td><i class="doc">   * The coupling of input and forget gate (CIFG) is based on:</i></td></tr>
<tr><th id="620">620</th><td><i class="doc">   * <a href="http://arxiv.org/pdf/1503.04069.pdf">http://arxiv.org/pdf/1503.04069.pdf</a></i></td></tr>
<tr><th id="621">621</th><td><i class="doc">   * Greff et al. "LSTM: A Search Space Odyssey"</i></td></tr>
<tr><th id="622">622</th><td><i class="doc">   *</i></td></tr>
<tr><th id="623">623</th><td><i class="doc">   * The class has the following independently optional inputs:</i></td></tr>
<tr><th id="624">624</th><td><i class="doc">   * * If input gate (if CIFG): “input_to_forget_weights”,</i></td></tr>
<tr><th id="625">625</th><td><i class="doc">   *   “recurrent_to_input_weights”, “cell_to_input_weights”, “input_gate_bias”.</i></td></tr>
<tr><th id="626">626</th><td><i class="doc">   * * If no peephole connections: “cell_to_input_weights”,</i></td></tr>
<tr><th id="627">627</th><td><i class="doc">   *   “cell_to_forget_weights”, “cell_to_output_weights”.</i></td></tr>
<tr><th id="628">628</th><td><i class="doc">   * * If no projection layer: “projection_weights” and “projection_bias”.</i></td></tr>
<tr><th id="629">629</th><td><i class="doc">   * * If no projection bias: “projection_bias”.</i></td></tr>
<tr><th id="630">630</th><td><i class="doc">   *</i></td></tr>
<tr><th id="631">631</th><td><i class="doc">   * Supported tensor types:</i></td></tr>
<tr><th id="632">632</th><td><i class="doc">   * * {<span class="command">@link</span><span class="verb"> ANEURALNETWORKS_TENSOR_FLOAT32}</span></i></td></tr>
<tr><th id="633">633</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="634">634</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Inputs:</span></i></td></tr>
<tr><th id="635">635</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: Input.</span></i></td></tr>
<tr><th id="636">636</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 2-D tensor of type T, of shape [batch_size, input_size], where</span></i></td></tr>
<tr><th id="637">637</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      “batch_size” corresponds to the batching dimension, and “input_size”</span></i></td></tr>
<tr><th id="638">638</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      is the size of the input.</span></i></td></tr>
<tr><th id="639">639</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 1: input_to_input_weights.</span></i></td></tr>
<tr><th id="640">640</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 2-D tensor of type T, of shape [num_units, input_size], where</span></i></td></tr>
<tr><th id="641">641</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      “num_units” corresponds to the number of cell units.</span></i></td></tr>
<tr><th id="642">642</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 2: input_to_forget_weights.</span></i></td></tr>
<tr><th id="643">643</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 2-D tensor of type T, of shape [num_units, input_size].</span></i></td></tr>
<tr><th id="644">644</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 3: input_to_cell_weights.</span></i></td></tr>
<tr><th id="645">645</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 2-D tensor of type T, of shape [num_units, input_size].</span></i></td></tr>
<tr><th id="646">646</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 4: input_to_output_weights.</span></i></td></tr>
<tr><th id="647">647</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 2-D tensor of type T, of shape [num_units, input_size].</span></i></td></tr>
<tr><th id="648">648</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 5: recurrent_to_input_weights.</span></i></td></tr>
<tr><th id="649">649</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 2-D tensor of type T, of shape [num_units, output_size], where</span></i></td></tr>
<tr><th id="650">650</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      “output_size” corresponds to either the number of cell units (i.e.,</span></i></td></tr>
<tr><th id="651">651</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      “num_units”), or the second dimension of the “projection_weights”, if</span></i></td></tr>
<tr><th id="652">652</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      defined.</span></i></td></tr>
<tr><th id="653">653</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 6: recurrent_to_forget_weights.</span></i></td></tr>
<tr><th id="654">654</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 2-D tensor of type T, of shape [num_units, output_size].</span></i></td></tr>
<tr><th id="655">655</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 7: recurrent_to_cell_weights.</span></i></td></tr>
<tr><th id="656">656</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 2-D tensor of type T, of shape [num_units, output_size].</span></i></td></tr>
<tr><th id="657">657</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 8: recurrent_to_output_weights.</span></i></td></tr>
<tr><th id="658">658</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 2-D tensor of type T, of shape [num_units, output_size].</span></i></td></tr>
<tr><th id="659">659</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 9: cell_to_input_weights.</span></i></td></tr>
<tr><th id="660">660</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 1-D tensor of type T, of shape [num_units].</span></i></td></tr>
<tr><th id="661">661</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 10:cell_to_forget_weights.</span></i></td></tr>
<tr><th id="662">662</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 1-D tensor of type T, of shape [num_units].</span></i></td></tr>
<tr><th id="663">663</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 11:cell_to_output_weights.</span></i></td></tr>
<tr><th id="664">664</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 1-D tensor of type T, of shape [num_units].</span></i></td></tr>
<tr><th id="665">665</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 12:input_gate_bias.</span></i></td></tr>
<tr><th id="666">666</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 1-D tensor of type T, of shape [num_units].</span></i></td></tr>
<tr><th id="667">667</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 13:forget_gate_bias.</span></i></td></tr>
<tr><th id="668">668</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 1-D tensor of type T, of shape [num_units].</span></i></td></tr>
<tr><th id="669">669</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 14:cell_bias.</span></i></td></tr>
<tr><th id="670">670</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 1-D tensor of type T, of shape [num_units].</span></i></td></tr>
<tr><th id="671">671</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 15:output_gate_bias.</span></i></td></tr>
<tr><th id="672">672</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 1-D tensor of type T, of shape [num_units].</span></i></td></tr>
<tr><th id="673">673</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 16:projection_weights.</span></i></td></tr>
<tr><th id="674">674</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 2-D tensor of type T, of shape [output_size, num_units].</span></i></td></tr>
<tr><th id="675">675</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 17:projection_bias.</span></i></td></tr>
<tr><th id="676">676</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 1-D tensor of type T, of shape [output_size].</span></i></td></tr>
<tr><th id="677">677</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="678">678</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Parameters:</span></i></td></tr>
<tr><th id="679">679</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 18:fused_activation_function.</span></i></td></tr>
<tr><th id="680">680</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      An (optional) ActivationFunctionType indicating the activation</span></i></td></tr>
<tr><th id="681">681</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      function.</span></i></td></tr>
<tr><th id="682">682</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      If “NONE” is specified then it results in a linear activation.</span></i></td></tr>
<tr><th id="683">683</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 19:cell_clip.</span></i></td></tr>
<tr><th id="684">684</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A clipping threshold for the cell state, such that values are bound</span></i></td></tr>
<tr><th id="685">685</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      within [-cell_clip, cell_clip]. If set to 0.0 then clipping is</span></i></td></tr>
<tr><th id="686">686</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      disabled.</span></i></td></tr>
<tr><th id="687">687</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 20:proj_clip.</span></i></td></tr>
<tr><th id="688">688</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A clipping threshold for the output from the projection layer, such</span></i></td></tr>
<tr><th id="689">689</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      that values are bound within [-proj_clip, proj_clip]. If set to 0.0</span></i></td></tr>
<tr><th id="690">690</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      then clipping is disabled.</span></i></td></tr>
<tr><th id="691">691</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="692">692</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Outputs:</span></i></td></tr>
<tr><th id="693">693</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: scratch_buffer.</span></i></td></tr>
<tr><th id="694">694</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 3-D tensor of type T, of shape [batch_size, num_cell, 4].</span></i></td></tr>
<tr><th id="695">695</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 1: output_state.</span></i></td></tr>
<tr><th id="696">696</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 2-D tensor of type T, of shape [batch_size, output_size].</span></i></td></tr>
<tr><th id="697">697</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 2: cell_state.</span></i></td></tr>
<tr><th id="698">698</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 2-D tensor of type T, of shape [batch_size, num_units].</span></i></td></tr>
<tr><th id="699">699</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 3: output.</span></i></td></tr>
<tr><th id="700">700</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 2-D tensor of type T, of shape [batch_size, output_size]. This is</span></i></td></tr>
<tr><th id="701">701</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      effectively the same as the current “output_state” value.</span></i></td></tr>
<tr><th id="702">702</th><td><i class="doc"><span class="verb"></span><span class="verb">   *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="703">703</th><td><span class="verb"></span>  <dfn class="enum" id="ANEURALNETWORKS_LSTM" title='ANEURALNETWORKS_LSTM' data-ref="ANEURALNETWORKS_LSTM">ANEURALNETWORKS_LSTM</dfn> = <var>16</var>,</td></tr>
<tr><th id="704">704</th><td></td></tr>
<tr><th id="705">705</th><td>  <i class="doc">/** Performs an 2-D max pooling operation.</i></td></tr>
<tr><th id="706">706</th><td><i class="doc">   *</i></td></tr>
<tr><th id="707">707</th><td><i class="doc">   * The output dimensions are functions of the filter dimensions, stride, and</i></td></tr>
<tr><th id="708">708</th><td><i class="doc">   * padding.</i></td></tr>
<tr><th id="709">709</th><td><i class="doc">   *</i></td></tr>
<tr><th id="710">710</th><td><i class="doc">   * The values in the output tensor are computed as:</i></td></tr>
<tr><th id="711">711</th><td><i class="doc">   *</i></td></tr>
<tr><th id="712">712</th><td><i class="doc">   *     output[batch, row, col, channel] =</i></td></tr>
<tr><th id="713">713</th><td><i class="doc">   *         max_{i, j} (input[batch, row + i, col + j, channel])</i></td></tr>
<tr><th id="714">714</th><td><i class="doc">   *</i></td></tr>
<tr><th id="715">715</th><td><i class="doc">   * Supported tensor types:</i></td></tr>
<tr><th id="716">716</th><td><i class="doc">   * * {<span class="command">@link</span><span class="verb"> ANEURALNETWORKS_TENSOR_FLOAT32}</span></i></td></tr>
<tr><th id="717">717</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * {@link ANEURALNETWORKS_TENSOR_QUANT8_ASYMM}</span></i></td></tr>
<tr><th id="718">718</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="719">719</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Supported tensor rank: 4, with "NHWC" data layout.</span></i></td></tr>
<tr><th id="720">720</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="721">721</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Inputs:</span></i></td></tr>
<tr><th id="722">722</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: A 4-D tensor, of shape [batches, height, width, depth], specifying the</span></i></td></tr>
<tr><th id="723">723</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> input.</span></i></td></tr>
<tr><th id="724">724</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 1: An INT32 value, specifying the padding on the left, in the ‘width’</span></i></td></tr>
<tr><th id="725">725</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> dimension.</span></i></td></tr>
<tr><th id="726">726</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 2: An INT32 value, specifying the padding on the right,in the ‘width’</span></i></td></tr>
<tr><th id="727">727</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> dimension.</span></i></td></tr>
<tr><th id="728">728</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 3: An INT32 value, specifying the padding on the top, in the ‘height’</span></i></td></tr>
<tr><th id="729">729</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> dimension.</span></i></td></tr>
<tr><th id="730">730</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 4: An INT32 value, specifying the padding on the bottom, in the ‘height’</span></i></td></tr>
<tr><th id="731">731</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> dimension.</span></i></td></tr>
<tr><th id="732">732</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 5: An INT32 value, specifying the output stride in the ‘width’ dimension.</span></i></td></tr>
<tr><th id="733">733</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 6: An INT32 value, specifying the output stride in the ‘height’</span></i></td></tr>
<tr><th id="734">734</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> dimension.</span></i></td></tr>
<tr><th id="735">735</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 7: An INT32 value, specifying the filter width.</span></i></td></tr>
<tr><th id="736">736</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 8: An INT32 value, specifying the filter height.</span></i></td></tr>
<tr><th id="737">737</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 9: An INT32 value, and has to be one of the {@link FuseCode} values.</span></i></td></tr>
<tr><th id="738">738</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      Specifies the activation to invoke on the result of each addition.</span></i></td></tr>
<tr><th id="739">739</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="740">740</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Outputs:</span></i></td></tr>
<tr><th id="741">741</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: The output 4-D tensor, of shape [batches, out_height, out_width,</span></i></td></tr>
<tr><th id="742">742</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> depth].</span></i></td></tr>
<tr><th id="743">743</th><td><i class="doc"><span class="verb"></span><span class="verb">   *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="744">744</th><td><span class="verb"></span>  <dfn class="enum" id="ANEURALNETWORKS_MAX_POOL_2D" title='ANEURALNETWORKS_MAX_POOL_2D' data-ref="ANEURALNETWORKS_MAX_POOL_2D">ANEURALNETWORKS_MAX_POOL_2D</dfn> = <var>17</var>,</td></tr>
<tr><th id="745">745</th><td></td></tr>
<tr><th id="746">746</th><td>  <i class="doc">/** Multiplies two tensors, element-wise.</i></td></tr>
<tr><th id="747">747</th><td><i class="doc">   *</i></td></tr>
<tr><th id="748">748</th><td><i class="doc">   * Takes two input tensors of identical type and compatible dimensions. The</i></td></tr>
<tr><th id="749">749</th><td><i class="doc">   * output is the product of both input tensors, optionally modified by an</i></td></tr>
<tr><th id="750">750</th><td><i class="doc">   * activation function.</i></td></tr>
<tr><th id="751">751</th><td><i class="doc">   *</i></td></tr>
<tr><th id="752">752</th><td><i class="doc">   * Two dimensions are compatible when:</i></td></tr>
<tr><th id="753">753</th><td><i class="doc">   *     1. they are equal, or</i></td></tr>
<tr><th id="754">754</th><td><i class="doc">   *     2. one of them is 1</i></td></tr>
<tr><th id="755">755</th><td><i class="doc">   *</i></td></tr>
<tr><th id="756">756</th><td><i class="doc">   * The size of the resulting output is the maximum size along each dimension</i></td></tr>
<tr><th id="757">757</th><td><i class="doc">   * of the input operands. It starts with the trailing dimensions, and works</i></td></tr>
<tr><th id="758">758</th><td><i class="doc">   * its way forward.</i></td></tr>
<tr><th id="759">759</th><td><i class="doc">   *</i></td></tr>
<tr><th id="760">760</th><td><i class="doc">   * Supported tensor types:</i></td></tr>
<tr><th id="761">761</th><td><i class="doc">   * * {<span class="command">@link</span><span class="verb"> ANEURALNETWORKS_TENSOR_FLOAT32}</span></i></td></tr>
<tr><th id="762">762</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="763">763</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Supported tensor rank: up to 4</span></i></td></tr>
<tr><th id="764">764</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="765">765</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Inputs:</span></i></td></tr>
<tr><th id="766">766</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: A tensor.</span></i></td></tr>
<tr><th id="767">767</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 1: A tensor of the same type, and compatible dimensions as input0.</span></i></td></tr>
<tr><th id="768">768</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 2: An INT32 value, and has to be one of the {@link FuseCode} values.</span></i></td></tr>
<tr><th id="769">769</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      Specifies the activation to invoke on the result of each addition.</span></i></td></tr>
<tr><th id="770">770</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="771">771</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Outputs:</span></i></td></tr>
<tr><th id="772">772</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: The product, a tensor of the same type as input0.</span></i></td></tr>
<tr><th id="773">773</th><td><i class="doc"><span class="verb"></span><span class="verb">   *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="774">774</th><td><span class="verb"></span>  <dfn class="enum" id="ANEURALNETWORKS_MUL" title='ANEURALNETWORKS_MUL' data-ref="ANEURALNETWORKS_MUL">ANEURALNETWORKS_MUL</dfn> = <var>18</var>,</td></tr>
<tr><th id="775">775</th><td>  <i class="doc">/** Computes rectified linear activation on the input tensor element-wise.</i></td></tr>
<tr><th id="776">776</th><td><i class="doc">   *</i></td></tr>
<tr><th id="777">777</th><td><i class="doc">   * The output is calculated using this formula:</i></td></tr>
<tr><th id="778">778</th><td><i class="doc">   *</i></td></tr>
<tr><th id="779">779</th><td><i class="doc">   *     output = max(0, input)</i></td></tr>
<tr><th id="780">780</th><td><i class="doc">   *</i></td></tr>
<tr><th id="781">781</th><td><i class="doc">   * Supported tensor types:</i></td></tr>
<tr><th id="782">782</th><td><i class="doc">   * * {<span class="command">@link</span><span class="verb"> ANEURALNETWORKS_TENSOR_FLOAT32}</span></i></td></tr>
<tr><th id="783">783</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * {@link ANEURALNETWORKS_TENSOR_QUANT8_ASYMM}</span></i></td></tr>
<tr><th id="784">784</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="785">785</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Supported tensor rank: up to 4.</span></i></td></tr>
<tr><th id="786">786</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="787">787</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Inputs:</span></i></td></tr>
<tr><th id="788">788</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: A tensor, specifying the input.</span></i></td></tr>
<tr><th id="789">789</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="790">790</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Outputs:</span></i></td></tr>
<tr><th id="791">791</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: The output tensor of same shape as input0.</span></i></td></tr>
<tr><th id="792">792</th><td><i class="doc"><span class="verb"></span><span class="verb">   *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="793">793</th><td><span class="verb"></span>  <dfn class="enum" id="ANEURALNETWORKS_RELU" title='ANEURALNETWORKS_RELU' data-ref="ANEURALNETWORKS_RELU">ANEURALNETWORKS_RELU</dfn> = <var>19</var>,</td></tr>
<tr><th id="794">794</th><td>  <i class="doc">/** Computes rectified linear 1 activation on the input tensor element-wise.</i></td></tr>
<tr><th id="795">795</th><td><i class="doc">   *</i></td></tr>
<tr><th id="796">796</th><td><i class="doc">   * The output is calculated using this formula:</i></td></tr>
<tr><th id="797">797</th><td><i class="doc">   *</i></td></tr>
<tr><th id="798">798</th><td><i class="doc">   *     output = min(1.f, max(-1.f, input))</i></td></tr>
<tr><th id="799">799</th><td><i class="doc">   *</i></td></tr>
<tr><th id="800">800</th><td><i class="doc">   * Supported tensor types:</i></td></tr>
<tr><th id="801">801</th><td><i class="doc">   * * {<span class="command">@link</span><span class="verb"> ANEURALNETWORKS_TENSOR_FLOAT32}</span></i></td></tr>
<tr><th id="802">802</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * {@link ANEURALNETWORKS_TENSOR_QUANT8_ASYMM}</span></i></td></tr>
<tr><th id="803">803</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="804">804</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Supported tensor rank: up to 4.</span></i></td></tr>
<tr><th id="805">805</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="806">806</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Inputs:</span></i></td></tr>
<tr><th id="807">807</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: A tensor, specifying the input.</span></i></td></tr>
<tr><th id="808">808</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="809">809</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Outputs:</span></i></td></tr>
<tr><th id="810">810</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: The output tensor of same shape as input0.</span></i></td></tr>
<tr><th id="811">811</th><td><i class="doc"><span class="verb"></span><span class="verb">   *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="812">812</th><td><span class="verb"></span>  <dfn class="enum" id="ANEURALNETWORKS_RELU1" title='ANEURALNETWORKS_RELU1' data-ref="ANEURALNETWORKS_RELU1">ANEURALNETWORKS_RELU1</dfn> = <var>20</var>,</td></tr>
<tr><th id="813">813</th><td>  <i class="doc">/** Computes rectified linear 6 activation on the input tensor element-wise.</i></td></tr>
<tr><th id="814">814</th><td><i class="doc">   *</i></td></tr>
<tr><th id="815">815</th><td><i class="doc">   * The output is calculated using this formula:</i></td></tr>
<tr><th id="816">816</th><td><i class="doc">   *</i></td></tr>
<tr><th id="817">817</th><td><i class="doc">   *     output = min(6, max(0, input))</i></td></tr>
<tr><th id="818">818</th><td><i class="doc">   *</i></td></tr>
<tr><th id="819">819</th><td><i class="doc">   * Supported tensor types:</i></td></tr>
<tr><th id="820">820</th><td><i class="doc">   * * {<span class="command">@link</span><span class="verb"> ANEURALNETWORKS_TENSOR_FLOAT32}</span></i></td></tr>
<tr><th id="821">821</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * {@link ANEURALNETWORKS_TENSOR_QUANT8_ASYMM}</span></i></td></tr>
<tr><th id="822">822</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="823">823</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Supported tensor rank: up to 4.</span></i></td></tr>
<tr><th id="824">824</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="825">825</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Inputs:</span></i></td></tr>
<tr><th id="826">826</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: A tensor, specifying the input.</span></i></td></tr>
<tr><th id="827">827</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="828">828</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Outputs:</span></i></td></tr>
<tr><th id="829">829</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: The output tensor of same shape as input0.</span></i></td></tr>
<tr><th id="830">830</th><td><i class="doc"><span class="verb"></span><span class="verb">   *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="831">831</th><td><span class="verb"></span>  <dfn class="enum" id="ANEURALNETWORKS_RELU6" title='ANEURALNETWORKS_RELU6' data-ref="ANEURALNETWORKS_RELU6">ANEURALNETWORKS_RELU6</dfn> = <var>21</var>,</td></tr>
<tr><th id="832">832</th><td>  <i class="doc">/** Reshapes a tensor.</i></td></tr>
<tr><th id="833">833</th><td><i class="doc">   *</i></td></tr>
<tr><th id="834">834</th><td><i class="doc">   * Given tensor, this operation returns a tensor that has the same values as</i></td></tr>
<tr><th id="835">835</th><td><i class="doc">   * tensor, but with a newly specified shape.</i></td></tr>
<tr><th id="836">836</th><td><i class="doc">   *</i></td></tr>
<tr><th id="837">837</th><td><i class="doc">   * Supported tensor types:</i></td></tr>
<tr><th id="838">838</th><td><i class="doc">   * * {<span class="command">@link</span><span class="verb"> ANEURALNETWORKS_TENSOR_FLOAT32}</span></i></td></tr>
<tr><th id="839">839</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * {@link ANEURALNETWORKS_TENSOR_QUANT8_ASYMM}</span></i></td></tr>
<tr><th id="840">840</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="841">841</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Supported tensor rank: up to 4.</span></i></td></tr>
<tr><th id="842">842</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="843">843</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Inputs:</span></i></td></tr>
<tr><th id="844">844</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: A tensor, specifying the tensor to be reshaped.</span></i></td></tr>
<tr><th id="845">845</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 1: A 1-D tensor of type {@link ANEURALNETWORKS_TENSOR_INT32}, defining</span></i></td></tr>
<tr><th id="846">846</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> the shape of the output tensor. The number of elements implied by shape</span></i></td></tr>
<tr><th id="847">847</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> must be the same as the number of elements in the input tensor.</span></i></td></tr>
<tr><th id="848">848</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="849">849</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Outputs:</span></i></td></tr>
<tr><th id="850">850</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: The output tensor, of shape specified by the input shape.</span></i></td></tr>
<tr><th id="851">851</th><td><i class="doc"><span class="verb"></span><span class="verb">   *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="852">852</th><td><span class="verb"></span>  <dfn class="enum" id="ANEURALNETWORKS_RESHAPE" title='ANEURALNETWORKS_RESHAPE' data-ref="ANEURALNETWORKS_RESHAPE">ANEURALNETWORKS_RESHAPE</dfn> = <var>22</var>,</td></tr>
<tr><th id="853">853</th><td>  <i class="doc">/** Resizes images to given size using the bilinear interpretation.</i></td></tr>
<tr><th id="854">854</th><td><i class="doc">   *</i></td></tr>
<tr><th id="855">855</th><td><i class="doc">   * Resized images will be distorted if their original aspect ratio is not the</i></td></tr>
<tr><th id="856">856</th><td><i class="doc">   * same as input.</i></td></tr>
<tr><th id="857">857</th><td><i class="doc">   *</i></td></tr>
<tr><th id="858">858</th><td><i class="doc">   * Supported tensor types:</i></td></tr>
<tr><th id="859">859</th><td><i class="doc">   * * {<span class="command">@link</span><span class="verb"> ANEURALNETWORKS_TENSOR_FLOAT32}</span></i></td></tr>
<tr><th id="860">860</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="861">861</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Supported tensor rank: 4, with "NHWC" data layout.</span></i></td></tr>
<tr><th id="862">862</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="863">863</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Inputs:</span></i></td></tr>
<tr><th id="864">864</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: A 4-D tensor, of shape [batches, height, width, depth], specifying the</span></i></td></tr>
<tr><th id="865">865</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> input.</span></i></td></tr>
<tr><th id="866">866</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 1: An INT32 value, specifying the output width of the output tensor.</span></i></td></tr>
<tr><th id="867">867</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 2: An INT32 value, specifying the output height of the output tensor.</span></i></td></tr>
<tr><th id="868">868</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="869">869</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Outputs:</span></i></td></tr>
<tr><th id="870">870</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: The output 4-D tensor, of shape [batches, new_height, new_width,</span></i></td></tr>
<tr><th id="871">871</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> depth].</span></i></td></tr>
<tr><th id="872">872</th><td><i class="doc"><span class="verb"></span><span class="verb">   *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="873">873</th><td><span class="verb"></span>  <dfn class="enum" id="ANEURALNETWORKS_RESIZE_BILINEAR" title='ANEURALNETWORKS_RESIZE_BILINEAR' data-ref="ANEURALNETWORKS_RESIZE_BILINEAR">ANEURALNETWORKS_RESIZE_BILINEAR</dfn> = <var>23</var>,</td></tr>
<tr><th id="874">874</th><td></td></tr>
<tr><th id="875">875</th><td>  <i class="doc">/**</i></td></tr>
<tr><th id="876">876</th><td><i class="doc">   * A basic recurrent neural network layer.</i></td></tr>
<tr><th id="877">877</th><td><i class="doc">   *</i></td></tr>
<tr><th id="878">878</th><td><i class="doc">   * This layer implements the operation:</i></td></tr>
<tr><th id="879">879</th><td><i class="doc">   * outputs = state = activation(inputs * input_weights + state *</i></td></tr>
<tr><th id="880">880</th><td><i class="doc">   * recurrent_weights + bias)</i></td></tr>
<tr><th id="881">881</th><td><i class="doc">   *</i></td></tr>
<tr><th id="882">882</th><td><i class="doc">   * Where:</i></td></tr>
<tr><th id="883">883</th><td><i class="doc">   * * “input_weights” is a weight matrix that multiplies the inputs;</i></td></tr>
<tr><th id="884">884</th><td><i class="doc">   * * “recurrent_weights” is a weight matrix that multiplies the current</i></td></tr>
<tr><th id="885">885</th><td><i class="doc">   *    “state” which itself is the output from the previous time step</i></td></tr>
<tr><th id="886">886</th><td><i class="doc">   *    computation;</i></td></tr>
<tr><th id="887">887</th><td><i class="doc">   * * “bias” is a bias vector (added to each output vector in the batch);</i></td></tr>
<tr><th id="888">888</th><td><i class="doc">   * * “activation” is the function passed as the “fused_activation_function”</i></td></tr>
<tr><th id="889">889</th><td><i class="doc">   *   argument (if not “NONE”).</i></td></tr>
<tr><th id="890">890</th><td><i class="doc">   *</i></td></tr>
<tr><th id="891">891</th><td><i class="doc">   * Supported tensor types:</i></td></tr>
<tr><th id="892">892</th><td><i class="doc">   * * {<span class="command">@link</span><span class="verb"> ANEURALNETWORKS_TENSOR_FLOAT32}</span></i></td></tr>
<tr><th id="893">893</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="894">894</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Inputs:</span></i></td></tr>
<tr><th id="895">895</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: input.</span></i></td></tr>
<tr><th id="896">896</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 2-D tensor of type T, of shape [batch_size, input_size], where</span></i></td></tr>
<tr><th id="897">897</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      “batch_size” corresponds to the batching dimension, and “input_size”</span></i></td></tr>
<tr><th id="898">898</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> is the size of the input.</span></i></td></tr>
<tr><th id="899">899</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 1: weights.</span></i></td></tr>
<tr><th id="900">900</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 2-D tensor of type T, of shape [num_units, input_size], where</span></i></td></tr>
<tr><th id="901">901</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      “num_units” corresponds to the number of units.</span></i></td></tr>
<tr><th id="902">902</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 2: recurrent_weights.</span></i></td></tr>
<tr><th id="903">903</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 2-D tensor of type T, of shape [num_units, num_units], with columns</span></i></td></tr>
<tr><th id="904">904</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      corresponding to the weights from each unit.</span></i></td></tr>
<tr><th id="905">905</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 3: bias.</span></i></td></tr>
<tr><th id="906">906</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 1-D tensor of type T, of shape [num_units].</span></i></td></tr>
<tr><th id="907">907</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="908">908</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">    For FLOAT32 input tensor, bias must also be FLOAT32.</span></i></td></tr>
<tr><th id="909">909</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">    For UINT8 input tensor, bias must be INT32.</span></i></td></tr>
<tr><th id="910">910</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="911">911</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Parameters</span></i></td></tr>
<tr><th id="912">912</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 4: fused_activation_function.</span></i></td></tr>
<tr><th id="913">913</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      An (optional) ActivationFunctionType indicating the activation</span></i></td></tr>
<tr><th id="914">914</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      function. If “NONE” is specified then it results in a linear</span></i></td></tr>
<tr><th id="915">915</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      activation.</span></i></td></tr>
<tr><th id="916">916</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="917">917</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 5: Hidden state.</span></i></td></tr>
<tr><th id="918">918</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 2-D tensor of type T, of shape [batch_size, num_units].</span></i></td></tr>
<tr><th id="919">919</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="920">920</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Outputs:</span></i></td></tr>
<tr><th id="921">921</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: output.</span></i></td></tr>
<tr><th id="922">922</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 2-D tensor of type T, of shape [batch_size, num_units]. This is</span></i></td></tr>
<tr><th id="923">923</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      effectively the same as the current state value.</span></i></td></tr>
<tr><th id="924">924</th><td><i class="doc"><span class="verb"></span><span class="verb">   *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="925">925</th><td><span class="verb"></span>  <dfn class="enum" id="ANEURALNETWORKS_RNN" title='ANEURALNETWORKS_RNN' data-ref="ANEURALNETWORKS_RNN">ANEURALNETWORKS_RNN</dfn> = <var>24</var>,</td></tr>
<tr><th id="926">926</th><td></td></tr>
<tr><th id="927">927</th><td>  <i class="doc">/** Computes the softmax activation on the input tensor element-wise, per</i></td></tr>
<tr><th id="928">928</th><td><i class="doc">   * batch, by normalizing the input vector so the maximum coefficient is zero.</i></td></tr>
<tr><th id="929">929</th><td><i class="doc">   *</i></td></tr>
<tr><th id="930">930</th><td><i class="doc">   * The output is calculated using this formula:</i></td></tr>
<tr><th id="931">931</th><td><i class="doc">   *</i></td></tr>
<tr><th id="932">932</th><td><i class="doc">   *     output[batch, i] =</i></td></tr>
<tr><th id="933">933</th><td><i class="doc">   *         exp((input[batch, i] - max(input[batch, :])) * beta) /</i></td></tr>
<tr><th id="934">934</th><td><i class="doc">   *         sum_{k}{exp((input[batch, k] - max(input[batch, :])) * beta)}</i></td></tr>
<tr><th id="935">935</th><td><i class="doc">   *</i></td></tr>
<tr><th id="936">936</th><td><i class="doc">   * Supported tensor types:</i></td></tr>
<tr><th id="937">937</th><td><i class="doc">   * * {<span class="command">@link</span><span class="verb"> ANEURALNETWORKS_TENSOR_FLOAT32}</span></i></td></tr>
<tr><th id="938">938</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * {@link ANEURALNETWORKS_TENSOR_QUANT8_ASYMM}</span></i></td></tr>
<tr><th id="939">939</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="940">940</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Supported tensor rank: 2 or 4.</span></i></td></tr>
<tr><th id="941">941</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="942">942</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Inputs:</span></i></td></tr>
<tr><th id="943">943</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: A 2-D or 4-D tensor, specifying the tensor to be reshaped.</span></i></td></tr>
<tr><th id="944">944</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 1: A FLOAT32 value, specifying the scaling factor for the exponent, beta.</span></i></td></tr>
<tr><th id="945">945</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="946">946</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Outputs:</span></i></td></tr>
<tr><th id="947">947</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: The output tensor of same shape as input0.</span></i></td></tr>
<tr><th id="948">948</th><td><i class="doc"><span class="verb"></span><span class="verb">   *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="949">949</th><td><span class="verb"></span>  <dfn class="enum" id="ANEURALNETWORKS_SOFTMAX" title='ANEURALNETWORKS_SOFTMAX' data-ref="ANEURALNETWORKS_SOFTMAX">ANEURALNETWORKS_SOFTMAX</dfn> = <var>25</var>,</td></tr>
<tr><th id="950">950</th><td></td></tr>
<tr><th id="951">951</th><td>  <i class="doc">/** Rearranges blocks of spatial data, into depth.</i></td></tr>
<tr><th id="952">952</th><td><i class="doc">   *</i></td></tr>
<tr><th id="953">953</th><td><i class="doc">   * More specifically, this op outputs a copy of the input tensor where values</i></td></tr>
<tr><th id="954">954</th><td><i class="doc">   * from the height and width dimensions are moved to the depth dimension. The</i></td></tr>
<tr><th id="955">955</th><td><i class="doc">   * value block_size indicates the input block size and how the data is moved.</i></td></tr>
<tr><th id="956">956</th><td><i class="doc">   *</i></td></tr>
<tr><th id="957">957</th><td><i class="doc">   * Chunks of data of size block_size * block_size from depth are rearranged</i></td></tr>
<tr><th id="958">958</th><td><i class="doc">   * into non-overlapping blocks of size block_size x block_size.</i></td></tr>
<tr><th id="959">959</th><td><i class="doc">   *</i></td></tr>
<tr><th id="960">960</th><td><i class="doc">   * The depth of the output tensor is input_depth * block_size * block_size.</i></td></tr>
<tr><th id="961">961</th><td><i class="doc">   * The input tensor's height and width must be divisible by block_size.</i></td></tr>
<tr><th id="962">962</th><td><i class="doc">   *</i></td></tr>
<tr><th id="963">963</th><td><i class="doc">   * Supported tensor types:</i></td></tr>
<tr><th id="964">964</th><td><i class="doc">   * * {<span class="command">@link</span><span class="verb"> ANEURALNETWORKS_TENSOR_FLOAT32}</span></i></td></tr>
<tr><th id="965">965</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * {@link ANEURALNETWORKS_TENSOR_QUANT8_ASYMM}</span></i></td></tr>
<tr><th id="966">966</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="967">967</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Supported tensor rank: 4, with "NHWC" data layout.</span></i></td></tr>
<tr><th id="968">968</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="969">969</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Inputs:</span></i></td></tr>
<tr><th id="970">970</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: A 4-D tensor, of shape [batches, height, width, depth_in], specifying</span></i></td></tr>
<tr><th id="971">971</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> the input.</span></i></td></tr>
<tr><th id="972">972</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 1: An INT32 value, specifying the block_size. block_size must be &gt;=1 and</span></i></td></tr>
<tr><th id="973">973</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      block_size must be a divisor of both the input height and width.</span></i></td></tr>
<tr><th id="974">974</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="975">975</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Outputs:</span></i></td></tr>
<tr><th id="976">976</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: The output 4-D tensor, of shape [batch, height/block_size,</span></i></td></tr>
<tr><th id="977">977</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> width/block_size, depth*block_size*block_size].</span></i></td></tr>
<tr><th id="978">978</th><td><i class="doc"><span class="verb"></span><span class="verb">   *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="979">979</th><td><span class="verb"></span>  <dfn class="enum" id="ANEURALNETWORKS_SPACE_TO_DEPTH" title='ANEURALNETWORKS_SPACE_TO_DEPTH' data-ref="ANEURALNETWORKS_SPACE_TO_DEPTH">ANEURALNETWORKS_SPACE_TO_DEPTH</dfn> = <var>26</var>,</td></tr>
<tr><th id="980">980</th><td></td></tr>
<tr><th id="981">981</th><td>  <i class="doc">/**</i></td></tr>
<tr><th id="982">982</th><td><i class="doc">   * SVDF op is a kind of stateful layer derived from the notion that a</i></td></tr>
<tr><th id="983">983</th><td><i class="doc">   * densely connected layer that's processing a sequence of input frames can</i></td></tr>
<tr><th id="984">984</th><td><i class="doc">   * be approximated by using a singular value decomposition of each of its</i></td></tr>
<tr><th id="985">985</th><td><i class="doc">   * nodes. The implementation is based on:</i></td></tr>
<tr><th id="986">986</th><td><i class="doc">   *</i></td></tr>
<tr><th id="987">987</th><td><i class="doc">   * <a href="https://research.google.com/pubs/archive/43813.pdf">https://research.google.com/pubs/archive/43813.pdf</a></i></td></tr>
<tr><th id="988">988</th><td><i class="doc">   *</i></td></tr>
<tr><th id="989">989</th><td><i class="doc">   * P. Nakkiran, R. Alvarez, R. Prabhavalkar, C. Parada.</i></td></tr>
<tr><th id="990">990</th><td><i class="doc">   * “Compressing Deep Neural Networks using a Rank-Constrained Topology”.</i></td></tr>
<tr><th id="991">991</th><td><i class="doc">   * INTERSPEECH, 2015.</i></td></tr>
<tr><th id="992">992</th><td><i class="doc">   *</i></td></tr>
<tr><th id="993">993</th><td><i class="doc">   * It processes the incoming input using a 2-stage filtering mechanism:</i></td></tr>
<tr><th id="994">994</th><td><i class="doc">   * * stage 1 performs filtering on the "features" dimension, whose outputs get</i></td></tr>
<tr><th id="995">995</th><td><i class="doc">   *   pushed into a memory of fixed-size memory_size.</i></td></tr>
<tr><th id="996">996</th><td><i class="doc">   * * stage 2 performs filtering on the "time" dimension of the memory_size</i></td></tr>
<tr><th id="997">997</th><td><i class="doc">   *   memoized outputs of stage 1.</i></td></tr>
<tr><th id="998">998</th><td><i class="doc">   *</i></td></tr>
<tr><th id="999">999</th><td><i class="doc">   * Specifically, for rank 1, this layer implements the operation:</i></td></tr>
<tr><th id="1000">1000</th><td><i class="doc">   *</i></td></tr>
<tr><th id="1001">1001</th><td><i class="doc">   *    memory = push(conv1d(inputs, weights_feature, feature_dim, "VALID"));</i></td></tr>
<tr><th id="1002">1002</th><td><i class="doc">   *    outputs = activation(memory * weights_time + bias);</i></td></tr>
<tr><th id="1003">1003</th><td><i class="doc">   *</i></td></tr>
<tr><th id="1004">1004</th><td><i class="doc">   * Where:</i></td></tr>
<tr><th id="1005">1005</th><td><i class="doc">   * * “weights_feature” is a weights matrix that processes the inputs (by</i></td></tr>
<tr><th id="1006">1006</th><td><i class="doc">   *   convolving the input with every “feature filter”), and whose outputs get</i></td></tr>
<tr><th id="1007">1007</th><td><i class="doc">   *   pushed, stacked in order, into the fixed-size “memory” (the oldest entry</i></td></tr>
<tr><th id="1008">1008</th><td><i class="doc">   *   gets dropped);</i></td></tr>
<tr><th id="1009">1009</th><td><i class="doc">   * * “weights_time” is a weights matrix that processes the “memory” (by a</i></td></tr>
<tr><th id="1010">1010</th><td><i class="doc">   *   batched matrix multiplication on the num_units);</i></td></tr>
<tr><th id="1011">1011</th><td><i class="doc">   * * “bias” is an optional bias vector (added to each output vector in the</i></td></tr>
<tr><th id="1012">1012</th><td><i class="doc">   *   batch); and</i></td></tr>
<tr><th id="1013">1013</th><td><i class="doc">   * * “activation” is the function passed as the “fused_activation_function”</i></td></tr>
<tr><th id="1014">1014</th><td><i class="doc">   *   argument (if not “NONE”).</i></td></tr>
<tr><th id="1015">1015</th><td><i class="doc">   *</i></td></tr>
<tr><th id="1016">1016</th><td><i class="doc">   * Each rank adds a dimension to the weights matrices by means of stacking</i></td></tr>
<tr><th id="1017">1017</th><td><i class="doc">   * the filters.</i></td></tr>
<tr><th id="1018">1018</th><td><i class="doc">   *</i></td></tr>
<tr><th id="1019">1019</th><td><i class="doc">   * Supported tensor types:</i></td></tr>
<tr><th id="1020">1020</th><td><i class="doc">   * * {<span class="command">@link</span><span class="verb"> ANEURALNETWORKS_TENSOR_FLOAT32}</span></i></td></tr>
<tr><th id="1021">1021</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="1022">1022</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Inputs:</span></i></td></tr>
<tr><th id="1023">1023</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: input.</span></i></td></tr>
<tr><th id="1024">1024</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 2-D tensor of type T, of shape [batch_size, input_size], where</span></i></td></tr>
<tr><th id="1025">1025</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      “batch_size” corresponds to the batching dimension, and “input_size”</span></i></td></tr>
<tr><th id="1026">1026</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> is the size of the input.</span></i></td></tr>
<tr><th id="1027">1027</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 1: weights_feature.</span></i></td></tr>
<tr><th id="1028">1028</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 2-D tensor of type T, of shape [num_units, input_size], where</span></i></td></tr>
<tr><th id="1029">1029</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      “num_units” corresponds to the number of units.</span></i></td></tr>
<tr><th id="1030">1030</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 2: weights_time.</span></i></td></tr>
<tr><th id="1031">1031</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 2-D tensor of type T, of shape [num_units, memory_size], where</span></i></td></tr>
<tr><th id="1032">1032</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      “memory_size” corresponds to the fixed-size of the memory.</span></i></td></tr>
<tr><th id="1033">1033</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 3: bias.</span></i></td></tr>
<tr><th id="1034">1034</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A optional 1-D tensor of type T, of shape [num_units].</span></i></td></tr>
<tr><th id="1035">1035</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="1036">1036</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">    For FLOAT32 input tensor, bias must also be FLOAT32.</span></i></td></tr>
<tr><th id="1037">1037</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">    For UINT8 input tensor, bias must be INT32.</span></i></td></tr>
<tr><th id="1038">1038</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="1039">1039</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Parameters:</span></i></td></tr>
<tr><th id="1040">1040</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 4: rank.</span></i></td></tr>
<tr><th id="1041">1041</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      The rank of the SVD approximation.</span></i></td></tr>
<tr><th id="1042">1042</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 5: fused_activation_function.</span></i></td></tr>
<tr><th id="1043">1043</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      An (optional) ActivationFunctionType indicating the activation</span></i></td></tr>
<tr><th id="1044">1044</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> function. If “NONE” is specified then it results in a linear activation.</span></i></td></tr>
<tr><th id="1045">1045</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="1046">1046</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Outputs:</span></i></td></tr>
<tr><th id="1047">1047</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: state.</span></i></td></tr>
<tr><th id="1048">1048</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 2-D tensor of type T, of shape [batch_size, (memory_size - 1) *</span></i></td></tr>
<tr><th id="1049">1049</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> num_units * rank].</span></i></td></tr>
<tr><th id="1050">1050</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 1: output.</span></i></td></tr>
<tr><th id="1051">1051</th><td><i class="doc"><span class="verb"></span>   *<span class="verb">      A 2-D tensor of type T, of shape [batch_size, num_units].</span></i></td></tr>
<tr><th id="1052">1052</th><td><i class="doc"><span class="verb"></span><span class="verb">   *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="1053">1053</th><td><span class="verb"></span>  <dfn class="enum" id="ANEURALNETWORKS_SVDF" title='ANEURALNETWORKS_SVDF' data-ref="ANEURALNETWORKS_SVDF">ANEURALNETWORKS_SVDF</dfn> = <var>27</var>,</td></tr>
<tr><th id="1054">1054</th><td></td></tr>
<tr><th id="1055">1055</th><td>  <i class="doc">/** Computes hyperbolic tangent of input tensor element-wise.</i></td></tr>
<tr><th id="1056">1056</th><td><i class="doc">   *</i></td></tr>
<tr><th id="1057">1057</th><td><i class="doc">   * The output is calculated using this formula:</i></td></tr>
<tr><th id="1058">1058</th><td><i class="doc">   *</i></td></tr>
<tr><th id="1059">1059</th><td><i class="doc">   *     output = tanh(input)</i></td></tr>
<tr><th id="1060">1060</th><td><i class="doc">   *</i></td></tr>
<tr><th id="1061">1061</th><td><i class="doc">   * Supported tensor types:</i></td></tr>
<tr><th id="1062">1062</th><td><i class="doc">   * * {<span class="command">@link</span><span class="verb"> ANEURALNETWORKS_TENSOR_FLOAT32}</span></i></td></tr>
<tr><th id="1063">1063</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="1064">1064</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Supported tensor rank: up to 4.</span></i></td></tr>
<tr><th id="1065">1065</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="1066">1066</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Inputs:</span></i></td></tr>
<tr><th id="1067">1067</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: A tensor, specifying the input.</span></i></td></tr>
<tr><th id="1068">1068</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"></span></i></td></tr>
<tr><th id="1069">1069</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> Outputs:</span></i></td></tr>
<tr><th id="1070">1070</th><td><i class="doc"><span class="verb"></span>   *<span class="verb"> * 0: The output tensor of same shape as input0.</span></i></td></tr>
<tr><th id="1071">1071</th><td><i class="doc"><span class="verb"></span><span class="verb">   *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="1072">1072</th><td><span class="verb"></span>  <dfn class="enum" id="ANEURALNETWORKS_TANH" title='ANEURALNETWORKS_TANH' data-ref="ANEURALNETWORKS_TANH">ANEURALNETWORKS_TANH</dfn> = <var>28</var>,</td></tr>
<tr><th id="1073">1073</th><td>};</td></tr>
<tr><th id="1074">1074</th><td></td></tr>
<tr><th id="1075">1075</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1076">1076</th><td><i class="doc"> * Fused activation function types.</i></td></tr>
<tr><th id="1077">1077</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1078">1078</th><td><i class="doc"> */</i></td></tr>
<tr><th id="1079">1079</th><td><b>enum</b> {</td></tr>
<tr><th id="1080">1080</th><td>  <i class="doc">/** NO fused activation function. */</i></td></tr>
<tr><th id="1081">1081</th><td>  <dfn class="enum" id="ANEURALNETWORKS_FUSED_NONE" title='ANEURALNETWORKS_FUSED_NONE' data-ref="ANEURALNETWORKS_FUSED_NONE">ANEURALNETWORKS_FUSED_NONE</dfn> = <var>0</var>,</td></tr>
<tr><th id="1082">1082</th><td>  <i class="doc">/** Fused ReLU activation function. */</i></td></tr>
<tr><th id="1083">1083</th><td>  <dfn class="enum" id="ANEURALNETWORKS_FUSED_RELU" title='ANEURALNETWORKS_FUSED_RELU' data-ref="ANEURALNETWORKS_FUSED_RELU">ANEURALNETWORKS_FUSED_RELU</dfn> = <var>1</var>,</td></tr>
<tr><th id="1084">1084</th><td>  <i class="doc">/** Fused ReLU1 activation function. */</i></td></tr>
<tr><th id="1085">1085</th><td>  <dfn class="enum" id="ANEURALNETWORKS_FUSED_RELU1" title='ANEURALNETWORKS_FUSED_RELU1' data-ref="ANEURALNETWORKS_FUSED_RELU1">ANEURALNETWORKS_FUSED_RELU1</dfn> = <var>2</var>,</td></tr>
<tr><th id="1086">1086</th><td>  <i class="doc">/** Fused ReLU6 activation function. */</i></td></tr>
<tr><th id="1087">1087</th><td>  <dfn class="enum" id="ANEURALNETWORKS_FUSED_RELU6" title='ANEURALNETWORKS_FUSED_RELU6' data-ref="ANEURALNETWORKS_FUSED_RELU6">ANEURALNETWORKS_FUSED_RELU6</dfn> = <var>3</var>,</td></tr>
<tr><th id="1088">1088</th><td>};</td></tr>
<tr><th id="1089">1089</th><td></td></tr>
<tr><th id="1090">1090</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1091">1091</th><td><i class="doc"> * Execution preferences.</i></td></tr>
<tr><th id="1092">1092</th><td><i class="doc"> */</i></td></tr>
<tr><th id="1093">1093</th><td><b>enum</b> {</td></tr>
<tr><th id="1094">1094</th><td>  <i class="doc">/**</i></td></tr>
<tr><th id="1095">1095</th><td><i class="doc">   * Prefer executing in a way that minimizes battery drain.</i></td></tr>
<tr><th id="1096">1096</th><td><i class="doc">   * This is desirable for compilations that will be executed often.</i></td></tr>
<tr><th id="1097">1097</th><td><i class="doc">   */</i></td></tr>
<tr><th id="1098">1098</th><td>  <dfn class="enum" id="ANEURALNETWORKS_PREFER_LOW_POWER" title='ANEURALNETWORKS_PREFER_LOW_POWER' data-ref="ANEURALNETWORKS_PREFER_LOW_POWER">ANEURALNETWORKS_PREFER_LOW_POWER</dfn> = <var>0</var>,</td></tr>
<tr><th id="1099">1099</th><td>  <i class="doc">/**</i></td></tr>
<tr><th id="1100">1100</th><td><i class="doc">   * Prefer returning a single answer as fast as possible, even if this causes</i></td></tr>
<tr><th id="1101">1101</th><td><i class="doc">   * more power consumption.</i></td></tr>
<tr><th id="1102">1102</th><td><i class="doc">   */</i></td></tr>
<tr><th id="1103">1103</th><td>  <dfn class="enum" id="ANEURALNETWORKS_PREFER_FAST_SINGLE_ANSWER" title='ANEURALNETWORKS_PREFER_FAST_SINGLE_ANSWER' data-ref="ANEURALNETWORKS_PREFER_FAST_SINGLE_ANSWER">ANEURALNETWORKS_PREFER_FAST_SINGLE_ANSWER</dfn> = <var>1</var>,</td></tr>
<tr><th id="1104">1104</th><td>  <i class="doc">/**</i></td></tr>
<tr><th id="1105">1105</th><td><i class="doc">   * Prefer maximizing the throughput of successive frames, for example when</i></td></tr>
<tr><th id="1106">1106</th><td><i class="doc">   * processing successive frames coming from the camera.</i></td></tr>
<tr><th id="1107">1107</th><td><i class="doc">   */</i></td></tr>
<tr><th id="1108">1108</th><td>  <dfn class="enum" id="ANEURALNETWORKS_PREFER_SUSTAINED_SPEED" title='ANEURALNETWORKS_PREFER_SUSTAINED_SPEED' data-ref="ANEURALNETWORKS_PREFER_SUSTAINED_SPEED">ANEURALNETWORKS_PREFER_SUSTAINED_SPEED</dfn> = <var>2</var>,</td></tr>
<tr><th id="1109">1109</th><td>};</td></tr>
<tr><th id="1110">1110</th><td></td></tr>
<tr><th id="1111">1111</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1112">1112</th><td><i class="doc"> * Result codes.</i></td></tr>
<tr><th id="1113">1113</th><td><i class="doc"> */</i></td></tr>
<tr><th id="1114">1114</th><td><b>enum</b> {</td></tr>
<tr><th id="1115">1115</th><td>  <dfn class="enum" id="ANEURALNETWORKS_NO_ERROR" title='ANEURALNETWORKS_NO_ERROR' data-ref="ANEURALNETWORKS_NO_ERROR">ANEURALNETWORKS_NO_ERROR</dfn> = <var>0</var>,</td></tr>
<tr><th id="1116">1116</th><td>  <dfn class="enum" id="ANEURALNETWORKS_OUT_OF_MEMORY" title='ANEURALNETWORKS_OUT_OF_MEMORY' data-ref="ANEURALNETWORKS_OUT_OF_MEMORY">ANEURALNETWORKS_OUT_OF_MEMORY</dfn> = <var>1</var>,</td></tr>
<tr><th id="1117">1117</th><td>  <dfn class="enum" id="ANEURALNETWORKS_INCOMPLETE" title='ANEURALNETWORKS_INCOMPLETE' data-ref="ANEURALNETWORKS_INCOMPLETE">ANEURALNETWORKS_INCOMPLETE</dfn> = <var>2</var>,</td></tr>
<tr><th id="1118">1118</th><td>  <dfn class="enum" id="ANEURALNETWORKS_UNEXPECTED_NULL" title='ANEURALNETWORKS_UNEXPECTED_NULL' data-ref="ANEURALNETWORKS_UNEXPECTED_NULL">ANEURALNETWORKS_UNEXPECTED_NULL</dfn> = <var>3</var>,</td></tr>
<tr><th id="1119">1119</th><td>  <dfn class="enum" id="ANEURALNETWORKS_BAD_DATA" title='ANEURALNETWORKS_BAD_DATA' data-ref="ANEURALNETWORKS_BAD_DATA">ANEURALNETWORKS_BAD_DATA</dfn> = <var>4</var>,</td></tr>
<tr><th id="1120">1120</th><td>  <dfn class="enum" id="ANEURALNETWORKS_OP_FAILED" title='ANEURALNETWORKS_OP_FAILED' data-ref="ANEURALNETWORKS_OP_FAILED">ANEURALNETWORKS_OP_FAILED</dfn> = <var>5</var>,</td></tr>
<tr><th id="1121">1121</th><td>  <dfn class="enum" id="ANEURALNETWORKS_UNMAPPABLE" title='ANEURALNETWORKS_UNMAPPABLE' data-ref="ANEURALNETWORKS_UNMAPPABLE">ANEURALNETWORKS_UNMAPPABLE</dfn> = <var>5</var>,</td></tr>
<tr><th id="1122">1122</th><td>  <dfn class="enum" id="ANEURALNETWORKS_BAD_STATE" title='ANEURALNETWORKS_BAD_STATE' data-ref="ANEURALNETWORKS_BAD_STATE">ANEURALNETWORKS_BAD_STATE</dfn> = <var>6</var>,</td></tr>
<tr><th id="1123">1123</th><td>};</td></tr>
<tr><th id="1124">1124</th><td></td></tr>
<tr><th id="1125">1125</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1126">1126</th><td><i class="doc"> * ANeuralNetworksMemory is an opaque type that represents memory.</i></td></tr>
<tr><th id="1127">1127</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1128">1128</th><td><i class="doc"> * This type is used to represent shared memory, memory mapped files,</i></td></tr>
<tr><th id="1129">1129</th><td><i class="doc"> * and similar memories.</i></td></tr>
<tr><th id="1130">1130</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1131">1131</th><td><i class="doc"> * By using shared memory, a program can efficiently communicate to the</i></td></tr>
<tr><th id="1132">1132</th><td><i class="doc"> * runtime and drivers the tensors that define a model. See</i></td></tr>
<tr><th id="1133">1133</th><td><i class="doc"> * {<span class="command">@link</span><span class="verb"> ANeuralNetworksModel_setOperandValueFromMemory}. An application</span></i></td></tr>
<tr><th id="1134">1134</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> should typically create one shared memory object that contains every tensor</span></i></td></tr>
<tr><th id="1135">1135</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> needed to define a model. {@link ANeuralNetworksMemory_createFromFd} can be</span></i></td></tr>
<tr><th id="1136">1136</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> used to create shared memory from a file handle. {@link</span></i></td></tr>
<tr><th id="1137">1137</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> ANeuralNetworksMemory_createShared} can be used to directly created shared</span></i></td></tr>
<tr><th id="1138">1138</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> memory.</span></i></td></tr>
<tr><th id="1139">1139</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1140">1140</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> Memory objects can also be used to specify the input and output arguments of</span></i></td></tr>
<tr><th id="1141">1141</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> an execution. See {@link ANeuralNetworksExecution_setInputFromMemory}</span></i></td></tr>
<tr><th id="1142">1142</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> and {@link ANeuralNetworksExecution_setOutputFromMemory}.</span></i></td></tr>
<tr><th id="1143">1143</th><td><i class="doc"><span class="verb"></span><span class="verb"> *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="1144">1144</th><td><span class="verb"></span><b>typedef</b> <b>struct</b> <dfn class="type" id="ANeuralNetworksMemory" title='ANeuralNetworksMemory' data-ref="ANeuralNetworksMemory"><a class="type" href="#ANeuralNetworksMemory" title='ANeuralNetworksMemory' data-ref="ANeuralNetworksMemory">ANeuralNetworksMemory</a></dfn> <dfn class="typedef" id="ANeuralNetworksMemory" title='ANeuralNetworksMemory' data-type='struct ANeuralNetworksMemory' data-ref="ANeuralNetworksMemory">ANeuralNetworksMemory</dfn>;</td></tr>
<tr><th id="1145">1145</th><td></td></tr>
<tr><th id="1146">1146</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1147">1147</th><td><i class="doc"> * ANeuralNetworksModel is an opaque type that contains a description of the</i></td></tr>
<tr><th id="1148">1148</th><td><i class="doc"> * mathematical operations that constitute the model.</i></td></tr>
<tr><th id="1149">1149</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1150">1150</th><td><i class="doc"> * <span class="tag">&lt;p&gt;</span>The model will be built by calling<span class="tag">&lt;ul&gt;</span></i></td></tr>
<tr><th id="1151">1151</th><td><i class="doc"> * <span class="tag">&lt;li&gt;</span>{<span class="command">@link</span><span class="verb"> ANeuralNetworksModel_create},&lt;/li&gt;</span></i></td></tr>
<tr><th id="1152">1152</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> &lt;li&gt;{@link ANeuralNetworksModel_addOperation},&lt;/li&gt;</span></i></td></tr>
<tr><th id="1153">1153</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> &lt;li&gt;{@link ANeuralNetworksModel_addOperand},&lt;/li&gt;</span></i></td></tr>
<tr><th id="1154">1154</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> &lt;/ul&gt;</span></i></td></tr>
<tr><th id="1155">1155</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1156">1156</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> A model is completed by calling {@link ANeuralNetworksModel_finish}.</span></i></td></tr>
<tr><th id="1157">1157</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> A model is destroyed by calling {@link ANeuralNetworksModel_free}.</span></i></td></tr>
<tr><th id="1158">1158</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1159">1159</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> &lt;p&gt;It is the application's responsibility to make sure that only one thread</span></i></td></tr>
<tr><th id="1160">1160</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> modifies a model at a given time. It is however safe for more than one</span></i></td></tr>
<tr><th id="1161">1161</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> thread to use the model once {@link ANeuralNetworksModel_finish} has</span></i></td></tr>
<tr><th id="1162">1162</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> returned.&lt;/p&gt;</span></i></td></tr>
<tr><th id="1163">1163</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1164">1164</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> &lt;p&gt;It is also the application's responsibility to ensure that there are no</span></i></td></tr>
<tr><th id="1165">1165</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> other uses of the model after calling {@link ANeuralNetworksModel_free}. This</span></i></td></tr>
<tr><th id="1166">1166</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> includes any compilation or execution object created using the model.&lt;/p&gt;</span></i></td></tr>
<tr><th id="1167">1167</th><td><i class="doc"><span class="verb"></span><span class="verb"> *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="1168">1168</th><td><span class="verb"></span><b>typedef</b> <b>struct</b> <dfn class="type" id="ANeuralNetworksModel" title='ANeuralNetworksModel' data-ref="ANeuralNetworksModel"><a class="type" href="#ANeuralNetworksModel" title='ANeuralNetworksModel' data-ref="ANeuralNetworksModel">ANeuralNetworksModel</a></dfn> <dfn class="typedef" id="ANeuralNetworksModel" title='ANeuralNetworksModel' data-type='struct ANeuralNetworksModel' data-ref="ANeuralNetworksModel">ANeuralNetworksModel</dfn>;</td></tr>
<tr><th id="1169">1169</th><td></td></tr>
<tr><th id="1170">1170</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1171">1171</th><td><i class="doc"> * ANeuralNetworksCompilation is an opaque type that can be used to compile</i></td></tr>
<tr><th id="1172">1172</th><td><i class="doc"> * a machine learning model.</i></td></tr>
<tr><th id="1173">1173</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1174">1174</th><td><i class="doc"> * <span class="tag">&lt;p&gt;</span>To use:<span class="tag">&lt;ul&gt;</span></i></td></tr>
<tr><th id="1175">1175</th><td><i class="doc"> *    <span class="tag">&lt;li&gt;</span>Create a new compilation instance by calling the</i></td></tr>
<tr><th id="1176">1176</th><td><i class="doc"> *        {<span class="command">@link</span><span class="verb"> ANeuralNetworksCompilation_create} function.&lt;/li&gt;</span></i></td></tr>
<tr><th id="1177">1177</th><td><i class="doc"><span class="verb"></span> *<span class="verb">    &lt;li&gt;Perform the compilation with {@link</span></i></td></tr>
<tr><th id="1178">1178</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> ANeuralNetworksCompilation_start}.&lt;/li&gt; &lt;li&gt;Wait for the compilation to</span></i></td></tr>
<tr><th id="1179">1179</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> complete with {@link ANeuralNetworksCompilation_wait}.&lt;/li&gt; &lt;li&gt;Use the</span></i></td></tr>
<tr><th id="1180">1180</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> compilation as many times as needed with {@link</span></i></td></tr>
<tr><th id="1181">1181</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> ANeuralNetworksExecution_create}.&lt;/li&gt; &lt;li&gt;Destroy the compilation with</span></i></td></tr>
<tr><th id="1182">1182</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> {@link ANeuralNetworksCompilation_free} once all executions using the</span></i></td></tr>
<tr><th id="1183">1183</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> compilation have completed.&lt;/li&gt;&lt;/ul&gt;&lt;/p&gt;</span></i></td></tr>
<tr><th id="1184">1184</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1185">1185</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> &lt;p&gt;A compilation cannot be modified once {@link</span></i></td></tr>
<tr><th id="1186">1186</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> ANeuralNetworksCompilation_start} has been called on it.&lt;/p&gt;</span></i></td></tr>
<tr><th id="1187">1187</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1188">1188</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> &lt;p&gt;It is the application's responsibility to make sure that only one thread</span></i></td></tr>
<tr><th id="1189">1189</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> modifies a compilation at a given time. It is however safe for more than one</span></i></td></tr>
<tr><th id="1190">1190</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> thread to use {@link ANeuralNetworksCompilation_wait} at the same time.</span></i></td></tr>
<tr><th id="1191">1191</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> It is also safe for multiple threads to use a compilation object once</span></i></td></tr>
<tr><th id="1192">1192</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> {@link ANeuralNetworksCompilation_wait} has completed.&lt;/p&gt;</span></i></td></tr>
<tr><th id="1193">1193</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1194">1194</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> &lt;p&gt;It is also the application's responsibility to ensure that there are no</span></i></td></tr>
<tr><th id="1195">1195</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> other uses of the compilation after calling {@link</span></i></td></tr>
<tr><th id="1196">1196</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> ANeuralNetworksCompilation_free}. This includes any execution object created</span></i></td></tr>
<tr><th id="1197">1197</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> using the compilation.&lt;/p&gt;</span></i></td></tr>
<tr><th id="1198">1198</th><td><i class="doc"><span class="verb"></span><span class="verb"> *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="1199">1199</th><td><span class="verb"></span><b>typedef</b> <b>struct</b> <dfn class="type" id="ANeuralNetworksCompilation" title='ANeuralNetworksCompilation' data-ref="ANeuralNetworksCompilation"><a class="type" href="#ANeuralNetworksCompilation" title='ANeuralNetworksCompilation' data-ref="ANeuralNetworksCompilation">ANeuralNetworksCompilation</a></dfn> <dfn class="typedef" id="ANeuralNetworksCompilation" title='ANeuralNetworksCompilation' data-type='struct ANeuralNetworksCompilation' data-ref="ANeuralNetworksCompilation">ANeuralNetworksCompilation</dfn>;</td></tr>
<tr><th id="1200">1200</th><td></td></tr>
<tr><th id="1201">1201</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1202">1202</th><td><i class="doc"> * ANeuralNetworksExecution is an opaque type that can be used to apply a</i></td></tr>
<tr><th id="1203">1203</th><td><i class="doc"> * machine learning model to a set of inputs.</i></td></tr>
<tr><th id="1204">1204</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1205">1205</th><td><i class="doc"> * <span class="tag">&lt;p&gt;</span>To use:<span class="tag">&lt;ul&gt;</span></i></td></tr>
<tr><th id="1206">1206</th><td><i class="doc"> *    <span class="tag">&lt;li&gt;</span>Create a new execution instance by calling the</i></td></tr>
<tr><th id="1207">1207</th><td><i class="doc"> *        {<span class="command">@link</span><span class="verb"> ANeuralNetworksExecution_create} function.&lt;/li&gt;</span></i></td></tr>
<tr><th id="1208">1208</th><td><i class="doc"><span class="verb"></span> *<span class="verb">    &lt;li&gt;Associate data to the model inputs with</span></i></td></tr>
<tr><th id="1209">1209</th><td><i class="doc"><span class="verb"></span> *<span class="verb">        {@link ANeuralNetworksExecution_setInput} or</span></i></td></tr>
<tr><th id="1210">1210</th><td><i class="doc"><span class="verb"></span> *<span class="verb">        {@link ANeuralNetworksExecution_setInputFromMemory}.&lt;/li&gt;</span></i></td></tr>
<tr><th id="1211">1211</th><td><i class="doc"><span class="verb"></span> *<span class="verb">    &lt;li&gt;Associate output buffers to the model outputs with</span></i></td></tr>
<tr><th id="1212">1212</th><td><i class="doc"><span class="verb"></span> *<span class="verb">        {@link ANeuralNetworksExecution_setOutput} or</span></i></td></tr>
<tr><th id="1213">1213</th><td><i class="doc"><span class="verb"></span> *<span class="verb">        {@link ANeuralNetworksExecution_setOutputFromMemory}.&lt;/li&gt;</span></i></td></tr>
<tr><th id="1214">1214</th><td><i class="doc"><span class="verb"></span> *<span class="verb">    &lt;li&gt;Apply the model with {@link</span></i></td></tr>
<tr><th id="1215">1215</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> ANeuralNetworksExecution_startCompute}.&lt;/li&gt; &lt;li&gt;Wait for the execution to</span></i></td></tr>
<tr><th id="1216">1216</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> complete with {@link ANeuralNetworksExecution_wait}.&lt;/li&gt; &lt;li&gt;Destroy the</span></i></td></tr>
<tr><th id="1217">1217</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> execution with</span></i></td></tr>
<tr><th id="1218">1218</th><td><i class="doc"><span class="verb"></span> *<span class="verb">        {@link ANeuralNetworksExecution_free}.&lt;/li&gt;&lt;/ul&gt;&lt;/p&gt;</span></i></td></tr>
<tr><th id="1219">1219</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1220">1220</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> &lt;p&gt;An execution cannot be modified once {@link</span></i></td></tr>
<tr><th id="1221">1221</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> ANeuralNetworksExecution_start} has been called on it.&lt;/p&gt;</span></i></td></tr>
<tr><th id="1222">1222</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1223">1223</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> &lt;p&gt;An execution can be applied to a model with</span></i></td></tr>
<tr><th id="1224">1224</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> {@link ANeuralNetworksExecution_startCompute} only once. Create new</span></i></td></tr>
<tr><th id="1225">1225</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> executions to do new evaluations of the model.&lt;/p&gt;</span></i></td></tr>
<tr><th id="1226">1226</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1227">1227</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> &lt;p&gt;It is the application's responsibility to make sure that only one thread</span></i></td></tr>
<tr><th id="1228">1228</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> modifies an execution at a given time. It is however safe for more than one</span></i></td></tr>
<tr><th id="1229">1229</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> thread to use {@link ANeuralNetworksExecution_wait} at the same time.&lt;/p&gt;</span></i></td></tr>
<tr><th id="1230">1230</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1231">1231</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> &lt;p&gt;It is also the application's responsibility to ensure that there are no</span></i></td></tr>
<tr><th id="1232">1232</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> other uses of the request after calling {@link</span></i></td></tr>
<tr><th id="1233">1233</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> ANeuralNetworksRequest_free}.&lt;/p&gt;</span></i></td></tr>
<tr><th id="1234">1234</th><td><i class="doc"><span class="verb"></span><span class="verb"> *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="1235">1235</th><td><span class="verb"></span><b>typedef</b> <b>struct</b> <dfn class="type" id="ANeuralNetworksExecution" title='ANeuralNetworksExecution' data-ref="ANeuralNetworksExecution"><a class="type" href="#ANeuralNetworksExecution" title='ANeuralNetworksExecution' data-ref="ANeuralNetworksExecution">ANeuralNetworksExecution</a></dfn> <dfn class="typedef" id="ANeuralNetworksExecution" title='ANeuralNetworksExecution' data-type='struct ANeuralNetworksExecution' data-ref="ANeuralNetworksExecution">ANeuralNetworksExecution</dfn>;</td></tr>
<tr><th id="1236">1236</th><td></td></tr>
<tr><th id="1237">1237</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1238">1238</th><td><i class="doc"> * ANeuralNetworksOperandType describes the type of an operand.</i></td></tr>
<tr><th id="1239">1239</th><td><i class="doc"> * This structure is used to describe both scalars and tensors.</i></td></tr>
<tr><th id="1240">1240</th><td><i class="doc"> */</i></td></tr>
<tr><th id="1241">1241</th><td><b>typedef</b> <b>struct</b> <dfn class="type def" id="ANeuralNetworksOperandType" title='ANeuralNetworksOperandType' data-ref="ANeuralNetworksOperandType"><a class="type" href="#ANeuralNetworksOperandType" title='ANeuralNetworksOperandType' data-ref="ANeuralNetworksOperandType">ANeuralNetworksOperandType</a></dfn> {</td></tr>
<tr><th id="1242">1242</th><td>  <i class="doc">/** The data type, e.g ANEURALNETWORKS_INT8. */</i></td></tr>
<tr><th id="1243">1243</th><td>  <a class="typedef" href="../../../../../include/x86_64-linux-gnu/sys/types.h.html#196" title='int32_t' data-type='int' data-ref="int32_t">int32_t</a> <dfn class="decl" id="ANeuralNetworksOperandType::type" title='ANeuralNetworksOperandType::type' data-ref="ANeuralNetworksOperandType::type">type</dfn>;</td></tr>
<tr><th id="1244">1244</th><td>  <i class="doc">/** The number of dimensions. It should be 0 for scalars. */</i></td></tr>
<tr><th id="1245">1245</th><td>  <a class="typedef" href="../../../../../include/stdint.h.html#uint32_t" title='uint32_t' data-type='unsigned int' data-ref="uint32_t">uint32_t</a> <dfn class="decl" id="ANeuralNetworksOperandType::dimensionCount" title='ANeuralNetworksOperandType::dimensionCount' data-ref="ANeuralNetworksOperandType::dimensionCount">dimensionCount</dfn>;</td></tr>
<tr><th id="1246">1246</th><td>  <i class="doc">/** The dimensions of the tensor. It should be nullptr for scalars. */</i></td></tr>
<tr><th id="1247">1247</th><td>  <em>const</em> <a class="typedef" href="../../../../../include/stdint.h.html#uint32_t" title='uint32_t' data-type='unsigned int' data-ref="uint32_t">uint32_t</a>* <dfn class="decl" id="ANeuralNetworksOperandType::dimensions" title='ANeuralNetworksOperandType::dimensions' data-ref="ANeuralNetworksOperandType::dimensions">dimensions</dfn>;</td></tr>
<tr><th id="1248">1248</th><td>  <i class="doc">/** These two fields are only used for quantized tensors.</i></td></tr>
<tr><th id="1249">1249</th><td><i class="doc">   * They should be zero for scalars and non-fixed point tensors.</i></td></tr>
<tr><th id="1250">1250</th><td><i class="doc">   * The dequantized value of each entry is (value - offset) * scale.</i></td></tr>
<tr><th id="1251">1251</th><td><i class="doc">   */</i></td></tr>
<tr><th id="1252">1252</th><td>  <em>float</em> <dfn class="decl" id="ANeuralNetworksOperandType::scale" title='ANeuralNetworksOperandType::scale' data-ref="ANeuralNetworksOperandType::scale">scale</dfn>;</td></tr>
<tr><th id="1253">1253</th><td>  <a class="typedef" href="../../../../../include/x86_64-linux-gnu/sys/types.h.html#196" title='int32_t' data-type='int' data-ref="int32_t">int32_t</a> <dfn class="decl" id="ANeuralNetworksOperandType::zeroPoint" title='ANeuralNetworksOperandType::zeroPoint' data-ref="ANeuralNetworksOperandType::zeroPoint">zeroPoint</dfn>;</td></tr>
<tr><th id="1254">1254</th><td>} <dfn class="typedef" id="ANeuralNetworksOperandType" title='ANeuralNetworksOperandType' data-type='struct ANeuralNetworksOperandType' data-ref="ANeuralNetworksOperandType">ANeuralNetworksOperandType</dfn>;</td></tr>
<tr><th id="1255">1255</th><td></td></tr>
<tr><th id="1256">1256</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1257">1257</th><td><i class="doc"> * ANeuralNetworksEvent is an opaque type that represents an event</i></td></tr>
<tr><th id="1258">1258</th><td><i class="doc"> * that will be signaled once an execution completes.</i></td></tr>
<tr><th id="1259">1259</th><td><i class="doc"> */</i></td></tr>
<tr><th id="1260">1260</th><td><b>typedef</b> <b>struct</b> <dfn class="type" id="ANeuralNetworksEvent" title='ANeuralNetworksEvent' data-ref="ANeuralNetworksEvent"><a class="type" href="#ANeuralNetworksEvent" title='ANeuralNetworksEvent' data-ref="ANeuralNetworksEvent">ANeuralNetworksEvent</a></dfn> <dfn class="typedef" id="ANeuralNetworksEvent" title='ANeuralNetworksEvent' data-type='struct ANeuralNetworksEvent' data-ref="ANeuralNetworksEvent">ANeuralNetworksEvent</dfn>;</td></tr>
<tr><th id="1261">1261</th><td></td></tr>
<tr><th id="1262">1262</th><td><b>typedef</b> <a class="typedef" href="../../../../../include/x86_64-linux-gnu/sys/types.h.html#196" title='int32_t' data-type='int' data-ref="int32_t">int32_t</a> <dfn class="typedef" id="ANeuralNetworksOperationType" title='ANeuralNetworksOperationType' data-type='int32_t' data-ref="ANeuralNetworksOperationType">ANeuralNetworksOperationType</dfn>;</td></tr>
<tr><th id="1263">1263</th><td></td></tr>
<tr><th id="1264">1264</th><td><i>// nn api function types</i></td></tr>
<tr><th id="1265">1265</th><td></td></tr>
<tr><th id="1266">1266</th><td><b>typedef</b> <em>int</em> (*<dfn class="typedef" id="ANeuralNetworksMemory_createFromFd_fn" title='ANeuralNetworksMemory_createFromFd_fn' data-type='int (*)(size_t, int, int, size_t, ANeuralNetworksMemory **)' data-ref="ANeuralNetworksMemory_createFromFd_fn">ANeuralNetworksMemory_createFromFd_fn</dfn>)(</td></tr>
<tr><th id="1267">1267</th><td>    <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <dfn class="local col7 decl" id="247size" title='size' data-type='size_t' data-ref="247size">size</dfn>, <em>int</em> <dfn class="local col8 decl" id="248protect" title='protect' data-type='int' data-ref="248protect">protect</dfn>, <em>int</em> <dfn class="local col9 decl" id="249fd" title='fd' data-type='int' data-ref="249fd">fd</dfn>, <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <dfn class="local col0 decl" id="250offset" title='offset' data-type='size_t' data-ref="250offset">offset</dfn>,</td></tr>
<tr><th id="1268">1268</th><td>    <a class="typedef" href="#ANeuralNetworksMemory" title='ANeuralNetworksMemory' data-type='struct ANeuralNetworksMemory' data-ref="ANeuralNetworksMemory">ANeuralNetworksMemory</a>** <dfn class="local col1 decl" id="251memory" title='memory' data-type='ANeuralNetworksMemory **' data-ref="251memory">memory</dfn>);</td></tr>
<tr><th id="1269">1269</th><td></td></tr>
<tr><th id="1270">1270</th><td><b>typedef</b> <em>void</em> (*<dfn class="typedef" id="ANeuralNetworksMemory_free_fn" title='ANeuralNetworksMemory_free_fn' data-type='void (*)(ANeuralNetworksMemory *)' data-ref="ANeuralNetworksMemory_free_fn">ANeuralNetworksMemory_free_fn</dfn>)(<a class="typedef" href="#ANeuralNetworksMemory" title='ANeuralNetworksMemory' data-type='struct ANeuralNetworksMemory' data-ref="ANeuralNetworksMemory">ANeuralNetworksMemory</a>* <dfn class="local col2 decl" id="252memory" title='memory' data-type='ANeuralNetworksMemory *' data-ref="252memory">memory</dfn>);</td></tr>
<tr><th id="1271">1271</th><td></td></tr>
<tr><th id="1272">1272</th><td><b>typedef</b> <em>int</em> (*<dfn class="typedef" id="ANeuralNetworksModel_create_fn" title='ANeuralNetworksModel_create_fn' data-type='int (*)(ANeuralNetworksModel **)' data-ref="ANeuralNetworksModel_create_fn">ANeuralNetworksModel_create_fn</dfn>)(<a class="typedef" href="#ANeuralNetworksModel" title='ANeuralNetworksModel' data-type='struct ANeuralNetworksModel' data-ref="ANeuralNetworksModel">ANeuralNetworksModel</a>** <dfn class="local col3 decl" id="253model" title='model' data-type='ANeuralNetworksModel **' data-ref="253model">model</dfn>);</td></tr>
<tr><th id="1273">1273</th><td></td></tr>
<tr><th id="1274">1274</th><td><b>typedef</b> <em>int</em> (*<dfn class="typedef" id="ANeuralNetworksModel_finish_fn" title='ANeuralNetworksModel_finish_fn' data-type='int (*)(ANeuralNetworksModel *)' data-ref="ANeuralNetworksModel_finish_fn">ANeuralNetworksModel_finish_fn</dfn>)(<a class="typedef" href="#ANeuralNetworksModel" title='ANeuralNetworksModel' data-type='struct ANeuralNetworksModel' data-ref="ANeuralNetworksModel">ANeuralNetworksModel</a>* <dfn class="local col4 decl" id="254model" title='model' data-type='ANeuralNetworksModel *' data-ref="254model">model</dfn>);</td></tr>
<tr><th id="1275">1275</th><td></td></tr>
<tr><th id="1276">1276</th><td><b>typedef</b> <em>void</em> (*<dfn class="typedef" id="ANeuralNetworksModel_free_fn" title='ANeuralNetworksModel_free_fn' data-type='void (*)(ANeuralNetworksModel *)' data-ref="ANeuralNetworksModel_free_fn">ANeuralNetworksModel_free_fn</dfn>)(<a class="typedef" href="#ANeuralNetworksModel" title='ANeuralNetworksModel' data-type='struct ANeuralNetworksModel' data-ref="ANeuralNetworksModel">ANeuralNetworksModel</a>* <dfn class="local col5 decl" id="255model" title='model' data-type='ANeuralNetworksModel *' data-ref="255model">model</dfn>);</td></tr>
<tr><th id="1277">1277</th><td></td></tr>
<tr><th id="1278">1278</th><td><b>typedef</b> <em>int</em> (*<dfn class="typedef" id="ANeuralNetworksCompilation_create_fn" title='ANeuralNetworksCompilation_create_fn' data-type='int (*)(ANeuralNetworksModel *, ANeuralNetworksCompilation **)' data-ref="ANeuralNetworksCompilation_create_fn">ANeuralNetworksCompilation_create_fn</dfn>)(</td></tr>
<tr><th id="1279">1279</th><td>    <a class="typedef" href="#ANeuralNetworksModel" title='ANeuralNetworksModel' data-type='struct ANeuralNetworksModel' data-ref="ANeuralNetworksModel">ANeuralNetworksModel</a>* <dfn class="local col6 decl" id="256model" title='model' data-type='ANeuralNetworksModel *' data-ref="256model">model</dfn>, <a class="typedef" href="#ANeuralNetworksCompilation" title='ANeuralNetworksCompilation' data-type='struct ANeuralNetworksCompilation' data-ref="ANeuralNetworksCompilation">ANeuralNetworksCompilation</a>** <dfn class="local col7 decl" id="257compilation" title='compilation' data-type='ANeuralNetworksCompilation **' data-ref="257compilation">compilation</dfn>);</td></tr>
<tr><th id="1280">1280</th><td></td></tr>
<tr><th id="1281">1281</th><td><b>typedef</b> <em>void</em> (*<dfn class="typedef" id="ANeuralNetworksCompilation_free_fn" title='ANeuralNetworksCompilation_free_fn' data-type='void (*)(ANeuralNetworksCompilation *)' data-ref="ANeuralNetworksCompilation_free_fn">ANeuralNetworksCompilation_free_fn</dfn>)(</td></tr>
<tr><th id="1282">1282</th><td>    <a class="typedef" href="#ANeuralNetworksCompilation" title='ANeuralNetworksCompilation' data-type='struct ANeuralNetworksCompilation' data-ref="ANeuralNetworksCompilation">ANeuralNetworksCompilation</a>* <dfn class="local col8 decl" id="258compilation" title='compilation' data-type='ANeuralNetworksCompilation *' data-ref="258compilation">compilation</dfn>);</td></tr>
<tr><th id="1283">1283</th><td></td></tr>
<tr><th id="1284">1284</th><td><b>typedef</b> <em>int</em> (*<dfn class="typedef" id="ANeuralNetworksCompilation_setPreference_fn" title='ANeuralNetworksCompilation_setPreference_fn' data-type='int (*)(ANeuralNetworksCompilation *, int32_t)' data-ref="ANeuralNetworksCompilation_setPreference_fn">ANeuralNetworksCompilation_setPreference_fn</dfn>)(</td></tr>
<tr><th id="1285">1285</th><td>    <a class="typedef" href="#ANeuralNetworksCompilation" title='ANeuralNetworksCompilation' data-type='struct ANeuralNetworksCompilation' data-ref="ANeuralNetworksCompilation">ANeuralNetworksCompilation</a>* <dfn class="local col9 decl" id="259compilation" title='compilation' data-type='ANeuralNetworksCompilation *' data-ref="259compilation">compilation</dfn>, <a class="typedef" href="../../../../../include/x86_64-linux-gnu/sys/types.h.html#196" title='int32_t' data-type='int' data-ref="int32_t">int32_t</a> <dfn class="local col0 decl" id="260preference" title='preference' data-type='int32_t' data-ref="260preference">preference</dfn>);</td></tr>
<tr><th id="1286">1286</th><td></td></tr>
<tr><th id="1287">1287</th><td><b>typedef</b> <em>int</em> (*<dfn class="typedef" id="ANeuralNetworksCompilation_finish_fn" title='ANeuralNetworksCompilation_finish_fn' data-type='int (*)(ANeuralNetworksCompilation *)' data-ref="ANeuralNetworksCompilation_finish_fn">ANeuralNetworksCompilation_finish_fn</dfn>)(</td></tr>
<tr><th id="1288">1288</th><td>    <a class="typedef" href="#ANeuralNetworksCompilation" title='ANeuralNetworksCompilation' data-type='struct ANeuralNetworksCompilation' data-ref="ANeuralNetworksCompilation">ANeuralNetworksCompilation</a>* <dfn class="local col1 decl" id="261compilation" title='compilation' data-type='ANeuralNetworksCompilation *' data-ref="261compilation">compilation</dfn>);</td></tr>
<tr><th id="1289">1289</th><td></td></tr>
<tr><th id="1290">1290</th><td><b>typedef</b> <em>int</em> (*<dfn class="typedef" id="ANeuralNetworksModel_addOperand_fn" title='ANeuralNetworksModel_addOperand_fn' data-type='int (*)(ANeuralNetworksModel *, const ANeuralNetworksOperandType *)' data-ref="ANeuralNetworksModel_addOperand_fn">ANeuralNetworksModel_addOperand_fn</dfn>)(</td></tr>
<tr><th id="1291">1291</th><td>    <a class="typedef" href="#ANeuralNetworksModel" title='ANeuralNetworksModel' data-type='struct ANeuralNetworksModel' data-ref="ANeuralNetworksModel">ANeuralNetworksModel</a>* <dfn class="local col2 decl" id="262model" title='model' data-type='ANeuralNetworksModel *' data-ref="262model">model</dfn>, <em>const</em> <a class="typedef" href="#ANeuralNetworksOperandType" title='ANeuralNetworksOperandType' data-type='struct ANeuralNetworksOperandType' data-ref="ANeuralNetworksOperandType">ANeuralNetworksOperandType</a>* <dfn class="local col3 decl" id="263type" title='type' data-type='const ANeuralNetworksOperandType *' data-ref="263type">type</dfn>);</td></tr>
<tr><th id="1292">1292</th><td></td></tr>
<tr><th id="1293">1293</th><td><b>typedef</b> <em>int</em> (*<dfn class="typedef" id="ANeuralNetworksModel_setOperandValue_fn" title='ANeuralNetworksModel_setOperandValue_fn' data-type='int (*)(ANeuralNetworksModel *, int32_t, const void *, size_t)' data-ref="ANeuralNetworksModel_setOperandValue_fn">ANeuralNetworksModel_setOperandValue_fn</dfn>)(</td></tr>
<tr><th id="1294">1294</th><td>    <a class="typedef" href="#ANeuralNetworksModel" title='ANeuralNetworksModel' data-type='struct ANeuralNetworksModel' data-ref="ANeuralNetworksModel">ANeuralNetworksModel</a>* <dfn class="local col4 decl" id="264model" title='model' data-type='ANeuralNetworksModel *' data-ref="264model">model</dfn>, <a class="typedef" href="../../../../../include/x86_64-linux-gnu/sys/types.h.html#196" title='int32_t' data-type='int' data-ref="int32_t">int32_t</a> <dfn class="local col5 decl" id="265index" title='index' data-type='int32_t' data-ref="265index">index</dfn>, <em>const</em> <em>void</em>* <dfn class="local col6 decl" id="266buffer" title='buffer' data-type='const void *' data-ref="266buffer">buffer</dfn>,</td></tr>
<tr><th id="1295">1295</th><td>    <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <dfn class="local col7 decl" id="267length" title='length' data-type='size_t' data-ref="267length">length</dfn>);</td></tr>
<tr><th id="1296">1296</th><td></td></tr>
<tr><th id="1297">1297</th><td><b>typedef</b> <em>int</em> (*<dfn class="typedef" id="ANeuralNetworksModel_setOperandValueFromMemory_fn" title='ANeuralNetworksModel_setOperandValueFromMemory_fn' data-type='int (*)(ANeuralNetworksModel *, int32_t, const ANeuralNetworksMemory *, size_t, size_t)' data-ref="ANeuralNetworksModel_setOperandValueFromMemory_fn">ANeuralNetworksModel_setOperandValueFromMemory_fn</dfn>)(</td></tr>
<tr><th id="1298">1298</th><td>    <a class="typedef" href="#ANeuralNetworksModel" title='ANeuralNetworksModel' data-type='struct ANeuralNetworksModel' data-ref="ANeuralNetworksModel">ANeuralNetworksModel</a>* <dfn class="local col8 decl" id="268model" title='model' data-type='ANeuralNetworksModel *' data-ref="268model">model</dfn>, <a class="typedef" href="../../../../../include/x86_64-linux-gnu/sys/types.h.html#196" title='int32_t' data-type='int' data-ref="int32_t">int32_t</a> <dfn class="local col9 decl" id="269index" title='index' data-type='int32_t' data-ref="269index">index</dfn>,</td></tr>
<tr><th id="1299">1299</th><td>    <em>const</em> <a class="typedef" href="#ANeuralNetworksMemory" title='ANeuralNetworksMemory' data-type='struct ANeuralNetworksMemory' data-ref="ANeuralNetworksMemory">ANeuralNetworksMemory</a>* <dfn class="local col0 decl" id="270memory" title='memory' data-type='const ANeuralNetworksMemory *' data-ref="270memory">memory</dfn>, <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <dfn class="local col1 decl" id="271offset" title='offset' data-type='size_t' data-ref="271offset">offset</dfn>, <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <dfn class="local col2 decl" id="272length" title='length' data-type='size_t' data-ref="272length">length</dfn>);</td></tr>
<tr><th id="1300">1300</th><td></td></tr>
<tr><th id="1301">1301</th><td><b>typedef</b> <em>int</em> (*<dfn class="typedef" id="ANeuralNetworksModel_addOperation_fn" title='ANeuralNetworksModel_addOperation_fn' data-type='int (*)(ANeuralNetworksModel *, ANeuralNetworksOperationType, uint32_t, const uint32_t *, uint32_t, const uint32_t *)' data-ref="ANeuralNetworksModel_addOperation_fn">ANeuralNetworksModel_addOperation_fn</dfn>)(</td></tr>
<tr><th id="1302">1302</th><td>    <a class="typedef" href="#ANeuralNetworksModel" title='ANeuralNetworksModel' data-type='struct ANeuralNetworksModel' data-ref="ANeuralNetworksModel">ANeuralNetworksModel</a>* <dfn class="local col3 decl" id="273model" title='model' data-type='ANeuralNetworksModel *' data-ref="273model">model</dfn>, <a class="typedef" href="#ANeuralNetworksOperationType" title='ANeuralNetworksOperationType' data-type='int32_t' data-ref="ANeuralNetworksOperationType">ANeuralNetworksOperationType</a> <dfn class="local col4 decl" id="274type" title='type' data-type='ANeuralNetworksOperationType' data-ref="274type">type</dfn>,</td></tr>
<tr><th id="1303">1303</th><td>    <a class="typedef" href="../../../../../include/stdint.h.html#uint32_t" title='uint32_t' data-type='unsigned int' data-ref="uint32_t">uint32_t</a> <dfn class="local col5 decl" id="275inputCount" title='inputCount' data-type='uint32_t' data-ref="275inputCount">inputCount</dfn>, <em>const</em> <a class="typedef" href="../../../../../include/stdint.h.html#uint32_t" title='uint32_t' data-type='unsigned int' data-ref="uint32_t">uint32_t</a>* <dfn class="local col6 decl" id="276inputs" title='inputs' data-type='const uint32_t *' data-ref="276inputs">inputs</dfn>, <a class="typedef" href="../../../../../include/stdint.h.html#uint32_t" title='uint32_t' data-type='unsigned int' data-ref="uint32_t">uint32_t</a> <dfn class="local col7 decl" id="277outputCount" title='outputCount' data-type='uint32_t' data-ref="277outputCount">outputCount</dfn>,</td></tr>
<tr><th id="1304">1304</th><td>    <em>const</em> <a class="typedef" href="../../../../../include/stdint.h.html#uint32_t" title='uint32_t' data-type='unsigned int' data-ref="uint32_t">uint32_t</a>* <dfn class="local col8 decl" id="278outputs" title='outputs' data-type='const uint32_t *' data-ref="278outputs">outputs</dfn>);</td></tr>
<tr><th id="1305">1305</th><td></td></tr>
<tr><th id="1306">1306</th><td><b>typedef</b> <em>int</em> (*<dfn class="typedef" id="ANeuralNetworksModel_identifyInputsAndOutputs_fn" title='ANeuralNetworksModel_identifyInputsAndOutputs_fn' data-type='int (*)(ANeuralNetworksModel *, uint32_t, const uint32_t *, uint32_t, const uint32_t *)' data-ref="ANeuralNetworksModel_identifyInputsAndOutputs_fn">ANeuralNetworksModel_identifyInputsAndOutputs_fn</dfn>)(</td></tr>
<tr><th id="1307">1307</th><td>    <a class="typedef" href="#ANeuralNetworksModel" title='ANeuralNetworksModel' data-type='struct ANeuralNetworksModel' data-ref="ANeuralNetworksModel">ANeuralNetworksModel</a>* <dfn class="local col9 decl" id="279model" title='model' data-type='ANeuralNetworksModel *' data-ref="279model">model</dfn>, <a class="typedef" href="../../../../../include/stdint.h.html#uint32_t" title='uint32_t' data-type='unsigned int' data-ref="uint32_t">uint32_t</a> <dfn class="local col0 decl" id="280inputCount" title='inputCount' data-type='uint32_t' data-ref="280inputCount">inputCount</dfn>, <em>const</em> <a class="typedef" href="../../../../../include/stdint.h.html#uint32_t" title='uint32_t' data-type='unsigned int' data-ref="uint32_t">uint32_t</a>* <dfn class="local col1 decl" id="281inputs" title='inputs' data-type='const uint32_t *' data-ref="281inputs">inputs</dfn>,</td></tr>
<tr><th id="1308">1308</th><td>    <a class="typedef" href="../../../../../include/stdint.h.html#uint32_t" title='uint32_t' data-type='unsigned int' data-ref="uint32_t">uint32_t</a> <dfn class="local col2 decl" id="282outputCount" title='outputCount' data-type='uint32_t' data-ref="282outputCount">outputCount</dfn>, <em>const</em> <a class="typedef" href="../../../../../include/stdint.h.html#uint32_t" title='uint32_t' data-type='unsigned int' data-ref="uint32_t">uint32_t</a>* <dfn class="local col3 decl" id="283outputs" title='outputs' data-type='const uint32_t *' data-ref="283outputs">outputs</dfn>);</td></tr>
<tr><th id="1309">1309</th><td></td></tr>
<tr><th id="1310">1310</th><td><b>typedef</b> <em>int</em> (*<dfn class="typedef" id="ANeuralNetworksExecution_create_fn" title='ANeuralNetworksExecution_create_fn' data-type='int (*)(ANeuralNetworksCompilation *, ANeuralNetworksExecution **)' data-ref="ANeuralNetworksExecution_create_fn">ANeuralNetworksExecution_create_fn</dfn>)(</td></tr>
<tr><th id="1311">1311</th><td>    <a class="typedef" href="#ANeuralNetworksCompilation" title='ANeuralNetworksCompilation' data-type='struct ANeuralNetworksCompilation' data-ref="ANeuralNetworksCompilation">ANeuralNetworksCompilation</a>* <dfn class="local col4 decl" id="284compilation" title='compilation' data-type='ANeuralNetworksCompilation *' data-ref="284compilation">compilation</dfn>,</td></tr>
<tr><th id="1312">1312</th><td>    <a class="typedef" href="#ANeuralNetworksExecution" title='ANeuralNetworksExecution' data-type='struct ANeuralNetworksExecution' data-ref="ANeuralNetworksExecution">ANeuralNetworksExecution</a>** <dfn class="local col5 decl" id="285execution" title='execution' data-type='ANeuralNetworksExecution **' data-ref="285execution">execution</dfn>);</td></tr>
<tr><th id="1313">1313</th><td></td></tr>
<tr><th id="1314">1314</th><td><b>typedef</b> <em>void</em> (*<dfn class="typedef" id="ANeuralNetworksExecution_free_fn" title='ANeuralNetworksExecution_free_fn' data-type='void (*)(ANeuralNetworksExecution *)' data-ref="ANeuralNetworksExecution_free_fn">ANeuralNetworksExecution_free_fn</dfn>)(</td></tr>
<tr><th id="1315">1315</th><td>    <a class="typedef" href="#ANeuralNetworksExecution" title='ANeuralNetworksExecution' data-type='struct ANeuralNetworksExecution' data-ref="ANeuralNetworksExecution">ANeuralNetworksExecution</a>* <dfn class="local col6 decl" id="286execution" title='execution' data-type='ANeuralNetworksExecution *' data-ref="286execution">execution</dfn>);</td></tr>
<tr><th id="1316">1316</th><td></td></tr>
<tr><th id="1317">1317</th><td><b>typedef</b> <em>int</em> (*<dfn class="typedef" id="ANeuralNetworksExecution_setInput_fn" title='ANeuralNetworksExecution_setInput_fn' data-type='int (*)(ANeuralNetworksExecution *, int32_t, const ANeuralNetworksOperandType *, const void *, size_t)' data-ref="ANeuralNetworksExecution_setInput_fn">ANeuralNetworksExecution_setInput_fn</dfn>)(</td></tr>
<tr><th id="1318">1318</th><td>    <a class="typedef" href="#ANeuralNetworksExecution" title='ANeuralNetworksExecution' data-type='struct ANeuralNetworksExecution' data-ref="ANeuralNetworksExecution">ANeuralNetworksExecution</a>* <dfn class="local col7 decl" id="287execution" title='execution' data-type='ANeuralNetworksExecution *' data-ref="287execution">execution</dfn>, <a class="typedef" href="../../../../../include/x86_64-linux-gnu/sys/types.h.html#196" title='int32_t' data-type='int' data-ref="int32_t">int32_t</a> <dfn class="local col8 decl" id="288index" title='index' data-type='int32_t' data-ref="288index">index</dfn>,</td></tr>
<tr><th id="1319">1319</th><td>    <em>const</em> <a class="typedef" href="#ANeuralNetworksOperandType" title='ANeuralNetworksOperandType' data-type='struct ANeuralNetworksOperandType' data-ref="ANeuralNetworksOperandType">ANeuralNetworksOperandType</a>* <dfn class="local col9 decl" id="289type" title='type' data-type='const ANeuralNetworksOperandType *' data-ref="289type">type</dfn>, <em>const</em> <em>void</em>* <dfn class="local col0 decl" id="290buffer" title='buffer' data-type='const void *' data-ref="290buffer">buffer</dfn>, <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <dfn class="local col1 decl" id="291length" title='length' data-type='size_t' data-ref="291length">length</dfn>);</td></tr>
<tr><th id="1320">1320</th><td></td></tr>
<tr><th id="1321">1321</th><td><b>typedef</b> <em>int</em> (*<dfn class="typedef" id="ANeuralNetworksExecution_setInputFromMemory_fn" title='ANeuralNetworksExecution_setInputFromMemory_fn' data-type='int (*)(ANeuralNetworksExecution *, int32_t, const ANeuralNetworksOperandType *, const ANeuralNetworksMemory *, size_t, size_t)' data-ref="ANeuralNetworksExecution_setInputFromMemory_fn">ANeuralNetworksExecution_setInputFromMemory_fn</dfn>)(</td></tr>
<tr><th id="1322">1322</th><td>    <a class="typedef" href="#ANeuralNetworksExecution" title='ANeuralNetworksExecution' data-type='struct ANeuralNetworksExecution' data-ref="ANeuralNetworksExecution">ANeuralNetworksExecution</a>* <dfn class="local col2 decl" id="292execution" title='execution' data-type='ANeuralNetworksExecution *' data-ref="292execution">execution</dfn>, <a class="typedef" href="../../../../../include/x86_64-linux-gnu/sys/types.h.html#196" title='int32_t' data-type='int' data-ref="int32_t">int32_t</a> <dfn class="local col3 decl" id="293index" title='index' data-type='int32_t' data-ref="293index">index</dfn>,</td></tr>
<tr><th id="1323">1323</th><td>    <em>const</em> <a class="typedef" href="#ANeuralNetworksOperandType" title='ANeuralNetworksOperandType' data-type='struct ANeuralNetworksOperandType' data-ref="ANeuralNetworksOperandType">ANeuralNetworksOperandType</a>* <dfn class="local col4 decl" id="294type" title='type' data-type='const ANeuralNetworksOperandType *' data-ref="294type">type</dfn>, <em>const</em> <a class="typedef" href="#ANeuralNetworksMemory" title='ANeuralNetworksMemory' data-type='struct ANeuralNetworksMemory' data-ref="ANeuralNetworksMemory">ANeuralNetworksMemory</a>* <dfn class="local col5 decl" id="295memory" title='memory' data-type='const ANeuralNetworksMemory *' data-ref="295memory">memory</dfn>,</td></tr>
<tr><th id="1324">1324</th><td>    <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <dfn class="local col6 decl" id="296offset" title='offset' data-type='size_t' data-ref="296offset">offset</dfn>, <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <dfn class="local col7 decl" id="297length" title='length' data-type='size_t' data-ref="297length">length</dfn>);</td></tr>
<tr><th id="1325">1325</th><td></td></tr>
<tr><th id="1326">1326</th><td><b>typedef</b> <em>int</em> (*<dfn class="typedef" id="ANeuralNetworksExecution_setOutput_fn" title='ANeuralNetworksExecution_setOutput_fn' data-type='int (*)(ANeuralNetworksExecution *, int32_t, const ANeuralNetworksOperandType *, void *, size_t)' data-ref="ANeuralNetworksExecution_setOutput_fn">ANeuralNetworksExecution_setOutput_fn</dfn>)(</td></tr>
<tr><th id="1327">1327</th><td>    <a class="typedef" href="#ANeuralNetworksExecution" title='ANeuralNetworksExecution' data-type='struct ANeuralNetworksExecution' data-ref="ANeuralNetworksExecution">ANeuralNetworksExecution</a>* <dfn class="local col8 decl" id="298execution" title='execution' data-type='ANeuralNetworksExecution *' data-ref="298execution">execution</dfn>, <a class="typedef" href="../../../../../include/x86_64-linux-gnu/sys/types.h.html#196" title='int32_t' data-type='int' data-ref="int32_t">int32_t</a> <dfn class="local col9 decl" id="299index" title='index' data-type='int32_t' data-ref="299index">index</dfn>,</td></tr>
<tr><th id="1328">1328</th><td>    <em>const</em> <a class="typedef" href="#ANeuralNetworksOperandType" title='ANeuralNetworksOperandType' data-type='struct ANeuralNetworksOperandType' data-ref="ANeuralNetworksOperandType">ANeuralNetworksOperandType</a>* <dfn class="local col0 decl" id="300type" title='type' data-type='const ANeuralNetworksOperandType *' data-ref="300type">type</dfn>, <em>void</em>* <dfn class="local col1 decl" id="301buffer" title='buffer' data-type='void *' data-ref="301buffer">buffer</dfn>, <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <dfn class="local col2 decl" id="302length" title='length' data-type='size_t' data-ref="302length">length</dfn>);</td></tr>
<tr><th id="1329">1329</th><td></td></tr>
<tr><th id="1330">1330</th><td><b>typedef</b> <em>int</em> (*<dfn class="typedef" id="ANeuralNetworksExecution_setOutputFromMemory_fn" title='ANeuralNetworksExecution_setOutputFromMemory_fn' data-type='int (*)(ANeuralNetworksExecution *, int32_t, const ANeuralNetworksOperandType *, const ANeuralNetworksMemory *, size_t, size_t)' data-ref="ANeuralNetworksExecution_setOutputFromMemory_fn">ANeuralNetworksExecution_setOutputFromMemory_fn</dfn>)(</td></tr>
<tr><th id="1331">1331</th><td>    <a class="typedef" href="#ANeuralNetworksExecution" title='ANeuralNetworksExecution' data-type='struct ANeuralNetworksExecution' data-ref="ANeuralNetworksExecution">ANeuralNetworksExecution</a>* <dfn class="local col3 decl" id="303execution" title='execution' data-type='ANeuralNetworksExecution *' data-ref="303execution">execution</dfn>, <a class="typedef" href="../../../../../include/x86_64-linux-gnu/sys/types.h.html#196" title='int32_t' data-type='int' data-ref="int32_t">int32_t</a> <dfn class="local col4 decl" id="304index" title='index' data-type='int32_t' data-ref="304index">index</dfn>,</td></tr>
<tr><th id="1332">1332</th><td>    <em>const</em> <a class="typedef" href="#ANeuralNetworksOperandType" title='ANeuralNetworksOperandType' data-type='struct ANeuralNetworksOperandType' data-ref="ANeuralNetworksOperandType">ANeuralNetworksOperandType</a>* <dfn class="local col5 decl" id="305type" title='type' data-type='const ANeuralNetworksOperandType *' data-ref="305type">type</dfn>, <em>const</em> <a class="typedef" href="#ANeuralNetworksMemory" title='ANeuralNetworksMemory' data-type='struct ANeuralNetworksMemory' data-ref="ANeuralNetworksMemory">ANeuralNetworksMemory</a>* <dfn class="local col6 decl" id="306memory" title='memory' data-type='const ANeuralNetworksMemory *' data-ref="306memory">memory</dfn>,</td></tr>
<tr><th id="1333">1333</th><td>    <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <dfn class="local col7 decl" id="307offset" title='offset' data-type='size_t' data-ref="307offset">offset</dfn>, <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <dfn class="local col8 decl" id="308length" title='length' data-type='size_t' data-ref="308length">length</dfn>);</td></tr>
<tr><th id="1334">1334</th><td></td></tr>
<tr><th id="1335">1335</th><td><b>typedef</b> <em>int</em> (*<dfn class="typedef" id="ANeuralNetworksExecution_startCompute_fn" title='ANeuralNetworksExecution_startCompute_fn' data-type='int (*)(ANeuralNetworksExecution *, ANeuralNetworksEvent **)' data-ref="ANeuralNetworksExecution_startCompute_fn">ANeuralNetworksExecution_startCompute_fn</dfn>)(</td></tr>
<tr><th id="1336">1336</th><td>    <a class="typedef" href="#ANeuralNetworksExecution" title='ANeuralNetworksExecution' data-type='struct ANeuralNetworksExecution' data-ref="ANeuralNetworksExecution">ANeuralNetworksExecution</a>* <dfn class="local col9 decl" id="309execution" title='execution' data-type='ANeuralNetworksExecution *' data-ref="309execution">execution</dfn>, <a class="typedef" href="#ANeuralNetworksEvent" title='ANeuralNetworksEvent' data-type='struct ANeuralNetworksEvent' data-ref="ANeuralNetworksEvent">ANeuralNetworksEvent</a>** <dfn class="local col0 decl" id="310event" title='event' data-type='ANeuralNetworksEvent **' data-ref="310event">event</dfn>);</td></tr>
<tr><th id="1337">1337</th><td></td></tr>
<tr><th id="1338">1338</th><td><b>typedef</b> <em>int</em> (*<dfn class="typedef" id="ANeuralNetworksEvent_wait_fn" title='ANeuralNetworksEvent_wait_fn' data-type='int (*)(ANeuralNetworksEvent *)' data-ref="ANeuralNetworksEvent_wait_fn">ANeuralNetworksEvent_wait_fn</dfn>)(<a class="typedef" href="#ANeuralNetworksEvent" title='ANeuralNetworksEvent' data-type='struct ANeuralNetworksEvent' data-ref="ANeuralNetworksEvent">ANeuralNetworksEvent</a>* <dfn class="local col1 decl" id="311event" title='event' data-type='ANeuralNetworksEvent *' data-ref="311event">event</dfn>);</td></tr>
<tr><th id="1339">1339</th><td></td></tr>
<tr><th id="1340">1340</th><td><b>typedef</b> <em>void</em> (*<dfn class="typedef" id="ANeuralNetworksEvent_free_fn" title='ANeuralNetworksEvent_free_fn' data-type='void (*)(ANeuralNetworksEvent *)' data-ref="ANeuralNetworksEvent_free_fn">ANeuralNetworksEvent_free_fn</dfn>)(<a class="typedef" href="#ANeuralNetworksEvent" title='ANeuralNetworksEvent' data-type='struct ANeuralNetworksEvent' data-ref="ANeuralNetworksEvent">ANeuralNetworksEvent</a>* <dfn class="local col2 decl" id="312event" title='event' data-type='ANeuralNetworksEvent *' data-ref="312event">event</dfn>);</td></tr>
<tr><th id="1341">1341</th><td></td></tr>
<tr><th id="1342">1342</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1343">1343</th><td><i class="doc"> * Creates a shared memory object from a file descriptor.</i></td></tr>
<tr><th id="1344">1344</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1345">1345</th><td><i class="doc"> * The shared memory is backed by a file descriptor via mmap.</i></td></tr>
<tr><th id="1346">1346</th><td><i class="doc"> * See {<span class="command">@link</span><span class="verb"> ANeuralNetworksMemory} for a description on how to use</span></i></td></tr>
<tr><th id="1347">1347</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> this shared memory.</span></i></td></tr>
<tr><th id="1348">1348</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1349">1349</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param size The requested size in bytes.</span></i></td></tr>
<tr><th id="1350">1350</th><td><i class="doc"><span class="verb"></span> *<span class="verb">             Must not be larger than the file size.</span></i></td></tr>
<tr><th id="1351">1351</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param prot The desired memory protection for the mapping.</span></i></td></tr>
<tr><th id="1352">1352</th><td><i class="doc"><span class="verb"></span> *<span class="verb">             It is either PROT_NONE or the bitwise OR of one or</span></i></td></tr>
<tr><th id="1353">1353</th><td><i class="doc"><span class="verb"></span> *<span class="verb">             more of the following flags: PROT_READ, PROT_WRITE.</span></i></td></tr>
<tr><th id="1354">1354</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param fd The requested file descriptor.</span></i></td></tr>
<tr><th id="1355">1355</th><td><i class="doc"><span class="verb"></span> *<span class="verb">           The file descriptor has to be mmap-able. The file</span></i></td></tr>
<tr><th id="1356">1356</th><td><i class="doc"><span class="verb"></span> *<span class="verb">           descriptor will be duplicated.</span></i></td></tr>
<tr><th id="1357">1357</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param offset The offset to the beginning of the file of the area to map.</span></i></td></tr>
<tr><th id="1358">1358</th><td><i class="doc"><span class="verb"></span> *<span class="verb">               The offset has to be aligned to a page size.</span></i></td></tr>
<tr><th id="1359">1359</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param memory The memory object to be created.</span></i></td></tr>
<tr><th id="1360">1360</th><td><i class="doc"><span class="verb"></span> *<span class="verb">               Set to NULL if unsuccessful.</span></i></td></tr>
<tr><th id="1361">1361</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1362">1362</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @return ANEURALNETWORKS_NO_ERROR if the request completed normally.</span></i></td></tr>
<tr><th id="1363">1363</th><td><i class="doc"><span class="verb"></span><span class="verb"> *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="1364">1364</th><td><span class="verb"></span><b>inline</b> <em>int</em> <dfn class="decl def" id="_Z34ANeuralNetworksMemory_createFromFdmiimPP21ANeuralNetworksMemory" title='ANeuralNetworksMemory_createFromFd' data-ref="_Z34ANeuralNetworksMemory_createFromFdmiimPP21ANeuralNetworksMemory">ANeuralNetworksMemory_createFromFd</dfn>(<span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <dfn class="local col3 decl" id="313size" title='size' data-type='size_t' data-ref="313size">size</dfn>, <em>int</em> <dfn class="local col4 decl" id="314protect" title='protect' data-type='int' data-ref="314protect">protect</dfn>, <em>int</em> <dfn class="local col5 decl" id="315fd" title='fd' data-type='int' data-ref="315fd">fd</dfn>,</td></tr>
<tr><th id="1365">1365</th><td>                                              <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <dfn class="local col6 decl" id="316offset" title='offset' data-type='size_t' data-ref="316offset">offset</dfn>,</td></tr>
<tr><th id="1366">1366</th><td>                                              <a class="typedef" href="#ANeuralNetworksMemory" title='ANeuralNetworksMemory' data-type='struct ANeuralNetworksMemory' data-ref="ANeuralNetworksMemory">ANeuralNetworksMemory</a>** <dfn class="local col7 decl" id="317memory" title='memory' data-type='ANeuralNetworksMemory **' data-ref="317memory">memory</dfn>) {</td></tr>
<tr><th id="1367">1367</th><td>  <a class="macro" href="#26" title="static ANeuralNetworksMemory_createFromFd_fn fn = reinterpret_cast&lt;ANeuralNetworksMemory_createFromFd_fn&gt;(loadFunction(&quot;ANeuralNetworksMemory_createFromFd&quot;));" data-ref="_M/LOAD_FUNCTION">LOAD_FUNCTION</a>(ANeuralNetworksMemory_createFromFd);</td></tr>
<tr><th id="1368">1368</th><td>  <a class="macro" href="#32" title="return fn != nullptr ? fn(size, protect, fd, offset, memory) : 0;" data-ref="_M/EXECUTE_FUNCTION_RETURN">EXECUTE_FUNCTION_RETURN</a>(<a class="local col3 ref" href="#313size" title='size' data-ref="313size">size</a>, <a class="local col4 ref" href="#314protect" title='protect' data-ref="314protect">protect</a>, <a class="local col5 ref" href="#315fd" title='fd' data-ref="315fd">fd</a>, <a class="local col6 ref" href="#316offset" title='offset' data-ref="316offset">offset</a>, <a class="local col7 ref" href="#317memory" title='memory' data-ref="317memory">memory</a>);</td></tr>
<tr><th id="1369">1369</th><td>}</td></tr>
<tr><th id="1370">1370</th><td></td></tr>
<tr><th id="1371">1371</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1372">1372</th><td><i class="doc"> * Delete a memory object.</i></td></tr>
<tr><th id="1373">1373</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1374">1374</th><td><i class="doc"> * Destroys the object used by the run time to keep track of the memory.</i></td></tr>
<tr><th id="1375">1375</th><td><i class="doc"> * This will free the underlying actual memory if no other code has open</i></td></tr>
<tr><th id="1376">1376</th><td><i class="doc"> * handles to this memory.</i></td></tr>
<tr><th id="1377">1377</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1378">1378</th><td><i class="doc"> * <span class="command">@param</span> <span class="arg">memory</span> The memory object to be freed.</i></td></tr>
<tr><th id="1379">1379</th><td><i class="doc"> */</i></td></tr>
<tr><th id="1380">1380</th><td><b>inline</b> <em>void</em> <dfn class="decl def" id="_Z26ANeuralNetworksMemory_freeP21ANeuralNetworksMemory" title='ANeuralNetworksMemory_free' data-ref="_Z26ANeuralNetworksMemory_freeP21ANeuralNetworksMemory">ANeuralNetworksMemory_free</dfn>(<a class="typedef" href="#ANeuralNetworksMemory" title='ANeuralNetworksMemory' data-type='struct ANeuralNetworksMemory' data-ref="ANeuralNetworksMemory">ANeuralNetworksMemory</a>* <dfn class="local col9 decl" id="319memory" title='memory' data-type='ANeuralNetworksMemory *' data-ref="319memory">memory</dfn>) {</td></tr>
<tr><th id="1381">1381</th><td>  <a class="macro" href="#26" title="static ANeuralNetworksMemory_free_fn fn = reinterpret_cast&lt;ANeuralNetworksMemory_free_fn&gt;(loadFunction(&quot;ANeuralNetworksMemory_free&quot;));" data-ref="_M/LOAD_FUNCTION">LOAD_FUNCTION</a>(ANeuralNetworksMemory_free);</td></tr>
<tr><th id="1382">1382</th><td>  <a class="macro" href="#28" title="if (fn != nullptr) { fn(memory); }" data-ref="_M/EXECUTE_FUNCTION">EXECUTE_FUNCTION</a>(<a class="local col9 ref" href="#319memory" title='memory' data-ref="319memory">memory</a>);</td></tr>
<tr><th id="1383">1383</th><td>}</td></tr>
<tr><th id="1384">1384</th><td></td></tr>
<tr><th id="1385">1385</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1386">1386</th><td><i class="doc"> * Create an empty {<span class="command">@link</span><span class="verb"> ANeuralNetworksModel}.</span></i></td></tr>
<tr><th id="1387">1387</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1388">1388</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> &lt;p&gt;This only creates the object. Computation is performed once</span></i></td></tr>
<tr><th id="1389">1389</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> {@link ANeuralNetworksExecution_startCompute} is invoked.</span></i></td></tr>
<tr><th id="1390">1390</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1391">1391</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> The model should be constructed with calls to</span></i></td></tr>
<tr><th id="1392">1392</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> {@link ANeuralNetworksModel_addOperation} and</span></i></td></tr>
<tr><th id="1393">1393</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> {@link ANeuralNetworksModel_addOperand}</span></i></td></tr>
<tr><th id="1394">1394</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1395">1395</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> &lt;p&gt;{@link ANeuralNetworksModel_finish} should be called once the model</span></i></td></tr>
<tr><th id="1396">1396</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> has been fully constructed.&lt;/p&gt;</span></i></td></tr>
<tr><th id="1397">1397</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1398">1398</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> &lt;p&gt;{@link ANeuralNetworksModel_free} should be called once the model</span></i></td></tr>
<tr><th id="1399">1399</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> is no longer needed.&lt;/p&gt;</span></i></td></tr>
<tr><th id="1400">1400</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1401">1401</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param model The {@link ANeuralNetworksModel} to be created.</span></i></td></tr>
<tr><th id="1402">1402</th><td><i class="doc"><span class="verb"></span> *<span class="verb">              Set to NULL if unsuccessful.</span></i></td></tr>
<tr><th id="1403">1403</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1404">1404</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @return ANEURALNETWORKS_NO_ERROR if successful.</span></i></td></tr>
<tr><th id="1405">1405</th><td><i class="doc"><span class="verb"></span><span class="verb"> *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="1406">1406</th><td><span class="verb"></span><b>inline</b> <em>int</em> <dfn class="decl def" id="_Z27ANeuralNetworksModel_createPP20ANeuralNetworksModel" title='ANeuralNetworksModel_create' data-ref="_Z27ANeuralNetworksModel_createPP20ANeuralNetworksModel">ANeuralNetworksModel_create</dfn>(<a class="typedef" href="#ANeuralNetworksModel" title='ANeuralNetworksModel' data-type='struct ANeuralNetworksModel' data-ref="ANeuralNetworksModel">ANeuralNetworksModel</a>** <dfn class="local col1 decl" id="321model" title='model' data-type='ANeuralNetworksModel **' data-ref="321model">model</dfn>) {</td></tr>
<tr><th id="1407">1407</th><td>  <a class="macro" href="#26" title="static ANeuralNetworksModel_create_fn fn = reinterpret_cast&lt;ANeuralNetworksModel_create_fn&gt;(loadFunction(&quot;ANeuralNetworksModel_create&quot;));" data-ref="_M/LOAD_FUNCTION">LOAD_FUNCTION</a>(ANeuralNetworksModel_create);</td></tr>
<tr><th id="1408">1408</th><td>  <a class="macro" href="#32" title="return fn != nullptr ? fn(model) : 0;" data-ref="_M/EXECUTE_FUNCTION_RETURN">EXECUTE_FUNCTION_RETURN</a>(<a class="local col1 ref" href="#321model" title='model' data-ref="321model">model</a>);</td></tr>
<tr><th id="1409">1409</th><td>}</td></tr>
<tr><th id="1410">1410</th><td></td></tr>
<tr><th id="1411">1411</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1412">1412</th><td><i class="doc"> * Destroy a model.</i></td></tr>
<tr><th id="1413">1413</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1414">1414</th><td><i class="doc"> * The model need not have been finished by a call to</i></td></tr>
<tr><th id="1415">1415</th><td><i class="doc"> * {<span class="command">@link</span><span class="verb"> ANeuralNetworksModel_finish}.</span></i></td></tr>
<tr><th id="1416">1416</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1417">1417</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> See {@link ANeuralNetworksModel} for information on multithreaded usage.</span></i></td></tr>
<tr><th id="1418">1418</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1419">1419</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param model The model to be destroyed. Passing NULL is acceptable and</span></i></td></tr>
<tr><th id="1420">1420</th><td><i class="doc"><span class="verb"></span> *<span class="verb">              results in no operation.</span></i></td></tr>
<tr><th id="1421">1421</th><td><i class="doc"><span class="verb"></span><span class="verb"> *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="1422">1422</th><td><span class="verb"></span><b>inline</b> <em>void</em> <dfn class="decl def" id="_Z25ANeuralNetworksModel_freeP20ANeuralNetworksModel" title='ANeuralNetworksModel_free' data-ref="_Z25ANeuralNetworksModel_freeP20ANeuralNetworksModel">ANeuralNetworksModel_free</dfn>(<a class="typedef" href="#ANeuralNetworksModel" title='ANeuralNetworksModel' data-type='struct ANeuralNetworksModel' data-ref="ANeuralNetworksModel">ANeuralNetworksModel</a>* <dfn class="local col3 decl" id="323model" title='model' data-type='ANeuralNetworksModel *' data-ref="323model">model</dfn>) {</td></tr>
<tr><th id="1423">1423</th><td>  <a class="macro" href="#26" title="static ANeuralNetworksModel_free_fn fn = reinterpret_cast&lt;ANeuralNetworksModel_free_fn&gt;(loadFunction(&quot;ANeuralNetworksModel_free&quot;));" data-ref="_M/LOAD_FUNCTION">LOAD_FUNCTION</a>(ANeuralNetworksModel_free);</td></tr>
<tr><th id="1424">1424</th><td>  <a class="macro" href="#28" title="if (fn != nullptr) { fn(model); }" data-ref="_M/EXECUTE_FUNCTION">EXECUTE_FUNCTION</a>(<a class="local col3 ref" href="#323model" title='model' data-ref="323model">model</a>);</td></tr>
<tr><th id="1425">1425</th><td>}</td></tr>
<tr><th id="1426">1426</th><td></td></tr>
<tr><th id="1427">1427</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1428">1428</th><td><i class="doc"> * Indicate that we have finished modifying a model. Required before</i></td></tr>
<tr><th id="1429">1429</th><td><i class="doc"> * calling {<span class="command">@link</span><span class="verb"> ANeuralNetworksCompilation_compile}.</span></i></td></tr>
<tr><th id="1430">1430</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1431">1431</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> An application is responsible to make sure that no other thread uses</span></i></td></tr>
<tr><th id="1432">1432</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> the model at the same time.</span></i></td></tr>
<tr><th id="1433">1433</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1434">1434</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> See {@link ANeuralNetworksModel} for information on multithreaded usage.</span></i></td></tr>
<tr><th id="1435">1435</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1436">1436</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param model The model to be finished.</span></i></td></tr>
<tr><th id="1437">1437</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1438">1438</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @return ANEURALNETWORKS_NO_ERROR if successful.</span></i></td></tr>
<tr><th id="1439">1439</th><td><i class="doc"><span class="verb"></span><span class="verb"> *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="1440">1440</th><td><span class="verb"></span><b>inline</b> <em>int</em> <dfn class="decl def" id="_Z27ANeuralNetworksModel_finishP20ANeuralNetworksModel" title='ANeuralNetworksModel_finish' data-ref="_Z27ANeuralNetworksModel_finishP20ANeuralNetworksModel">ANeuralNetworksModel_finish</dfn>(<a class="typedef" href="#ANeuralNetworksModel" title='ANeuralNetworksModel' data-type='struct ANeuralNetworksModel' data-ref="ANeuralNetworksModel">ANeuralNetworksModel</a>* <dfn class="local col5 decl" id="325model" title='model' data-type='ANeuralNetworksModel *' data-ref="325model">model</dfn>) {</td></tr>
<tr><th id="1441">1441</th><td>  <a class="macro" href="#26" title="static ANeuralNetworksModel_finish_fn fn = reinterpret_cast&lt;ANeuralNetworksModel_finish_fn&gt;(loadFunction(&quot;ANeuralNetworksModel_finish&quot;));" data-ref="_M/LOAD_FUNCTION">LOAD_FUNCTION</a>(ANeuralNetworksModel_finish);</td></tr>
<tr><th id="1442">1442</th><td>  <a class="macro" href="#32" title="return fn != nullptr ? fn(model) : 0;" data-ref="_M/EXECUTE_FUNCTION_RETURN">EXECUTE_FUNCTION_RETURN</a>(<a class="local col5 ref" href="#325model" title='model' data-ref="325model">model</a>);</td></tr>
<tr><th id="1443">1443</th><td>}</td></tr>
<tr><th id="1444">1444</th><td></td></tr>
<tr><th id="1445">1445</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1446">1446</th><td><i class="doc"> * Add an operand to a model.</i></td></tr>
<tr><th id="1447">1447</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1448">1448</th><td><i class="doc"> * The order in which the operands are added is important. The first one added</i></td></tr>
<tr><th id="1449">1449</th><td><i class="doc"> * to a model will have the index value 0, the second 1, etc. These indexes are</i></td></tr>
<tr><th id="1450">1450</th><td><i class="doc"> * used as operand identifiers in {<span class="command">@link</span><span class="verb"> ANeuralNetworksModel_addOperation},</span></i></td></tr>
<tr><th id="1451">1451</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> {@link ANeuralNetworksExecution_setInput},</span></i></td></tr>
<tr><th id="1452">1452</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> {@link ANeuralNetworksExecution_setInputFromMemory},</span></i></td></tr>
<tr><th id="1453">1453</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> {@link ANeuralNetworksExecution_setOutput},</span></i></td></tr>
<tr><th id="1454">1454</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> {@link ANeuralNetworksExecution_setOutputFromMemory} and</span></i></td></tr>
<tr><th id="1455">1455</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> {@link ANeuralNetworksExecution_setOperandValue}.</span></i></td></tr>
<tr><th id="1456">1456</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1457">1457</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> To build a model that can accommodate inputs of various sizes, as you may</span></i></td></tr>
<tr><th id="1458">1458</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> want to do for a CNN, set the size of the dimensions that will vary at run</span></i></td></tr>
<tr><th id="1459">1459</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> time to 0. If you do so, provide the full dimensions when calling</span></i></td></tr>
<tr><th id="1460">1460</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> {@link ANeuralNetworksExecution_setInput} or {@link</span></i></td></tr>
<tr><th id="1461">1461</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> ANeuralNetworksExecution_setInputFromMemory}.</span></i></td></tr>
<tr><th id="1462">1462</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1463">1463</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> Attempting to modify a model once {@link ANeuralNetworksModel_finish} has</span></i></td></tr>
<tr><th id="1464">1464</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> been called will return an error.</span></i></td></tr>
<tr><th id="1465">1465</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1466">1466</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> See {@link ANeuralNetworksModel} for information on multithreaded usage.</span></i></td></tr>
<tr><th id="1467">1467</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1468">1468</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param model The model to be modified.</span></i></td></tr>
<tr><th id="1469">1469</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param type The {@link ANeuralNetworksOperandType} that describes the shape</span></i></td></tr>
<tr><th id="1470">1470</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> of the operand.</span></i></td></tr>
<tr><th id="1471">1471</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1472">1472</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @return ANEURALNETWORKS_NO_ERROR if successful.</span></i></td></tr>
<tr><th id="1473">1473</th><td><i class="doc"><span class="verb"></span><span class="verb"> *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="1474">1474</th><td><span class="verb"></span><b>inline</b> <em>int</em> <dfn class="decl def" id="_Z31ANeuralNetworksModel_addOperandP20ANeuralNetworksModelPK26ANeuralNetworksOperandType" title='ANeuralNetworksModel_addOperand' data-ref="_Z31ANeuralNetworksModel_addOperandP20ANeuralNetworksModelPK26ANeuralNetworksOperandType">ANeuralNetworksModel_addOperand</dfn>(</td></tr>
<tr><th id="1475">1475</th><td>    <a class="typedef" href="#ANeuralNetworksModel" title='ANeuralNetworksModel' data-type='struct ANeuralNetworksModel' data-ref="ANeuralNetworksModel">ANeuralNetworksModel</a>* <dfn class="local col7 decl" id="327model" title='model' data-type='ANeuralNetworksModel *' data-ref="327model">model</dfn>, <em>const</em> <a class="typedef" href="#ANeuralNetworksOperandType" title='ANeuralNetworksOperandType' data-type='struct ANeuralNetworksOperandType' data-ref="ANeuralNetworksOperandType">ANeuralNetworksOperandType</a>* <dfn class="local col8 decl" id="328type" title='type' data-type='const ANeuralNetworksOperandType *' data-ref="328type">type</dfn>) {</td></tr>
<tr><th id="1476">1476</th><td>  <a class="macro" href="#26" title="static ANeuralNetworksModel_addOperand_fn fn = reinterpret_cast&lt;ANeuralNetworksModel_addOperand_fn&gt;(loadFunction(&quot;ANeuralNetworksModel_addOperand&quot;));" data-ref="_M/LOAD_FUNCTION">LOAD_FUNCTION</a>(ANeuralNetworksModel_addOperand);</td></tr>
<tr><th id="1477">1477</th><td>  <a class="macro" href="#32" title="return fn != nullptr ? fn(model, type) : 0;" data-ref="_M/EXECUTE_FUNCTION_RETURN">EXECUTE_FUNCTION_RETURN</a>(<a class="local col7 ref" href="#327model" title='model' data-ref="327model">model</a>, <a class="local col8 ref" href="#328type" title='type' data-ref="328type">type</a>);</td></tr>
<tr><th id="1478">1478</th><td>}</td></tr>
<tr><th id="1479">1479</th><td></td></tr>
<tr><th id="1480">1480</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1481">1481</th><td><i class="doc"> * Sets an operand to a constant value.</i></td></tr>
<tr><th id="1482">1482</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1483">1483</th><td><i class="doc"> * For scalar values, the content of buffer is copied into the model.</i></td></tr>
<tr><th id="1484">1484</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1485">1485</th><td><i class="doc"> * For tensor values, a pointer to the buffer is stored within the model.</i></td></tr>
<tr><th id="1486">1486</th><td><i class="doc"> * The application is responsible for not changing the content of this region</i></td></tr>
<tr><th id="1487">1487</th><td><i class="doc"> * until all executions using this model have completed. As the data may</i></td></tr>
<tr><th id="1488">1488</th><td><i class="doc"> * be copied during processing, modifying the data after this call yields</i></td></tr>
<tr><th id="1489">1489</th><td><i class="doc"> * undefined results.</i></td></tr>
<tr><th id="1490">1490</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1491">1491</th><td><i class="doc"> * Attempting to modify a model once {<span class="command">@link</span><span class="verb"> ANeuralNetworksModel_finish} has</span></i></td></tr>
<tr><th id="1492">1492</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> been called will return an error.</span></i></td></tr>
<tr><th id="1493">1493</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1494">1494</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> See {@link ANeuralNetworksModel} for information on multithreaded usage.</span></i></td></tr>
<tr><th id="1495">1495</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1496">1496</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param model The model to be modified.</span></i></td></tr>
<tr><th id="1497">1497</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param index The index of the model operand we're setting.</span></i></td></tr>
<tr><th id="1498">1498</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param buffer A pointer to the data to use.</span></i></td></tr>
<tr><th id="1499">1499</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param length The size in bytes of the data value.</span></i></td></tr>
<tr><th id="1500">1500</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1501">1501</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @return ANEURALNETWORKS_NO_ERROR if successful.</span></i></td></tr>
<tr><th id="1502">1502</th><td><i class="doc"><span class="verb"></span><span class="verb"> *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="1503">1503</th><td><span class="verb"></span><b>inline</b> <em>int</em> <dfn class="decl def" id="_Z36ANeuralNetworksModel_setOperandValueP20ANeuralNetworksModeliPKvm" title='ANeuralNetworksModel_setOperandValue' data-ref="_Z36ANeuralNetworksModel_setOperandValueP20ANeuralNetworksModeliPKvm">ANeuralNetworksModel_setOperandValue</dfn>(<a class="typedef" href="#ANeuralNetworksModel" title='ANeuralNetworksModel' data-type='struct ANeuralNetworksModel' data-ref="ANeuralNetworksModel">ANeuralNetworksModel</a>* <dfn class="local col0 decl" id="330model" title='model' data-type='ANeuralNetworksModel *' data-ref="330model">model</dfn>,</td></tr>
<tr><th id="1504">1504</th><td>                                                <a class="typedef" href="../../../../../include/x86_64-linux-gnu/sys/types.h.html#196" title='int32_t' data-type='int' data-ref="int32_t">int32_t</a> <dfn class="local col1 decl" id="331index" title='index' data-type='int32_t' data-ref="331index">index</dfn>,</td></tr>
<tr><th id="1505">1505</th><td>                                                <em>const</em> <em>void</em>* <dfn class="local col2 decl" id="332buffer" title='buffer' data-type='const void *' data-ref="332buffer">buffer</dfn>,</td></tr>
<tr><th id="1506">1506</th><td>                                                <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <dfn class="local col3 decl" id="333length" title='length' data-type='size_t' data-ref="333length">length</dfn>) {</td></tr>
<tr><th id="1507">1507</th><td>  <a class="macro" href="#26" title="static ANeuralNetworksModel_setOperandValue_fn fn = reinterpret_cast&lt;ANeuralNetworksModel_setOperandValue_fn&gt;(loadFunction(&quot;ANeuralNetworksModel_setOperandValue&quot;));" data-ref="_M/LOAD_FUNCTION">LOAD_FUNCTION</a>(ANeuralNetworksModel_setOperandValue);</td></tr>
<tr><th id="1508">1508</th><td>  <a class="macro" href="#32" title="return fn != nullptr ? fn(model, index, buffer, length) : 0;" data-ref="_M/EXECUTE_FUNCTION_RETURN">EXECUTE_FUNCTION_RETURN</a>(<a class="local col0 ref" href="#330model" title='model' data-ref="330model">model</a>, <a class="local col1 ref" href="#331index" title='index' data-ref="331index">index</a>, <a class="local col2 ref" href="#332buffer" title='buffer' data-ref="332buffer">buffer</a>, <a class="local col3 ref" href="#333length" title='length' data-ref="333length">length</a>);</td></tr>
<tr><th id="1509">1509</th><td>}</td></tr>
<tr><th id="1510">1510</th><td></td></tr>
<tr><th id="1511">1511</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1512">1512</th><td><i class="doc"> * Sets an operand to a value stored in a memory object.</i></td></tr>
<tr><th id="1513">1513</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1514">1514</th><td><i class="doc"> * The content of the memory is not copied. A reference to that memory is stored</i></td></tr>
<tr><th id="1515">1515</th><td><i class="doc"> * inside the model. The application is responsible for not changing the content</i></td></tr>
<tr><th id="1516">1516</th><td><i class="doc"> * of the memory region until all executions using this model have completed.</i></td></tr>
<tr><th id="1517">1517</th><td><i class="doc"> * As the data may be copied during processing, modifying the data after this</i></td></tr>
<tr><th id="1518">1518</th><td><i class="doc"> * call yields undefined results.</i></td></tr>
<tr><th id="1519">1519</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1520">1520</th><td><i class="doc"> * Attempting to modify a model once {<span class="command">@link</span><span class="verb"> ANeuralNetworksModel_finish} has</span></i></td></tr>
<tr><th id="1521">1521</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> been called will return an error.</span></i></td></tr>
<tr><th id="1522">1522</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1523">1523</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> See {@link ANeuralNetworksModel} for information on multithreaded usage.</span></i></td></tr>
<tr><th id="1524">1524</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1525">1525</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param model The model to be modified.</span></i></td></tr>
<tr><th id="1526">1526</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param index The index of the model operand we're setting.</span></i></td></tr>
<tr><th id="1527">1527</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param buffer A pointer to the data to use.</span></i></td></tr>
<tr><th id="1528">1528</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param memory The memory containing the data.</span></i></td></tr>
<tr><th id="1529">1529</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param offset This specifies the location of the data within the memory.</span></i></td></tr>
<tr><th id="1530">1530</th><td><i class="doc"><span class="verb"></span> *<span class="verb">               The offset is in bytes from the start of memory.</span></i></td></tr>
<tr><th id="1531">1531</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param length The size in bytes of the data value.</span></i></td></tr>
<tr><th id="1532">1532</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1533">1533</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @return ANEURALNETWORKS_NO_ERROR if successful.</span></i></td></tr>
<tr><th id="1534">1534</th><td><i class="doc"><span class="verb"></span><span class="verb"> *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="1535">1535</th><td><span class="verb"></span><b>inline</b> <em>int</em> <dfn class="decl def" id="_Z46ANeuralNetworksModel_setOperandValueFromMemoryP20ANeuralNetworksModeliPK21ANeuralNetworksMemorymm" title='ANeuralNetworksModel_setOperandValueFromMemory' data-ref="_Z46ANeuralNetworksModel_setOperandValueFromMemoryP20ANeuralNetworksModeliPK21ANeuralNetworksMemorymm">ANeuralNetworksModel_setOperandValueFromMemory</dfn>(</td></tr>
<tr><th id="1536">1536</th><td>    <a class="typedef" href="#ANeuralNetworksModel" title='ANeuralNetworksModel' data-type='struct ANeuralNetworksModel' data-ref="ANeuralNetworksModel">ANeuralNetworksModel</a>* <dfn class="local col5 decl" id="335model" title='model' data-type='ANeuralNetworksModel *' data-ref="335model">model</dfn>, <a class="typedef" href="../../../../../include/x86_64-linux-gnu/sys/types.h.html#196" title='int32_t' data-type='int' data-ref="int32_t">int32_t</a> <dfn class="local col6 decl" id="336index" title='index' data-type='int32_t' data-ref="336index">index</dfn>,</td></tr>
<tr><th id="1537">1537</th><td>    <em>const</em> <a class="typedef" href="#ANeuralNetworksMemory" title='ANeuralNetworksMemory' data-type='struct ANeuralNetworksMemory' data-ref="ANeuralNetworksMemory">ANeuralNetworksMemory</a>* <dfn class="local col7 decl" id="337memory" title='memory' data-type='const ANeuralNetworksMemory *' data-ref="337memory">memory</dfn>, <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <dfn class="local col8 decl" id="338offset" title='offset' data-type='size_t' data-ref="338offset">offset</dfn>, <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <dfn class="local col9 decl" id="339length" title='length' data-type='size_t' data-ref="339length">length</dfn>) {</td></tr>
<tr><th id="1538">1538</th><td>  <a class="macro" href="#26" title="static ANeuralNetworksModel_setOperandValueFromMemory_fn fn = reinterpret_cast&lt;ANeuralNetworksModel_setOperandValueFromMemory_fn&gt;(loadFunction(&quot;ANeuralNetworksModel_setOperandValueFromMemory&quot;));" data-ref="_M/LOAD_FUNCTION">LOAD_FUNCTION</a>(ANeuralNetworksModel_setOperandValueFromMemory);</td></tr>
<tr><th id="1539">1539</th><td>  <a class="macro" href="#32" title="return fn != nullptr ? fn(model, index, memory, offset, length) : 0;" data-ref="_M/EXECUTE_FUNCTION_RETURN">EXECUTE_FUNCTION_RETURN</a>(<a class="local col5 ref" href="#335model" title='model' data-ref="335model">model</a>, <a class="local col6 ref" href="#336index" title='index' data-ref="336index">index</a>, <a class="local col7 ref" href="#337memory" title='memory' data-ref="337memory">memory</a>, <a class="local col8 ref" href="#338offset" title='offset' data-ref="338offset">offset</a>, <a class="local col9 ref" href="#339length" title='length' data-ref="339length">length</a>);</td></tr>
<tr><th id="1540">1540</th><td>}</td></tr>
<tr><th id="1541">1541</th><td></td></tr>
<tr><th id="1542">1542</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1543">1543</th><td><i class="doc"> * Add an operation to a model.</i></td></tr>
<tr><th id="1544">1544</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1545">1545</th><td><i class="doc"> * <span class="command">@param</span> <span class="arg">model</span> The model to be modified.</i></td></tr>
<tr><th id="1546">1546</th><td><i class="doc"> * <span class="command">@param</span> <span class="arg">type</span> The type of the operation.</i></td></tr>
<tr><th id="1547">1547</th><td><i class="doc"> * <span class="command">@param</span> <span class="arg">inputCount</span> The number of entries in the inputs array.</i></td></tr>
<tr><th id="1548">1548</th><td><i class="doc"> * <span class="command">@param</span> <span class="arg">inputs</span> An array of indexes identifying each operand.</i></td></tr>
<tr><th id="1549">1549</th><td><i class="doc"> * <span class="command">@param</span> <span class="arg">outputCount</span> The number of entries in the outputs array.</i></td></tr>
<tr><th id="1550">1550</th><td><i class="doc"> * <span class="command">@param</span> <span class="arg">outputs</span> An array of indexes identifying each operand.</i></td></tr>
<tr><th id="1551">1551</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1552">1552</th><td><i class="doc"> * The operands specified by inputs and outputs must have been</i></td></tr>
<tr><th id="1553">1553</th><td><i class="doc"> * previously added by calls to {<span class="command">@link</span><span class="verb"> ANeuralNetworksModel_addOperand}.</span></i></td></tr>
<tr><th id="1554">1554</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1555">1555</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> Attempting to modify a model once {@link ANeuralNetworksModel_finish} has</span></i></td></tr>
<tr><th id="1556">1556</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> been called will return an error.</span></i></td></tr>
<tr><th id="1557">1557</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1558">1558</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> See {@link ANeuralNetworksModel} for information on multithreaded usage.</span></i></td></tr>
<tr><th id="1559">1559</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1560">1560</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @return ANEURALNETWORKS_NO_ERROR if successful.</span></i></td></tr>
<tr><th id="1561">1561</th><td><i class="doc"><span class="verb"></span><span class="verb"> *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="1562">1562</th><td><span class="verb"></span><b>inline</b> <em>int</em> <dfn class="decl def" id="_Z33ANeuralNetworksModel_addOperationP20ANeuralNetworksModelijPKjjS2_" title='ANeuralNetworksModel_addOperation' data-ref="_Z33ANeuralNetworksModel_addOperationP20ANeuralNetworksModelijPKjjS2_">ANeuralNetworksModel_addOperation</dfn>(<a class="typedef" href="#ANeuralNetworksModel" title='ANeuralNetworksModel' data-type='struct ANeuralNetworksModel' data-ref="ANeuralNetworksModel">ANeuralNetworksModel</a>* <dfn class="local col1 decl" id="341model" title='model' data-type='ANeuralNetworksModel *' data-ref="341model">model</dfn>,</td></tr>
<tr><th id="1563">1563</th><td>                                             <a class="typedef" href="#ANeuralNetworksOperationType" title='ANeuralNetworksOperationType' data-type='int32_t' data-ref="ANeuralNetworksOperationType">ANeuralNetworksOperationType</a> <dfn class="local col2 decl" id="342type" title='type' data-type='ANeuralNetworksOperationType' data-ref="342type">type</dfn>,</td></tr>
<tr><th id="1564">1564</th><td>                                             <a class="typedef" href="../../../../../include/stdint.h.html#uint32_t" title='uint32_t' data-type='unsigned int' data-ref="uint32_t">uint32_t</a> <dfn class="local col3 decl" id="343inputCount" title='inputCount' data-type='uint32_t' data-ref="343inputCount">inputCount</dfn>,</td></tr>
<tr><th id="1565">1565</th><td>                                             <em>const</em> <a class="typedef" href="../../../../../include/stdint.h.html#uint32_t" title='uint32_t' data-type='unsigned int' data-ref="uint32_t">uint32_t</a>* <dfn class="local col4 decl" id="344inputs" title='inputs' data-type='const uint32_t *' data-ref="344inputs">inputs</dfn>,</td></tr>
<tr><th id="1566">1566</th><td>                                             <a class="typedef" href="../../../../../include/stdint.h.html#uint32_t" title='uint32_t' data-type='unsigned int' data-ref="uint32_t">uint32_t</a> <dfn class="local col5 decl" id="345outputCount" title='outputCount' data-type='uint32_t' data-ref="345outputCount">outputCount</dfn>,</td></tr>
<tr><th id="1567">1567</th><td>                                             <em>const</em> <a class="typedef" href="../../../../../include/stdint.h.html#uint32_t" title='uint32_t' data-type='unsigned int' data-ref="uint32_t">uint32_t</a>* <dfn class="local col6 decl" id="346outputs" title='outputs' data-type='const uint32_t *' data-ref="346outputs">outputs</dfn>) {</td></tr>
<tr><th id="1568">1568</th><td>  <a class="macro" href="#26" title="static ANeuralNetworksModel_addOperation_fn fn = reinterpret_cast&lt;ANeuralNetworksModel_addOperation_fn&gt;(loadFunction(&quot;ANeuralNetworksModel_addOperation&quot;));" data-ref="_M/LOAD_FUNCTION">LOAD_FUNCTION</a>(ANeuralNetworksModel_addOperation);</td></tr>
<tr><th id="1569">1569</th><td>  <a class="macro" href="#32" title="return fn != nullptr ? fn(model, type, inputCount, inputs, outputCount, outputs) : 0;" data-ref="_M/EXECUTE_FUNCTION_RETURN">EXECUTE_FUNCTION_RETURN</a>(<a class="local col1 ref" href="#341model" title='model' data-ref="341model">model</a>, <a class="local col2 ref" href="#342type" title='type' data-ref="342type">type</a>, <a class="local col3 ref" href="#343inputCount" title='inputCount' data-ref="343inputCount">inputCount</a>, <a class="local col4 ref" href="#344inputs" title='inputs' data-ref="344inputs">inputs</a>, <a class="local col5 ref" href="#345outputCount" title='outputCount' data-ref="345outputCount">outputCount</a>,</td></tr>
<tr><th id="1570">1570</th><td>                          <a class="local col6 ref" href="#346outputs" title='outputs' data-ref="346outputs">outputs</a>);</td></tr>
<tr><th id="1571">1571</th><td>}</td></tr>
<tr><th id="1572">1572</th><td></td></tr>
<tr><th id="1573">1573</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1574">1574</th><td><i class="doc"> * Specifies which operands will be the model's inputs and outputs.</i></td></tr>
<tr><th id="1575">1575</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1576">1576</th><td><i class="doc"> * An operand cannot be used for both input and output. Doing so will</i></td></tr>
<tr><th id="1577">1577</th><td><i class="doc"> * return an error.</i></td></tr>
<tr><th id="1578">1578</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1579">1579</th><td><i class="doc"> * <span class="command">@param</span> <span class="arg">model</span> The model to be modified.</i></td></tr>
<tr><th id="1580">1580</th><td><i class="doc"> * <span class="command">@param</span> <span class="arg">inputCount</span> The number of entries in the inputs array.</i></td></tr>
<tr><th id="1581">1581</th><td><i class="doc"> * <span class="command">@param</span> <span class="arg">inputs</span> An array of indexes identifying the input operands.</i></td></tr>
<tr><th id="1582">1582</th><td><i class="doc"> * <span class="command">@param</span> <span class="arg">outputCount</span> The number of entries in the outputs array.</i></td></tr>
<tr><th id="1583">1583</th><td><i class="doc"> * <span class="command">@param</span> <span class="arg">outputs</span> An array of indexes identifying the output operands.</i></td></tr>
<tr><th id="1584">1584</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1585">1585</th><td><i class="doc"> * The operands specified by inputs and outputs must have been</i></td></tr>
<tr><th id="1586">1586</th><td><i class="doc"> * previously added by calls to {<span class="command">@link</span><span class="verb"> ANeuralNetworksModel_addOperand}.</span></i></td></tr>
<tr><th id="1587">1587</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1588">1588</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> Attempting to modify a model once {@link ANeuralNetworksModel_finish} has</span></i></td></tr>
<tr><th id="1589">1589</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> been called will return an error.</span></i></td></tr>
<tr><th id="1590">1590</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1591">1591</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> See {@link ANeuralNetworksModel} for information on multithreaded usage.</span></i></td></tr>
<tr><th id="1592">1592</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1593">1593</th><td><i class="doc"><span class="verb"></span><span class="verb"> *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="1594">1594</th><td><span class="verb"></span><b>inline</b> <em>int</em> <dfn class="decl def" id="_Z45ANeuralNetworksModel_identifyInputsAndOutputsP20ANeuralNetworksModeljPKjjS2_" title='ANeuralNetworksModel_identifyInputsAndOutputs' data-ref="_Z45ANeuralNetworksModel_identifyInputsAndOutputsP20ANeuralNetworksModeljPKjjS2_">ANeuralNetworksModel_identifyInputsAndOutputs</dfn>(</td></tr>
<tr><th id="1595">1595</th><td>    <a class="typedef" href="#ANeuralNetworksModel" title='ANeuralNetworksModel' data-type='struct ANeuralNetworksModel' data-ref="ANeuralNetworksModel">ANeuralNetworksModel</a>* <dfn class="local col8 decl" id="348model" title='model' data-type='ANeuralNetworksModel *' data-ref="348model">model</dfn>, <a class="typedef" href="../../../../../include/stdint.h.html#uint32_t" title='uint32_t' data-type='unsigned int' data-ref="uint32_t">uint32_t</a> <dfn class="local col9 decl" id="349inputCount" title='inputCount' data-type='uint32_t' data-ref="349inputCount">inputCount</dfn>, <em>const</em> <a class="typedef" href="../../../../../include/stdint.h.html#uint32_t" title='uint32_t' data-type='unsigned int' data-ref="uint32_t">uint32_t</a>* <dfn class="local col0 decl" id="350inputs" title='inputs' data-type='const uint32_t *' data-ref="350inputs">inputs</dfn>,</td></tr>
<tr><th id="1596">1596</th><td>    <a class="typedef" href="../../../../../include/stdint.h.html#uint32_t" title='uint32_t' data-type='unsigned int' data-ref="uint32_t">uint32_t</a> <dfn class="local col1 decl" id="351outputCount" title='outputCount' data-type='uint32_t' data-ref="351outputCount">outputCount</dfn>, <em>const</em> <a class="typedef" href="../../../../../include/stdint.h.html#uint32_t" title='uint32_t' data-type='unsigned int' data-ref="uint32_t">uint32_t</a>* <dfn class="local col2 decl" id="352outputs" title='outputs' data-type='const uint32_t *' data-ref="352outputs">outputs</dfn>) {</td></tr>
<tr><th id="1597">1597</th><td>  <a class="macro" href="#26" title="static ANeuralNetworksModel_identifyInputsAndOutputs_fn fn = reinterpret_cast&lt;ANeuralNetworksModel_identifyInputsAndOutputs_fn&gt;(loadFunction(&quot;ANeuralNetworksModel_identifyInputsAndOutputs&quot;));" data-ref="_M/LOAD_FUNCTION">LOAD_FUNCTION</a>(ANeuralNetworksModel_identifyInputsAndOutputs);</td></tr>
<tr><th id="1598">1598</th><td>  <a class="macro" href="#32" title="return fn != nullptr ? fn(model, inputCount, inputs, outputCount, outputs) : 0;" data-ref="_M/EXECUTE_FUNCTION_RETURN">EXECUTE_FUNCTION_RETURN</a>(<a class="local col8 ref" href="#348model" title='model' data-ref="348model">model</a>, <a class="local col9 ref" href="#349inputCount" title='inputCount' data-ref="349inputCount">inputCount</a>, <a class="local col0 ref" href="#350inputs" title='inputs' data-ref="350inputs">inputs</a>, <a class="local col1 ref" href="#351outputCount" title='outputCount' data-ref="351outputCount">outputCount</a>, <a class="local col2 ref" href="#352outputs" title='outputs' data-ref="352outputs">outputs</a>);</td></tr>
<tr><th id="1599">1599</th><td>}</td></tr>
<tr><th id="1600">1600</th><td></td></tr>
<tr><th id="1601">1601</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1602">1602</th><td><i class="doc"> * Create a {<span class="command">@link</span><span class="verb"> ANeuralNetworksCompilation} to compile the given model.</span></i></td></tr>
<tr><th id="1603">1603</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> This only creates the object. Compilation is only performed once</span></i></td></tr>
<tr><th id="1604">1604</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> {@link ANeuralNetworksCompilation_start} is invoked.</span></i></td></tr>
<tr><th id="1605">1605</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1606">1606</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> &lt;p&gt;The provided model must outlive the compilation.&lt;/p&gt;</span></i></td></tr>
<tr><th id="1607">1607</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1608">1608</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> The model must already have been finished by a call to</span></i></td></tr>
<tr><th id="1609">1609</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> {@link ANeuralNetworksModel_finish}.</span></i></td></tr>
<tr><th id="1610">1610</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1611">1611</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> See {@link ANeuralNetworksCompilation} for information on multithreaded</span></i></td></tr>
<tr><th id="1612">1612</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> usage.</span></i></td></tr>
<tr><th id="1613">1613</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1614">1614</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param model The {@link ANeuralNetworksModel} to be compiled.</span></i></td></tr>
<tr><th id="1615">1615</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param compilation The newly created object or NULL if unsuccessful.</span></i></td></tr>
<tr><th id="1616">1616</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1617">1617</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @return ANEURALNETWORKS_NO_ERROR if successful, ANEURALNETWORKS_BAD_DATA</span></i></td></tr>
<tr><th id="1618">1618</th><td><i class="doc"><span class="verb"></span> *<span class="verb">         if the model is invalid.</span></i></td></tr>
<tr><th id="1619">1619</th><td><i class="doc"><span class="verb"></span><span class="verb"> *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="1620">1620</th><td><span class="verb"></span><b>inline</b> <em>int</em> <dfn class="decl def" id="_Z33ANeuralNetworksCompilation_createP20ANeuralNetworksModelPP26ANeuralNetworksCompilation" title='ANeuralNetworksCompilation_create' data-ref="_Z33ANeuralNetworksCompilation_createP20ANeuralNetworksModelPP26ANeuralNetworksCompilation">ANeuralNetworksCompilation_create</dfn>(</td></tr>
<tr><th id="1621">1621</th><td>    <a class="typedef" href="#ANeuralNetworksModel" title='ANeuralNetworksModel' data-type='struct ANeuralNetworksModel' data-ref="ANeuralNetworksModel">ANeuralNetworksModel</a>* <dfn class="local col4 decl" id="354model" title='model' data-type='ANeuralNetworksModel *' data-ref="354model">model</dfn>, <a class="typedef" href="#ANeuralNetworksCompilation" title='ANeuralNetworksCompilation' data-type='struct ANeuralNetworksCompilation' data-ref="ANeuralNetworksCompilation">ANeuralNetworksCompilation</a>** <dfn class="local col5 decl" id="355compilation" title='compilation' data-type='ANeuralNetworksCompilation **' data-ref="355compilation">compilation</dfn>) {</td></tr>
<tr><th id="1622">1622</th><td>  <a class="macro" href="#26" title="static ANeuralNetworksCompilation_create_fn fn = reinterpret_cast&lt;ANeuralNetworksCompilation_create_fn&gt;(loadFunction(&quot;ANeuralNetworksCompilation_create&quot;));" data-ref="_M/LOAD_FUNCTION">LOAD_FUNCTION</a>(ANeuralNetworksCompilation_create);</td></tr>
<tr><th id="1623">1623</th><td>  <a class="macro" href="#32" title="return fn != nullptr ? fn(model, compilation) : 0;" data-ref="_M/EXECUTE_FUNCTION_RETURN">EXECUTE_FUNCTION_RETURN</a>(<a class="local col4 ref" href="#354model" title='model' data-ref="354model">model</a>, <a class="local col5 ref" href="#355compilation" title='compilation' data-ref="355compilation">compilation</a>);</td></tr>
<tr><th id="1624">1624</th><td>}</td></tr>
<tr><th id="1625">1625</th><td></td></tr>
<tr><th id="1626">1626</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1627">1627</th><td><i class="doc"> * Destroy a compilation.</i></td></tr>
<tr><th id="1628">1628</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1629">1629</th><td><i class="doc"> * <span class="tag">&lt;p&gt;</span>If called on a compilation for which</i></td></tr>
<tr><th id="1630">1630</th><td><i class="doc"> * {<span class="command">@link</span><span class="verb"> ANeuralNetworksCompilation_start} has been called, the</span></i></td></tr>
<tr><th id="1631">1631</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> function will return immediately but will mark the compilation to be deleted</span></i></td></tr>
<tr><th id="1632">1632</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> once the compilation completes. The {@link ANeuralNetworksCompilation_wait}</span></i></td></tr>
<tr><th id="1633">1633</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> will return ERROR_DELETED.</span></i></td></tr>
<tr><th id="1634">1634</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1635">1635</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> See {@link ANeuralNetworksCompilation} for information on multithreaded</span></i></td></tr>
<tr><th id="1636">1636</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> usage.</span></i></td></tr>
<tr><th id="1637">1637</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1638">1638</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param compilation The compilation to be destroyed. Passing NULL is</span></i></td></tr>
<tr><th id="1639">1639</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> acceptable and results in no operation.</span></i></td></tr>
<tr><th id="1640">1640</th><td><i class="doc"><span class="verb"></span><span class="verb"> *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="1641">1641</th><td><span class="verb"></span><b>inline</b> <em>void</em> <dfn class="decl def" id="_Z31ANeuralNetworksCompilation_freeP26ANeuralNetworksCompilation" title='ANeuralNetworksCompilation_free' data-ref="_Z31ANeuralNetworksCompilation_freeP26ANeuralNetworksCompilation">ANeuralNetworksCompilation_free</dfn>(</td></tr>
<tr><th id="1642">1642</th><td>    <a class="typedef" href="#ANeuralNetworksCompilation" title='ANeuralNetworksCompilation' data-type='struct ANeuralNetworksCompilation' data-ref="ANeuralNetworksCompilation">ANeuralNetworksCompilation</a>* <dfn class="local col7 decl" id="357compilation" title='compilation' data-type='ANeuralNetworksCompilation *' data-ref="357compilation">compilation</dfn>) {</td></tr>
<tr><th id="1643">1643</th><td>  <a class="macro" href="#26" title="static ANeuralNetworksCompilation_free_fn fn = reinterpret_cast&lt;ANeuralNetworksCompilation_free_fn&gt;(loadFunction(&quot;ANeuralNetworksCompilation_free&quot;));" data-ref="_M/LOAD_FUNCTION">LOAD_FUNCTION</a>(ANeuralNetworksCompilation_free);</td></tr>
<tr><th id="1644">1644</th><td>  <a class="macro" href="#28" title="if (fn != nullptr) { fn(compilation); }" data-ref="_M/EXECUTE_FUNCTION">EXECUTE_FUNCTION</a>(<a class="local col7 ref" href="#357compilation" title='compilation' data-ref="357compilation">compilation</a>);</td></tr>
<tr><th id="1645">1645</th><td>}</td></tr>
<tr><th id="1646">1646</th><td></td></tr>
<tr><th id="1647">1647</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1648">1648</th><td><i class="doc"> * Sets the execution preference.</i></td></tr>
<tr><th id="1649">1649</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1650">1650</th><td><i class="doc"> * <span class="tag">&lt;p&gt;</span>Provides guidance to the runtime when trade-offs are possible.<span class="tag">&lt;/p&gt;</span></i></td></tr>
<tr><th id="1651">1651</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1652">1652</th><td><i class="doc"> * See {<span class="command">@link</span><span class="verb"> ANeuralNetworksCompilation} for information on multithreaded</span></i></td></tr>
<tr><th id="1653">1653</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> usage.</span></i></td></tr>
<tr><th id="1654">1654</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1655">1655</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param compilation The compilation to be modified.</span></i></td></tr>
<tr><th id="1656">1656</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param preference Either {@link PREFER_LOW_POWER},</span></i></td></tr>
<tr><th id="1657">1657</th><td><i class="doc"><span class="verb"></span> *<span class="verb">                  {@link PREFER_SINGLE_FAST_ANSWER}, or</span></i></td></tr>
<tr><th id="1658">1658</th><td><i class="doc"><span class="verb"></span> *<span class="verb">                  {@link PREFER_SUSTAINED_SPEED}.</span></i></td></tr>
<tr><th id="1659">1659</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1660">1660</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @return ANEURALNETWORKS_NO_ERROR if successful.</span></i></td></tr>
<tr><th id="1661">1661</th><td><i class="doc"><span class="verb"></span><span class="verb"> *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="1662">1662</th><td><span class="verb"></span><b>inline</b> <em>int</em> <dfn class="decl def" id="_Z40ANeuralNetworksCompilation_setPreferenceP26ANeuralNetworksCompilationi" title='ANeuralNetworksCompilation_setPreference' data-ref="_Z40ANeuralNetworksCompilation_setPreferenceP26ANeuralNetworksCompilationi">ANeuralNetworksCompilation_setPreference</dfn>(</td></tr>
<tr><th id="1663">1663</th><td>    <a class="typedef" href="#ANeuralNetworksCompilation" title='ANeuralNetworksCompilation' data-type='struct ANeuralNetworksCompilation' data-ref="ANeuralNetworksCompilation">ANeuralNetworksCompilation</a>* <dfn class="local col9 decl" id="359compilation" title='compilation' data-type='ANeuralNetworksCompilation *' data-ref="359compilation">compilation</dfn>, <a class="typedef" href="../../../../../include/x86_64-linux-gnu/sys/types.h.html#196" title='int32_t' data-type='int' data-ref="int32_t">int32_t</a> <dfn class="local col0 decl" id="360preference" title='preference' data-type='int32_t' data-ref="360preference">preference</dfn>) {</td></tr>
<tr><th id="1664">1664</th><td>  <a class="macro" href="#26" title="static ANeuralNetworksCompilation_setPreference_fn fn = reinterpret_cast&lt;ANeuralNetworksCompilation_setPreference_fn&gt;(loadFunction(&quot;ANeuralNetworksCompilation_setPreference&quot;));" data-ref="_M/LOAD_FUNCTION">LOAD_FUNCTION</a>(ANeuralNetworksCompilation_setPreference);</td></tr>
<tr><th id="1665">1665</th><td>  <a class="macro" href="#32" title="return fn != nullptr ? fn(compilation, preference) : 0;" data-ref="_M/EXECUTE_FUNCTION_RETURN">EXECUTE_FUNCTION_RETURN</a>(<a class="local col9 ref" href="#359compilation" title='compilation' data-ref="359compilation">compilation</a>, <a class="local col0 ref" href="#360preference" title='preference' data-ref="360preference">preference</a>);</td></tr>
<tr><th id="1666">1666</th><td>}</td></tr>
<tr><th id="1667">1667</th><td></td></tr>
<tr><th id="1668">1668</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1669">1669</th><td><i class="doc"> * Waits until the compilation completes.</i></td></tr>
<tr><th id="1670">1670</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1671">1671</th><td><i class="doc"> * More than one thread can wait on a compilation. When the compilation</i></td></tr>
<tr><th id="1672">1672</th><td><i class="doc"> * completes, all threads will be released.</i></td></tr>
<tr><th id="1673">1673</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1674">1674</th><td><i class="doc"> * See {<span class="command">@link</span><span class="verb"> ANeuralNetworksCompilation} for information on multithreaded</span></i></td></tr>
<tr><th id="1675">1675</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> usage.</span></i></td></tr>
<tr><th id="1676">1676</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1677">1677</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @return ANEURALNETWORKS_NO_ERROR if the compilation completed normally.</span></i></td></tr>
<tr><th id="1678">1678</th><td><i class="doc"><span class="verb"></span><span class="verb"> *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="1679">1679</th><td><span class="verb"></span><b>inline</b> <em>int</em> <dfn class="decl def" id="_Z33ANeuralNetworksCompilation_finishP26ANeuralNetworksCompilation" title='ANeuralNetworksCompilation_finish' data-ref="_Z33ANeuralNetworksCompilation_finishP26ANeuralNetworksCompilation">ANeuralNetworksCompilation_finish</dfn>(</td></tr>
<tr><th id="1680">1680</th><td>    <a class="typedef" href="#ANeuralNetworksCompilation" title='ANeuralNetworksCompilation' data-type='struct ANeuralNetworksCompilation' data-ref="ANeuralNetworksCompilation">ANeuralNetworksCompilation</a>* <dfn class="local col2 decl" id="362compilation" title='compilation' data-type='ANeuralNetworksCompilation *' data-ref="362compilation">compilation</dfn>) {</td></tr>
<tr><th id="1681">1681</th><td>  <a class="macro" href="#26" title="static ANeuralNetworksCompilation_finish_fn fn = reinterpret_cast&lt;ANeuralNetworksCompilation_finish_fn&gt;(loadFunction(&quot;ANeuralNetworksCompilation_finish&quot;));" data-ref="_M/LOAD_FUNCTION">LOAD_FUNCTION</a>(ANeuralNetworksCompilation_finish);</td></tr>
<tr><th id="1682">1682</th><td>  <a class="macro" href="#32" title="return fn != nullptr ? fn(compilation) : 0;" data-ref="_M/EXECUTE_FUNCTION_RETURN">EXECUTE_FUNCTION_RETURN</a>(<a class="local col2 ref" href="#362compilation" title='compilation' data-ref="362compilation">compilation</a>);</td></tr>
<tr><th id="1683">1683</th><td>}</td></tr>
<tr><th id="1684">1684</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1685">1685</th><td><i class="doc"> * Create a {<span class="command">@link</span><span class="verb"> ANeuralNetworksExecution} to apply the given compilation.</span></i></td></tr>
<tr><th id="1686">1686</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> This only creates the object. Computation is only performed once</span></i></td></tr>
<tr><th id="1687">1687</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> {@link ANeuralNetworksExecution_startCompute} is invoked.</span></i></td></tr>
<tr><th id="1688">1688</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1689">1689</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> &lt;p&gt;The provided compilation must outlive the execution.&lt;/p&gt;</span></i></td></tr>
<tr><th id="1690">1690</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1691">1691</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> See {@link ANeuralNetworksExecution} for information on multithreaded usage.</span></i></td></tr>
<tr><th id="1692">1692</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1693">1693</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param compilation The {@link ANeuralNetworksCompilation} to be evaluated.</span></i></td></tr>
<tr><th id="1694">1694</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param execution The newly created object or NULL if unsuccessful.</span></i></td></tr>
<tr><th id="1695">1695</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1696">1696</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @return ANEURALNETWORKS_NO_ERROR if successful, ANEURALNETWORKS_BAD_DATA</span></i></td></tr>
<tr><th id="1697">1697</th><td><i class="doc"><span class="verb"></span> *<span class="verb">         if the compilation is invalid.</span></i></td></tr>
<tr><th id="1698">1698</th><td><i class="doc"><span class="verb"></span><span class="verb"> *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="1699">1699</th><td><span class="verb"></span><b>inline</b> <em>int</em> <dfn class="decl def" id="_Z31ANeuralNetworksExecution_createP26ANeuralNetworksCompilationPP24ANeuralNetworksExecution" title='ANeuralNetworksExecution_create' data-ref="_Z31ANeuralNetworksExecution_createP26ANeuralNetworksCompilationPP24ANeuralNetworksExecution">ANeuralNetworksExecution_create</dfn>(</td></tr>
<tr><th id="1700">1700</th><td>    <a class="typedef" href="#ANeuralNetworksCompilation" title='ANeuralNetworksCompilation' data-type='struct ANeuralNetworksCompilation' data-ref="ANeuralNetworksCompilation">ANeuralNetworksCompilation</a>* <dfn class="local col4 decl" id="364compilation" title='compilation' data-type='ANeuralNetworksCompilation *' data-ref="364compilation">compilation</dfn>,</td></tr>
<tr><th id="1701">1701</th><td>    <a class="typedef" href="#ANeuralNetworksExecution" title='ANeuralNetworksExecution' data-type='struct ANeuralNetworksExecution' data-ref="ANeuralNetworksExecution">ANeuralNetworksExecution</a>** <dfn class="local col5 decl" id="365execution" title='execution' data-type='ANeuralNetworksExecution **' data-ref="365execution">execution</dfn>) {</td></tr>
<tr><th id="1702">1702</th><td>  <a class="macro" href="#26" title="static ANeuralNetworksExecution_create_fn fn = reinterpret_cast&lt;ANeuralNetworksExecution_create_fn&gt;(loadFunction(&quot;ANeuralNetworksExecution_create&quot;));" data-ref="_M/LOAD_FUNCTION">LOAD_FUNCTION</a>(ANeuralNetworksExecution_create);</td></tr>
<tr><th id="1703">1703</th><td>  <a class="macro" href="#32" title="return fn != nullptr ? fn(compilation, execution) : 0;" data-ref="_M/EXECUTE_FUNCTION_RETURN">EXECUTE_FUNCTION_RETURN</a>(<a class="local col4 ref" href="#364compilation" title='compilation' data-ref="364compilation">compilation</a>, <a class="local col5 ref" href="#365execution" title='execution' data-ref="365execution">execution</a>);</td></tr>
<tr><th id="1704">1704</th><td>}</td></tr>
<tr><th id="1705">1705</th><td></td></tr>
<tr><th id="1706">1706</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1707">1707</th><td><i class="doc"> * Destroy an execution.</i></td></tr>
<tr><th id="1708">1708</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1709">1709</th><td><i class="doc"> * <span class="tag">&lt;p&gt;</span>If called on an execution for which</i></td></tr>
<tr><th id="1710">1710</th><td><i class="doc"> * {<span class="command">@link</span><span class="verb"> ANeuralNetworksExecution_startCompute} has been called, the</span></i></td></tr>
<tr><th id="1711">1711</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> function will return immediately but will mark the execution to be deleted</span></i></td></tr>
<tr><th id="1712">1712</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> once the computation completes.   The {link ANeuralNetworksExecution_wait}</span></i></td></tr>
<tr><th id="1713">1713</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> will return ANEURALNETWORKS_ERROR_DELETED.</span></i></td></tr>
<tr><th id="1714">1714</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1715">1715</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> See {@link ANeuralNetworksExecution} for information on multithreaded usage.</span></i></td></tr>
<tr><th id="1716">1716</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1717">1717</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param execution The execution to be destroyed. Passing NULL is acceptable</span></i></td></tr>
<tr><th id="1718">1718</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> and results in no operation.</span></i></td></tr>
<tr><th id="1719">1719</th><td><i class="doc"><span class="verb"></span><span class="verb"> *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="1720">1720</th><td><span class="verb"></span><b>inline</b> <em>void</em> <dfn class="decl def" id="_Z29ANeuralNetworksExecution_freeP24ANeuralNetworksExecution" title='ANeuralNetworksExecution_free' data-ref="_Z29ANeuralNetworksExecution_freeP24ANeuralNetworksExecution">ANeuralNetworksExecution_free</dfn>(<a class="typedef" href="#ANeuralNetworksExecution" title='ANeuralNetworksExecution' data-type='struct ANeuralNetworksExecution' data-ref="ANeuralNetworksExecution">ANeuralNetworksExecution</a>* <dfn class="local col7 decl" id="367execution" title='execution' data-type='ANeuralNetworksExecution *' data-ref="367execution">execution</dfn>) {</td></tr>
<tr><th id="1721">1721</th><td>  <a class="macro" href="#26" title="static ANeuralNetworksExecution_free_fn fn = reinterpret_cast&lt;ANeuralNetworksExecution_free_fn&gt;(loadFunction(&quot;ANeuralNetworksExecution_free&quot;));" data-ref="_M/LOAD_FUNCTION">LOAD_FUNCTION</a>(ANeuralNetworksExecution_free);</td></tr>
<tr><th id="1722">1722</th><td>  <a class="macro" href="#28" title="if (fn != nullptr) { fn(execution); }" data-ref="_M/EXECUTE_FUNCTION">EXECUTE_FUNCTION</a>(<a class="local col7 ref" href="#367execution" title='execution' data-ref="367execution">execution</a>);</td></tr>
<tr><th id="1723">1723</th><td>}</td></tr>
<tr><th id="1724">1724</th><td></td></tr>
<tr><th id="1725">1725</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1726">1726</th><td><i class="doc"> * Associate a user buffer with an input of the model of the</i></td></tr>
<tr><th id="1727">1727</th><td><i class="doc"> * {<span class="command">@link</span><span class="verb"> ANeuralNetworksExecution}.</span></i></td></tr>
<tr><th id="1728">1728</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1729">1729</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> &lt;p&gt;The provided buffer must outlive the execution.&lt;/p&gt;</span></i></td></tr>
<tr><th id="1730">1730</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1731">1731</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> See {@link ANeuralNetworksExecution} for information on multithreaded usage.</span></i></td></tr>
<tr><th id="1732">1732</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1733">1733</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param execution The execution to be modified.</span></i></td></tr>
<tr><th id="1734">1734</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param index The index of the input argument we are setting. It is</span></i></td></tr>
<tr><th id="1735">1735</th><td><i class="doc"><span class="verb"></span> *<span class="verb">              an index into the lists passed to</span></i></td></tr>
<tr><th id="1736">1736</th><td><i class="doc"><span class="verb"></span> *<span class="verb">              {@link ANeuralNetworksModel_identifyInputsAndOutputs}. It is not</span></i></td></tr>
<tr><th id="1737">1737</th><td><i class="doc"><span class="verb"></span> *<span class="verb">              the index associated with {@link</span></i></td></tr>
<tr><th id="1738">1738</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> ANeuralNetworksModel_addOperand}.</span></i></td></tr>
<tr><th id="1739">1739</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param type The type of the operand. This should be used to specify the</span></i></td></tr>
<tr><th id="1740">1740</th><td><i class="doc"><span class="verb"></span> *<span class="verb">             dimensions that were set to 0 when the operand was added to the</span></i></td></tr>
<tr><th id="1741">1741</th><td><i class="doc"><span class="verb"></span> *<span class="verb">             model. All other properties of the type must be the same as</span></i></td></tr>
<tr><th id="1742">1742</th><td><i class="doc"><span class="verb"></span> *<span class="verb">             specified in the model. If the type is the same as specified</span></i></td></tr>
<tr><th id="1743">1743</th><td><i class="doc"><span class="verb"></span> *<span class="verb">             when the model was built, NULL can be passed.</span></i></td></tr>
<tr><th id="1744">1744</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param buffer The buffer containing the data.</span></i></td></tr>
<tr><th id="1745">1745</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param length The length in bytes of the buffer.</span></i></td></tr>
<tr><th id="1746">1746</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1747">1747</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @return ANEURALNETWORKS_NO_ERROR if successful, ANEURALNETWORKS_BAD_DATA if</span></i></td></tr>
<tr><th id="1748">1748</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> the name is not recognized or the buffer is too small for the input.</span></i></td></tr>
<tr><th id="1749">1749</th><td><i class="doc"><span class="verb"></span><span class="verb"> *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="1750">1750</th><td><span class="verb"></span><b>inline</b> <em>int</em> <dfn class="decl def" id="_Z33ANeuralNetworksExecution_setInputP24ANeuralNetworksExecutioniPK26ANeuralNetworksOperandTypePKvm" title='ANeuralNetworksExecution_setInput' data-ref="_Z33ANeuralNetworksExecution_setInputP24ANeuralNetworksExecutioniPK26ANeuralNetworksOperandTypePKvm">ANeuralNetworksExecution_setInput</dfn>(</td></tr>
<tr><th id="1751">1751</th><td>    <a class="typedef" href="#ANeuralNetworksExecution" title='ANeuralNetworksExecution' data-type='struct ANeuralNetworksExecution' data-ref="ANeuralNetworksExecution">ANeuralNetworksExecution</a>* <dfn class="local col9 decl" id="369execution" title='execution' data-type='ANeuralNetworksExecution *' data-ref="369execution">execution</dfn>, <a class="typedef" href="../../../../../include/x86_64-linux-gnu/sys/types.h.html#196" title='int32_t' data-type='int' data-ref="int32_t">int32_t</a> <dfn class="local col0 decl" id="370index" title='index' data-type='int32_t' data-ref="370index">index</dfn>,</td></tr>
<tr><th id="1752">1752</th><td>    <em>const</em> <a class="typedef" href="#ANeuralNetworksOperandType" title='ANeuralNetworksOperandType' data-type='struct ANeuralNetworksOperandType' data-ref="ANeuralNetworksOperandType">ANeuralNetworksOperandType</a>* <dfn class="local col1 decl" id="371type" title='type' data-type='const ANeuralNetworksOperandType *' data-ref="371type">type</dfn>, <em>const</em> <em>void</em>* <dfn class="local col2 decl" id="372buffer" title='buffer' data-type='const void *' data-ref="372buffer">buffer</dfn>, <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <dfn class="local col3 decl" id="373length" title='length' data-type='size_t' data-ref="373length">length</dfn>) {</td></tr>
<tr><th id="1753">1753</th><td>  <a class="macro" href="#26" title="static ANeuralNetworksExecution_setInput_fn fn = reinterpret_cast&lt;ANeuralNetworksExecution_setInput_fn&gt;(loadFunction(&quot;ANeuralNetworksExecution_setInput&quot;));" data-ref="_M/LOAD_FUNCTION">LOAD_FUNCTION</a>(ANeuralNetworksExecution_setInput);</td></tr>
<tr><th id="1754">1754</th><td>  <a class="macro" href="#32" title="return fn != nullptr ? fn(execution, index, type, buffer, length) : 0;" data-ref="_M/EXECUTE_FUNCTION_RETURN">EXECUTE_FUNCTION_RETURN</a>(<a class="local col9 ref" href="#369execution" title='execution' data-ref="369execution">execution</a>, <a class="local col0 ref" href="#370index" title='index' data-ref="370index">index</a>, <a class="local col1 ref" href="#371type" title='type' data-ref="371type">type</a>, <a class="local col2 ref" href="#372buffer" title='buffer' data-ref="372buffer">buffer</a>, <a class="local col3 ref" href="#373length" title='length' data-ref="373length">length</a>);</td></tr>
<tr><th id="1755">1755</th><td>}</td></tr>
<tr><th id="1756">1756</th><td></td></tr>
<tr><th id="1757">1757</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1758">1758</th><td><i class="doc"> * Associate part of a memory object with an input of the model of the</i></td></tr>
<tr><th id="1759">1759</th><td><i class="doc"> * {<span class="command">@link</span><span class="verb"> ANeuralNetworksExecution}.</span></i></td></tr>
<tr><th id="1760">1760</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1761">1761</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> &lt;p&gt;The provided memory must outlive the execution.&lt;/p&gt;</span></i></td></tr>
<tr><th id="1762">1762</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1763">1763</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> See {@link ANeuralNetworksExecution} for information on multithreaded usage.</span></i></td></tr>
<tr><th id="1764">1764</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1765">1765</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param execution The execution to be modified.</span></i></td></tr>
<tr><th id="1766">1766</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param index The index of the input argument we are setting. It is</span></i></td></tr>
<tr><th id="1767">1767</th><td><i class="doc"><span class="verb"></span> *<span class="verb">              an index into the lists passed to</span></i></td></tr>
<tr><th id="1768">1768</th><td><i class="doc"><span class="verb"></span> *<span class="verb">              {@link ANeuralNetworksModel_identifyInputsAndOutputs}. It is not</span></i></td></tr>
<tr><th id="1769">1769</th><td><i class="doc"><span class="verb"></span> *<span class="verb">              the index associated with {@link</span></i></td></tr>
<tr><th id="1770">1770</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> ANeuralNetworksModel_addOperand}.</span></i></td></tr>
<tr><th id="1771">1771</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param type The type of the operand. This can be used to specify the</span></i></td></tr>
<tr><th id="1772">1772</th><td><i class="doc"><span class="verb"></span> *<span class="verb">             dimensions that were set to 0 when the operand was added to the</span></i></td></tr>
<tr><th id="1773">1773</th><td><i class="doc"><span class="verb"></span> *<span class="verb">             model. All other values must be the same as specified in the</span></i></td></tr>
<tr><th id="1774">1774</th><td><i class="doc"><span class="verb"></span> *<span class="verb">             model. If the type is the same as specified when the model</span></i></td></tr>
<tr><th id="1775">1775</th><td><i class="doc"><span class="verb"></span> *<span class="verb">             was built, NULL can be passed.</span></i></td></tr>
<tr><th id="1776">1776</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param memory The memory containing the data.</span></i></td></tr>
<tr><th id="1777">1777</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param offset This specifies the location of the data within the memory.</span></i></td></tr>
<tr><th id="1778">1778</th><td><i class="doc"><span class="verb"></span> *<span class="verb">               The offset is in bytes from the start of memory.</span></i></td></tr>
<tr><th id="1779">1779</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param length The size in bytes of the data value.</span></i></td></tr>
<tr><th id="1780">1780</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1781">1781</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @return ANEURALNETWORKS_NO_ERROR if successful, ANEURALNETWORKS_BAD_DATA if</span></i></td></tr>
<tr><th id="1782">1782</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> the name is not recognized or the buffer is too small for the input.</span></i></td></tr>
<tr><th id="1783">1783</th><td><i class="doc"><span class="verb"></span><span class="verb"> *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="1784">1784</th><td><span class="verb"></span><b>inline</b> <em>int</em> <dfn class="decl def" id="_Z43ANeuralNetworksExecution_setInputFromMemoryP24ANeuralNetworksExecutioniPK26ANeuralNetworksOperandTypePK21ANeuralNetworksMemorymm" title='ANeuralNetworksExecution_setInputFromMemory' data-ref="_Z43ANeuralNetworksExecution_setInputFromMemoryP24ANeuralNetworksExecutioniPK26ANeuralNetworksOperandTypePK21ANeuralNetworksMemorymm">ANeuralNetworksExecution_setInputFromMemory</dfn>(</td></tr>
<tr><th id="1785">1785</th><td>    <a class="typedef" href="#ANeuralNetworksExecution" title='ANeuralNetworksExecution' data-type='struct ANeuralNetworksExecution' data-ref="ANeuralNetworksExecution">ANeuralNetworksExecution</a>* <dfn class="local col5 decl" id="375execution" title='execution' data-type='ANeuralNetworksExecution *' data-ref="375execution">execution</dfn>, <a class="typedef" href="../../../../../include/x86_64-linux-gnu/sys/types.h.html#196" title='int32_t' data-type='int' data-ref="int32_t">int32_t</a> <dfn class="local col6 decl" id="376index" title='index' data-type='int32_t' data-ref="376index">index</dfn>,</td></tr>
<tr><th id="1786">1786</th><td>    <em>const</em> <a class="typedef" href="#ANeuralNetworksOperandType" title='ANeuralNetworksOperandType' data-type='struct ANeuralNetworksOperandType' data-ref="ANeuralNetworksOperandType">ANeuralNetworksOperandType</a>* <dfn class="local col7 decl" id="377type" title='type' data-type='const ANeuralNetworksOperandType *' data-ref="377type">type</dfn>, <em>const</em> <a class="typedef" href="#ANeuralNetworksMemory" title='ANeuralNetworksMemory' data-type='struct ANeuralNetworksMemory' data-ref="ANeuralNetworksMemory">ANeuralNetworksMemory</a>* <dfn class="local col8 decl" id="378memory" title='memory' data-type='const ANeuralNetworksMemory *' data-ref="378memory">memory</dfn>,</td></tr>
<tr><th id="1787">1787</th><td>    <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <dfn class="local col9 decl" id="379offset" title='offset' data-type='size_t' data-ref="379offset">offset</dfn>, <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <dfn class="local col0 decl" id="380length" title='length' data-type='size_t' data-ref="380length">length</dfn>) {</td></tr>
<tr><th id="1788">1788</th><td>  <a class="macro" href="#26" title="static ANeuralNetworksExecution_setInputFromMemory_fn fn = reinterpret_cast&lt;ANeuralNetworksExecution_setInputFromMemory_fn&gt;(loadFunction(&quot;ANeuralNetworksExecution_setInputFromMemory&quot;));" data-ref="_M/LOAD_FUNCTION">LOAD_FUNCTION</a>(ANeuralNetworksExecution_setInputFromMemory);</td></tr>
<tr><th id="1789">1789</th><td>  <a class="macro" href="#32" title="return fn != nullptr ? fn(execution, index, type, memory, offset, length) : 0;" data-ref="_M/EXECUTE_FUNCTION_RETURN">EXECUTE_FUNCTION_RETURN</a>(<a class="local col5 ref" href="#375execution" title='execution' data-ref="375execution">execution</a>, <a class="local col6 ref" href="#376index" title='index' data-ref="376index">index</a>, <a class="local col7 ref" href="#377type" title='type' data-ref="377type">type</a>, <a class="local col8 ref" href="#378memory" title='memory' data-ref="378memory">memory</a>, <a class="local col9 ref" href="#379offset" title='offset' data-ref="379offset">offset</a>, <a class="local col0 ref" href="#380length" title='length' data-ref="380length">length</a>);</td></tr>
<tr><th id="1790">1790</th><td>}</td></tr>
<tr><th id="1791">1791</th><td></td></tr>
<tr><th id="1792">1792</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1793">1793</th><td><i class="doc"> * Associate a user buffer with an output of the model of the</i></td></tr>
<tr><th id="1794">1794</th><td><i class="doc"> * {<span class="command">@link</span><span class="verb"> ANeuralNetworksExecution}.</span></i></td></tr>
<tr><th id="1795">1795</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1796">1796</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> &lt;p&gt;The provided buffer must outlive the execution.&lt;/p&gt;</span></i></td></tr>
<tr><th id="1797">1797</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1798">1798</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> See {@link ANeuralNetworksExecution} for information on multithreaded usage.</span></i></td></tr>
<tr><th id="1799">1799</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1800">1800</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param execution The execution to be modified.</span></i></td></tr>
<tr><th id="1801">1801</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param index The index of the output argument we are setting. It is</span></i></td></tr>
<tr><th id="1802">1802</th><td><i class="doc"><span class="verb"></span> *<span class="verb">              an index into the lists passed to</span></i></td></tr>
<tr><th id="1803">1803</th><td><i class="doc"><span class="verb"></span> *<span class="verb">              {@link ANeuralNetworksModel_identifyInputsAndOutputs}. It is not</span></i></td></tr>
<tr><th id="1804">1804</th><td><i class="doc"><span class="verb"></span> *<span class="verb">              the index associated with {@link</span></i></td></tr>
<tr><th id="1805">1805</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> ANeuralNetworksModel_addOperand}.</span></i></td></tr>
<tr><th id="1806">1806</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param type The type of the operand. This can be used to specify the</span></i></td></tr>
<tr><th id="1807">1807</th><td><i class="doc"><span class="verb"></span> *<span class="verb">             dimensions that were set to 0 when the operand was added to the</span></i></td></tr>
<tr><th id="1808">1808</th><td><i class="doc"><span class="verb"></span> *<span class="verb">             model. All other values must be the same as specified in the</span></i></td></tr>
<tr><th id="1809">1809</th><td><i class="doc"><span class="verb"></span> *<span class="verb">             model. If the type is the same as specified when the model</span></i></td></tr>
<tr><th id="1810">1810</th><td><i class="doc"><span class="verb"></span> *<span class="verb">             was built, NULL can be passed.</span></i></td></tr>
<tr><th id="1811">1811</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param buffer The buffer where the data is to be written.</span></i></td></tr>
<tr><th id="1812">1812</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param length The length in bytes of the buffer.</span></i></td></tr>
<tr><th id="1813">1813</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1814">1814</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @return ANEURALNETWORKS_NO_ERROR if successful, ANEURALNETWORKS_BAD_DATA if</span></i></td></tr>
<tr><th id="1815">1815</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> the name is not recognized or the buffer is too small for the output.</span></i></td></tr>
<tr><th id="1816">1816</th><td><i class="doc"><span class="verb"></span><span class="verb"> *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="1817">1817</th><td><span class="verb"></span><b>inline</b> <em>int</em> <dfn class="decl def" id="_Z34ANeuralNetworksExecution_setOutputP24ANeuralNetworksExecutioniPK26ANeuralNetworksOperandTypePvm" title='ANeuralNetworksExecution_setOutput' data-ref="_Z34ANeuralNetworksExecution_setOutputP24ANeuralNetworksExecutioniPK26ANeuralNetworksOperandTypePvm">ANeuralNetworksExecution_setOutput</dfn>(</td></tr>
<tr><th id="1818">1818</th><td>    <a class="typedef" href="#ANeuralNetworksExecution" title='ANeuralNetworksExecution' data-type='struct ANeuralNetworksExecution' data-ref="ANeuralNetworksExecution">ANeuralNetworksExecution</a>* <dfn class="local col2 decl" id="382execution" title='execution' data-type='ANeuralNetworksExecution *' data-ref="382execution">execution</dfn>, <a class="typedef" href="../../../../../include/x86_64-linux-gnu/sys/types.h.html#196" title='int32_t' data-type='int' data-ref="int32_t">int32_t</a> <dfn class="local col3 decl" id="383index" title='index' data-type='int32_t' data-ref="383index">index</dfn>,</td></tr>
<tr><th id="1819">1819</th><td>    <em>const</em> <a class="typedef" href="#ANeuralNetworksOperandType" title='ANeuralNetworksOperandType' data-type='struct ANeuralNetworksOperandType' data-ref="ANeuralNetworksOperandType">ANeuralNetworksOperandType</a>* <dfn class="local col4 decl" id="384type" title='type' data-type='const ANeuralNetworksOperandType *' data-ref="384type">type</dfn>, <em>void</em>* <dfn class="local col5 decl" id="385buffer" title='buffer' data-type='void *' data-ref="385buffer">buffer</dfn>, <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <dfn class="local col6 decl" id="386length" title='length' data-type='size_t' data-ref="386length">length</dfn>) {</td></tr>
<tr><th id="1820">1820</th><td>  <a class="macro" href="#26" title="static ANeuralNetworksExecution_setOutput_fn fn = reinterpret_cast&lt;ANeuralNetworksExecution_setOutput_fn&gt;(loadFunction(&quot;ANeuralNetworksExecution_setOutput&quot;));" data-ref="_M/LOAD_FUNCTION">LOAD_FUNCTION</a>(ANeuralNetworksExecution_setOutput);</td></tr>
<tr><th id="1821">1821</th><td>  <a class="macro" href="#32" title="return fn != nullptr ? fn(execution, index, type, buffer, length) : 0;" data-ref="_M/EXECUTE_FUNCTION_RETURN">EXECUTE_FUNCTION_RETURN</a>(<a class="local col2 ref" href="#382execution" title='execution' data-ref="382execution">execution</a>, <a class="local col3 ref" href="#383index" title='index' data-ref="383index">index</a>, <a class="local col4 ref" href="#384type" title='type' data-ref="384type">type</a>, <a class="local col5 ref" href="#385buffer" title='buffer' data-ref="385buffer">buffer</a>, <a class="local col6 ref" href="#386length" title='length' data-ref="386length">length</a>);</td></tr>
<tr><th id="1822">1822</th><td>}</td></tr>
<tr><th id="1823">1823</th><td></td></tr>
<tr><th id="1824">1824</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1825">1825</th><td><i class="doc"> * Associate part of a memory object with an output of the model of the</i></td></tr>
<tr><th id="1826">1826</th><td><i class="doc"> * {<span class="command">@link</span><span class="verb"> ANeuralNetworksExecution}.</span></i></td></tr>
<tr><th id="1827">1827</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1828">1828</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> &lt;p&gt;The provided memory must outlive the execution.&lt;/p&gt;</span></i></td></tr>
<tr><th id="1829">1829</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1830">1830</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> See {@link ANeuralNetworksExecution} for information on multithreaded usage.</span></i></td></tr>
<tr><th id="1831">1831</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1832">1832</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param execution The execution to be modified.</span></i></td></tr>
<tr><th id="1833">1833</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param index The index of the output argument we are setting. It is</span></i></td></tr>
<tr><th id="1834">1834</th><td><i class="doc"><span class="verb"></span> *<span class="verb">              an index into the lists passed to</span></i></td></tr>
<tr><th id="1835">1835</th><td><i class="doc"><span class="verb"></span> *<span class="verb">              {@link ANeuralNetworksModel_identifyInputsAndOutputs}. It is not</span></i></td></tr>
<tr><th id="1836">1836</th><td><i class="doc"><span class="verb"></span> *<span class="verb">              the index associated with {@link</span></i></td></tr>
<tr><th id="1837">1837</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> ANeuralNetworksModel_addOperand}.</span></i></td></tr>
<tr><th id="1838">1838</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param type The type of the operand. This can be used to specify the</span></i></td></tr>
<tr><th id="1839">1839</th><td><i class="doc"><span class="verb"></span> *<span class="verb">             dimensions that were set to 0 when the operand was added to the</span></i></td></tr>
<tr><th id="1840">1840</th><td><i class="doc"><span class="verb"></span> *<span class="verb">             model. All other values must be the same as specified in the</span></i></td></tr>
<tr><th id="1841">1841</th><td><i class="doc"><span class="verb"></span> *<span class="verb">             model. If the type is the same as specified when the model</span></i></td></tr>
<tr><th id="1842">1842</th><td><i class="doc"><span class="verb"></span> *<span class="verb">             was built, NULL can be passed.</span></i></td></tr>
<tr><th id="1843">1843</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param memory The memory where the data is to be stored.</span></i></td></tr>
<tr><th id="1844">1844</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param offset This specifies the location of the data within the memory.</span></i></td></tr>
<tr><th id="1845">1845</th><td><i class="doc"><span class="verb"></span> *<span class="verb">               The offset is in bytes from the start of memory.</span></i></td></tr>
<tr><th id="1846">1846</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param length The length in bytes of the data value.</span></i></td></tr>
<tr><th id="1847">1847</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1848">1848</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @return ANEURALNETWORKS_NO_ERROR if successful, ANEURALNETWORKS_BAD_DATA if</span></i></td></tr>
<tr><th id="1849">1849</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> the name is not recognized or the buffer is too small for the output.</span></i></td></tr>
<tr><th id="1850">1850</th><td><i class="doc"><span class="verb"></span><span class="verb"> *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="1851">1851</th><td><span class="verb"></span><b>inline</b> <em>int</em> <dfn class="decl def" id="_Z44ANeuralNetworksExecution_setOutputFromMemoryP24ANeuralNetworksExecutioniPK26ANeuralNetworksOperandTypePK21ANeuralNetworksMemorymm" title='ANeuralNetworksExecution_setOutputFromMemory' data-ref="_Z44ANeuralNetworksExecution_setOutputFromMemoryP24ANeuralNetworksExecutioniPK26ANeuralNetworksOperandTypePK21ANeuralNetworksMemorymm">ANeuralNetworksExecution_setOutputFromMemory</dfn>(</td></tr>
<tr><th id="1852">1852</th><td>    <a class="typedef" href="#ANeuralNetworksExecution" title='ANeuralNetworksExecution' data-type='struct ANeuralNetworksExecution' data-ref="ANeuralNetworksExecution">ANeuralNetworksExecution</a>* <dfn class="local col8 decl" id="388execution" title='execution' data-type='ANeuralNetworksExecution *' data-ref="388execution">execution</dfn>, <a class="typedef" href="../../../../../include/x86_64-linux-gnu/sys/types.h.html#196" title='int32_t' data-type='int' data-ref="int32_t">int32_t</a> <dfn class="local col9 decl" id="389index" title='index' data-type='int32_t' data-ref="389index">index</dfn>,</td></tr>
<tr><th id="1853">1853</th><td>    <em>const</em> <a class="typedef" href="#ANeuralNetworksOperandType" title='ANeuralNetworksOperandType' data-type='struct ANeuralNetworksOperandType' data-ref="ANeuralNetworksOperandType">ANeuralNetworksOperandType</a>* <dfn class="local col0 decl" id="390type" title='type' data-type='const ANeuralNetworksOperandType *' data-ref="390type">type</dfn>, <em>const</em> <a class="typedef" href="#ANeuralNetworksMemory" title='ANeuralNetworksMemory' data-type='struct ANeuralNetworksMemory' data-ref="ANeuralNetworksMemory">ANeuralNetworksMemory</a>* <dfn class="local col1 decl" id="391memory" title='memory' data-type='const ANeuralNetworksMemory *' data-ref="391memory">memory</dfn>,</td></tr>
<tr><th id="1854">1854</th><td>    <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <dfn class="local col2 decl" id="392offset" title='offset' data-type='size_t' data-ref="392offset">offset</dfn>, <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <dfn class="local col3 decl" id="393length" title='length' data-type='size_t' data-ref="393length">length</dfn>) {</td></tr>
<tr><th id="1855">1855</th><td>  <a class="macro" href="#26" title="static ANeuralNetworksExecution_setOutputFromMemory_fn fn = reinterpret_cast&lt;ANeuralNetworksExecution_setOutputFromMemory_fn&gt;(loadFunction(&quot;ANeuralNetworksExecution_setOutputFromMemory&quot;));" data-ref="_M/LOAD_FUNCTION">LOAD_FUNCTION</a>(ANeuralNetworksExecution_setOutputFromMemory);</td></tr>
<tr><th id="1856">1856</th><td>  <a class="macro" href="#32" title="return fn != nullptr ? fn(execution, index, type, memory, offset, length) : 0;" data-ref="_M/EXECUTE_FUNCTION_RETURN">EXECUTE_FUNCTION_RETURN</a>(<a class="local col8 ref" href="#388execution" title='execution' data-ref="388execution">execution</a>, <a class="local col9 ref" href="#389index" title='index' data-ref="389index">index</a>, <a class="local col0 ref" href="#390type" title='type' data-ref="390type">type</a>, <a class="local col1 ref" href="#391memory" title='memory' data-ref="391memory">memory</a>, <a class="local col2 ref" href="#392offset" title='offset' data-ref="392offset">offset</a>, <a class="local col3 ref" href="#393length" title='length' data-ref="393length">length</a>);</td></tr>
<tr><th id="1857">1857</th><td>}</td></tr>
<tr><th id="1858">1858</th><td></td></tr>
<tr><th id="1859">1859</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1860">1860</th><td><i class="doc"> * Schedule evaluation of the execution.</i></td></tr>
<tr><th id="1861">1861</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1862">1862</th><td><i class="doc"> * <span class="tag">&lt;p&gt;</span>Schedules evaluation of the execution. Once the model has been</i></td></tr>
<tr><th id="1863">1863</th><td><i class="doc"> * applied and the outputs are ready to be consumed, the execution will be</i></td></tr>
<tr><th id="1864">1864</th><td><i class="doc"> * signaled. Use {<span class="command">@link</span><span class="verb"> ANeuralNetworksExecution_wait} to wait for that signal.</span></i></td></tr>
<tr><th id="1865">1865</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> &lt;/p&gt;</span></i></td></tr>
<tr><th id="1866">1866</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1867">1867</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> Multiple executions can be scheduled and evaluated concurrently, and</span></i></td></tr>
<tr><th id="1868">1868</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> compilations can be performed concurrently with executions. The runtime makes</span></i></td></tr>
<tr><th id="1869">1869</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> no guarantee on the ordering of the completion of compilations and</span></i></td></tr>
<tr><th id="1870">1870</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> executions. If it's important to the application, the application should</span></i></td></tr>
<tr><th id="1871">1871</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> enforce the ordering by using {@link ANeuralNetworksCompilation_wait} and</span></i></td></tr>
<tr><th id="1872">1872</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> {@link ANeuralNetworksExecution_wait}.</span></i></td></tr>
<tr><th id="1873">1873</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1874">1874</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> ANeuralNetworksExecution_wait must be called to recuperate the resources used</span></i></td></tr>
<tr><th id="1875">1875</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> by the execution.</span></i></td></tr>
<tr><th id="1876">1876</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1877">1877</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> See {@link ANeuralNetworksExecution} for information on multithreaded usage.</span></i></td></tr>
<tr><th id="1878">1878</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1879">1879</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @param execution The execution to be scheduled and executed.</span></i></td></tr>
<tr><th id="1880">1880</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1881">1881</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @return ANEURALNETWORKS_NO_ERROR if successful.</span></i></td></tr>
<tr><th id="1882">1882</th><td><i class="doc"><span class="verb"></span><span class="verb"> *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="1883">1883</th><td><span class="verb"></span><b>inline</b> <em>int</em> <dfn class="decl def" id="_Z37ANeuralNetworksExecution_startComputeP24ANeuralNetworksExecutionPP20ANeuralNetworksEvent" title='ANeuralNetworksExecution_startCompute' data-ref="_Z37ANeuralNetworksExecution_startComputeP24ANeuralNetworksExecutionPP20ANeuralNetworksEvent">ANeuralNetworksExecution_startCompute</dfn>(</td></tr>
<tr><th id="1884">1884</th><td>    <a class="typedef" href="#ANeuralNetworksExecution" title='ANeuralNetworksExecution' data-type='struct ANeuralNetworksExecution' data-ref="ANeuralNetworksExecution">ANeuralNetworksExecution</a>* <dfn class="local col5 decl" id="395execution" title='execution' data-type='ANeuralNetworksExecution *' data-ref="395execution">execution</dfn>, <a class="typedef" href="#ANeuralNetworksEvent" title='ANeuralNetworksEvent' data-type='struct ANeuralNetworksEvent' data-ref="ANeuralNetworksEvent">ANeuralNetworksEvent</a>** <dfn class="local col6 decl" id="396event" title='event' data-type='ANeuralNetworksEvent **' data-ref="396event">event</dfn>) {</td></tr>
<tr><th id="1885">1885</th><td>  <a class="macro" href="#26" title="static ANeuralNetworksExecution_startCompute_fn fn = reinterpret_cast&lt;ANeuralNetworksExecution_startCompute_fn&gt;(loadFunction(&quot;ANeuralNetworksExecution_startCompute&quot;));" data-ref="_M/LOAD_FUNCTION">LOAD_FUNCTION</a>(ANeuralNetworksExecution_startCompute);</td></tr>
<tr><th id="1886">1886</th><td>  <a class="macro" href="#32" title="return fn != nullptr ? fn(execution, event) : 0;" data-ref="_M/EXECUTE_FUNCTION_RETURN">EXECUTE_FUNCTION_RETURN</a>(<a class="local col5 ref" href="#395execution" title='execution' data-ref="395execution">execution</a>, <a class="local col6 ref" href="#396event" title='event' data-ref="396event">event</a>);</td></tr>
<tr><th id="1887">1887</th><td>}</td></tr>
<tr><th id="1888">1888</th><td></td></tr>
<tr><th id="1889">1889</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1890">1890</th><td><i class="doc"> * Waits until the execution completes.</i></td></tr>
<tr><th id="1891">1891</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1892">1892</th><td><i class="doc"> * More than one thread can wait on an event. When the execution completes,</i></td></tr>
<tr><th id="1893">1893</th><td><i class="doc"> * all threads will be released.</i></td></tr>
<tr><th id="1894">1894</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1895">1895</th><td><i class="doc"> * See {<span class="command">@link</span><span class="verb"> ANeuralNetworksExecution} for information on multithreaded usage.</span></i></td></tr>
<tr><th id="1896">1896</th><td><i class="doc"><span class="verb"></span> *<span class="verb"></span></i></td></tr>
<tr><th id="1897">1897</th><td><i class="doc"><span class="verb"></span> *<span class="verb"> @return ANEURALNETWORKS_NO_ERROR if the execution completed normally.</span></i></td></tr>
<tr><th id="1898">1898</th><td><i class="doc"><span class="verb"></span><span class="verb"> *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="1899">1899</th><td><span class="verb"></span><b>inline</b> <em>int</em> <dfn class="decl def" id="_Z25ANeuralNetworksEvent_waitP20ANeuralNetworksEvent" title='ANeuralNetworksEvent_wait' data-ref="_Z25ANeuralNetworksEvent_waitP20ANeuralNetworksEvent">ANeuralNetworksEvent_wait</dfn>(<a class="typedef" href="#ANeuralNetworksEvent" title='ANeuralNetworksEvent' data-type='struct ANeuralNetworksEvent' data-ref="ANeuralNetworksEvent">ANeuralNetworksEvent</a>* <dfn class="local col8 decl" id="398event" title='event' data-type='ANeuralNetworksEvent *' data-ref="398event">event</dfn>) {</td></tr>
<tr><th id="1900">1900</th><td>  <a class="macro" href="#26" title="static ANeuralNetworksEvent_wait_fn fn = reinterpret_cast&lt;ANeuralNetworksEvent_wait_fn&gt;(loadFunction(&quot;ANeuralNetworksEvent_wait&quot;));" data-ref="_M/LOAD_FUNCTION">LOAD_FUNCTION</a>(ANeuralNetworksEvent_wait);</td></tr>
<tr><th id="1901">1901</th><td>  <a class="macro" href="#32" title="return fn != nullptr ? fn(event) : 0;" data-ref="_M/EXECUTE_FUNCTION_RETURN">EXECUTE_FUNCTION_RETURN</a>(<a class="local col8 ref" href="#398event" title='event' data-ref="398event">event</a>);</td></tr>
<tr><th id="1902">1902</th><td>}</td></tr>
<tr><th id="1903">1903</th><td></td></tr>
<tr><th id="1904">1904</th><td><i class="doc">/**</i></td></tr>
<tr><th id="1905">1905</th><td><i class="doc"> * Destroys the event.</i></td></tr>
<tr><th id="1906">1906</th><td><i class="doc"> *</i></td></tr>
<tr><th id="1907">1907</th><td><i class="doc"> * See {<span class="command">@link</span><span class="verb"> ANeuralNetworksExecution} for information on multithreaded usage.</span></i></td></tr>
<tr><th id="1908">1908</th><td><i class="doc"><span class="verb"></span><span class="verb"> *</span>/</i><span class="verb"></span></td></tr>
<tr><th id="1909">1909</th><td><span class="verb"></span><b>inline</b> <em>void</em> <dfn class="decl def" id="_Z25ANeuralNetworksEvent_freeP20ANeuralNetworksEvent" title='ANeuralNetworksEvent_free' data-ref="_Z25ANeuralNetworksEvent_freeP20ANeuralNetworksEvent">ANeuralNetworksEvent_free</dfn>(<a class="typedef" href="#ANeuralNetworksEvent" title='ANeuralNetworksEvent' data-type='struct ANeuralNetworksEvent' data-ref="ANeuralNetworksEvent">ANeuralNetworksEvent</a>* <dfn class="local col0 decl" id="400event" title='event' data-type='ANeuralNetworksEvent *' data-ref="400event">event</dfn>) {</td></tr>
<tr><th id="1910">1910</th><td>  <a class="macro" href="#26" title="static ANeuralNetworksEvent_free_fn fn = reinterpret_cast&lt;ANeuralNetworksEvent_free_fn&gt;(loadFunction(&quot;ANeuralNetworksEvent_free&quot;));" data-ref="_M/LOAD_FUNCTION">LOAD_FUNCTION</a>(ANeuralNetworksEvent_free);</td></tr>
<tr><th id="1911">1911</th><td>  <a class="macro" href="#28" title="if (fn != nullptr) { fn(event); }" data-ref="_M/EXECUTE_FUNCTION">EXECUTE_FUNCTION</a>(<a class="local col0 ref" href="#400event" title='event' data-ref="400event">event</a>);</td></tr>
<tr><th id="1912">1912</th><td>}</td></tr>
<tr><th id="1913">1913</th><td></td></tr>
<tr><th id="1914">1914</th><td><i class="doc">/**/</i></td></tr>
<tr><th id="1915">1915</th><td></td></tr>
<tr><th id="1916">1916</th><td><u>#<span data-ppcond="15">endif</span>  // NN_API_SHIM_H0</u></td></tr>
<tr><th id="1917">1917</th><td></td></tr>
</table><hr/><p id='footer'>
Generated while processing <a href='../allocation.cc.html'>tensorflow/tensorflow/contrib/lite/allocation.cc</a><br/>Generated on <em>2018-Aug-16</em> from project tensorflow revision <em>v1.8</em><br />Powered by <a href='https://woboq.com'><img alt='Woboq' src='https://code.woboq.org/woboq-16.png' width='41' height='16' /></a> <a href='https://code.woboq.org'>Code Browser</a> 2.1
<br/>Generator usage only permitted with license.</p>
</div></body></html>
