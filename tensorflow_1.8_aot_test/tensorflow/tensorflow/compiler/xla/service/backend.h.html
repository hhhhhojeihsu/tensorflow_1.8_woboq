<!doctype html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0"><title>backend.h source code [tensorflow/tensorflow/compiler/xla/service/backend.h] - Woboq Code Browser</title>
<meta name="woboq:interestingDefinitions" content="xla::Backend,xla::BackendOptions "/>
<link rel="stylesheet" href="https://code.woboq.org/data/qtcreator.css" title="QtCreator"/>
<link rel="alternate stylesheet" href="https://code.woboq.org/data/kdevelop.css" title="KDevelop"/>
<script type="text/javascript" src="https://code.woboq.org/data/jquery/jquery.min.js"></script>
<script type="text/javascript" src="https://code.woboq.org/data/jquery/jquery-ui.min.js"></script>
<script>var file = 'tensorflow/tensorflow/compiler/xla/service/backend.h'; var root_path = '../../../../..'; var data_path = 'https://code.woboq.org/data';</script>
<script src='https://code.woboq.org/data/codebrowser.js'></script>
</head>
<body><div id='header'><h1 id='breadcrumb'><span>Browse the source code of </span><a href='../../../..'>tensorflow</a>/<a href='../../..'>tensorflow</a>/<a href='../..'>compiler</a>/<a href='..'>xla</a>/<a href='./'>service</a>/<a href='backend.h.html'>backend.h</a></h1></div>
<hr/><div id='content'><table class="code">
<tr><th id="1">1</th><td><i>/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.</i></td></tr>
<tr><th id="2">2</th><td><i></i></td></tr>
<tr><th id="3">3</th><td><i>Licensed under the Apache License, Version 2.0 (the "License");</i></td></tr>
<tr><th id="4">4</th><td><i>you may not use this file except in compliance with the License.</i></td></tr>
<tr><th id="5">5</th><td><i>You may obtain a copy of the License at</i></td></tr>
<tr><th id="6">6</th><td><i></i></td></tr>
<tr><th id="7">7</th><td><i>    <a href="http://www.apache.org/licenses/LICENSE-2.0">http://www.apache.org/licenses/LICENSE-2.0</a></i></td></tr>
<tr><th id="8">8</th><td><i></i></td></tr>
<tr><th id="9">9</th><td><i>Unless required by applicable law or agreed to in writing, software</i></td></tr>
<tr><th id="10">10</th><td><i>distributed under the License is distributed on an "AS IS" BASIS,</i></td></tr>
<tr><th id="11">11</th><td><i>WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</i></td></tr>
<tr><th id="12">12</th><td><i>See the License for the specific language governing permissions and</i></td></tr>
<tr><th id="13">13</th><td><i>limitations under the License.</i></td></tr>
<tr><th id="14">14</th><td><i>==============================================================================*/</i></td></tr>
<tr><th id="15">15</th><td></td></tr>
<tr><th id="16">16</th><td><u>#<span data-ppcond="16">ifndef</span> <span class="macro" data-ref="_M/TENSORFLOW_COMPILER_XLA_SERVICE_BACKEND_H_">TENSORFLOW_COMPILER_XLA_SERVICE_BACKEND_H_</span></u></td></tr>
<tr><th id="17">17</th><td><u>#define <dfn class="macro" id="_M/TENSORFLOW_COMPILER_XLA_SERVICE_BACKEND_H_" data-ref="_M/TENSORFLOW_COMPILER_XLA_SERVICE_BACKEND_H_">TENSORFLOW_COMPILER_XLA_SERVICE_BACKEND_H_</dfn></u></td></tr>
<tr><th id="18">18</th><td></td></tr>
<tr><th id="19">19</th><td><u>#include <a href="../../../../../include/c++/5/map.html">&lt;map&gt;</a></u></td></tr>
<tr><th id="20">20</th><td><u>#include <a href="../../../../../include/c++/5/memory.html">&lt;memory&gt;</a></u></td></tr>
<tr><th id="21">21</th><td><u>#include <a href="../../../../../include/c++/5/string.html">&lt;string&gt;</a></u></td></tr>
<tr><th id="22">22</th><td><u>#include <a href="../../../../../include/c++/5/vector.html">&lt;vector&gt;</a></u></td></tr>
<tr><th id="23">23</th><td></td></tr>
<tr><th id="24">24</th><td><u>#include <a href="compiler.h.html">"tensorflow/compiler/xla/service/compiler.h"</a></u></td></tr>
<tr><th id="25">25</th><td><u>#include <a href="computation_placer.h.html">"tensorflow/compiler/xla/service/computation_placer.h"</a></u></td></tr>
<tr><th id="26">26</th><td><u>#include <a href="device_memory_allocator.h.html">"tensorflow/compiler/xla/service/device_memory_allocator.h"</a></u></td></tr>
<tr><th id="27">27</th><td><u>#include <a href="pool.h.html">"tensorflow/compiler/xla/service/pool.h"</a></u></td></tr>
<tr><th id="28">28</th><td><u>#include <a href="transfer_manager.h.html">"tensorflow/compiler/xla/service/transfer_manager.h"</a></u></td></tr>
<tr><th id="29">29</th><td><u>#include <a href="../statusor.h.html">"tensorflow/compiler/xla/statusor.h"</a></u></td></tr>
<tr><th id="30">30</th><td><u>#include <a href="../types.h.html">"tensorflow/compiler/xla/types.h"</a></u></td></tr>
<tr><th id="31">31</th><td><u>#include <a href="../../../core/lib/gtl/array_slice.h.html">"tensorflow/core/lib/gtl/array_slice.h"</a></u></td></tr>
<tr><th id="32">32</th><td><u>#include <a href="../../../core/lib/strings/strcat.h.html">"tensorflow/core/lib/strings/strcat.h"</a></u></td></tr>
<tr><th id="33">33</th><td><u>#include <a href="../../../core/platform/mutex.h.html">"tensorflow/core/platform/mutex.h"</a></u></td></tr>
<tr><th id="34">34</th><td><u>#include <a href="../../../core/platform/stream_executor_no_cuda.h.html">"tensorflow/core/platform/stream_executor_no_cuda.h"</a></u></td></tr>
<tr><th id="35">35</th><td><u>#include <a href="../../../core/platform/thread_annotations.h.html">"tensorflow/core/platform/thread_annotations.h"</a></u></td></tr>
<tr><th id="36">36</th><td></td></tr>
<tr><th id="37">37</th><td><b>namespace</b> <span class="namespace">Eigen</span> {</td></tr>
<tr><th id="38">38</th><td><b>struct</b> <dfn class='type' title='Eigen::ThreadPoolDevice' data-ref="Eigen::ThreadPoolDevice" id="Eigen::ThreadPoolDevice">ThreadPoolDevice</dfn>;</td></tr>
<tr><th id="39">39</th><td>}</td></tr>
<tr><th id="40">40</th><td></td></tr>
<tr><th id="41">41</th><td><b>namespace</b> <span class="namespace">xla</span> {</td></tr>
<tr><th id="42">42</th><td></td></tr>
<tr><th id="43">43</th><td><i>// Options to configure the backend when it is created.</i></td></tr>
<tr><th id="44">44</th><td><b>class</b> <dfn class="type def" id="xla::BackendOptions" title='xla::BackendOptions' data-ref="xla::BackendOptions">BackendOptions</dfn> {</td></tr>
<tr><th id="45">45</th><td> <b>public</b>:</td></tr>
<tr><th id="46">46</th><td>  <i>// Set the platform backing the backend, or nullptr for the default platform.</i></td></tr>
<tr><th id="47">47</th><td>  <a class="type" href="#xla::BackendOptions" title='xla::BackendOptions' data-ref="xla::BackendOptions">BackendOptions</a>&amp; <dfn class="decl" id="_ZN3xla14BackendOptions12set_platformEPN9perftools8gputools8PlatformE" title='xla::BackendOptions::set_platform' data-ref="_ZN3xla14BackendOptions12set_platformEPN9perftools8gputools8PlatformE">set_platform</dfn>(<span class="namespace">perftools::gputools::</span><a class="type" href="../../../stream_executor/platform.h.html#perftools::gputools::Platform" title='perftools::gputools::Platform' data-ref="perftools::gputools::Platform">Platform</a>* <dfn class="local col8 decl" id="178platform" title='platform' data-type='perftools::gputools::Platform *' data-ref="178platform">platform</dfn>);</td></tr>
<tr><th id="48">48</th><td>  <span class="namespace">perftools::gputools::</span><a class="type" href="../../../stream_executor/platform.h.html#perftools::gputools::Platform" title='perftools::gputools::Platform' data-ref="perftools::gputools::Platform">Platform</a>* <dfn class="decl" id="_ZNK3xla14BackendOptions8platformEv" title='xla::BackendOptions::platform' data-ref="_ZNK3xla14BackendOptions8platformEv">platform</dfn>() <em>const</em>;</td></tr>
<tr><th id="49">49</th><td></td></tr>
<tr><th id="50">50</th><td>  <i>// Sets the thread pool size for parallel execution of an individual operator.</i></td></tr>
<tr><th id="51">51</th><td><i>  // The default value of -1 will result in initializing the thread pool with</i></td></tr>
<tr><th id="52">52</th><td><i>  // the number of threads equal to the number of cores in the system.</i></td></tr>
<tr><th id="53">53</th><td>  <a class="type" href="#xla::BackendOptions" title='xla::BackendOptions' data-ref="xla::BackendOptions">BackendOptions</a>&amp; <dfn class="decl" id="_ZN3xla14BackendOptions32set_intra_op_parallelism_threadsEi" title='xla::BackendOptions::set_intra_op_parallelism_threads' data-ref="_ZN3xla14BackendOptions32set_intra_op_parallelism_threadsEi">set_intra_op_parallelism_threads</dfn>(<em>int</em> <dfn class="local col9 decl" id="179num_threads" title='num_threads' data-type='int' data-ref="179num_threads">num_threads</dfn>);</td></tr>
<tr><th id="54">54</th><td>  <em>int</em> <dfn class="decl" id="_ZNK3xla14BackendOptions28intra_op_parallelism_threadsEv" title='xla::BackendOptions::intra_op_parallelism_threads' data-ref="_ZNK3xla14BackendOptions28intra_op_parallelism_threadsEv">intra_op_parallelism_threads</dfn>() <em>const</em>;</td></tr>
<tr><th id="55">55</th><td></td></tr>
<tr><th id="56">56</th><td> <b>private</b>:</td></tr>
<tr><th id="57">57</th><td>  <span class="namespace">perftools::gputools::</span><a class="type" href="../../../stream_executor/platform.h.html#perftools::gputools::Platform" title='perftools::gputools::Platform' data-ref="perftools::gputools::Platform">Platform</a>* <dfn class="decl" id="xla::BackendOptions::platform_" title='xla::BackendOptions::platform_' data-ref="xla::BackendOptions::platform_">platform_</dfn> = <b>nullptr</b>;</td></tr>
<tr><th id="58">58</th><td>  <em>int</em> <dfn class="decl" id="xla::BackendOptions::intra_op_parallelism_threads_" title='xla::BackendOptions::intra_op_parallelism_threads_' data-ref="xla::BackendOptions::intra_op_parallelism_threads_">intra_op_parallelism_threads_</dfn> = -<var>1</var>;</td></tr>
<tr><th id="59">59</th><td>};</td></tr>
<tr><th id="60">60</th><td></td></tr>
<tr><th id="61">61</th><td><i>// Class which encapsulates an XLA backend. It includes everything necessary</i></td></tr>
<tr><th id="62">62</th><td><i>// to compile and execute computations on a particular platform.</i></td></tr>
<tr><th id="63">63</th><td><i>//</i></td></tr>
<tr><th id="64">64</th><td><i>// It also offers a pooling API for creation/use of initialized streams:</i></td></tr>
<tr><th id="65">65</th><td><i>//</i></td></tr>
<tr><th id="66">66</th><td><i>//    StreamPtr stream = backend-&gt;BorrowStream().ConsumeValueOrDie();</i></td></tr>
<tr><th id="67">67</th><td><b>class</b> <dfn class="type def" id="xla::Backend" title='xla::Backend' data-ref="xla::Backend">Backend</dfn> {</td></tr>
<tr><th id="68">68</th><td> <b>public</b>:</td></tr>
<tr><th id="69">69</th><td>  <b>using</b> <dfn class="typedef" id="xla::Backend::StreamPtr" title='xla::Backend::StreamPtr' data-type='Pool&lt;perftools::gputools::Stream&gt;::SmartPtr' data-ref="xla::Backend::StreamPtr">StreamPtr</dfn> = <a class="type" href="pool.h.html#xla::Pool" title='xla::Pool' data-ref="xla::Pool">Pool</a>&lt;<span class="namespace">perftools::gputools::</span><a class="type" href="../../../stream_executor/stream.h.html#perftools::gputools::Stream" title='perftools::gputools::Stream' data-ref="perftools::gputools::Stream">Stream</a>&gt;::<a class="typedef" href="pool.h.html#xla::Pool{perftools::gputools::Stream}::SmartPtr" title='xla::Pool&lt;perftools::gputools::Stream&gt;::SmartPtr' data-type='std::unique_ptr&lt;Stream, Deleter&gt;' data-ref="xla::Pool{perftools::gputools::Stream}::SmartPtr">SmartPtr</a>;</td></tr>
<tr><th id="70">70</th><td></td></tr>
<tr><th id="71">71</th><td>  <i>// Creates a new backend.</i></td></tr>
<tr><th id="72">72</th><td>  <em>static</em> <a class="type" href="../statusor.h.html#xla::StatusOr" title='xla::StatusOr' data-ref="xla::StatusOr">StatusOr</a>&lt;<span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/unique_ptr.h.html#std::unique_ptr" title='std::unique_ptr' data-ref="std::unique_ptr">unique_ptr</a>&lt;<a class="type" href="#xla::Backend" title='xla::Backend' data-ref="xla::Backend">Backend</a>&gt;&gt; <dfn class="decl" id="_ZN3xla7Backend13CreateBackendERKNS_14BackendOptionsE" title='xla::Backend::CreateBackend' data-ref="_ZN3xla7Backend13CreateBackendERKNS_14BackendOptionsE">CreateBackend</dfn>(</td></tr>
<tr><th id="73">73</th><td>      <em>const</em> <a class="type" href="#xla::BackendOptions" title='xla::BackendOptions' data-ref="xla::BackendOptions">BackendOptions</a>&amp; <dfn class="local col0 decl" id="180options" title='options' data-type='const xla::BackendOptions &amp;' data-ref="180options">options</dfn>);</td></tr>
<tr><th id="74">74</th><td></td></tr>
<tr><th id="75">75</th><td>  <i>// Creates a backend for the default platform. The default platform is defined</i></td></tr>
<tr><th id="76">76</th><td><i>  // in PlatformUtil.</i></td></tr>
<tr><th id="77">77</th><td>  <em>static</em> <a class="type" href="../statusor.h.html#xla::StatusOr" title='xla::StatusOr' data-ref="xla::StatusOr">StatusOr</a>&lt;<span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/unique_ptr.h.html#std::unique_ptr" title='std::unique_ptr' data-ref="std::unique_ptr">unique_ptr</a>&lt;<a class="type" href="#xla::Backend" title='xla::Backend' data-ref="xla::Backend">Backend</a>&gt;&gt; <dfn class="decl" id="_ZN3xla7Backend20CreateDefaultBackendEv" title='xla::Backend::CreateDefaultBackend' data-ref="_ZN3xla7Backend20CreateDefaultBackendEv">CreateDefaultBackend</dfn>();</td></tr>
<tr><th id="78">78</th><td></td></tr>
<tr><th id="79">79</th><td>  <dfn class="decl" id="_ZN3xla7BackendD1Ev" title='xla::Backend::~Backend' data-ref="_ZN3xla7BackendD1Ev">~Backend</dfn>();</td></tr>
<tr><th id="80">80</th><td></td></tr>
<tr><th id="81">81</th><td>  <i>// Accessors for the various objects.</i></td></tr>
<tr><th id="82">82</th><td>  <span class="namespace">perftools::gputools::</span><a class="type" href="../../../stream_executor/platform.h.html#perftools::gputools::Platform" title='perftools::gputools::Platform' data-ref="perftools::gputools::Platform">Platform</a>* <dfn class="decl def" id="_ZNK3xla7Backend8platformEv" title='xla::Backend::platform' data-ref="_ZNK3xla7Backend8platformEv">platform</dfn>() <em>const</em> { <b>return</b> <a class="member" href="#xla::Backend::platform_" title='xla::Backend::platform_' data-ref="xla::Backend::platform_">platform_</a>; }</td></tr>
<tr><th id="83">83</th><td>  <a class="type" href="compiler.h.html#xla::Compiler" title='xla::Compiler' data-ref="xla::Compiler">Compiler</a>* <dfn class="decl def" id="_ZNK3xla7Backend8compilerEv" title='xla::Backend::compiler' data-ref="_ZNK3xla7Backend8compilerEv">compiler</dfn>() <em>const</em> { <b>return</b> <a class="member" href="#xla::Backend::compiler_" title='xla::Backend::compiler_' data-ref="xla::Backend::compiler_">compiler_</a>; }</td></tr>
<tr><th id="84">84</th><td>  <a class="type" href="device_memory_allocator.h.html#xla::DeviceMemoryAllocator" title='xla::DeviceMemoryAllocator' data-ref="xla::DeviceMemoryAllocator">DeviceMemoryAllocator</a>* <dfn class="decl def" id="_ZNK3xla7Backend16memory_allocatorEv" title='xla::Backend::memory_allocator' data-ref="_ZNK3xla7Backend16memory_allocatorEv">memory_allocator</dfn>() <em>const</em> {</td></tr>
<tr><th id="85">85</th><td>    <b>return</b> <a class="member" href="#xla::Backend::memory_allocator_" title='xla::Backend::memory_allocator_' data-ref="xla::Backend::memory_allocator_">memory_allocator_</a>.<a class="ref" href="../../../../../include/c++/5/bits/unique_ptr.h.html#_ZNKSt10unique_ptr3getEv" title='std::unique_ptr::get' data-ref="_ZNKSt10unique_ptr3getEv">get</a>();</td></tr>
<tr><th id="86">86</th><td>  }</td></tr>
<tr><th id="87">87</th><td>  <a class="type" href="transfer_manager.h.html#xla::TransferManager" title='xla::TransferManager' data-ref="xla::TransferManager">TransferManager</a>* <dfn class="decl def" id="_ZNK3xla7Backend16transfer_managerEv" title='xla::Backend::transfer_manager' data-ref="_ZNK3xla7Backend16transfer_managerEv">transfer_manager</dfn>() <em>const</em> { <b>return</b> <a class="member" href="#xla::Backend::transfer_manager_" title='xla::Backend::transfer_manager_' data-ref="xla::Backend::transfer_manager_">transfer_manager_</a>; }</td></tr>
<tr><th id="88">88</th><td>  <a class="type" href="computation_placer.h.html#xla::ComputationPlacer" title='xla::ComputationPlacer' data-ref="xla::ComputationPlacer">ComputationPlacer</a>* <dfn class="decl def" id="_ZNK3xla7Backend18computation_placerEv" title='xla::Backend::computation_placer' data-ref="_ZNK3xla7Backend18computation_placerEv">computation_placer</dfn>() <em>const</em> { <b>return</b> <a class="member" href="#xla::Backend::computation_placer_" title='xla::Backend::computation_placer_' data-ref="xla::Backend::computation_placer_">computation_placer_</a>; }</td></tr>
<tr><th id="89">89</th><td></td></tr>
<tr><th id="90">90</th><td>  <i>// Returns the number of devices of the platform type which are visible. Not</i></td></tr>
<tr><th id="91">91</th><td><i>  // all of these devices may be usable by XLA.</i></td></tr>
<tr><th id="92">92</th><td>  <em>int</em> <dfn class="decl def" id="_ZNK3xla7Backend12device_countEv" title='xla::Backend::device_count' data-ref="_ZNK3xla7Backend12device_countEv">device_count</dfn>() <em>const</em> { <b>return</b> <a class="member" href="#xla::Backend::stream_executors_" title='xla::Backend::stream_executors_' data-ref="xla::Backend::stream_executors_">stream_executors_</a>.<a class="ref" href="../../../../../include/c++/5/bits/stl_vector.h.html#_ZNKSt6vector4sizeEv" title='std::vector::size' data-ref="_ZNKSt6vector4sizeEv">size</a>(); }</td></tr>
<tr><th id="93">93</th><td></td></tr>
<tr><th id="94">94</th><td>  <i>// Returns the device ordinal number of the default device.</i></td></tr>
<tr><th id="95">95</th><td>  <em>int</em> <dfn class="decl" id="_ZNK3xla7Backend22default_device_ordinalEv" title='xla::Backend::default_device_ordinal' data-ref="_ZNK3xla7Backend22default_device_ordinalEv">default_device_ordinal</dfn>() <em>const</em>;</td></tr>
<tr><th id="96">96</th><td></td></tr>
<tr><th id="97">97</th><td>  <i>// Returns stream executors of all supported devices for this backend. The</i></td></tr>
<tr><th id="98">98</th><td><i>  // executors are ordered by the device ordinal.</i></td></tr>
<tr><th id="99">99</th><td>  <em>const</em> <span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/stl_vector.h.html#std::vector" title='std::vector' data-ref="std::vector">vector</a>&lt;<span class="namespace">perftools::gputools::</span><a class="type" href="../../../stream_executor/stream_executor_pimpl.h.html#perftools::gputools::StreamExecutor" title='perftools::gputools::StreamExecutor' data-ref="perftools::gputools::StreamExecutor">StreamExecutor</a>*&gt;&amp; <dfn class="decl def" id="_ZNK3xla7Backend16stream_executorsEv" title='xla::Backend::stream_executors' data-ref="_ZNK3xla7Backend16stream_executorsEv">stream_executors</dfn>()</td></tr>
<tr><th id="100">100</th><td>      <em>const</em> {</td></tr>
<tr><th id="101">101</th><td>    <b>return</b> <a class="member" href="#xla::Backend::stream_executors_" title='xla::Backend::stream_executors_' data-ref="xla::Backend::stream_executors_">stream_executors_</a>;</td></tr>
<tr><th id="102">102</th><td>  }</td></tr>
<tr><th id="103">103</th><td></td></tr>
<tr><th id="104">104</th><td>  <i>// Returns the stream executor for the given device ordinal.</i></td></tr>
<tr><th id="105">105</th><td>  <a class="type" href="../statusor.h.html#xla::StatusOr" title='xla::StatusOr' data-ref="xla::StatusOr">StatusOr</a>&lt;<span class="namespace">perftools::gputools::</span><a class="type" href="../../../stream_executor/stream_executor_pimpl.h.html#perftools::gputools::StreamExecutor" title='perftools::gputools::StreamExecutor' data-ref="perftools::gputools::StreamExecutor">StreamExecutor</a>*&gt; <dfn class="decl" id="_ZNK3xla7Backend15stream_executorEi" title='xla::Backend::stream_executor' data-ref="_ZNK3xla7Backend15stream_executorEi">stream_executor</dfn>(</td></tr>
<tr><th id="106">106</th><td>      <em>int</em> <dfn class="local col1 decl" id="181device_ordinal" title='device_ordinal' data-type='int' data-ref="181device_ordinal">device_ordinal</dfn>) <em>const</em>;</td></tr>
<tr><th id="107">107</th><td></td></tr>
<tr><th id="108">108</th><td>  <i>// Returns the stream executor for the default device ordinal. This stream</i></td></tr>
<tr><th id="109">109</th><td><i>  // executor can only be used when the number of computations is 1 (replication</i></td></tr>
<tr><th id="110">110</th><td><i>  // can be &gt; 1).</i></td></tr>
<tr><th id="111">111</th><td>  <span class="namespace">perftools::gputools::</span><a class="type" href="../../../stream_executor/stream_executor_pimpl.h.html#perftools::gputools::StreamExecutor" title='perftools::gputools::StreamExecutor' data-ref="perftools::gputools::StreamExecutor">StreamExecutor</a>* <dfn class="decl def" id="_ZNK3xla7Backend23default_stream_executorEv" title='xla::Backend::default_stream_executor' data-ref="_ZNK3xla7Backend23default_stream_executorEv">default_stream_executor</dfn>() <em>const</em> {</td></tr>
<tr><th id="112">112</th><td>    <a class="macro" href="../../../core/platform/default/logging.h.html#97" title="if ((__builtin_expect(!(!stream_executors_.empty()), 0))) ::tensorflow::internal::LogMessageFatal(&quot;/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/./tensorflow/compiler/xla/service/backend.h&quot;, 112) &lt;&lt; &quot;Check failed: &quot; &quot;!stream_executors_.empty()&quot; &quot; &quot;" data-ref="_M/CHECK">CHECK</a>(!<a class="member" href="#xla::Backend::stream_executors_" title='xla::Backend::stream_executors_' data-ref="xla::Backend::stream_executors_">stream_executors_</a>.<a class="ref" href="../../../../../include/c++/5/bits/stl_vector.h.html#_ZNKSt6vector5emptyEv" title='std::vector::empty' data-ref="_ZNKSt6vector5emptyEv">empty</a>());</td></tr>
<tr><th id="113">113</th><td>    <b>return</b> <a class="member" href="#xla::Backend::stream_executors_" title='xla::Backend::stream_executors_' data-ref="xla::Backend::stream_executors_">stream_executors_</a><a class="ref" href="../../../../../include/c++/5/bits/stl_vector.h.html#_ZNKSt6vectorixEm" title='std::vector::operator[]' data-ref="_ZNKSt6vectorixEm">[<var>0</var>]</a>;</td></tr>
<tr><th id="114">114</th><td>  }</td></tr>
<tr><th id="115">115</th><td></td></tr>
<tr><th id="116">116</th><td>  <i>// Borrows a stream for use by the caller, either by grabbing it from an</i></td></tr>
<tr><th id="117">117</th><td><i>  // internal pool, or by constructing/initializating it, and returns the result</i></td></tr>
<tr><th id="118">118</th><td><i>  // to the caller.</i></td></tr>
<tr><th id="119">119</th><td>  <a class="type" href="../statusor.h.html#xla::StatusOr" title='xla::StatusOr' data-ref="xla::StatusOr">StatusOr</a>&lt;<a class="typedef" href="#xla::Backend::StreamPtr" title='xla::Backend::StreamPtr' data-type='Pool&lt;perftools::gputools::Stream&gt;::SmartPtr' data-ref="xla::Backend::StreamPtr">StreamPtr</a>&gt; <dfn class="decl" id="_ZN3xla7Backend12BorrowStreamEi" title='xla::Backend::BorrowStream' data-ref="_ZN3xla7Backend12BorrowStreamEi">BorrowStream</dfn>(<em>int</em> <dfn class="local col2 decl" id="182device_ordinal" title='device_ordinal' data-type='int' data-ref="182device_ordinal">device_ordinal</dfn>);</td></tr>
<tr><th id="120">120</th><td>  <a class="type" href="../statusor.h.html#xla::StatusOr" title='xla::StatusOr' data-ref="xla::StatusOr">StatusOr</a>&lt;<a class="typedef" href="#xla::Backend::StreamPtr" title='xla::Backend::StreamPtr' data-type='Pool&lt;perftools::gputools::Stream&gt;::SmartPtr' data-ref="xla::Backend::StreamPtr">StreamPtr</a>&gt; <dfn class="decl" id="_ZN3xla7Backend12BorrowStreamEPN9perftools8gputools14StreamExecutorE" title='xla::Backend::BorrowStream' data-ref="_ZN3xla7Backend12BorrowStreamEPN9perftools8gputools14StreamExecutorE">BorrowStream</dfn>(</td></tr>
<tr><th id="121">121</th><td>      <span class="namespace">perftools::gputools::</span><a class="type" href="../../../stream_executor/stream_executor_pimpl.h.html#perftools::gputools::StreamExecutor" title='perftools::gputools::StreamExecutor' data-ref="perftools::gputools::StreamExecutor">StreamExecutor</a>* <dfn class="local col3 decl" id="183executor" title='executor' data-type='perftools::gputools::StreamExecutor *' data-ref="183executor">executor</dfn>);</td></tr>
<tr><th id="122">122</th><td></td></tr>
<tr><th id="123">123</th><td>  <i>// Returns a function to borrow a stream, as `BorrowStream` above does.</i></td></tr>
<tr><th id="124">124</th><td><i>  // Purely for convenience, the caller could rather make this anonymous</i></td></tr>
<tr><th id="125">125</th><td><i>  // function itself.</i></td></tr>
<tr><th id="126">126</th><td>  <span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/functional.html#std::function" title='std::function' data-ref="std::function">function</a>&lt;<a class="type" href="../statusor.h.html#xla::StatusOr" title='xla::StatusOr' data-ref="xla::StatusOr">StatusOr</a>&lt;<a class="typedef" href="#xla::Backend::StreamPtr" title='xla::Backend::StreamPtr' data-type='Pool&lt;perftools::gputools::Stream&gt;::SmartPtr' data-ref="xla::Backend::StreamPtr">StreamPtr</a>&gt;(<em>int</em>)&gt; <dfn class="decl def" id="_ZN3xla7Backend14StreamBorrowerEv" title='xla::Backend::StreamBorrower' data-ref="_ZN3xla7Backend14StreamBorrowerEv">StreamBorrower</dfn>() {</td></tr>
<tr><th id="127">127</th><td>    <b>return</b> <a class="ref fake" href="../../../../../include/c++/5/functional.html#_ZNSt8functionIFT_DpT0_EEC1ET_" title='std::function&lt;type-parameter-0-0 (type-parameter-0-1...)&gt;::function&lt;type-parameter-0-0 (type-parameter-0-1...)&gt;' data-ref="_ZNSt8functionIFT_DpT0_EEC1ET_"></a>[<b>this</b>](<em>int</em> <dfn class="local col4 decl" id="184device_ordinal" title='device_ordinal' data-type='int' data-ref="184device_ordinal">device_ordinal</dfn>) { <b>return</b> <a class="member" href="#_ZN3xla7Backend12BorrowStreamEi" title='xla::Backend::BorrowStream' data-ref="_ZN3xla7Backend12BorrowStreamEi">BorrowStream</a>(<a class="local col4 ref" href="#184device_ordinal" title='device_ordinal' data-ref="184device_ordinal">device_ordinal</a>); };</td></tr>
<tr><th id="128">128</th><td>  }</td></tr>
<tr><th id="129">129</th><td></td></tr>
<tr><th id="130">130</th><td>  <i>// Returns whether the given device ordinal of the backend is supported.</i></td></tr>
<tr><th id="131">131</th><td>  <em>bool</em> <dfn class="decl def" id="_ZNK3xla7Backend24device_ordinal_supportedEi" title='xla::Backend::device_ordinal_supported' data-ref="_ZNK3xla7Backend24device_ordinal_supportedEi">device_ordinal_supported</dfn>(<em>int</em> <dfn class="local col5 decl" id="185device_ordinal" title='device_ordinal' data-type='int' data-ref="185device_ordinal">device_ordinal</dfn>) <em>const</em> {</td></tr>
<tr><th id="132">132</th><td>    <b>return</b> (<a class="local col5 ref" href="#185device_ordinal" title='device_ordinal' data-ref="185device_ordinal">device_ordinal</a> &gt;= <var>0</var> &amp;&amp; <a class="local col5 ref" href="#185device_ordinal" title='device_ordinal' data-ref="185device_ordinal">device_ordinal</a> &lt; <a class="member" href="#_ZNK3xla7Backend12device_countEv" title='xla::Backend::device_count' data-ref="_ZNK3xla7Backend12device_countEv">device_count</a>() &amp;&amp;</td></tr>
<tr><th id="133">133</th><td>            <a class="member" href="#xla::Backend::stream_executors_" title='xla::Backend::stream_executors_' data-ref="xla::Backend::stream_executors_">stream_executors_</a><a class="ref" href="../../../../../include/c++/5/bits/stl_vector.h.html#_ZNKSt6vectorixEm" title='std::vector::operator[]' data-ref="_ZNKSt6vectorixEm">[<a class="local col5 ref" href="#185device_ordinal" title='device_ordinal' data-ref="185device_ordinal">device_ordinal</a>]</a> != <b>nullptr</b>);</td></tr>
<tr><th id="134">134</th><td>  }</td></tr>
<tr><th id="135">135</th><td></td></tr>
<tr><th id="136">136</th><td>  <i>// Return a string identifier for the given device, eg: "GPU:3".</i></td></tr>
<tr><th id="137">137</th><td>  <a class="typedef" href="../../../../../include/c++/5/bits/stringfwd.h.html#std::string" title='std::string' data-type='basic_string&lt;char&gt;' data-ref="std::string">string</a> <dfn class="decl def" id="_ZNK3xla7Backend11device_nameEi" title='xla::Backend::device_name' data-ref="_ZNK3xla7Backend11device_nameEi">device_name</dfn>(<em>int</em> <dfn class="local col6 decl" id="186device_ordinal" title='device_ordinal' data-type='int' data-ref="186device_ordinal">device_ordinal</dfn>) <em>const</em> {</td></tr>
<tr><th id="138">138</th><td>    <b>return</b> <span class="namespace">tensorflow::strings::</span><a class="ref" href="../../../core/lib/strings/strcat.h.html#_ZN10tensorflow7strings6StrCatERKNS0_8AlphaNumES3_S3_" title='tensorflow::strings::StrCat' data-ref="_ZN10tensorflow7strings6StrCatERKNS0_8AlphaNumES3_S3_">StrCat</a>(<a class="ref fake" href="../../../core/lib/strings/strcat.h.html#_ZN10tensorflow7strings8AlphaNumC1ERKSs" title='tensorflow::strings::AlphaNum::AlphaNum' data-ref="_ZN10tensorflow7strings8AlphaNumC1ERKSs"></a><a class="member" href="#xla::Backend::platform_" title='xla::Backend::platform_' data-ref="xla::Backend::platform_">platform_</a>-&gt;<a class="virtual ref" href="../../../stream_executor/platform.h.html#_ZNK9perftools8gputools8Platform4NameEv" title='perftools::gputools::Platform::Name' data-ref="_ZNK9perftools8gputools8Platform4NameEv">Name</a>(), <a class="ref fake" href="../../../core/lib/strings/strcat.h.html#_ZN10tensorflow7strings8AlphaNumC1EPKc" title='tensorflow::strings::AlphaNum::AlphaNum' data-ref="_ZN10tensorflow7strings8AlphaNumC1EPKc"></a><q>":"</q>, <a class="ref fake" href="../../../core/lib/strings/strcat.h.html#_ZN10tensorflow7strings8AlphaNumC1Ei" title='tensorflow::strings::AlphaNum::AlphaNum' data-ref="_ZN10tensorflow7strings8AlphaNumC1Ei"></a><a class="local col6 ref" href="#186device_ordinal" title='device_ordinal' data-ref="186device_ordinal">device_ordinal</a>);</td></tr>
<tr><th id="139">139</th><td>  }</td></tr>
<tr><th id="140">140</th><td></td></tr>
<tr><th id="141">141</th><td>  <i>// Returns true if the devices with the given ordinals are equivalent from</i></td></tr>
<tr><th id="142">142</th><td><i>  // XLA's perspective. That is, an executable compiled for one device would</i></td></tr>
<tr><th id="143">143</th><td><i>  // be equivalent to an executable compiled for the other.</i></td></tr>
<tr><th id="144">144</th><td>  <a class="type" href="../statusor.h.html#xla::StatusOr" title='xla::StatusOr' data-ref="xla::StatusOr">StatusOr</a>&lt;<em>bool</em>&gt; <dfn class="decl" id="_ZN3xla7Backend18devices_equivalentEii" title='xla::Backend::devices_equivalent' data-ref="_ZN3xla7Backend18devices_equivalentEii">devices_equivalent</dfn>(<em>int</em> <dfn class="local col7 decl" id="187device_ordinal_a" title='device_ordinal_a' data-type='int' data-ref="187device_ordinal_a">device_ordinal_a</dfn>, <em>int</em> <dfn class="local col8 decl" id="188device_ordinal_b" title='device_ordinal_b' data-type='int' data-ref="188device_ordinal_b">device_ordinal_b</dfn>);</td></tr>
<tr><th id="145">145</th><td></td></tr>
<tr><th id="146">146</th><td>  <i>// For the host platform, returns the threadpool to use when scheduling</i></td></tr>
<tr><th id="147">147</th><td><i>  // parallel operators. For other platforms, returns NULL.</i></td></tr>
<tr><th id="148">148</th><td>  <span class="namespace">tensorflow::thread::</span><a class="type" href="../../../core/lib/core/threadpool.h.html#tensorflow::thread::ThreadPool" title='tensorflow::thread::ThreadPool' data-ref="tensorflow::thread::ThreadPool">ThreadPool</a>* <dfn class="decl" id="_ZNK3xla7Backend20inter_op_thread_poolEv" title='xla::Backend::inter_op_thread_pool' data-ref="_ZNK3xla7Backend20inter_op_thread_poolEv">inter_op_thread_pool</dfn>() <em>const</em>;</td></tr>
<tr><th id="149">149</th><td></td></tr>
<tr><th id="150">150</th><td>  <i>// For the host platform, returns the configured eigen threadpool device to be</i></td></tr>
<tr><th id="151">151</th><td><i>  // used for scheduling work. For other platforms, returns NULL.</i></td></tr>
<tr><th id="152">152</th><td>  <em>const</em> <span class="namespace">Eigen::</span><span class='type' title='Eigen::ThreadPoolDevice' data-ref="Eigen::ThreadPoolDevice">ThreadPoolDevice</span>* <dfn class="decl" id="_ZNK3xla7Backend33eigen_intra_op_thread_pool_deviceEv" title='xla::Backend::eigen_intra_op_thread_pool_device' data-ref="_ZNK3xla7Backend33eigen_intra_op_thread_pool_deviceEv">eigen_intra_op_thread_pool_device</dfn>() <em>const</em>;</td></tr>
<tr><th id="153">153</th><td>  <span class="namespace">tensorflow::thread::</span><a class="type" href="../../../core/lib/core/threadpool.h.html#tensorflow::thread::ThreadPool" title='tensorflow::thread::ThreadPool' data-ref="tensorflow::thread::ThreadPool">ThreadPool</a>* <dfn class="decl" id="_ZNK3xla7Backend26eigen_intra_op_thread_poolEv" title='xla::Backend::eigen_intra_op_thread_pool' data-ref="_ZNK3xla7Backend26eigen_intra_op_thread_poolEv">eigen_intra_op_thread_pool</dfn>() <em>const</em>;</td></tr>
<tr><th id="154">154</th><td></td></tr>
<tr><th id="155">155</th><td>  <i>// Resets the devices associated with this backend.</i></td></tr>
<tr><th id="156">156</th><td>  <a class="type" href="../../../core/lib/core/status.h.html#tensorflow::Status" title='tensorflow::Status' data-ref="tensorflow::Status">Status</a> <dfn class="decl" id="_ZN3xla7Backend12ResetDevicesEv" title='xla::Backend::ResetDevices' data-ref="_ZN3xla7Backend12ResetDevicesEv">ResetDevices</dfn>();</td></tr>
<tr><th id="157">157</th><td></td></tr>
<tr><th id="158">158</th><td> <b>private</b>:</td></tr>
<tr><th id="159">159</th><td>  <b>struct</b> <dfn class="type" id="xla::Backend::EigenThreadPoolWrapper" title='xla::Backend::EigenThreadPoolWrapper' data-ref="xla::Backend::EigenThreadPoolWrapper">EigenThreadPoolWrapper</dfn>;</td></tr>
<tr><th id="160">160</th><td>  <dfn class="decl" id="_ZN3xla7BackendC1EPN9perftools8gputools8PlatformEPNS_8CompilerEN10tensorflow3gtl10ArraySliceIPNS2_14StreamExecutorEEEPNS_15TransferManagerEPNS_17ComputationPlacerEi" title='xla::Backend::Backend' data-ref="_ZN3xla7BackendC1EPN9perftools8gputools8PlatformEPNS_8CompilerEN10tensorflow3gtl10ArraySliceIPNS2_14StreamExecutorEEEPNS_15TransferManagerEPNS_17ComputationPlacerEi">Backend</dfn>(<span class="namespace">perftools::gputools::</span><a class="type" href="../../../stream_executor/platform.h.html#perftools::gputools::Platform" title='perftools::gputools::Platform' data-ref="perftools::gputools::Platform">Platform</a>* <dfn class="local col9 decl" id="189platform" title='platform' data-type='perftools::gputools::Platform *' data-ref="189platform">platform</dfn>, <a class="type" href="compiler.h.html#xla::Compiler" title='xla::Compiler' data-ref="xla::Compiler">Compiler</a>* <dfn class="local col0 decl" id="190compiler" title='compiler' data-type='xla::Compiler *' data-ref="190compiler">compiler</dfn>,</td></tr>
<tr><th id="161">161</th><td>          <span class="namespace">tensorflow::gtl::</span><a class="type" href="../../../core/lib/gtl/array_slice.h.html#tensorflow::gtl::ArraySlice" title='tensorflow::gtl::ArraySlice' data-ref="tensorflow::gtl::ArraySlice">ArraySlice</a>&lt;<span class="namespace">perftools::gputools::</span><a class="type" href="../../../stream_executor/stream_executor_pimpl.h.html#perftools::gputools::StreamExecutor" title='perftools::gputools::StreamExecutor' data-ref="perftools::gputools::StreamExecutor">StreamExecutor</a>*&gt;</td></tr>
<tr><th id="162">162</th><td>              <dfn class="local col1 decl" id="191stream_executors" title='stream_executors' data-type='tensorflow::gtl::ArraySlice&lt;perftools::gputools::StreamExecutor *&gt;' data-ref="191stream_executors">stream_executors</dfn>,</td></tr>
<tr><th id="163">163</th><td>          <a class="type" href="transfer_manager.h.html#xla::TransferManager" title='xla::TransferManager' data-ref="xla::TransferManager">TransferManager</a>* <dfn class="local col2 decl" id="192transfer_manager" title='transfer_manager' data-type='xla::TransferManager *' data-ref="192transfer_manager">transfer_manager</dfn>,</td></tr>
<tr><th id="164">164</th><td>          <a class="type" href="computation_placer.h.html#xla::ComputationPlacer" title='xla::ComputationPlacer' data-ref="xla::ComputationPlacer">ComputationPlacer</a>* <dfn class="local col3 decl" id="193computation_placer" title='computation_placer' data-type='xla::ComputationPlacer *' data-ref="193computation_placer">computation_placer</dfn>,</td></tr>
<tr><th id="165">165</th><td>          <em>int</em> <dfn class="local col4 decl" id="194intra_op_parallelism_threads" title='intra_op_parallelism_threads' data-type='int' data-ref="194intra_op_parallelism_threads">intra_op_parallelism_threads</dfn>);</td></tr>
<tr><th id="166">166</th><td>  <dfn class="decl def" id="_ZN3xla7BackendC1ERKS0_" title='xla::Backend::Backend' data-ref="_ZN3xla7BackendC1ERKS0_">Backend</dfn>(<em>const</em> <a class="type" href="#xla::Backend" title='xla::Backend' data-ref="xla::Backend">Backend</a>&amp;) = <b>delete</b>;</td></tr>
<tr><th id="167">167</th><td>  <a class="type" href="#xla::Backend" title='xla::Backend' data-ref="xla::Backend">Backend</a>&amp; <dfn class="decl def" id="_ZN3xla7BackendaSERKS0_" title='xla::Backend::operator=' data-ref="_ZN3xla7BackendaSERKS0_"><b>operator</b>=</dfn>(<em>const</em> <a class="type" href="#xla::Backend" title='xla::Backend' data-ref="xla::Backend">Backend</a>&amp;) = <b>delete</b>;</td></tr>
<tr><th id="168">168</th><td></td></tr>
<tr><th id="169">169</th><td>  <span class="namespace">perftools::gputools::</span><a class="type" href="../../../stream_executor/platform.h.html#perftools::gputools::Platform" title='perftools::gputools::Platform' data-ref="perftools::gputools::Platform">Platform</a>* <dfn class="decl" id="xla::Backend::platform_" title='xla::Backend::platform_' data-ref="xla::Backend::platform_">platform_</dfn>;</td></tr>
<tr><th id="170">170</th><td>  <a class="type" href="compiler.h.html#xla::Compiler" title='xla::Compiler' data-ref="xla::Compiler">Compiler</a>* <dfn class="decl" id="xla::Backend::compiler_" title='xla::Backend::compiler_' data-ref="xla::Backend::compiler_">compiler_</dfn>;</td></tr>
<tr><th id="171">171</th><td>  <a class="type" href="transfer_manager.h.html#xla::TransferManager" title='xla::TransferManager' data-ref="xla::TransferManager">TransferManager</a>* <dfn class="decl" id="xla::Backend::transfer_manager_" title='xla::Backend::transfer_manager_' data-ref="xla::Backend::transfer_manager_">transfer_manager_</dfn>;</td></tr>
<tr><th id="172">172</th><td>  <a class="type" href="computation_placer.h.html#xla::ComputationPlacer" title='xla::ComputationPlacer' data-ref="xla::ComputationPlacer">ComputationPlacer</a>* <dfn class="decl" id="xla::Backend::computation_placer_" title='xla::Backend::computation_placer_' data-ref="xla::Backend::computation_placer_">computation_placer_</dfn>;</td></tr>
<tr><th id="173">173</th><td></td></tr>
<tr><th id="174">174</th><td>  <i>// Vector of stream executors. stream_executors_[0] is the default executor.</i></td></tr>
<tr><th id="175">175</th><td>  <span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/stl_vector.h.html#std::vector" title='std::vector' data-ref="std::vector">vector</a>&lt;<span class="namespace">perftools::gputools::</span><a class="type" href="../../../stream_executor/stream_executor_pimpl.h.html#perftools::gputools::StreamExecutor" title='perftools::gputools::StreamExecutor' data-ref="perftools::gputools::StreamExecutor">StreamExecutor</a>*&gt; <dfn class="decl" id="xla::Backend::stream_executors_" title='xla::Backend::stream_executors_' data-ref="xla::Backend::stream_executors_">stream_executors_</dfn>;</td></tr>
<tr><th id="176">176</th><td></td></tr>
<tr><th id="177">177</th><td>  <span class="namespace">tensorflow::</span><a class="type" href="../../../core/platform/default/mutex.h.html#tensorflow::mutex" title='tensorflow::mutex' data-ref="tensorflow::mutex">mutex</a> <dfn class="decl" id="xla::Backend::mu_" title='xla::Backend::mu_' data-ref="xla::Backend::mu_">mu_</dfn>;</td></tr>
<tr><th id="178">178</th><td></td></tr>
<tr><th id="179">179</th><td>  <i>// Mapping from stream executor to stream pools, used by `BorrowStream` above.</i></td></tr>
<tr><th id="180">180</th><td>  <span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/stl_map.h.html#std::map" title='std::map' data-ref="std::map">map</a>&lt;<span class="namespace">perftools::gputools::</span><a class="type" href="../../../stream_executor/stream_executor_pimpl.h.html#perftools::gputools::StreamExecutor" title='perftools::gputools::StreamExecutor' data-ref="perftools::gputools::StreamExecutor">StreamExecutor</a>*,</td></tr>
<tr><th id="181">181</th><td>           <a class="type" href="pool.h.html#xla::Pool" title='xla::Pool' data-ref="xla::Pool">Pool</a>&lt;<span class="namespace">perftools::gputools::</span><a class="type" href="../../../stream_executor/stream.h.html#perftools::gputools::Stream" title='perftools::gputools::Stream' data-ref="perftools::gputools::Stream">Stream</a>&gt;&gt;</td></tr>
<tr><th id="182">182</th><td>      <dfn class="decl" id="xla::Backend::stream_pools_" title='xla::Backend::stream_pools_' data-ref="xla::Backend::stream_pools_">stream_pools_</dfn> <a class="macro" href="../../../core/platform/default/thread_annotations.h.html#52" title="__attribute__((guarded_by(mu_)))" data-ref="_M/GUARDED_BY">GUARDED_BY</a>(<a class="ref" href="#xla::Backend::mu_" title='xla::Backend::mu_' data-ref="xla::Backend::mu_">mu_</a>);</td></tr>
<tr><th id="183">183</th><td></td></tr>
<tr><th id="184">184</th><td>  <i>// The default memory allocator to use.</i></td></tr>
<tr><th id="185">185</th><td>  <span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/unique_ptr.h.html#std::unique_ptr" title='std::unique_ptr' data-ref="std::unique_ptr">unique_ptr</a>&lt;<a class="type" href="device_memory_allocator.h.html#xla::StreamExecutorMemoryAllocator" title='xla::StreamExecutorMemoryAllocator' data-ref="xla::StreamExecutorMemoryAllocator">StreamExecutorMemoryAllocator</a>&gt; <dfn class="decl" id="xla::Backend::memory_allocator_" title='xla::Backend::memory_allocator_' data-ref="xla::Backend::memory_allocator_">memory_allocator_</dfn>;</td></tr>
<tr><th id="186">186</th><td></td></tr>
<tr><th id="187">187</th><td>  <i>// For the CPU backend, a threadpool for scheduling parallel operators.</i></td></tr>
<tr><th id="188">188</th><td>  <span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/unique_ptr.h.html#std::unique_ptr" title='std::unique_ptr' data-ref="std::unique_ptr">unique_ptr</a>&lt;<span class="namespace">tensorflow::thread::</span><a class="type" href="../../../core/lib/core/threadpool.h.html#tensorflow::thread::ThreadPool" title='tensorflow::thread::ThreadPool' data-ref="tensorflow::thread::ThreadPool">ThreadPool</a>&gt; <dfn class="decl" id="xla::Backend::inter_op_thread_pool_" title='xla::Backend::inter_op_thread_pool_' data-ref="xla::Backend::inter_op_thread_pool_">inter_op_thread_pool_</dfn>;</td></tr>
<tr><th id="189">189</th><td></td></tr>
<tr><th id="190">190</th><td>  <i>// For the CPU backend, an Eigen threadpool device for use by Eigen code.</i></td></tr>
<tr><th id="191">191</th><td>  <span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/unique_ptr.h.html#std::unique_ptr" title='std::unique_ptr' data-ref="std::unique_ptr">unique_ptr</a>&lt;<a class="type" href="#xla::Backend::EigenThreadPoolWrapper" title='xla::Backend::EigenThreadPoolWrapper' data-ref="xla::Backend::EigenThreadPoolWrapper">EigenThreadPoolWrapper</a>&gt; <dfn class="decl" id="xla::Backend::intra_op_thread_pool_wrapper_" title='xla::Backend::intra_op_thread_pool_wrapper_' data-ref="xla::Backend::intra_op_thread_pool_wrapper_">intra_op_thread_pool_wrapper_</dfn>;</td></tr>
<tr><th id="192">192</th><td>};</td></tr>
<tr><th id="193">193</th><td></td></tr>
<tr><th id="194">194</th><td>}  <i>// namespace xla</i></td></tr>
<tr><th id="195">195</th><td></td></tr>
<tr><th id="196">196</th><td><u>#<span data-ppcond="16">endif</span>  // TENSORFLOW_COMPILER_XLA_SERVICE_BACKEND_H_</u></td></tr>
<tr><th id="197">197</th><td></td></tr>
</table><hr/><p id='footer'>
Generated while processing <a href='../../aot/compile.cc.html'>tensorflow/tensorflow/compiler/aot/compile.cc</a><br/>Generated on <em>2018-Aug-20</em> from project tensorflow revision <em>v1.8</em><br />Powered by <a href='https://woboq.com'><img alt='Woboq' src='https://code.woboq.org/woboq-16.png' width='41' height='16' /></a> <a href='https://code.woboq.org'>Code Browser</a> 2.1
<br/>Generator usage only permitted with license.</p>
</div></body></html>
