<dec f='tensorflow/tensorflow/compiler/xla/service/cpu/ir_emitter.h' l='100' type='StatusOr&lt;llvm::Function *&gt; xla::cpu::IrEmitter::EmitComputation(xla::HloComputation * computation, const string &amp; function_name_prefix, bool is_top_level_computation, std::vector&lt;const HloInstruction *&gt; * instruction_order)'/>
<use f='tensorflow/tensorflow/compiler/xla/service/cpu/cpu_compiler.cc' l='603' u='c' c='_ZN3xla3cpu11CpuCompiler10RunBackendESt10unique_ptrINS_9HloModuleESt14default_deleteIS3_EEPN9perftools8gputools14StreamExecutorEPNS_21DeviceMemoryAllocatorE'/>
<use f='tensorflow/tensorflow/compiler/xla/service/cpu/cpu_compiler.cc' l='679' u='c' c='_ZN3xla3cpu11CpuCompiler10RunBackendESt10unique_ptrINS_9HloModuleESt14default_deleteIS3_EEPN9perftools8gputools14StreamExecutorEPNS_21DeviceMemoryAllocatorE'/>
<use f='tensorflow/tensorflow/compiler/xla/service/cpu/cpu_compiler.cc' l='690' u='c' c='_ZN3xla3cpu11CpuCompiler10RunBackendESt10unique_ptrINS_9HloModuleESt14default_deleteIS3_EEPN9perftools8gputools14StreamExecutorEPNS_21DeviceMemoryAllocatorE'/>
<use f='tensorflow/tensorflow/compiler/xla/service/cpu/cpu_compiler.cc' l='858' u='c' c='_ZN3xla3cpu11CpuCompiler18CompileAheadOfTimeESt6vectorISt10unique_ptrINS_9HloModuleESt14default_deleteIS4_EESaIS7_EERKNS_21AotCompilationOptionsE'/>
<use f='tensorflow/tensorflow/compiler/xla/service/cpu/cpu_compiler.cc' l='867' u='c' c='_ZN3xla3cpu11CpuCompiler18CompileAheadOfTimeESt6vectorISt10unique_ptrINS_9HloModuleESt14default_deleteIS4_EESaIS7_EERKNS_21AotCompilationOptionsE'/>
<doc f='tensorflow/tensorflow/compiler/xla/service/cpu/ir_emitter.h' l='83'>// Emit and return the given HLO computation as an LLVM IR
  // function.
  //
  // function_name_prefix is the desired name of the function. If the name is
  // not unique among already emitted functions then a suffix is appended to
  // make the name unique.
  //
  // &apos;is_top_level_computation&apos; has the following meanings for each CPU backend:
  // *) sequential: indicates that this is the entry computation of the HLO
  //    module.
  // *) parallel: indices that this is the callee of a kCall HLO in the entry
  //    computation of the HLO module.
  //
  // If &apos;instruction_order&apos; is not NULL, then the HLO instructions are emitted
  // in the given order.  In this case, &apos;instruction_order&apos; must be a
  // topological sort of the set of nodes accessible from the root of the
  // computation.</doc>
<def f='tensorflow/tensorflow/compiler/xla/service/cpu/ir_emitter.cc' l='106' ll='137' type='StatusOr&lt;llvm::Function *&gt; xla::cpu::IrEmitter::EmitComputation(xla::HloComputation * computation, const string &amp; function_name_prefix, bool is_top_level_computation, std::vector&lt;const HloInstruction *&gt; * instruction_order)'/>
