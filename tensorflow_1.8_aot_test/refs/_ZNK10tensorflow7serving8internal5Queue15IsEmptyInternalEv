<dec f='tensorflow/tensorflow/core/kernels/batching_util/shared_batch_scheduler.h' l='277' type='bool tensorflow::serving::internal::Queue::IsEmptyInternal() const'/>
<use f='tensorflow/tensorflow/core/kernels/batching_util/shared_batch_scheduler.h' l='520' u='c' c='_ZN10tensorflow7serving8internal5QueueD1Ev'/>
<use f='tensorflow/tensorflow/core/kernels/batching_util/shared_batch_scheduler.h' l='623' u='c' c='_ZN10tensorflow7serving8internal5Queue12ProcessBatchESt10unique_ptrINS0_5BatchIT_EESt14default_deleteIS6_EE'/>
<use f='tensorflow/tensorflow/core/kernels/batching_util/shared_batch_scheduler.h' l='632' u='c' c='_ZNK10tensorflow7serving8internal5Queue7IsEmptyEv'/>
<use f='tensorflow/tensorflow/core/kernels/batching_util/shared_batch_scheduler.h' l='641' u='c' c='_ZN10tensorflow7serving8internal5Queue22CloseAndWaitUntilEmptyEv'/>
<def f='tensorflow/tensorflow/core/kernels/batching_util/shared_batch_scheduler.h' l='651' ll='655' type='bool tensorflow::serving::internal::Queue::IsEmptyInternal() const'/>
<doc f='tensorflow/tensorflow/core/kernels/batching_util/shared_batch_scheduler.h' l='276'>// Same as IsEmpty(), but assumes the caller already holds a lock on &apos;mu_&apos;.</doc>
