<dec f='tensorflow/tensorflow/stream_executor/dnn.h' l='1456' type='bool perftools::gputools::dnn::DnnSupport::DoMatMul(perftools::gputools::Stream * stream, const DeviceMemory&lt;float&gt; &amp; input_data, const DeviceMemory&lt;float&gt; &amp; weights, const dnn::BatchDescriptor &amp; input_dimensions, const dnn::BatchDescriptor &amp; output_dimensions, DeviceMemory&lt;float&gt; * output_data)'/>
<doc f='tensorflow/tensorflow/stream_executor/dnn.h' l='1410'>// Fully connects the &quot;nodes&quot; (float values) in input_data with
  // shape input_dimensions to output_data with output_dimensions
  // using provided weights. This is equivalent to computing a matrix
  // product, hence the name MatMul.
  //
  // A BatchDescriptor has four dimensions: batch, y, x, depth. Matrix products
  // happen in two dimensions. To get down to two dimensions, we consider the
  // input y, x and depth dimension as one combined dimension T. For now,
  // assume that the output height and width are 1 and let OD be the output
  // depth.
  //
  // There are three device memory buffers passed in to this
  // function. We can now view all three as matrices:
  //
  //   input_data: A batch x T matrix
  //   weights: A T x OD matrix
  //   output_data: A batch x OD matrix
  //
  // This function then computes the matrix product of input_data and
  // weights and writes the result into output_data.
  //
  // Here the weights buffer is in row major order, i.e. the first OD
  // entries in weights are the first row, the second OD entries in
  // weights are the second row and so on.
  //
  // The case for output width*height &gt; 1 is more complicated. Let K =
  // OY * OX where OY is the output height and OX is the output
  // width. Then weights is divided into K sub-arrays W_i, for
  // i=0,...,k-1, that each represent a T x OD matrix. This function
  // then computes the K matrix multiplications of input_data with
  // each W_i. This creates K matrices with dimensions batch x
  // OD. These K matrices are concatenated horizontally to form one
  // larger matrix with dimensions batch x (K*OD); note that this is
  // not the same as concatenating the bytes of the matrices. The
  // combined matrix can then be interpreted as a tensor with
  // dimensions (batch, OY, OX, OD). If the output tensor format is
  // not kBatchYXDepth, this function would then need to arrange for
  // the output to be in the requested layout, if that is
  // supported. Note that the case K=1 is equivalent to the
  // description above. It is recommended to prefer the case K=1.
  //
  // Arguments (all borrowed):
  //  stream: borrowed pointer to the stream that the &apos;fully connect&apos; operation
  //    should be enqueued onto.
  //  output_data: un-owned device memory region in which to place the
  //    fully connected result.</doc>
<use f='tensorflow/tensorflow/stream_executor/stream.cc' l='1295' u='c' c='_ZN9perftools8gputools6Stream10ThenMatMulERKNS0_12DeviceMemoryIfEES5_RKNS0_3dnn15BatchDescriptorES9_PS3_'/>
