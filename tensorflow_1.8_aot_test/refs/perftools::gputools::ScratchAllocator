<def f='tensorflow/tensorflow/stream_executor/scratch_allocator.h' l='41' ll='57'/>
<ovr f='tensorflow/tensorflow/stream_executor/scratch_allocator.h' l='66' c='perftools::gputools::OneTimeScratchAllocator'/>
<size>8</size>
<doc f='tensorflow/tensorflow/stream_executor/scratch_allocator.h' l='31'>// Interface that allows stream operations (e.g.
// Stream::ThenConvolveWithScratch) to optionally request scratch space be
// allocated in order to speed up the operation being enqueued.
//
// Note that the caller is responsible for deallocating the scratch space at a
// known-safe point, when all scratch-memory-consuming kernels are known for
// sure to have finished; e.g. at stream synchronization time. This is different
// from a traditional C++ object allocator, where the client is responsible for
// releasing. (Conceptually, scratch memory is a form of &quot;temporary&quot; device
// memory allocation.)</doc>
<fun r='_ZN9perftools8gputools16ScratchAllocatorD1Ev'/>
<fun r='_ZN9perftools8gputools16ScratchAllocator21GetMemoryLimitInBytesEPNS0_6StreamE'/>
<fun r='_ZN9perftools8gputools16ScratchAllocator13AllocateBytesEPNS0_6StreamEx'/>
