<inh f='tensorflow/tensorflow/compiler/xla/service/device_memory_allocator.h' l='32' c='xla::DeviceMemoryAllocator'/>
<def f='tensorflow/tensorflow/compiler/xla/service/device_memory_allocator.h' l='64' ll='86'/>
<size>40</size>
<doc f='tensorflow/tensorflow/compiler/xla/service/device_memory_allocator.h' l='62'>// Default memory allocator for a platform which uses
// StreamExecutor::Allocate/Deallocate.</doc>
<fun r='_ZN3xla29StreamExecutorMemoryAllocatorC1EPKN9perftools8gputools8PlatformEN10tensorflow3gtl10ArraySliceIPNS2_14StreamExecutorEEE'/>
<fun r='_ZN3xla29StreamExecutorMemoryAllocator8AllocateEiyb'/>
<fun r='_ZN3xla29StreamExecutorMemoryAllocator10DeallocateEiPN9perftools8gputools16DeviceMemoryBaseE'/>
<fun r='_ZNK3xla29StreamExecutorMemoryAllocator30AllowsAsynchronousDeallocationEv'/>
<fun r='_ZN3xla29StreamExecutorMemoryAllocator17GetStreamExecutorEi'/>
<mbr r='xla::StreamExecutorMemoryAllocator::stream_executors_' o='128' t='std::vector&lt;perftools::gputools::StreamExecutor *&gt;'/>
