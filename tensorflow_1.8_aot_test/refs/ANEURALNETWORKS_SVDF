<dec f='tensorflow/tensorflow/contrib/lite/nnapi/NeuralNetworksShim.h' l='1053' type='27'/>
<doc f='tensorflow/tensorflow/contrib/lite/nnapi/NeuralNetworksShim.h' l='981'>/**
   * SVDF op is a kind of stateful layer derived from the notion that a
   * densely connected layer that&apos;s processing a sequence of input frames can
   * be approximated by using a singular value decomposition of each of its
   * nodes. The implementation is based on:
   *
   * https://research.google.com/pubs/archive/43813.pdf
   *
   * P. Nakkiran, R. Alvarez, R. Prabhavalkar, C. Parada.
   * “Compressing Deep Neural Networks using a Rank-Constrained Topology”.
   * INTERSPEECH, 2015.
   *
   * It processes the incoming input using a 2-stage filtering mechanism:
   * * stage 1 performs filtering on the &quot;features&quot; dimension, whose outputs get
   *   pushed into a memory of fixed-size memory_size.
   * * stage 2 performs filtering on the &quot;time&quot; dimension of the memory_size
   *   memoized outputs of stage 1.
   *
   * Specifically, for rank 1, this layer implements the operation:
   *
   *    memory = push(conv1d(inputs, weights_feature, feature_dim, &quot;VALID&quot;));
   *    outputs = activation(memory * weights_time + bias);
   *
   * Where:
   * * “weights_feature” is a weights matrix that processes the inputs (by
   *   convolving the input with every “feature filter”), and whose outputs get
   *   pushed, stacked in order, into the fixed-size “memory” (the oldest entry
   *   gets dropped);
   * * “weights_time” is a weights matrix that processes the “memory” (by a
   *   batched matrix multiplication on the num_units);
   * * “bias” is an optional bias vector (added to each output vector in the
   *   batch); and
   * * “activation” is the function passed as the “fused_activation_function”
   *   argument (if not “NONE”).
   *
   * Each rank adds a dimension to the weights matrices by means of stacking
   * the filters.
   *
   * Supported tensor types:
   * * {@link ANEURALNETWORKS_TENSOR_FLOAT32}
   *
   * Inputs:
   * * 0: input.
   *      A 2-D tensor of type T, of shape [batch_size, input_size], where
   *      “batch_size” corresponds to the batching dimension, and “input_size”
   * is the size of the input.
   * * 1: weights_feature.
   *      A 2-D tensor of type T, of shape [num_units, input_size], where
   *      “num_units” corresponds to the number of units.
   * * 2: weights_time.
   *      A 2-D tensor of type T, of shape [num_units, memory_size], where
   *      “memory_size” corresponds to the fixed-size of the memory.
   * * 3: bias.
   *      A optional 1-D tensor of type T, of shape [num_units].
   *
   *    For FLOAT32 input tensor, bias must also be FLOAT32.
   *    For UINT8 input tensor, bias must be INT32.
   *
   * Parameters:
   * * 4: rank.
   *      The rank of the SVD approximation.
   * * 5: fused_activation_function.
   *      An (optional) ActivationFunctionType indicating the activation
   * function. If “NONE” is specified then it results in a linear activation.
   *
   * Outputs:
   * * 0: state.
   *      A 2-D tensor of type T, of shape [batch_size, (memory_size - 1) *
   * num_units * rank].
   * * 1: output.
   *      A 2-D tensor of type T, of shape [batch_size, num_units].
   */</doc>
