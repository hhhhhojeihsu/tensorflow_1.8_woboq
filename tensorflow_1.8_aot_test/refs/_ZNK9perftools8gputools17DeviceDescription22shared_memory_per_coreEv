<def f='tensorflow/tensorflow/stream_executor/device_description.h' l='167' type='uint64 perftools::gputools::DeviceDescription::shared_memory_per_core() const'/>
<doc f='tensorflow/tensorflow/stream_executor/device_description.h' l='163'>// Returns the maximum amount of shared memory present on a single core
  // (i.e. Streaming Multiprocessor on NVIDIA GPUs; Compute Unit for OpenCL
  // devices). Note that some devices, such as NVIDIA&apos;s have a configurable
  // partitioning between shared memory and L1 cache.</doc>
<use f='tensorflow/tensorflow/stream_executor/device_description.cc' l='176' u='c' c='_ZN9perftools8gputools18CalculateOccupancyERKNS0_17DeviceDescriptionEyyRKNS0_9ThreadDimE'/>
<use f='tensorflow/tensorflow/stream_executor/device_description.cc' l='176' u='c' c='_ZN9perftools8gputools18CalculateOccupancyERKNS0_17DeviceDescriptionEyyRKNS0_9ThreadDimE'/>
<use f='tensorflow/tensorflow/stream_executor/device_description.cc' l='208' u='c' c='_ZN9perftools8gputools18CalculateOccupancyERKNS0_17DeviceDescriptionEyyRKNS0_9ThreadDimE'/>
