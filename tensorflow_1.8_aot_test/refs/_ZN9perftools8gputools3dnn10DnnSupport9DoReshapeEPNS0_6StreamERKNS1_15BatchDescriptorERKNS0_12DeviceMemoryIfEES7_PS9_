<def f='tensorflow/tensorflow/stream_executor/dnn.h' l='1733' ll='1739' type='bool perftools::gputools::dnn::DnnSupport::DoReshape(perftools::gputools::Stream * stream, const dnn::BatchDescriptor &amp; input_dimensions, const DeviceMemory&lt;float&gt; &amp; input_data, const dnn::BatchDescriptor &amp; output_dimensions, DeviceMemory&lt;float&gt; * output_data)'/>
<doc f='tensorflow/tensorflow/stream_executor/dnn.h' l='1705'>// Change the layout of the data by shrinking one dimension (or set of
  // dimensions) and growing another dimension (or set of dimensions), while
  // keeping the total number of data elements constant, and maintaining the
  // current data ordering.
  //
  // Currently, the only supported operation is depth into space by a power of
  // 2. E.g. (y, x, z) -&gt; (y*2, x*2, z/4)
  //
  // Note that Reshape may not be a no-op, depending on the platform and which
  // dimensions are being changed.
  //
  // Example: forgetting about batch for the moment, let&apos;s take a tensor that&apos;s
  // 2x1x8 (y by x by z) and reshape to a tensor that&apos;s 4x2x2. The memory layout
  // is row-major order: y,x,z. I.e. z changes the fastest, then x, then y. The
  // elements of the tensor range from 0 to 15. The x,y,z indices are below each
  // element.
  //
  //  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15
  // y0 y0 y0 y0 y0 y0 y0 y0 y1 y1 y1 y1 y1 y1 y1 y1
  // x0 x0 x0 x0 x0 x0 x0 x0 x0 x0 x0 x0 x0 x0 x0 x0
  // z0 z1 z2 z3 z4 z5 z6 z7 z0 z1 z2 z3 z4 z5 z6 z7
  //
  // reshape to 4x2x2
  //
  //  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15
  // y0 y0 y0 y0 y1 y1 y1 y1 y2 y2 y2 y2 y3 y3 y3 y3
  // x0 x0 x1 x1 x0 x0 x1 x1 x0 x0 x1 x1 x0 x0 x1 x1
  // z0 z1 z0 z1 z0 z1 z0 z1 z0 z1 z0 z1 z0 z1 z0 z1</doc>
<use f='tensorflow/tensorflow/stream_executor/stream.cc' l='1676' u='c' c='_ZN9perftools8gputools6Stream11ThenReshapeERKNS0_3dnn15BatchDescriptorERKNS0_12DeviceMemoryIfEES5_PS7_'/>
