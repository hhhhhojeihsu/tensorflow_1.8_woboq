<inh f='tensorflow/tensorflow/compiler/xla/service/device_memory_allocator.h' l='32' c='xla::DeviceMemoryAllocator'/>
<def f='tensorflow/tensorflow/compiler/jit/xla_launch_util.h' l='47' ll='68'/>
<size>24</size>
<doc f='tensorflow/tensorflow/compiler/jit/xla_launch_util.h' l='44'>// Adapter class that wraps a Tensorflow allocator as an XLA allocator.
// Assumes that the Tensorflow allocator permits asynchronous deallocation:
// see comment on `AllowsAsynchronousDeallocation()`.</doc>
<fun r='_ZN10tensorflow12XlaAllocatorC1EPKN9perftools8gputools8PlatformEPNS_9AllocatorE'/>
<fun r='_ZN10tensorflow12XlaAllocatorD1Ev'/>
<fun r='_ZN10tensorflow12XlaAllocator8AllocateEiyb'/>
<fun r='_ZN10tensorflow12XlaAllocator10DeallocateEiPN9perftools8gputools16DeviceMemoryBaseE'/>
<fun r='_ZNK10tensorflow12XlaAllocator30AllowsAsynchronousDeallocationEv'/>
<mbr r='tensorflow::XlaAllocator::wrapped_' o='128' t='tensorflow::Allocator *'/>
