<def f='tensorflow/tensorflow/c/eager/tape.h' l='436' type='const int'/>
<use f='tensorflow/tensorflow/c/eager/tape.h' l='547' c='_ZN10tensorflow5eager12GradientTape15ComputeGradientERKNS0_6VSpaceIT_T0_EENS_3gtl10ArraySliceIxEESA_NS9_IPS3_EEPSt6vectorISB_SaISB_EE'/>
<doc f='tensorflow/tensorflow/c/eager/tape.h' l='433'>// If over kMinAggregateCount gradients are accumulated and the total
// memory consumption is over kMinAggregateBytes, do an early aggregation
// so as to release the gradient tensor to save memory.</doc>
