<dec f='tensorflow/tensorflow/core/profiler/internal/tfprof_node.h' l='91' type='void tensorflow::tfprof::ExecStep::AddTimeStats(const string &amp; dev, const tensorflow::NodeExecStats &amp; step_stat)'/>
<def f='tensorflow/tensorflow/core/profiler/internal/tfprof_node.cc' l='47' ll='79' type='void tensorflow::tfprof::ExecStep::AddTimeStats(const string &amp; dev, const tensorflow::NodeExecStats &amp; step_stat)'/>
<use f='tensorflow/tensorflow/core/profiler/internal/tfprof_node.cc' l='228' u='c' c='_ZN10tensorflow6tfprof11TFGraphNode11AddStepStatExRKSsRKNS_13NodeExecStatsE'/>
<doc f='tensorflow/tensorflow/core/profiler/internal/tfprof_node.cc' l='31'>// Notes about start and end time from the NodeExecStats proto:
// For GPU, there is no difference between op_end_rel_micros and
// all_end_rel_micros. All are kernel times.
// For CPU, op_end_rel is the kernel time, while all_end_rel_micros includes
// some post-processing. Besides, currently, there is no way to measure
// the execution time of async ops accurately.
//
// Notes about device:
// For ops on gpu:
// It will appear in three different devices in RunMetadata: 1) gpu:x,
// 2) gpu:x:stream:all and 3) gpu:x:stream:id. 2) is used a combined view
// of all different 3). 1) is the op scheduling, pre-processing and
// post processing time. 3) is the execution time of GPU kernels on a stream.
// For ops on cpu:
// It will only appear as cpu:0.</doc>
