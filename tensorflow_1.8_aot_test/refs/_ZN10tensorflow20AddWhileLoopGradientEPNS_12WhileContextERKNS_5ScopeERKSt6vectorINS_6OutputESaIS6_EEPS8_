<dec f='tensorflow/tensorflow/cc/framework/while_gradients.h' l='34' type='tensorflow::Status tensorflow::AddWhileLoopGradient(tensorflow::WhileContext * while_ctx, const tensorflow::Scope &amp; scope, const std::vector&lt;Output&gt; &amp; grad_inputs, std::vector&lt;Output&gt; * grad_outputs)'/>
<use f='tensorflow/tensorflow/cc/framework/gradients.cc' l='422' u='c' c='_ZN10tensorflow12_GLOBAL__N_123SymbolicGradientBuilder16ProcessWhileLoopEPNS_4NodeERKNS_6OutputE'/>
<doc f='tensorflow/tensorflow/cc/framework/while_gradients.h' l='27'>// Adds the gradient computation for the while loop associated with
// `while_ctx`. `grad_inputs` are the partial derivatives w.r.t. the loop
// outputs, i.e. the exit nodes.  The partial derivatives w.r.t. the loop
// inputs, i.e. the input loop vars, are returned in `grad_outputs`.
// `grad_inputs` and `grad_outputs` are both in loop-variable order, as defined
// by the original inputs to BuildWhileLoop().
// TODO(skyewm): maybe comment on NoGradient once it&apos;s supported</doc>
<def f='tensorflow/tensorflow/cc/framework/while_gradients.cc' l='179' ll='196' type='tensorflow::Status tensorflow::AddWhileLoopGradient(tensorflow::WhileContext * while_ctx, const tensorflow::Scope &amp; scope, const std::vector&lt;Output&gt; &amp; grad_inputs, std::vector&lt;Output&gt; * grad_outputs)'/>
