<inh f='tensorflow/tensorflow/core/framework/op_kernel.h' l='74' c='tensorflow::OpKernel'/>
<def f='tensorflow/tensorflow/compiler/jit/xla_compile_on_demand_op.h' l='37' ll='52'/>
<size>288</size>
<doc f='tensorflow/tensorflow/compiler/jit/xla_compile_on_demand_op.h' l='31'>// An OpKernel that compiles an op to an XLA computation and runs it. Unlike
// _XlaLaunch this doesn&apos;t rely on any rewrites of the graphdef - it will run a
// vanilla TensorFlow op as long as the bridge supports it.
//
// Importantly _XlaLaunch assumes all input and output tensors are on the host,
// whereas XlacompileOnDemandOp works with tensors in device memory.</doc>
<fun r='_ZN10tensorflow20XlaCompileOnDemandOpC1EPNS_20OpKernelConstructionE'/>
<fun r='_ZN10tensorflow20XlaCompileOnDemandOp7ComputeEPNS_15OpKernelContextE'/>
<fun r='_ZN10tensorflow20XlaCompileOnDemandOp22CreateCompilerArgumentEPNS_15OpKernelContextEx'/>
<fun r='_ZN10tensorflow20XlaCompileOnDemandOp24ShouldArgumentBeConstantEPKNS_8OpKernelEx'/>
<fun r='_ZN10tensorflow20XlaCompileOnDemandOp22MustArgumentBeConstantEPKNS_8OpKernelEx'/>
<fun r='_ZN10tensorflow20XlaCompileOnDemandOp7CompileEPNS_15OpKernelContextERKNS_9XlaDevice8MetadataEPPKNS_11XlaCompiler17CompilationResultEPPN3xla15LocalExecutableE'/>
<fun r='_ZN10tensorflow20XlaCompileOnDemandOp3RunEPNS_15OpKernelContextERKNS_9XlaDevice8MetadataEPKNS_11XlaCompiler17CompilationResultEPN3xla15LocalExecutableE'/>
<fun r='_ZN10tensorflow20XlaCompileOnDemandOp3RunEPNS_15OpKernelContextERKNS_9XlaDevice8MetadataEPKNS_11XlaCompiler17CompilationResultEPN3xla15LocalExecutableE'/>
<fun r='_ZN10tensorflow20XlaCompileOnDemandOp22MustArgumentBeConstantEPKNS_8OpKernelEx'/>
<fun r='_ZN10tensorflow20XlaCompileOnDemandOp24ShouldArgumentBeConstantEPKNS_8OpKernelEx'/>
<fun r='_ZN10tensorflow20XlaCompileOnDemandOp7CompileEPNS_15OpKernelContextERKNS_9XlaDevice8MetadataEPPKNS_11XlaCompiler17CompilationResultEPPN3xla15LocalExecutableE'/>
<fun r='_ZN10tensorflow20XlaCompileOnDemandOp7ComputeEPNS_15OpKernelContextE'/>
