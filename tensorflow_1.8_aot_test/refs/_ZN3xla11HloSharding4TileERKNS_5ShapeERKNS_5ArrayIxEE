<def f='tensorflow/tensorflow/compiler/xla/service/hlo_sharding.h' l='62' ll='65' type='static xla::HloSharding xla::HloSharding::Tile(const xla::Shape &amp; tile_shape, const Array&lt;int64&gt; &amp; tile_assignment)'/>
<doc f='tensorflow/tensorflow/compiler/xla/service/hlo_sharding.h' l='49'>// Creates a new sharding which splits a shape into tiles each with shape
  // `tile_shape`. Each tile is assigned to one device, which is specified by
  // `tile_assignment`. Any tensor not a multiple of the tile size in any
  // dimension is implicitly padded to the tile size.
  //
  // e.g. Tile({2, 2}, {0, 1}) on a tensor of shape {3, 2} would look like:
  //      2     1 padding
  //   &lt;------&gt;&lt;-&gt;
  //   +----+----+
  //   | 0  |  1 |
  //   +----+----+
  //
  // Split into two tiles, one of which is implicitly padded by one.</doc>
<use f='tensorflow/tensorflow/compiler/xla/service/hlo_sharding.cc' l='376' u='c' c='_ZNK3xla11HloSharding25TransformShardedTileShapeERKNS_5ShapeERKSt8functionIFxxxEE'/>
