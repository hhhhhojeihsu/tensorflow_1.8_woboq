<use f='tensorflow/tensorflow/core/common_runtime/gpu/gpu_event_mgr.h' l='76' u='c' c='_ZN10tensorflow8EventMgr16ThenDeleteBufferEPN9perftools8gputools6StreamENS0_6BufRecE'/>
<use f='tensorflow/tensorflow/core/common_runtime/gpu/gpu_event_mgr.h' l='87' u='c' c='_ZN10tensorflow8EventMgr11ThenExecuteEPN9perftools8gputools6StreamESt8functionIFvvEE'/>
<dec f='tensorflow/tensorflow/core/common_runtime/gpu/gpu_event_mgr.h' l='159' type='void tensorflow::EventMgr::PollEvents(bool is_dedicated_poller, ToFreeVector * to_free)'/>
<use f='tensorflow/tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc' l='142' u='c' c='_ZN10tensorflow8EventMgr8PollLoopEv'/>
<def f='tensorflow/tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc' l='193' ll='231' type='void tensorflow::EventMgr::PollEvents(bool is_dedicated_poller, gtl::InlinedVector&lt;InUse, 4&gt; * to_free)'/>
<doc f='tensorflow/tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc' l='174'>// This function must be called periodically to check whether pending
// events have recorded, and then retire them.  Initial observations
// suggest that typical behavior in a TensorFlow program is to have
// 0-3 events pending most of the time, but there are occasionally
// spikes of up to several hundred outstanding.
//
// NOTE: If all events are on the same stream, no later event will
// complete before an earlier event, except possibly if the earlier
// event transitions to an error state, so there&apos;s no advantage in
// looking past the first kPending event.  However, if we&apos;re using
// multiple streams there may be some gain in looking deeper.
// As a compromise, PollEvent() calls that are triggered by the queueing
// of a single event never look past the first kPending event.  Calls
// coming from the dedicated polling thread always sweep the full queue.
//
// Note that allowing the queue to grow very long could cause overall
// GPU memory use to spike needlessly.  An alternative strategy would
// be to throttle new Op execution until the pending event queue
// clears.</doc>
<doc f='tensorflow/tensorflow/core/common_runtime/gpu/gpu_event_mgr.h' l='154'>// This function should be called at roughly the same tempo as
  // QueueTensors() to check whether pending events have recorded,
  // and then retire them.  It appends InUse elements that need cleanup
  // to &quot;*to_free&quot;.  The caller should call FreeMemory(to_free)
  // when this returns.</doc>
