<dec f='tensorflow/tensorflow/contrib/lite/nnapi/NeuralNetworksShim.h' l='437' type='9'/>
<doc f='tensorflow/tensorflow/contrib/lite/nnapi/NeuralNetworksShim.h' l='405'>/** Denotes a fully (densely) connected layer, which connects all elements in
   * the input tensor with each element in the output tensor.
   *
   * This layer implements the operation:
   *
   *     outputs = activation(inputs * weights’ + bias)
   *
   * Supported tensor types:
   * * {@link ANEURALNETWORKS_TENSOR_FLOAT32}
   * * {@link ANEURALNETWORKS_TENSOR_QUANT8_ASYMM}
   *
   * Supported tensor rank: up to 4.
   *
   * Inputs:
   * * 0: A tensor, specifying the input. If rank is greater than 2, then it
   * gets flattened to a 2-D Tensor. The 2-D Tensor is handled as if dimensions
   * corresponded to shape [batch_size, input_size], where “batch_size”
   * corresponds to the batching dimension, and “input_size” is the size of the
   * input.
   * * 1: A 2-D tensor, specifying the weights, of shape [num_units,
   * input_size], where &quot;num_units&quot; corresponds to the number of output nodes.
   * * 2: A 1-D tensor, of shape [num_units], specifying the bias.
   *      For input tensor of {@link ANEURALNETWORKS_TENSOR_FLOAT32} type, the
   * bias should also be of {@link ANEURALNETWORKS_TENSOR_FLOAT32}. For input
   * tensor of {@link ANEURALNETWORKS_TENSOR_QUANT8_ASYMM} type, the bias should
   * be of {@link ANEURALNETWORKS_TENSOR_INT32}.
   * * 3: An INT32 value, and has to be one of the {@link FuseCode} values.
   *      Specifies the activation to invoke on the result of each addition.
   *
   * Outputs:
   * * 0: The output tensor, of shape [batch_size, num_units].
   */</doc>
<use f='tensorflow/tensorflow/contrib/lite/nnapi_delegate.cc' l='298' u='r' c='_ZN6tflite15AddOpsAndParamsEPNS_11InterpreterEP20ANeuralNetworksModelj'/>
