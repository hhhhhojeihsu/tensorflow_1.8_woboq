<dec f='tensorflow/tensorflow/stream_executor/stream.h' l='1967' type='perftools::gputools::Stream &amp; perftools::gputools::Stream::ThenEnqueueOnBackgroundThread(std::function&lt;void (StreamExecutor *)&gt; task)'/>
<doc f='tensorflow/tensorflow/stream_executor/stream.h' l='1951'>// Warning! This method interacts with internal threads in
  // sometimes-unpredictable ways and is intended for GPU-Executor-internal
  // use
  // only. Please check with a member of the FASTR team before making use of
  // this method.
  //
  // Entrains onto the stream a function to be executed on the host at some
  // point in the future.
  // Async host callbacks DO NOT block the stream as device functions (or as
  // synchronous host callbacks). No synchronization is possible with
  // asynchronous callbacks; they are strictly fire-and-forget.
  // This method is private due to the potential for undefined behavior with
  // synchronization using OpenCL user events.
  // The ONLY lifetime guarantee in these calls is that the StreamExecutor
  // parameter will still be valid - this Stream may not be!
  // Any callbacks requiring device API calls must use this method.</doc>
<def f='tensorflow/tensorflow/stream_executor/stream.cc' l='5152' ll='5162' type='perftools::gputools::Stream &amp; perftools::gputools::Stream::ThenEnqueueOnBackgroundThread(std::function&lt;void (StreamExecutor *)&gt; task)'/>
<doc f='tensorflow/tensorflow/stream_executor/stream.cc' l='5150'>// It looks confusing, but all this is doing is inserting a callback at the
// present point in the stream to then enqueue a task on the host executor.</doc>
