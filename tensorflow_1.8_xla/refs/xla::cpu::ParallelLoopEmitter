<inh f='tensorflow/tensorflow/compiler/xla/service/llvm_ir/loop_emitter.h' l='39' c='xla::llvm_ir::LoopEmitter'/>
<def f='tensorflow/tensorflow/compiler/xla/service/cpu/parallel_loop_emitter.h' l='48' ll='68'/>
<size>144</size>
<doc f='tensorflow/tensorflow/compiler/xla/service/cpu/parallel_loop_emitter.h' l='28'>// ParallelLoopEmitter emits a loop nest for the target array shape.
// The outer loop bounds of the loop nest are passed as ir values at runtime
// (specified in &apos;dynamic_loop_bounds&apos;), and the inner loop bounds are static.
// Dynamic loop bounds are specified as an array of dimension index
// [start, limit) pairs of ir values (one for each partitioned outer dimension).
//
// EX: Let &apos;shape&apos; = [8, 16, 32], with the loop bounds of the two-most major
//     dimensions dynamic. Then &apos;dynamic_loop_bounds&apos; will contain the
//     following ir values for the two most-major dimensions:
//       [dim0_index_start_ir_value, dim0_index_limit_ir_value]
//       [dim1_index_start_ir_value, dim1_index_limit_ir_value]
//
// Code emitted by ParallelLoopEmitter will be called in a multi-threaded
// context where each thread will be assigned a different set of outer dimension
// partitions, and where all threads will collectively iterate over the
// entire target array shape.
//
// Outer dimension partitions can be generated using the ShapePartitionAssigner
// and ShapePartitionIterator utility classes from shape_partition.cc.
//</doc>
<fun r='_ZN3xla3cpu19ParallelLoopEmitterC1ERKSt8functionIFNS_8StatusOrIPN4llvm5ValueEEERKNS_7llvm_ir7IrArray5IndexEEERKS9_PKSt6vectorISt4pairIS6_S6_ESaISL_EEP4257267'/>
<fun r='_ZN3xla3cpu19ParallelLoopEmitterC1ERKS1_'/>
<fun r='_ZN3xla3cpu19ParallelLoopEmitteraSERKS1_'/>
<fun r='_ZN3xla3cpu19ParallelLoopEmitterD1Ev'/>
<fun r='_ZN3xla3cpu19ParallelLoopEmitter29EmitIndexAndSetExitBasicBlockEN10tensorflow11StringPieceE'/>
<mbr r='xla::cpu::ParallelLoopEmitter::dynamic_loop_bounds_' o='1088' t='const DynamicLoopBounds *'/>
