<dec f='tensorflow/tensorflow/compiler/xla/service/compiler.h' l='139' type='StatusOr&lt;std::unique_ptr&lt;Executable&gt; &gt; xla::Compiler::RunBackend(std::unique_ptr&lt;HloModule&gt; module, perftools::gputools::StreamExecutor * executor, xla::DeviceMemoryAllocator * device_allocator)'/>
<doc f='tensorflow/tensorflow/compiler/xla/service/compiler.h' l='127'>// Compiles the HLO module for execution on a device given by the executor,
  // and returns an executable object or an error status. No HLO passes are
  // applied to module. Generally a module should be passed through RunHloPasses
  // prior to calling this method because some HLO passes are required for
  // correctness. Takes ownership of the HLO module and is free to transform it.
  //
  // The compiler may optionally specialize to the individual device
  // (not just type of device) indicated by the executor.
  //
  // device_allocator is optional; see RunHloPasses.
  //
  // Use the overload below to compile computations that run in parallel.</doc>
<ovr f='tensorflow/tensorflow/compiler/xla/service/cpu/cpu_compiler.cc' l='456' c='_ZN3xla3cpu11CpuCompiler10RunBackendESt10unique_ptrINS_9HloModuleESt14default_deleteIS3_EEPN9perftools8gputools14StreamExecutorEPNS_21DeviceMemoryAllocatorE'/>
<use f='tensorflow/tensorflow/compiler/xla/service/llvm_compiler.cc' l='51' u='c' c='_ZN3xla12LLVMCompiler7CompileESt6vectorISt10unique_ptrINS_9HloModuleESt14default_deleteIS3_EESaIS6_EES1_IS1_IPN9perftools8gputools14StreamExecutorESaI14102789'/>
<use f='tensorflow/tensorflow/compiler/xla/service/service.cc' l='483' u='c' c='_ZN3xla7Service15BuildExecutableERKNS_26VersionedComputationHandleESt10unique_ptrINS_15HloModuleConfigESt14default_deleteIS5_EEPNS_7BackendEPN9perftoo7048551'/>
<use f='tensorflow/tensorflow/compiler/xla/service/service.cc' l='1148' u='c' c='_ZN3xla7Service15BuildExecutableERKNS_14HloModuleProtoESt10unique_ptrINS_15HloModuleConfigESt14default_deleteIS5_EEPNS_7BackendEPN9perftools8gputools116387209'/>
