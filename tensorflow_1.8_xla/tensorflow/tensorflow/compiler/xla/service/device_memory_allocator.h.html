<!doctype html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0"><title>device_memory_allocator.h source code [tensorflow/tensorflow/compiler/xla/service/device_memory_allocator.h] - Woboq Code Browser</title>
<meta name="woboq:interestingDefinitions" content="xla::DeviceMemoryAllocator,xla::StreamExecutorMemoryAllocator "/>
<link rel="stylesheet" href="https://code.woboq.org/data/qtcreator.css" title="QtCreator"/>
<link rel="alternate stylesheet" href="https://code.woboq.org/data/kdevelop.css" title="KDevelop"/>
<script type="text/javascript" src="https://code.woboq.org/data/jquery/jquery.min.js"></script>
<script type="text/javascript" src="https://code.woboq.org/data/jquery/jquery-ui.min.js"></script>
<script>var file = 'tensorflow/tensorflow/compiler/xla/service/device_memory_allocator.h'; var root_path = '../../../../..'; var data_path = 'https://code.woboq.org/data';</script>
<script src='https://code.woboq.org/data/codebrowser.js'></script>
</head>
<body><div id='header'><h1 id='breadcrumb'><span>Browse the source code of </span><a href='../../../..'>tensorflow</a>/<a href='../../..'>tensorflow</a>/<a href='../..'>compiler</a>/<a href='..'>xla</a>/<a href='./'>service</a>/<a href='device_memory_allocator.h.html'>device_memory_allocator.h</a></h1></div>
<hr/><div id='content'><table class="code">
<tr><th id="1">1</th><td><i>/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.</i></td></tr>
<tr><th id="2">2</th><td><i></i></td></tr>
<tr><th id="3">3</th><td><i>Licensed under the Apache License, Version 2.0 (the "License");</i></td></tr>
<tr><th id="4">4</th><td><i>you may not use this file except in compliance with the License.</i></td></tr>
<tr><th id="5">5</th><td><i>You may obtain a copy of the License at</i></td></tr>
<tr><th id="6">6</th><td><i></i></td></tr>
<tr><th id="7">7</th><td><i>    <a href="http://www.apache.org/licenses/LICENSE-2.0">http://www.apache.org/licenses/LICENSE-2.0</a></i></td></tr>
<tr><th id="8">8</th><td><i></i></td></tr>
<tr><th id="9">9</th><td><i>Unless required by applicable law or agreed to in writing, software</i></td></tr>
<tr><th id="10">10</th><td><i>distributed under the License is distributed on an "AS IS" BASIS,</i></td></tr>
<tr><th id="11">11</th><td><i>WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</i></td></tr>
<tr><th id="12">12</th><td><i>See the License for the specific language governing permissions and</i></td></tr>
<tr><th id="13">13</th><td><i>limitations under the License.</i></td></tr>
<tr><th id="14">14</th><td><i>==============================================================================*/</i></td></tr>
<tr><th id="15">15</th><td></td></tr>
<tr><th id="16">16</th><td><u>#<span data-ppcond="16">ifndef</span> <span class="macro" data-ref="_M/TENSORFLOW_COMPILER_XLA_SERVICE_DEVICE_MEMORY_ALLOCATOR_H_">TENSORFLOW_COMPILER_XLA_SERVICE_DEVICE_MEMORY_ALLOCATOR_H_</span></u></td></tr>
<tr><th id="17">17</th><td><u>#define <dfn class="macro" id="_M/TENSORFLOW_COMPILER_XLA_SERVICE_DEVICE_MEMORY_ALLOCATOR_H_" data-ref="_M/TENSORFLOW_COMPILER_XLA_SERVICE_DEVICE_MEMORY_ALLOCATOR_H_">TENSORFLOW_COMPILER_XLA_SERVICE_DEVICE_MEMORY_ALLOCATOR_H_</dfn></u></td></tr>
<tr><th id="18">18</th><td></td></tr>
<tr><th id="19">19</th><td><u>#include <a href="../../../../../include/c++/5/vector.html">&lt;vector&gt;</a></u></td></tr>
<tr><th id="20">20</th><td></td></tr>
<tr><th id="21">21</th><td><u>#include <a href="../statusor.h.html">"tensorflow/compiler/xla/statusor.h"</a></u></td></tr>
<tr><th id="22">22</th><td><u>#include <a href="../types.h.html">"tensorflow/compiler/xla/types.h"</a></u></td></tr>
<tr><th id="23">23</th><td><u>#include <a href="../../../core/lib/gtl/array_slice.h.html">"tensorflow/core/lib/gtl/array_slice.h"</a></u></td></tr>
<tr><th id="24">24</th><td><u>#include <a href="../../../core/platform/stream_executor_no_cuda.h.html">"tensorflow/core/platform/stream_executor_no_cuda.h"</a></u></td></tr>
<tr><th id="25">25</th><td><u>#include <a href="../../../core/platform/types.h.html">"tensorflow/core/platform/types.h"</a></u></td></tr>
<tr><th id="26">26</th><td></td></tr>
<tr><th id="27">27</th><td><b>namespace</b> <span class="namespace">xla</span> {</td></tr>
<tr><th id="28">28</th><td></td></tr>
<tr><th id="29">29</th><td><i>// Interface for device memory allocators used within the XLA service. An</i></td></tr>
<tr><th id="30">30</th><td><i>// allocator is responsible for allocating memory on all devices of a particular</i></td></tr>
<tr><th id="31">31</th><td><i>// platform.</i></td></tr>
<tr><th id="32">32</th><td><b>class</b> <dfn class="type def" id="xla::DeviceMemoryAllocator" title='xla::DeviceMemoryAllocator' data-ref="xla::DeviceMemoryAllocator">DeviceMemoryAllocator</dfn> {</td></tr>
<tr><th id="33">33</th><td> <b>public</b>:</td></tr>
<tr><th id="34">34</th><td>  <i>// Parameter platform indicates which platform the allocator allocates memory</i></td></tr>
<tr><th id="35">35</th><td><i>  // on. Must be non-null.</i></td></tr>
<tr><th id="36">36</th><td>  <b>explicit</b> <dfn class="decl def" id="_ZN3xla21DeviceMemoryAllocatorC1EPKN9perftools8gputools8PlatformE" title='xla::DeviceMemoryAllocator::DeviceMemoryAllocator' data-ref="_ZN3xla21DeviceMemoryAllocatorC1EPKN9perftools8gputools8PlatformE">DeviceMemoryAllocator</dfn>(<em>const</em> <span class="namespace">perftools::gputools::</span><a class="type" href="../../../stream_executor/platform.h.html#perftools::gputools::Platform" title='perftools::gputools::Platform' data-ref="perftools::gputools::Platform">Platform</a>* <dfn class="local col0 decl" id="7010platform" title='platform' data-type='const perftools::gputools::Platform *' data-ref="7010platform">platform</dfn>)</td></tr>
<tr><th id="37">37</th><td>      : <a class="member" href="#xla::DeviceMemoryAllocator::platform_" title='xla::DeviceMemoryAllocator::platform_' data-ref="xla::DeviceMemoryAllocator::platform_">platform_</a>(<a class="local col0 ref" href="#7010platform" title='platform' data-ref="7010platform">platform</a>) {}</td></tr>
<tr><th id="38">38</th><td>  <b>virtual</b> <dfn class="virtual decl def" id="_ZN3xla21DeviceMemoryAllocatorD1Ev" title='xla::DeviceMemoryAllocator::~DeviceMemoryAllocator' data-ref="_ZN3xla21DeviceMemoryAllocatorD1Ev">~DeviceMemoryAllocator</dfn>() {}</td></tr>
<tr><th id="39">39</th><td></td></tr>
<tr><th id="40">40</th><td>  <i>// 'retry_on_failure': If false, and the first attempt to allocate the memory</i></td></tr>
<tr><th id="41">41</th><td><i>  // fails, the allocation should return immediately without retrying.</i></td></tr>
<tr><th id="42">42</th><td><i>  // An example use case is optional scratch spaces where a failure</i></td></tr>
<tr><th id="43">43</th><td><i>  // has only performance impact.</i></td></tr>
<tr><th id="44">44</th><td><i>  // Allocate() should return a null pointer for a size-0 allocation.</i></td></tr>
<tr><th id="45">45</th><td><i>  // Deallocate() must be a no-op for null pointers.</i></td></tr>
<tr><th id="46">46</th><td>  <b>virtual</b> <a class="type" href="../statusor.h.html#xla::StatusOr" title='xla::StatusOr' data-ref="xla::StatusOr">StatusOr</a>&lt;<span class="namespace">perftools::gputools::</span><a class="type" href="../../../stream_executor/device_memory.h.html#perftools::gputools::DeviceMemoryBase" title='perftools::gputools::DeviceMemoryBase' data-ref="perftools::gputools::DeviceMemoryBase">DeviceMemoryBase</a>&gt; <dfn class="virtual decl" id="_ZN3xla21DeviceMemoryAllocator8AllocateEiyb" title='xla::DeviceMemoryAllocator::Allocate' data-ref="_ZN3xla21DeviceMemoryAllocator8AllocateEiyb">Allocate</dfn>(</td></tr>
<tr><th id="47">47</th><td>      <em>int</em> <dfn class="local col1 decl" id="7011device_ordinal" title='device_ordinal' data-type='int' data-ref="7011device_ordinal">device_ordinal</dfn>, <a class="typedef" href="../../../core/platform/default/integral_types.h.html#tensorflow::uint64" title='tensorflow::uint64' data-type='unsigned long long' data-ref="tensorflow::uint64">uint64</a> <dfn class="local col2 decl" id="7012size" title='size' data-type='uint64' data-ref="7012size">size</dfn>, <em>bool</em> <dfn class="local col3 decl" id="7013retry_on_failure" title='retry_on_failure' data-type='bool' data-ref="7013retry_on_failure">retry_on_failure</dfn> = <b>true</b>) = <var>0</var>;</td></tr>
<tr><th id="48">48</th><td>  <b>virtual</b> <span class="namespace">tensorflow::</span><a class="type" href="../../../core/lib/core/status.h.html#tensorflow::Status" title='tensorflow::Status' data-ref="tensorflow::Status">Status</a> <dfn class="virtual decl" id="_ZN3xla21DeviceMemoryAllocator10DeallocateEiPN9perftools8gputools16DeviceMemoryBaseE" title='xla::DeviceMemoryAllocator::Deallocate' data-ref="_ZN3xla21DeviceMemoryAllocator10DeallocateEiPN9perftools8gputools16DeviceMemoryBaseE">Deallocate</dfn>(</td></tr>
<tr><th id="49">49</th><td>      <em>int</em> <dfn class="local col4 decl" id="7014device_ordinal" title='device_ordinal' data-type='int' data-ref="7014device_ordinal">device_ordinal</dfn>, <span class="namespace">perftools::gputools::</span><a class="type" href="../../../stream_executor/device_memory.h.html#perftools::gputools::DeviceMemoryBase" title='perftools::gputools::DeviceMemoryBase' data-ref="perftools::gputools::DeviceMemoryBase">DeviceMemoryBase</a>* <dfn class="local col5 decl" id="7015mem" title='mem' data-type='perftools::gputools::DeviceMemoryBase *' data-ref="7015mem">mem</dfn>) = <var>0</var>;</td></tr>
<tr><th id="50">50</th><td></td></tr>
<tr><th id="51">51</th><td>  <i>// Return the platform that the allocator allocates memory on.</i></td></tr>
<tr><th id="52">52</th><td>  <em>const</em> <span class="namespace">perftools::gputools::</span><a class="type" href="../../../stream_executor/platform.h.html#perftools::gputools::Platform" title='perftools::gputools::Platform' data-ref="perftools::gputools::Platform">Platform</a>* <dfn class="decl def" id="_ZNK3xla21DeviceMemoryAllocator8platformEv" title='xla::DeviceMemoryAllocator::platform' data-ref="_ZNK3xla21DeviceMemoryAllocator8platformEv">platform</dfn>() <em>const</em> { <b>return</b> <a class="member" href="#xla::DeviceMemoryAllocator::platform_" title='xla::DeviceMemoryAllocator::platform_' data-ref="xla::DeviceMemoryAllocator::platform_">platform_</a>; }</td></tr>
<tr><th id="53">53</th><td></td></tr>
<tr><th id="54">54</th><td>  <i>// Can we call Deallocate() as soon as a computation has been scheduled on</i></td></tr>
<tr><th id="55">55</th><td><i>  // a stream, or do we have to wait for the computation to complete first?</i></td></tr>
<tr><th id="56">56</th><td>  <b>virtual</b> <em>bool</em> <dfn class="virtual decl" id="_ZNK3xla21DeviceMemoryAllocator30AllowsAsynchronousDeallocationEv" title='xla::DeviceMemoryAllocator::AllowsAsynchronousDeallocation' data-ref="_ZNK3xla21DeviceMemoryAllocator30AllowsAsynchronousDeallocationEv">AllowsAsynchronousDeallocation</dfn>() <em>const</em> = <var>0</var>;</td></tr>
<tr><th id="57">57</th><td></td></tr>
<tr><th id="58">58</th><td> <b>protected</b>:</td></tr>
<tr><th id="59">59</th><td>  <em>const</em> <span class="namespace">perftools::gputools::</span><a class="type" href="../../../stream_executor/platform.h.html#perftools::gputools::Platform" title='perftools::gputools::Platform' data-ref="perftools::gputools::Platform">Platform</a>* <dfn class="decl" id="xla::DeviceMemoryAllocator::platform_" title='xla::DeviceMemoryAllocator::platform_' data-ref="xla::DeviceMemoryAllocator::platform_">platform_</dfn>;</td></tr>
<tr><th id="60">60</th><td>};</td></tr>
<tr><th id="61">61</th><td></td></tr>
<tr><th id="62">62</th><td><i>// Default memory allocator for a platform which uses</i></td></tr>
<tr><th id="63">63</th><td><i>// StreamExecutor::Allocate/Deallocate.</i></td></tr>
<tr><th id="64">64</th><td><b>class</b> <dfn class="type def" id="xla::StreamExecutorMemoryAllocator" title='xla::StreamExecutorMemoryAllocator' data-ref="xla::StreamExecutorMemoryAllocator">StreamExecutorMemoryAllocator</dfn> : <b>public</b> <a class="type" href="#xla::DeviceMemoryAllocator" title='xla::DeviceMemoryAllocator' data-ref="xla::DeviceMemoryAllocator">DeviceMemoryAllocator</a> {</td></tr>
<tr><th id="65">65</th><td> <b>public</b>:</td></tr>
<tr><th id="66">66</th><td>  <dfn class="decl" id="_ZN3xla29StreamExecutorMemoryAllocatorC1EPKN9perftools8gputools8PlatformEN10tensorflow3gtl10ArraySliceIPNS2_14StreamExecutorEEE" title='xla::StreamExecutorMemoryAllocator::StreamExecutorMemoryAllocator' data-ref="_ZN3xla29StreamExecutorMemoryAllocatorC1EPKN9perftools8gputools8PlatformEN10tensorflow3gtl10ArraySliceIPNS2_14StreamExecutorEEE">StreamExecutorMemoryAllocator</dfn>(</td></tr>
<tr><th id="67">67</th><td>      <em>const</em> <span class="namespace">perftools::gputools::</span><a class="type" href="../../../stream_executor/platform.h.html#perftools::gputools::Platform" title='perftools::gputools::Platform' data-ref="perftools::gputools::Platform">Platform</a>* <dfn class="local col6 decl" id="7016platform" title='platform' data-type='const perftools::gputools::Platform *' data-ref="7016platform">platform</dfn>,</td></tr>
<tr><th id="68">68</th><td>      <span class="namespace">tensorflow::gtl::</span><a class="type" href="../../../core/lib/gtl/array_slice.h.html#tensorflow::gtl::ArraySlice" title='tensorflow::gtl::ArraySlice' data-ref="tensorflow::gtl::ArraySlice">ArraySlice</a>&lt;<span class="namespace">perftools::gputools::</span><a class="type" href="../../../stream_executor/stream_executor_pimpl.h.html#perftools::gputools::StreamExecutor" title='perftools::gputools::StreamExecutor' data-ref="perftools::gputools::StreamExecutor">StreamExecutor</a>*&gt;</td></tr>
<tr><th id="69">69</th><td>          <dfn class="local col7 decl" id="7017stream_executors" title='stream_executors' data-type='tensorflow::gtl::ArraySlice&lt;perftools::gputools::StreamExecutor *&gt;' data-ref="7017stream_executors">stream_executors</dfn>);</td></tr>
<tr><th id="70">70</th><td></td></tr>
<tr><th id="71">71</th><td>  <a class="type" href="../statusor.h.html#xla::StatusOr" title='xla::StatusOr' data-ref="xla::StatusOr">StatusOr</a>&lt;<span class="namespace">perftools::gputools::</span><a class="type" href="../../../stream_executor/device_memory.h.html#perftools::gputools::DeviceMemoryBase" title='perftools::gputools::DeviceMemoryBase' data-ref="perftools::gputools::DeviceMemoryBase">DeviceMemoryBase</a>&gt; <dfn class="virtual decl" id="_ZN3xla29StreamExecutorMemoryAllocator8AllocateEiyb" title='xla::StreamExecutorMemoryAllocator::Allocate' data-ref="_ZN3xla29StreamExecutorMemoryAllocator8AllocateEiyb">Allocate</dfn>(</td></tr>
<tr><th id="72">72</th><td>      <em>int</em> <dfn class="local col8 decl" id="7018device_ordinal" title='device_ordinal' data-type='int' data-ref="7018device_ordinal">device_ordinal</dfn>, <a class="typedef" href="../../../core/platform/default/integral_types.h.html#tensorflow::uint64" title='tensorflow::uint64' data-type='unsigned long long' data-ref="tensorflow::uint64">uint64</a> <dfn class="local col9 decl" id="7019size" title='size' data-type='uint64' data-ref="7019size">size</dfn>, <em>bool</em> <dfn class="local col0 decl" id="7020retry_on_failure" title='retry_on_failure' data-type='bool' data-ref="7020retry_on_failure">retry_on_failure</dfn> = <b>true</b>) override;</td></tr>
<tr><th id="73">73</th><td>  <span class="namespace">tensorflow::</span><a class="type" href="../../../core/lib/core/status.h.html#tensorflow::Status" title='tensorflow::Status' data-ref="tensorflow::Status">Status</a> <dfn class="virtual decl" id="_ZN3xla29StreamExecutorMemoryAllocator10DeallocateEiPN9perftools8gputools16DeviceMemoryBaseE" title='xla::StreamExecutorMemoryAllocator::Deallocate' data-ref="_ZN3xla29StreamExecutorMemoryAllocator10DeallocateEiPN9perftools8gputools16DeviceMemoryBaseE">Deallocate</dfn>(</td></tr>
<tr><th id="74">74</th><td>      <em>int</em> <dfn class="local col1 decl" id="7021device_ordinal" title='device_ordinal' data-type='int' data-ref="7021device_ordinal">device_ordinal</dfn>, <span class="namespace">perftools::gputools::</span><a class="type" href="../../../stream_executor/device_memory.h.html#perftools::gputools::DeviceMemoryBase" title='perftools::gputools::DeviceMemoryBase' data-ref="perftools::gputools::DeviceMemoryBase">DeviceMemoryBase</a>* <dfn class="local col2 decl" id="7022mem" title='mem' data-type='perftools::gputools::DeviceMemoryBase *' data-ref="7022mem">mem</dfn>) override;</td></tr>
<tr><th id="75">75</th><td></td></tr>
<tr><th id="76">76</th><td>  <em>bool</em> <dfn class="virtual decl" id="_ZNK3xla29StreamExecutorMemoryAllocator30AllowsAsynchronousDeallocationEv" title='xla::StreamExecutorMemoryAllocator::AllowsAsynchronousDeallocation' data-ref="_ZNK3xla29StreamExecutorMemoryAllocator30AllowsAsynchronousDeallocationEv">AllowsAsynchronousDeallocation</dfn>() <em>const</em> override;</td></tr>
<tr><th id="77">77</th><td></td></tr>
<tr><th id="78">78</th><td> <b>private</b>:</td></tr>
<tr><th id="79">79</th><td>  <a class="type" href="../statusor.h.html#xla::StatusOr" title='xla::StatusOr' data-ref="xla::StatusOr">StatusOr</a>&lt;<span class="namespace">perftools::gputools::</span><a class="type" href="../../../stream_executor/stream_executor_pimpl.h.html#perftools::gputools::StreamExecutor" title='perftools::gputools::StreamExecutor' data-ref="perftools::gputools::StreamExecutor">StreamExecutor</a>*&gt; <dfn class="decl" id="_ZN3xla29StreamExecutorMemoryAllocator17GetStreamExecutorEi" title='xla::StreamExecutorMemoryAllocator::GetStreamExecutor' data-ref="_ZN3xla29StreamExecutorMemoryAllocator17GetStreamExecutorEi">GetStreamExecutor</dfn>(</td></tr>
<tr><th id="80">80</th><td>      <em>int</em> <dfn class="local col3 decl" id="7023device_ordinal" title='device_ordinal' data-type='int' data-ref="7023device_ordinal">device_ordinal</dfn>);</td></tr>
<tr><th id="81">81</th><td></td></tr>
<tr><th id="82">82</th><td>  <i>// A vector indexed by device ordinal of StreamExecutors for each device of</i></td></tr>
<tr><th id="83">83</th><td><i>  // the allocator's platform type. If an element is nullptr, then the device</i></td></tr>
<tr><th id="84">84</th><td><i>  // with the respective device ordinal is not supported by XLA.</i></td></tr>
<tr><th id="85">85</th><td>  <span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/stl_vector.h.html#std::vector" title='std::vector' data-ref="std::vector">vector</a>&lt;<span class="namespace">perftools::gputools::</span><a class="type" href="../../../stream_executor/stream_executor_pimpl.h.html#perftools::gputools::StreamExecutor" title='perftools::gputools::StreamExecutor' data-ref="perftools::gputools::StreamExecutor">StreamExecutor</a>*&gt; <dfn class="decl" id="xla::StreamExecutorMemoryAllocator::stream_executors_" title='xla::StreamExecutorMemoryAllocator::stream_executors_' data-ref="xla::StreamExecutorMemoryAllocator::stream_executors_">stream_executors_</dfn>;</td></tr>
<tr><th id="86">86</th><td>};</td></tr>
<tr><th id="87">87</th><td></td></tr>
<tr><th id="88">88</th><td>}  <i>// namespace xla</i></td></tr>
<tr><th id="89">89</th><td></td></tr>
<tr><th id="90">90</th><td><u>#<span data-ppcond="16">endif</span>  // TENSORFLOW_COMPILER_XLA_SERVICE_DEVICE_MEMORY_ALLOCATOR_H_</u></td></tr>
<tr><th id="91">91</th><td></td></tr>
</table><hr/><p id='footer'>
Generated while processing <a href='../../jit/kernels/xla_launch_op.cc.html'>tensorflow/tensorflow/compiler/jit/kernels/xla_launch_op.cc</a><br/>Generated on <em>2018-Aug-09</em> from project tensorflow revision <em>v1.8</em><br />Powered by <a href='https://woboq.com'><img alt='Woboq' src='https://code.woboq.org/woboq-16.png' width='41' height='16' /></a> <a href='https://code.woboq.org'>Code Browser</a> 2.1
<br/>Generator usage only permitted with license.</p>
</div></body></html>
