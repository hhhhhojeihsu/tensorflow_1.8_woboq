<!doctype html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0"><title>parallel_loop_emitter.h source code [tensorflow/tensorflow/compiler/xla/service/gpu/parallel_loop_emitter.h] - Woboq Code Browser</title>
<meta name="woboq:interestingDefinitions" content="xla::gpu::ParallelLoopEmitter "/>
<link rel="stylesheet" href="https://code.woboq.org/data/qtcreator.css" title="QtCreator"/>
<link rel="alternate stylesheet" href="https://code.woboq.org/data/kdevelop.css" title="KDevelop"/>
<script type="text/javascript" src="https://code.woboq.org/data/jquery/jquery.min.js"></script>
<script type="text/javascript" src="https://code.woboq.org/data/jquery/jquery-ui.min.js"></script>
<script>var file = 'tensorflow/tensorflow/compiler/xla/service/gpu/parallel_loop_emitter.h'; var root_path = '../../../../../..'; var data_path = 'https://code.woboq.org/data';</script>
<script src='https://code.woboq.org/data/codebrowser.js'></script>
</head>
<body><div id='header'><h1 id='breadcrumb'><span>Browse the source code of </span><a href='../../../../..'>tensorflow</a>/<a href='../../../..'>tensorflow</a>/<a href='../../..'>compiler</a>/<a href='../..'>xla</a>/<a href='..'>service</a>/<a href='./'>gpu</a>/<a href='parallel_loop_emitter.h.html'>parallel_loop_emitter.h</a></h1></div>
<hr/><div id='content'><table class="code">
<tr><th id="1">1</th><td><i>/* Copyright 2017 The TensorFlow Authors. All Rights Reserved.</i></td></tr>
<tr><th id="2">2</th><td><i></i></td></tr>
<tr><th id="3">3</th><td><i>Licensed under the Apache License, Version 2.0 (the "License");</i></td></tr>
<tr><th id="4">4</th><td><i>you may not use this file except in compliance with the License.</i></td></tr>
<tr><th id="5">5</th><td><i>You may obtain a copy of the License at</i></td></tr>
<tr><th id="6">6</th><td><i></i></td></tr>
<tr><th id="7">7</th><td><i>    <a href="http://www.apache.org/licenses/LICENSE-2.0">http://www.apache.org/licenses/LICENSE-2.0</a></i></td></tr>
<tr><th id="8">8</th><td><i></i></td></tr>
<tr><th id="9">9</th><td><i>Unless required by applicable law or agreed to in writing, software</i></td></tr>
<tr><th id="10">10</th><td><i>distributed under the License is distributed on an "AS IS" BASIS,</i></td></tr>
<tr><th id="11">11</th><td><i>WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</i></td></tr>
<tr><th id="12">12</th><td><i>See the License for the specific language governing permissions and</i></td></tr>
<tr><th id="13">13</th><td><i>limitations under the License.</i></td></tr>
<tr><th id="14">14</th><td><i>==============================================================================*/</i></td></tr>
<tr><th id="15">15</th><td></td></tr>
<tr><th id="16">16</th><td><u>#<span data-ppcond="16">ifndef</span> <span class="macro" data-ref="_M/TENSORFLOW_COMPILER_XLA_SERVICE_GPU_PARALLEL_LOOP_EMITTER_H_">TENSORFLOW_COMPILER_XLA_SERVICE_GPU_PARALLEL_LOOP_EMITTER_H_</span></u></td></tr>
<tr><th id="17">17</th><td><u>#define <dfn class="macro" id="_M/TENSORFLOW_COMPILER_XLA_SERVICE_GPU_PARALLEL_LOOP_EMITTER_H_" data-ref="_M/TENSORFLOW_COMPILER_XLA_SERVICE_GPU_PARALLEL_LOOP_EMITTER_H_">TENSORFLOW_COMPILER_XLA_SERVICE_GPU_PARALLEL_LOOP_EMITTER_H_</dfn></u></td></tr>
<tr><th id="18">18</th><td></td></tr>
<tr><th id="19">19</th><td><u>#include "llvm/IR/IRBuilder.h"</u></td></tr>
<tr><th id="20">20</th><td><u>#include <a href="partition_assignment.h.html">"tensorflow/compiler/xla/service/gpu/partition_assignment.h"</a></u></td></tr>
<tr><th id="21">21</th><td><u>#include <a href="../llvm_ir/ir_array.h.html">"tensorflow/compiler/xla/service/llvm_ir/ir_array.h"</a></u></td></tr>
<tr><th id="22">22</th><td><u>#include <a href="../llvm_ir/loop_emitter.h.html">"tensorflow/compiler/xla/service/llvm_ir/loop_emitter.h"</a></u></td></tr>
<tr><th id="23">23</th><td></td></tr>
<tr><th id="24">24</th><td><b>namespace</b> <span class="namespace">xla</span> {</td></tr>
<tr><th id="25">25</th><td><b>namespace</b> <span class="namespace">gpu</span> {</td></tr>
<tr><th id="26">26</th><td></td></tr>
<tr><th id="27">27</th><td><i>// Emits a parallel loop for every element in the given array shape. This loop</i></td></tr>
<tr><th id="28">28</th><td><i>// emitted will be executed by multiple threads in parallel. Therefore, each</i></td></tr>
<tr><th id="29">29</th><td><i>// thread instance of the loop iterates over part of the array, and they</i></td></tr>
<tr><th id="30">30</th><td><i>// collectively iterates over the entire array.</i></td></tr>
<tr><th id="31">31</th><td><b>class</b> <dfn class="type def" id="xla::gpu::ParallelLoopEmitter" title='xla::gpu::ParallelLoopEmitter' data-ref="xla::gpu::ParallelLoopEmitter">ParallelLoopEmitter</dfn> : <b>public</b> <span class="namespace">llvm_ir::</span><a class="type" href="../llvm_ir/loop_emitter.h.html#xla::llvm_ir::LoopEmitter" title='xla::llvm_ir::LoopEmitter' data-ref="xla::llvm_ir::LoopEmitter">LoopEmitter</a> {</td></tr>
<tr><th id="32">32</th><td> <b>public</b>:</td></tr>
<tr><th id="33">33</th><td>  <i>// `thread_count` is the number of threads to parallelize the loop on.</i></td></tr>
<tr><th id="34">34</th><td><i>  // The meanings of other parameters are the same as LoopEmitter.</i></td></tr>
<tr><th id="35">35</th><td>  <a class="decl" href="parallel_loop_emitter.cc.html#_ZN3xla3gpu19ParallelLoopEmitterC1ESt8functionIFN10tensorflow6StatusERKNS_7llvm_ir7IrArray5IndexEEERKNS_5ShapeERKNS0_16LaunchDimensionsEPN4llvm9IRBuil11960996" title='xla::gpu::ParallelLoopEmitter::ParallelLoopEmitter' data-ref="_ZN3xla3gpu19ParallelLoopEmitterC1ESt8functionIFN10tensorflow6StatusERKNS_7llvm_ir7IrArray5IndexEEERKNS_5ShapeERKNS0_16LaunchDimensionsEPN4llvm9IRBuil11960996" id="_ZN3xla3gpu19ParallelLoopEmitterC1ESt8functionIFN10tensorflow6StatusERKNS_7llvm_ir7IrArray5IndexEEERKNS_5ShapeERKNS0_16LaunchDimensionsEPN4llvm9IRBuil11960996">ParallelLoopEmitter</a>(<a class="typedef" href="../llvm_ir/loop_emitter.h.html#xla::llvm_ir::LoopEmitter::BodyEmitter" title='xla::llvm_ir::LoopEmitter::BodyEmitter' data-type='std::function&lt;tensorflow::Status (const IrArray::Index &amp;)&gt;' data-ref="xla::llvm_ir::LoopEmitter::BodyEmitter">BodyEmitter</a> <dfn class="local col1 decl" id="1body_emitter" title='body_emitter' data-type='BodyEmitter' data-ref="1body_emitter">body_emitter</dfn>, <em>const</em> <a class="type" href="../../xla_data.pb.h.html#xla::Shape" title='xla::Shape' data-ref="xla::Shape">Shape</a>&amp; <dfn class="local col2 decl" id="2shape" title='shape' data-type='const xla::Shape &amp;' data-ref="2shape">shape</dfn>,</td></tr>
<tr><th id="36">36</th><td>                      <em>const</em> <a class="type" href="partition_assignment.h.html#xla::gpu::LaunchDimensions" title='xla::gpu::LaunchDimensions' data-ref="xla::gpu::LaunchDimensions">LaunchDimensions</a>&amp; <dfn class="local col3 decl" id="3launch_dimensions" title='launch_dimensions' data-type='const xla::gpu::LaunchDimensions &amp;' data-ref="3launch_dimensions">launch_dimensions</dfn>,</td></tr>
<tr><th id="37">37</th><td>                      <span class="namespace">llvm::</span><span class='type' title='llvm::IRBuilder' data-ref="llvm::IRBuilder">IRBuilder</span>&lt;&gt;* <dfn class="local col4 decl" id="4ir_builder" title='ir_builder' data-type='llvm::IRBuilder&lt;&gt; *' data-ref="4ir_builder">ir_builder</dfn>);</td></tr>
<tr><th id="38">38</th><td>  <i>// Constructs a ParallelLoopEmitter from an element generator that generates</i></td></tr>
<tr><th id="39">39</th><td><i>  // each element of the given target array.</i></td></tr>
<tr><th id="40">40</th><td>  <a class="decl" href="parallel_loop_emitter.cc.html#_ZN3xla3gpu19ParallelLoopEmitterC1ERKSt8functionIFNS_8StatusOrIPN4llvm5ValueEEERKNS_7llvm_ir7IrArray5IndexEEERKS9_RKNS0_16LaunchDimensionsEPNS4_9IRBui11611440" title='xla::gpu::ParallelLoopEmitter::ParallelLoopEmitter' data-ref="_ZN3xla3gpu19ParallelLoopEmitterC1ERKSt8functionIFNS_8StatusOrIPN4llvm5ValueEEERKNS_7llvm_ir7IrArray5IndexEEERKS9_RKNS0_16LaunchDimensionsEPNS4_9IRBui11611440" id="_ZN3xla3gpu19ParallelLoopEmitterC1ERKSt8functionIFNS_8StatusOrIPN4llvm5ValueEEERKNS_7llvm_ir7IrArray5IndexEEERKS9_RKNS0_16LaunchDimensionsEPNS4_9IRBui11611440">ParallelLoopEmitter</a>(<em>const</em> <span class="namespace">llvm_ir::</span><a class="typedef" href="../llvm_ir/loop_emitter.h.html#xla::llvm_ir::ElementGenerator" title='xla::llvm_ir::ElementGenerator' data-type='std::function&lt;StatusOr&lt;llvm::Value *&gt; (const IrArray::Index &amp;)&gt;' data-ref="xla::llvm_ir::ElementGenerator">ElementGenerator</a>&amp; <dfn class="local col5 decl" id="5target_element_generator" title='target_element_generator' data-type='const llvm_ir::ElementGenerator &amp;' data-ref="5target_element_generator">target_element_generator</dfn>,</td></tr>
<tr><th id="41">41</th><td>                      <em>const</em> <span class="namespace">llvm_ir::</span><a class="type" href="../llvm_ir/ir_array.h.html#xla::llvm_ir::IrArray" title='xla::llvm_ir::IrArray' data-ref="xla::llvm_ir::IrArray">IrArray</a>&amp; <dfn class="local col6 decl" id="6target_array" title='target_array' data-type='const llvm_ir::IrArray &amp;' data-ref="6target_array">target_array</dfn>,</td></tr>
<tr><th id="42">42</th><td>                      <em>const</em> <a class="type" href="partition_assignment.h.html#xla::gpu::LaunchDimensions" title='xla::gpu::LaunchDimensions' data-ref="xla::gpu::LaunchDimensions">LaunchDimensions</a>&amp; <dfn class="local col7 decl" id="7launch_dimensions" title='launch_dimensions' data-type='const xla::gpu::LaunchDimensions &amp;' data-ref="7launch_dimensions">launch_dimensions</dfn>,</td></tr>
<tr><th id="43">43</th><td>                      <span class="namespace">llvm::</span><span class='type' title='llvm::IRBuilder' data-ref="llvm::IRBuilder">IRBuilder</span>&lt;&gt;* <dfn class="local col8 decl" id="8ir_builder" title='ir_builder' data-type='llvm::IRBuilder&lt;&gt; *' data-ref="8ir_builder">ir_builder</dfn>);</td></tr>
<tr><th id="44">44</th><td></td></tr>
<tr><th id="45">45</th><td>  <i>// Constructs a loop emitter for a loop that generates on element of each of N</i></td></tr>
<tr><th id="46">46</th><td><i>  // arrays on each iteration.</i></td></tr>
<tr><th id="47">47</th><td><i>  //</i></td></tr>
<tr><th id="48">48</th><td><i>  // This is used in multi-output fusion.  target_element_generator should</i></td></tr>
<tr><th id="49">49</th><td><i>  // produce a struct with N elements, one for each of target_arrays.</i></td></tr>
<tr><th id="50">50</th><td>  <a class="decl" href="parallel_loop_emitter.cc.html#_ZN3xla3gpu19ParallelLoopEmitterC1ERKSt8functionIFNS_8StatusOrIPN4llvm5ValueEEERKNS_7llvm_ir7IrArray5IndexEEEN10tensorflow3gtl10ArraySliceIS9_EERKNS0_6328673" title='xla::gpu::ParallelLoopEmitter::ParallelLoopEmitter' data-ref="_ZN3xla3gpu19ParallelLoopEmitterC1ERKSt8functionIFNS_8StatusOrIPN4llvm5ValueEEERKNS_7llvm_ir7IrArray5IndexEEEN10tensorflow3gtl10ArraySliceIS9_EERKNS0_6328673" id="_ZN3xla3gpu19ParallelLoopEmitterC1ERKSt8functionIFNS_8StatusOrIPN4llvm5ValueEEERKNS_7llvm_ir7IrArray5IndexEEEN10tensorflow3gtl10ArraySliceIS9_EERKNS0_6328673">ParallelLoopEmitter</a>(</td></tr>
<tr><th id="51">51</th><td>      <em>const</em> <span class="namespace">llvm_ir::</span><a class="typedef" href="../llvm_ir/loop_emitter.h.html#xla::llvm_ir::ElementGenerator" title='xla::llvm_ir::ElementGenerator' data-type='std::function&lt;StatusOr&lt;llvm::Value *&gt; (const IrArray::Index &amp;)&gt;' data-ref="xla::llvm_ir::ElementGenerator">ElementGenerator</a>&amp; <dfn class="local col9 decl" id="9target_element_generator" title='target_element_generator' data-type='const llvm_ir::ElementGenerator &amp;' data-ref="9target_element_generator">target_element_generator</dfn>,</td></tr>
<tr><th id="52">52</th><td>      <span class="namespace">tensorflow::gtl::</span><a class="type" href="../../../../core/lib/gtl/array_slice.h.html#tensorflow::gtl::ArraySlice" title='tensorflow::gtl::ArraySlice' data-ref="tensorflow::gtl::ArraySlice">ArraySlice</a>&lt;<span class="namespace">llvm_ir::</span><a class="type" href="../llvm_ir/ir_array.h.html#xla::llvm_ir::IrArray" title='xla::llvm_ir::IrArray' data-ref="xla::llvm_ir::IrArray">IrArray</a>&gt; <dfn class="local col0 decl" id="10target_arrays" title='target_arrays' data-type='tensorflow::gtl::ArraySlice&lt;llvm_ir::IrArray&gt;' data-ref="10target_arrays">target_arrays</dfn>,</td></tr>
<tr><th id="53">53</th><td>      <em>const</em> <a class="type" href="partition_assignment.h.html#xla::gpu::LaunchDimensions" title='xla::gpu::LaunchDimensions' data-ref="xla::gpu::LaunchDimensions">LaunchDimensions</a>&amp; <dfn class="local col1 decl" id="11launch_dimensions" title='launch_dimensions' data-type='const xla::gpu::LaunchDimensions &amp;' data-ref="11launch_dimensions">launch_dimensions</dfn>, <span class="namespace">llvm::</span><span class='type' title='llvm::IRBuilder' data-ref="llvm::IRBuilder">IRBuilder</span>&lt;&gt;* <dfn class="local col2 decl" id="12ir_builder" title='ir_builder' data-type='llvm::IRBuilder&lt;&gt; *' data-ref="12ir_builder">ir_builder</dfn>);</td></tr>
<tr><th id="54">54</th><td></td></tr>
<tr><th id="55">55</th><td>  <dfn class="decl def" id="_ZN3xla3gpu19ParallelLoopEmitterC1ERKS1_" title='xla::gpu::ParallelLoopEmitter::ParallelLoopEmitter' data-ref="_ZN3xla3gpu19ParallelLoopEmitterC1ERKS1_">ParallelLoopEmitter</dfn>(<em>const</em> <a class="type" href="#xla::gpu::ParallelLoopEmitter" title='xla::gpu::ParallelLoopEmitter' data-ref="xla::gpu::ParallelLoopEmitter">ParallelLoopEmitter</a>&amp;) = <b>delete</b>;</td></tr>
<tr><th id="56">56</th><td>  <a class="type" href="#xla::gpu::ParallelLoopEmitter" title='xla::gpu::ParallelLoopEmitter' data-ref="xla::gpu::ParallelLoopEmitter">ParallelLoopEmitter</a>&amp; <dfn class="decl def" id="_ZN3xla3gpu19ParallelLoopEmitteraSERKS1_" title='xla::gpu::ParallelLoopEmitter::operator=' data-ref="_ZN3xla3gpu19ParallelLoopEmitteraSERKS1_"><b>operator</b>=</dfn>(<em>const</em> <a class="type" href="#xla::gpu::ParallelLoopEmitter" title='xla::gpu::ParallelLoopEmitter' data-ref="xla::gpu::ParallelLoopEmitter">ParallelLoopEmitter</a>&amp;) = <b>delete</b>;</td></tr>
<tr><th id="57">57</th><td>  <dfn class="virtual decl" id="_ZN3xla3gpu19ParallelLoopEmitterD1Ev" title='xla::gpu::ParallelLoopEmitter::~ParallelLoopEmitter' data-ref="_ZN3xla3gpu19ParallelLoopEmitterD1Ev">~ParallelLoopEmitter</dfn>() override = <b>default</b>;</td></tr>
<tr><th id="58">58</th><td></td></tr>
<tr><th id="59">59</th><td>  <span class="namespace">llvm_ir::</span><a class="type" href="../llvm_ir/ir_array.h.html#xla::llvm_ir::IrArray" title='xla::llvm_ir::IrArray' data-ref="xla::llvm_ir::IrArray">IrArray</a>::<a class="type" href="../llvm_ir/ir_array.h.html#xla::llvm_ir::IrArray::Index" title='xla::llvm_ir::IrArray::Index' data-ref="xla::llvm_ir::IrArray::Index">Index</a> <a class="virtual decl" href="parallel_loop_emitter.cc.html#_ZN3xla3gpu19ParallelLoopEmitter29EmitIndexAndSetExitBasicBlockEN10tensorflow11StringPieceE" title='xla::gpu::ParallelLoopEmitter::EmitIndexAndSetExitBasicBlock' data-ref="_ZN3xla3gpu19ParallelLoopEmitter29EmitIndexAndSetExitBasicBlockEN10tensorflow11StringPieceE" id="_ZN3xla3gpu19ParallelLoopEmitter29EmitIndexAndSetExitBasicBlockEN10tensorflow11StringPieceE">EmitIndexAndSetExitBasicBlock</a>(</td></tr>
<tr><th id="60">60</th><td>      <span class="namespace">tensorflow::</span><a class="type" href="../../../../core/lib/core/stringpiece.h.html#tensorflow::StringPiece" title='tensorflow::StringPiece' data-ref="tensorflow::StringPiece">StringPiece</a> <dfn class="local col3 decl" id="13loop_name" title='loop_name' data-type='tensorflow::StringPiece' data-ref="13loop_name">loop_name</dfn>) override;</td></tr>
<tr><th id="61">61</th><td></td></tr>
<tr><th id="62">62</th><td> <b>private</b>:</td></tr>
<tr><th id="63">63</th><td>  <i>// The thread and block dimension to parallelize the loop on.</i></td></tr>
<tr><th id="64">64</th><td>  <em>const</em> <a class="type" href="partition_assignment.h.html#xla::gpu::LaunchDimensions" title='xla::gpu::LaunchDimensions' data-ref="xla::gpu::LaunchDimensions">LaunchDimensions</a> <dfn class="decl" id="xla::gpu::ParallelLoopEmitter::launch_dimensions_" title='xla::gpu::ParallelLoopEmitter::launch_dimensions_' data-ref="xla::gpu::ParallelLoopEmitter::launch_dimensions_">launch_dimensions_</dfn>;</td></tr>
<tr><th id="65">65</th><td>};</td></tr>
<tr><th id="66">66</th><td></td></tr>
<tr><th id="67">67</th><td>}  <i>// namespace gpu</i></td></tr>
<tr><th id="68">68</th><td>}  <i>// namespace xla</i></td></tr>
<tr><th id="69">69</th><td></td></tr>
<tr><th id="70">70</th><td><u>#<span data-ppcond="16">endif</span>  // TENSORFLOW_COMPILER_XLA_SERVICE_GPU_PARALLEL_LOOP_EMITTER_H_</u></td></tr>
<tr><th id="71">71</th><td></td></tr>
</table><hr/><p id='footer'>
Generated while processing <a href='parallel_loop_emitter.cc.html'>tensorflow/tensorflow/compiler/xla/service/gpu/parallel_loop_emitter.cc</a><br/>Generated on <em>2018-Sep-06</em> from project tensorflow revision <em>v1.8</em><br />Powered by <a href='https://woboq.com'><img alt='Woboq' src='https://code.woboq.org/woboq-16.png' width='41' height='16' /></a> <a href='https://code.woboq.org'>Code Browser</a> 2.1
<br/>Generator usage only permitted with license.</p>
</div></body></html>
