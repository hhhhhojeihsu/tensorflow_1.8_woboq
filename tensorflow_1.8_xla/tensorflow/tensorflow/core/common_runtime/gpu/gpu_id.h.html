<!doctype html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0"><title>gpu_id.h source code [tensorflow/tensorflow/core/common_runtime/gpu/gpu_id.h] - Woboq Code Browser</title>
<link rel="stylesheet" href="https://code.woboq.org/data/qtcreator.css" title="QtCreator"/>
<link rel="alternate stylesheet" href="https://code.woboq.org/data/kdevelop.css" title="KDevelop"/>
<script type="text/javascript" src="https://code.woboq.org/data/jquery/jquery.min.js"></script>
<script type="text/javascript" src="https://code.woboq.org/data/jquery/jquery-ui.min.js"></script>
<script>var file = 'tensorflow/tensorflow/core/common_runtime/gpu/gpu_id.h'; var root_path = '../../../../..'; var data_path = 'https://code.woboq.org/data';</script>
<script src='https://code.woboq.org/data/codebrowser.js'></script>
</head>
<body><div id='header'><h1 id='breadcrumb'><span>Browse the source code of </span><a href='../../../..'>tensorflow</a>/<a href='../../..'>tensorflow</a>/<a href='../..'>core</a>/<a href='..'>common_runtime</a>/<a href='./'>gpu</a>/<a href='gpu_id.h.html'>gpu_id.h</a></h1></div>
<hr/><div id='content'><table class="code">
<tr><th id="1">1</th><td><i>/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.</i></td></tr>
<tr><th id="2">2</th><td><i></i></td></tr>
<tr><th id="3">3</th><td><i>Licensed under the Apache License, Version 2.0 (the "License");</i></td></tr>
<tr><th id="4">4</th><td><i>you may not use this file except in compliance with the License.</i></td></tr>
<tr><th id="5">5</th><td><i>You may obtain a copy of the License at</i></td></tr>
<tr><th id="6">6</th><td><i></i></td></tr>
<tr><th id="7">7</th><td><i>    <a href="http://www.apache.org/licenses/LICENSE-2.0">http://www.apache.org/licenses/LICENSE-2.0</a></i></td></tr>
<tr><th id="8">8</th><td><i></i></td></tr>
<tr><th id="9">9</th><td><i>Unless required by applicable law or agreed to in writing, software</i></td></tr>
<tr><th id="10">10</th><td><i>distributed under the License is distributed on an "AS IS" BASIS,</i></td></tr>
<tr><th id="11">11</th><td><i>WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</i></td></tr>
<tr><th id="12">12</th><td><i>See the License for the specific language governing permissions and</i></td></tr>
<tr><th id="13">13</th><td><i>limitations under the License.</i></td></tr>
<tr><th id="14">14</th><td><i>==============================================================================*/</i></td></tr>
<tr><th id="15">15</th><td></td></tr>
<tr><th id="16">16</th><td><u>#<span data-ppcond="16">ifndef</span> <span class="macro" data-ref="_M/TENSORFLOW_CORE_COMMON_RUNTIME_GPU_GPU_ID_H_">TENSORFLOW_CORE_COMMON_RUNTIME_GPU_GPU_ID_H_</span></u></td></tr>
<tr><th id="17">17</th><td><u>#define <dfn class="macro" id="_M/TENSORFLOW_CORE_COMMON_RUNTIME_GPU_GPU_ID_H_" data-ref="_M/TENSORFLOW_CORE_COMMON_RUNTIME_GPU_GPU_ID_H_">TENSORFLOW_CORE_COMMON_RUNTIME_GPU_GPU_ID_H_</dfn></u></td></tr>
<tr><th id="18">18</th><td></td></tr>
<tr><th id="19">19</th><td><u>#include <a href="../../lib/gtl/int_type.h.html">"tensorflow/core/lib/gtl/int_type.h"</a></u></td></tr>
<tr><th id="20">20</th><td></td></tr>
<tr><th id="21">21</th><td><b>namespace</b> <span class="namespace">tensorflow</span> {</td></tr>
<tr><th id="22">22</th><td></td></tr>
<tr><th id="23">23</th><td><i>// There are three types of GPU ids:</i></td></tr>
<tr><th id="24">24</th><td><i>// - *physical* GPU id: this is the integer index of a GPU hardware in the</i></td></tr>
<tr><th id="25">25</th><td><i>//   physical machine, it can be filtered by CUDA environment variable</i></td></tr>
<tr><th id="26">26</th><td><i>//   CUDA_VISIBLE_DEVICES. Note that this id is not visible to Tensorflow, but</i></td></tr>
<tr><th id="27">27</th><td><i>//   result after filtering by CUDA_VISIBLE_DEVICES is visible to TF and is</i></td></tr>
<tr><th id="28">28</th><td><i>//   called CUDA GPU id as below. See</i></td></tr>
<tr><th id="29">29</th><td><i>//   <a href="http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars">http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars</a></i></td></tr>
<tr><th id="30">30</th><td><i>//   for more details.</i></td></tr>
<tr><th id="31">31</th><td><i>// - CUDA GPU id (also called *visible* GPU id in</i></td></tr>
<tr><th id="32">32</th><td><i>//   third_party/tensorflow/core/protobuf/config.proto): this is the id that is</i></td></tr>
<tr><th id="33">33</th><td><i>//   visible to Tensorflow after filtering by CUDA_VISIBLE_DEVICES, and is</i></td></tr>
<tr><th id="34">34</th><td><i>//   generated by the CUDA GPU driver. It starts from 0 and is used for CUDA API</i></td></tr>
<tr><th id="35">35</th><td><i>//   calls like cuDeviceGet().</i></td></tr>
<tr><th id="36">36</th><td><i>// - TF GPU id (also called *virtual* GPU id in</i></td></tr>
<tr><th id="37">37</th><td><i>//   third_party/tensorflow/core/protobuf/config.proto): this is the id that</i></td></tr>
<tr><th id="38">38</th><td><i>//   Tensorflow generates and exposes to its users. It is the id in the &lt;id&gt;</i></td></tr>
<tr><th id="39">39</th><td><i>//   field of the device name "/device:GPU:&lt;id&gt;", and is also the identifier of</i></td></tr>
<tr><th id="40">40</th><td><i>//   a BaseGPUDevice. Note that the configuration allows us to create multiple</i></td></tr>
<tr><th id="41">41</th><td><i>//   BaseGPUDevice per GPU hardware in order to use multi CUDA streams on the</i></td></tr>
<tr><th id="42">42</th><td><i>//   hardware, so the mapping between TF GPU id and CUDA GPU id is not a 1:1</i></td></tr>
<tr><th id="43">43</th><td><i>//   mapping, see the example below.</i></td></tr>
<tr><th id="44">44</th><td><i>//</i></td></tr>
<tr><th id="45">45</th><td><i>// For example, assuming that in the machine we have GPU device with index 0, 1,</i></td></tr>
<tr><th id="46">46</th><td><i>// 2 and 3 (physical GPU id). Setting "CUDA_VISIBLE_DEVICES=1,2,3" will create</i></td></tr>
<tr><th id="47">47</th><td><i>// the following mapping between CUDA GPU id and physical GPU id:</i></td></tr>
<tr><th id="48">48</th><td><i>//</i></td></tr>
<tr><th id="49">49</th><td><i>//        CUDA GPU id -&gt;  physical GPU id</i></td></tr>
<tr><th id="50">50</th><td><i>//                 0  -&gt;  1</i></td></tr>
<tr><th id="51">51</th><td><i>//                 1  -&gt;  2</i></td></tr>
<tr><th id="52">52</th><td><i>//                 2  -&gt;  3</i></td></tr>
<tr><th id="53">53</th><td><i>//</i></td></tr>
<tr><th id="54">54</th><td><i>// Note that physical GPU id 0 is invisible to TF so there is no mapping entry</i></td></tr>
<tr><th id="55">55</th><td><i>// for it.</i></td></tr>
<tr><th id="56">56</th><td><i>//</i></td></tr>
<tr><th id="57">57</th><td><i>// Assuming we configure the Session to create one BaseGPUDevice per GPU</i></td></tr>
<tr><th id="58">58</th><td><i>// hardware, then setting GPUOptions::visible_device_list to "2,0" will create</i></td></tr>
<tr><th id="59">59</th><td><i>// the following mappting between TF GPU id and CUDA GPU id:</i></td></tr>
<tr><th id="60">60</th><td><i>//</i></td></tr>
<tr><th id="61">61</th><td><i>//                  TF GPU id  -&gt;  CUDA GPU ID</i></td></tr>
<tr><th id="62">62</th><td><i>//      0 (i.e. /device:GPU:0) -&gt;  2</i></td></tr>
<tr><th id="63">63</th><td><i>//      1 (i.e. /device:GPU:1) -&gt;  0</i></td></tr>
<tr><th id="64">64</th><td><i>//</i></td></tr>
<tr><th id="65">65</th><td><i>// Note that CUDA GPU id 1 is filtered out by GPUOptions::visible_device_list,</i></td></tr>
<tr><th id="66">66</th><td><i>// so it won't be used by the TF process.</i></td></tr>
<tr><th id="67">67</th><td><i>//</i></td></tr>
<tr><th id="68">68</th><td><i>// On the other hand, if we configure it to create 2 BaseGPUDevice per GPU</i></td></tr>
<tr><th id="69">69</th><td><i>// hardware, then setting GPUOptions::visible_device_list to "2,0" will create</i></td></tr>
<tr><th id="70">70</th><td><i>// the following mappting between TF GPU id and CUDA GPU id:</i></td></tr>
<tr><th id="71">71</th><td><i>//</i></td></tr>
<tr><th id="72">72</th><td><i>//                  TF GPU id  -&gt;  CUDA GPU ID</i></td></tr>
<tr><th id="73">73</th><td><i>//      0 (i.e. /device:GPU:0) -&gt;  2</i></td></tr>
<tr><th id="74">74</th><td><i>//      1 (i.e. /device:GPU:1) -&gt;  2</i></td></tr>
<tr><th id="75">75</th><td><i>//      2 (i.e. /device:GPU:2) -&gt;  0</i></td></tr>
<tr><th id="76">76</th><td><i>//      3 (i.e. /device:GPU:3) -&gt;  0</i></td></tr>
<tr><th id="77">77</th><td><i>//</i></td></tr>
<tr><th id="78">78</th><td><i>// We create strong-typed integer classes for both TF GPU id and CUDA GPU id to</i></td></tr>
<tr><th id="79">79</th><td><i>// minimize programming errors and improve code readability. Except for the</i></td></tr>
<tr><th id="80">80</th><td><i>// StreamExecutor interface (as we don't change its API), whenever we need a</i></td></tr>
<tr><th id="81">81</th><td><i>// TF GPU id (or CUDA GPU id) we should use TfGpuId (or CudaGpuId) instead of a</i></td></tr>
<tr><th id="82">82</th><td><i>// raw integer.</i></td></tr>
<tr><th id="83">83</th><td><a class="macro" href="../../lib/gtl/int_type.h.html#173" title="struct TfGpuId_tag_ {}; typedef ::tensorflow::gtl::IntType&lt;TfGpuId_tag_, int32&gt; TfGpuId;" data-ref="_M/TF_LIB_GTL_DEFINE_INT_TYPE">TF_LIB_GTL_DEFINE_INT_TYPE</a>(<dfn class="typedef" id="tensorflow::TfGpuId" title='tensorflow::TfGpuId' data-type='::tensorflow::gtl::IntType&lt;TfGpuId_tag_, int32&gt;' data-ref="tensorflow::TfGpuId">TfGpuId</dfn>, <a class="typedef" href="../../platform/default/integral_types.h.html#tensorflow::int32" title='tensorflow::int32' data-type='int' data-ref="tensorflow::int32">int32</a>);</td></tr>
<tr><th id="84">84</th><td><a class="macro" href="../../lib/gtl/int_type.h.html#173" title="struct CudaGpuId_tag_ {}; typedef ::tensorflow::gtl::IntType&lt;CudaGpuId_tag_, int32&gt; CudaGpuId;" data-ref="_M/TF_LIB_GTL_DEFINE_INT_TYPE">TF_LIB_GTL_DEFINE_INT_TYPE</a>(<dfn class="typedef" id="tensorflow::CudaGpuId" title='tensorflow::CudaGpuId' data-type='::tensorflow::gtl::IntType&lt;CudaGpuId_tag_, int32&gt;' data-ref="tensorflow::CudaGpuId">CudaGpuId</dfn>, <a class="typedef" href="../../platform/default/integral_types.h.html#tensorflow::int32" title='tensorflow::int32' data-type='int' data-ref="tensorflow::int32">int32</a>);</td></tr>
<tr><th id="85">85</th><td></td></tr>
<tr><th id="86">86</th><td>}  <i>// namespace tensorflow</i></td></tr>
<tr><th id="87">87</th><td></td></tr>
<tr><th id="88">88</th><td><u>#<span data-ppcond="16">endif</span>  // TENSORFLOW_CORE_COMMON_RUNTIME_GPU_GPU_ID_H_</u></td></tr>
<tr><th id="89">89</th><td></td></tr>
</table><hr/><p id='footer'>
Generated while processing <a href='gpu_bfc_allocator.cc.html'>tensorflow/tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc</a><br/>Generated on <em>2018-Sep-06</em> from project tensorflow revision <em>v1.8</em><br />Powered by <a href='https://woboq.com'><img alt='Woboq' src='https://code.woboq.org/woboq-16.png' width='41' height='16' /></a> <a href='https://code.woboq.org'>Code Browser</a> 2.1
<br/>Generator usage only permitted with license.</p>
</div></body></html>
