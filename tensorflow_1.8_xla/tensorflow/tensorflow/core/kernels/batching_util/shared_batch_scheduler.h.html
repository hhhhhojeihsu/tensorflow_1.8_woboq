<!doctype html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0"><title>shared_batch_scheduler.h source code [tensorflow/tensorflow/core/kernels/batching_util/shared_batch_scheduler.h] - Woboq Code Browser</title>
<meta name="woboq:interestingDefinitions" content="tensorflow::serving::SharedBatchScheduler,tensorflow::serving::internal::Queue,tensorflow::serving::internal::QueueHandle "/>
<link rel="stylesheet" href="https://code.woboq.org/data/qtcreator.css" title="QtCreator"/>
<link rel="alternate stylesheet" href="https://code.woboq.org/data/kdevelop.css" title="KDevelop"/>
<script type="text/javascript" src="https://code.woboq.org/data/jquery/jquery.min.js"></script>
<script type="text/javascript" src="https://code.woboq.org/data/jquery/jquery-ui.min.js"></script>
<script>var file = 'tensorflow/tensorflow/core/kernels/batching_util/shared_batch_scheduler.h'; var root_path = '../../../../..'; var data_path = 'https://code.woboq.org/data';</script>
<script src='https://code.woboq.org/data/codebrowser.js'></script>
</head>
<body><div id='header'><h1 id='breadcrumb'><span>Browse the source code of </span><a href='../../../..'>tensorflow</a>/<a href='../../..'>tensorflow</a>/<a href='../..'>core</a>/<a href='..'>kernels</a>/<a href='./'>batching_util</a>/<a href='shared_batch_scheduler.h.html'>shared_batch_scheduler.h</a></h1></div>
<hr/><div id='content'><table class="code">
<tr><th id="1">1</th><td><i>/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.</i></td></tr>
<tr><th id="2">2</th><td><i></i></td></tr>
<tr><th id="3">3</th><td><i>Licensed under the Apache License, Version 2.0 (the "License");</i></td></tr>
<tr><th id="4">4</th><td><i>you may not use this file except in compliance with the License.</i></td></tr>
<tr><th id="5">5</th><td><i>You may obtain a copy of the License at</i></td></tr>
<tr><th id="6">6</th><td><i></i></td></tr>
<tr><th id="7">7</th><td><i>    <a href="http://www.apache.org/licenses/LICENSE-2.0">http://www.apache.org/licenses/LICENSE-2.0</a></i></td></tr>
<tr><th id="8">8</th><td><i></i></td></tr>
<tr><th id="9">9</th><td><i>Unless required by applicable law or agreed to in writing, software</i></td></tr>
<tr><th id="10">10</th><td><i>distributed under the License is distributed on an "AS IS" BASIS,</i></td></tr>
<tr><th id="11">11</th><td><i>WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</i></td></tr>
<tr><th id="12">12</th><td><i>See the License for the specific language governing permissions and</i></td></tr>
<tr><th id="13">13</th><td><i>limitations under the License.</i></td></tr>
<tr><th id="14">14</th><td><i>==============================================================================*/</i></td></tr>
<tr><th id="15">15</th><td></td></tr>
<tr><th id="16">16</th><td><u>#<span data-ppcond="16">ifndef</span> <span class="macro" data-ref="_M/TENSORFLOW_CORE_KERNELS_BATCHING_UTIL_SHARED_BATCH_SCHEDULER_H_">TENSORFLOW_CORE_KERNELS_BATCHING_UTIL_SHARED_BATCH_SCHEDULER_H_</span></u></td></tr>
<tr><th id="17">17</th><td><u>#define <dfn class="macro" id="_M/TENSORFLOW_CORE_KERNELS_BATCHING_UTIL_SHARED_BATCH_SCHEDULER_H_" data-ref="_M/TENSORFLOW_CORE_KERNELS_BATCHING_UTIL_SHARED_BATCH_SCHEDULER_H_">TENSORFLOW_CORE_KERNELS_BATCHING_UTIL_SHARED_BATCH_SCHEDULER_H_</dfn></u></td></tr>
<tr><th id="18">18</th><td></td></tr>
<tr><th id="19">19</th><td><u>#include &lt;stddef.h&gt;</u></td></tr>
<tr><th id="20">20</th><td><u>#include <a href="../../../../../include/c++/5/deque.html">&lt;deque&gt;</a></u></td></tr>
<tr><th id="21">21</th><td><u>#include <a href="../../../../../include/c++/5/functional.html">&lt;functional&gt;</a></u></td></tr>
<tr><th id="22">22</th><td><u>#include <a href="../../../../../include/c++/5/list.html">&lt;list&gt;</a></u></td></tr>
<tr><th id="23">23</th><td><u>#include <a href="../../../../../include/c++/5/memory.html">&lt;memory&gt;</a></u></td></tr>
<tr><th id="24">24</th><td><u>#include <a href="../../../../../include/c++/5/string.html">&lt;string&gt;</a></u></td></tr>
<tr><th id="25">25</th><td><u>#include <a href="../../../../../include/c++/5/utility.html">&lt;utility&gt;</a></u></td></tr>
<tr><th id="26">26</th><td><u>#include <a href="../../../../../include/c++/5/vector.html">&lt;vector&gt;</a></u></td></tr>
<tr><th id="27">27</th><td></td></tr>
<tr><th id="28">28</th><td><u>#include <a href="batch_scheduler.h.html">"tensorflow/core/kernels/batching_util/batch_scheduler.h"</a></u></td></tr>
<tr><th id="29">29</th><td><u>#include <a href="periodic_function.h.html">"tensorflow/core/kernels/batching_util/periodic_function.h"</a></u></td></tr>
<tr><th id="30">30</th><td><u>#include <a href="../../lib/core/errors.h.html">"tensorflow/core/lib/core/errors.h"</a></u></td></tr>
<tr><th id="31">31</th><td><u>#include <a href="../../lib/core/status.h.html">"tensorflow/core/lib/core/status.h"</a></u></td></tr>
<tr><th id="32">32</th><td><u>#include <a href="../../lib/strings/strcat.h.html">"tensorflow/core/lib/strings/strcat.h"</a></u></td></tr>
<tr><th id="33">33</th><td><u>#include <a href="../../platform/cpu_info.h.html">"tensorflow/core/platform/cpu_info.h"</a></u></td></tr>
<tr><th id="34">34</th><td><u>#include <a href="../../platform/env.h.html">"tensorflow/core/platform/env.h"</a></u></td></tr>
<tr><th id="35">35</th><td><u>#include <a href="../../platform/thread_annotations.h.html">"tensorflow/core/platform/thread_annotations.h"</a></u></td></tr>
<tr><th id="36">36</th><td><u>#include <a href="../../platform/types.h.html">"tensorflow/core/platform/types.h"</a></u></td></tr>
<tr><th id="37">37</th><td></td></tr>
<tr><th id="38">38</th><td><b>namespace</b> <span class="namespace">tensorflow</span> {</td></tr>
<tr><th id="39">39</th><td><b>namespace</b> <span class="namespace">serving</span> {</td></tr>
<tr><th id="40">40</th><td><b>namespace</b> <span class="namespace">internal</span> {</td></tr>
<tr><th id="41">41</th><td><b>template</b> &lt;<b>typename</b> TaskType&gt;</td></tr>
<tr><th id="42">42</th><td><b>class</b> <a class="type" href="#tensorflow::serving::internal::Queue" title='tensorflow::serving::internal::Queue' data-ref="tensorflow::serving::internal::Queue">Queue</a>;</td></tr>
<tr><th id="43">43</th><td>}  <i>// namespace internal</i></td></tr>
<tr><th id="44">44</th><td>}  <i>// namespace serving</i></td></tr>
<tr><th id="45">45</th><td>}  <i>// namespace tensorflow</i></td></tr>
<tr><th id="46">46</th><td></td></tr>
<tr><th id="47">47</th><td><b>namespace</b> <span class="namespace">tensorflow</span> {</td></tr>
<tr><th id="48">48</th><td><b>namespace</b> <span class="namespace">serving</span> {</td></tr>
<tr><th id="49">49</th><td></td></tr>
<tr><th id="50">50</th><td><i>// A batch scheduler for server instances that service multiple request types</i></td></tr>
<tr><th id="51">51</th><td><i>// (e.g. multiple machine-learned models, or multiple versions of a model served</i></td></tr>
<tr><th id="52">52</th><td><i>// concurrently), or even multiple distinct tasks for a given request. The</i></td></tr>
<tr><th id="53">53</th><td><i>// scheduler multiplexes batches of different kinds of tasks onto a fixed-size</i></td></tr>
<tr><th id="54">54</th><td><i>// thread pool (each batch contains tasks of a single type), in a carefully</i></td></tr>
<tr><th id="55">55</th><td><i>// controlled manner. A common configuration is to set the number of threads</i></td></tr>
<tr><th id="56">56</th><td><i>// equal to the number of hardware accelerator units, in which case the</i></td></tr>
<tr><th id="57">57</th><td><i>// scheduler takes care of multiplexing the task types onto the shared hardware,</i></td></tr>
<tr><th id="58">58</th><td><i>// in a manner that is both fair and efficient.</i></td></tr>
<tr><th id="59">59</th><td><i>//</i></td></tr>
<tr><th id="60">60</th><td><i>// Semantically, SharedBatchScheduler behaves like having N instances of</i></td></tr>
<tr><th id="61">61</th><td><i>// BasicBatchScheduler (see basic_batch_scheduler.h), one per task type. The</i></td></tr>
<tr><th id="62">62</th><td><i>// difference is that under the covers there is a single shared thread pool,</i></td></tr>
<tr><th id="63">63</th><td><i>// instead of N independent ones, with their sharing deliberately coordinated.</i></td></tr>
<tr><th id="64">64</th><td><i>//</i></td></tr>
<tr><th id="65">65</th><td><i>// SharedBatchScheduler does not implement the BatchScheduler API; rather, it</i></td></tr>
<tr><th id="66">66</th><td><i>// presents an abstraction of "queues", where each queue corresponds to one type</i></td></tr>
<tr><th id="67">67</th><td><i>// of task. Tasks submitted to a given queue are placed in their own batches,</i></td></tr>
<tr><th id="68">68</th><td><i>// and cannot be mixed with other tasks. Queues can be added and deleted</i></td></tr>
<tr><th id="69">69</th><td><i>// dynamically, to accommodate e.g. versions of a model being brought up and</i></td></tr>
<tr><th id="70">70</th><td><i>// down over the lifetime of a server.</i></td></tr>
<tr><th id="71">71</th><td><i>//</i></td></tr>
<tr><th id="72">72</th><td><i>// The batch thread pool round-robins through the queues, running one batch</i></td></tr>
<tr><th id="73">73</th><td><i>// from a queue and then moving to the next queue. Each queue behaves like a</i></td></tr>
<tr><th id="74">74</th><td><i>// BasicBatchScheduler instance, in the sense that it has maximum batch size and</i></td></tr>
<tr><th id="75">75</th><td><i>// timeout parameters, which govern when a batch is eligible to be processed.</i></td></tr>
<tr><th id="76">76</th><td><i>//</i></td></tr>
<tr><th id="77">77</th><td><i>// Each queue is independently configured with a maximum size (in terms of the</i></td></tr>
<tr><th id="78">78</th><td><i>// maximum number of batches worth of enqueued tasks). For online serving, it is</i></td></tr>
<tr><th id="79">79</th><td><i>// recommended that the queue sizes be configured such that the sum of the sizes</i></td></tr>
<tr><th id="80">80</th><td><i>// of the active queues roughly equal the number of batch threads. (The idea is</i></td></tr>
<tr><th id="81">81</th><td><i>// that if all threads become available at roughly the same time, there will be</i></td></tr>
<tr><th id="82">82</th><td><i>// enough enqueued work for them to take on, but no more.)</i></td></tr>
<tr><th id="83">83</th><td><i>//</i></td></tr>
<tr><th id="84">84</th><td><i>// If queue sizes are configured in the manner suggested above, the maximum time</i></td></tr>
<tr><th id="85">85</th><td><i>// a task can spend in a queue before being placed in a batch and assigned to a</i></td></tr>
<tr><th id="86">86</th><td><i>// thread for processing, is the greater of:</i></td></tr>
<tr><th id="87">87</th><td><i>//  - the maximum time to process one batch of tasks from any active queue</i></td></tr>
<tr><th id="88">88</th><td><i>//  - the configured timeout parameter for the task's queue (which can be 0)</i></td></tr>
<tr><th id="89">89</th><td><i>//</i></td></tr>
<tr><th id="90">90</th><td><i>// For bulk processing jobs and throughput-oriented benchmarks, you may want to</i></td></tr>
<tr><th id="91">91</th><td><i>// set the maximum queue size to a large value.</i></td></tr>
<tr><th id="92">92</th><td><i>//</i></td></tr>
<tr><th id="93">93</th><td><i>// TODO(b/26539183): Support queue servicing policies other than round-robin.</i></td></tr>
<tr><th id="94">94</th><td><i>// E.g. let each queue specify a "share" (an int &gt;= 1), so e.g. with queues A</i></td></tr>
<tr><th id="95">95</th><td><i>// and B having shares 1 and 2 respectively, the servicing pattern is ABBABB...</i></td></tr>
<tr><th id="96">96</th><td><i>//</i></td></tr>
<tr><th id="97">97</th><td><i>//</i></td></tr>
<tr><th id="98">98</th><td><i>// PERFORMANCE TUNING: See README.md.</i></td></tr>
<tr><th id="99">99</th><td><i>//</i></td></tr>
<tr><th id="100">100</th><td><b>template</b> &lt;<b>typename</b> TaskType&gt;</td></tr>
<tr><th id="101">101</th><td><b>class</b> <dfn class="type def" id="tensorflow::serving::SharedBatchScheduler" title='tensorflow::serving::SharedBatchScheduler' data-ref="tensorflow::serving::SharedBatchScheduler">SharedBatchScheduler</dfn></td></tr>
<tr><th id="102">102</th><td>    : <b>public</b> <span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/shared_ptr_base.h.html#std::enable_shared_from_this" title='std::enable_shared_from_this' data-ref="std::enable_shared_from_this">enable_shared_from_this</a>&lt;<a class="type" href="#tensorflow::serving::SharedBatchScheduler" title='tensorflow::serving::SharedBatchScheduler' data-ref="tensorflow::serving::SharedBatchScheduler">SharedBatchScheduler</a>&lt;TaskType&gt;&gt; {</td></tr>
<tr><th id="103">103</th><td> <b>public</b>:</td></tr>
<tr><th id="104">104</th><td>  <i>// TODO(b/25089730): Tune defaults based on best practices as they develop.</i></td></tr>
<tr><th id="105">105</th><td>  <b>struct</b> <dfn class="type def" id="tensorflow::serving::SharedBatchScheduler::Options" title='tensorflow::serving::SharedBatchScheduler::Options' data-ref="tensorflow::serving::SharedBatchScheduler::Options">Options</dfn> {</td></tr>
<tr><th id="106">106</th><td>    <i>// The name to use for the pool of batch threads.</i></td></tr>
<tr><th id="107">107</th><td>    <a class="typedef" href="../../../../../include/c++/5/bits/stringfwd.h.html#std::string" title='std::string' data-type='basic_string&lt;char&gt;' data-ref="std::string">string</a> <dfn class="decl" id="tensorflow::serving::SharedBatchScheduler::Options::thread_pool_name" title='tensorflow::serving::SharedBatchScheduler::Options::thread_pool_name' data-ref="tensorflow::serving::SharedBatchScheduler::Options::thread_pool_name">thread_pool_name</dfn> = <a class="ref" href="../../../../../include/c++/5/bits/basic_string.h.html#_ZNSt12basic_stringC1EPKT_RKT1_" title='std::basic_string::basic_string&lt;_CharT, _Traits, _Alloc&gt;' data-ref="_ZNSt12basic_stringC1EPKT_RKT1_">{</a><q>"batch_threads"</q>};</td></tr>
<tr><th id="108">108</th><td></td></tr>
<tr><th id="109">109</th><td>    <i>// The number of threads to use to process batches.</i></td></tr>
<tr><th id="110">110</th><td><i>    // Must be &gt;= 1, and should be tuned carefully.</i></td></tr>
<tr><th id="111">111</th><td>    <em>int</em> <dfn class="decl" id="tensorflow::serving::SharedBatchScheduler::Options::num_batch_threads" title='tensorflow::serving::SharedBatchScheduler::Options::num_batch_threads' data-ref="tensorflow::serving::SharedBatchScheduler::Options::num_batch_threads">num_batch_threads</dfn> = <span class="namespace">port::</span><a class="ref" href="../../platform/cpu_info.h.html#_ZN10tensorflow4port18NumSchedulableCPUsEv" title='tensorflow::port::NumSchedulableCPUs' data-ref="_ZN10tensorflow4port18NumSchedulableCPUsEv">NumSchedulableCPUs</a>();</td></tr>
<tr><th id="112">112</th><td></td></tr>
<tr><th id="113">113</th><td>    <i>// The environment to use.</i></td></tr>
<tr><th id="114">114</th><td><i>    // (Typically only overridden by test code.)</i></td></tr>
<tr><th id="115">115</th><td>    <a class="type" href="../../platform/env.h.html#tensorflow::Env" title='tensorflow::Env' data-ref="tensorflow::Env">Env</a>* <dfn class="decl" id="tensorflow::serving::SharedBatchScheduler::Options::env" title='tensorflow::serving::SharedBatchScheduler::Options::env' data-ref="tensorflow::serving::SharedBatchScheduler::Options::env">env</dfn> = <a class="type" href="../../platform/env.h.html#tensorflow::Env" title='tensorflow::Env' data-ref="tensorflow::Env">Env</a>::<a class="ref" href="../../platform/env.h.html#_ZN10tensorflow3Env7DefaultEv" title='tensorflow::Env::Default' data-ref="_ZN10tensorflow3Env7DefaultEv">Default</a>();</td></tr>
<tr><th id="116">116</th><td>  };</td></tr>
<tr><th id="117">117</th><td>  <i>// Ownership is shared between the caller of Create() and any queues created</i></td></tr>
<tr><th id="118">118</th><td><i>  // via AddQueue().</i></td></tr>
<tr><th id="119">119</th><td>  <em>static</em> <a class="type" href="../../lib/core/status.h.html#tensorflow::Status" title='tensorflow::Status' data-ref="tensorflow::Status">Status</a> <a class="decl" href="#_ZN10tensorflow7serving20SharedBatchScheduler6CreateERKNS1_7OptionsEPSt10shared_ptrINS0_20SharedBatchSchedulerIT_EEE" title='tensorflow::serving::SharedBatchScheduler::Create' data-ref="_ZN10tensorflow7serving20SharedBatchScheduler6CreateERKNS1_7OptionsEPSt10shared_ptrINS0_20SharedBatchSchedulerIT_EEE">Create</a>(</td></tr>
<tr><th id="120">120</th><td>      <em>const</em> <a class="type" href="#tensorflow::serving::SharedBatchScheduler::Options" title='tensorflow::serving::SharedBatchScheduler::Options' data-ref="tensorflow::serving::SharedBatchScheduler::Options">Options</a>&amp; <dfn class="local col0 decl" id="20options" title='options' data-type='const tensorflow::serving::SharedBatchScheduler::Options &amp;' data-ref="20options">options</dfn>,</td></tr>
<tr><th id="121">121</th><td>      <span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/shared_ptr_base.h.html#std::shared_ptr" title='std::shared_ptr' data-ref="std::shared_ptr">shared_ptr</a>&lt;<a class="type" href="#tensorflow::serving::SharedBatchScheduler" title='tensorflow::serving::SharedBatchScheduler' data-ref="tensorflow::serving::SharedBatchScheduler">SharedBatchScheduler</a>&lt;TaskType&gt;&gt;* <dfn class="local col1 decl" id="21scheduler" title='scheduler' data-type='std::shared_ptr&lt;SharedBatchScheduler&lt;TaskType&gt; &gt; *' data-ref="21scheduler">scheduler</dfn>);</td></tr>
<tr><th id="122">122</th><td></td></tr>
<tr><th id="123">123</th><td>  <a class="decl" href="#_ZN10tensorflow7serving20SharedBatchSchedulerD1Ev" title='tensorflow::serving::SharedBatchScheduler::~SharedBatchScheduler&lt;TaskType&gt;' data-ref="_ZN10tensorflow7serving20SharedBatchSchedulerD1Ev">~SharedBatchScheduler</a>();</td></tr>
<tr><th id="124">124</th><td></td></tr>
<tr><th id="125">125</th><td>  <i>// Adds a queue to which tasks may be submitted. The returned queue implements</i></td></tr>
<tr><th id="126">126</th><td><i>  // the BatchScheduler API. Each queue has its own set of scheduling options,</i></td></tr>
<tr><th id="127">127</th><td><i>  // and its own callback to process batches of tasks submitted to the queue.</i></td></tr>
<tr><th id="128">128</th><td><i>  //</i></td></tr>
<tr><th id="129">129</th><td><i>  // The returned queue's destructor blocks until all tasks submitted to it have</i></td></tr>
<tr><th id="130">130</th><td><i>  // been processed.</i></td></tr>
<tr><th id="131">131</th><td>  <b>struct</b> <dfn class="type def" id="tensorflow::serving::SharedBatchScheduler::QueueOptions" title='tensorflow::serving::SharedBatchScheduler::QueueOptions' data-ref="tensorflow::serving::SharedBatchScheduler::QueueOptions">QueueOptions</dfn> {</td></tr>
<tr><th id="132">132</th><td>    <i>// The maximum size of each batch.</i></td></tr>
<tr><th id="133">133</th><td><i>    //</i></td></tr>
<tr><th id="134">134</th><td><i>    // The scheduler may form batches of any size between 1 and this number</i></td></tr>
<tr><th id="135">135</th><td><i>    // (inclusive). If there is a need to quantize the batch sizes, i.e. only</i></td></tr>
<tr><th id="136">136</th><td><i>    // submit batches whose size is in a small set of allowed sizes, that can be</i></td></tr>
<tr><th id="137">137</th><td><i>    // done by adding padding in the process-batch callback.</i></td></tr>
<tr><th id="138">138</th><td>    <em>int</em> <dfn class="decl" id="tensorflow::serving::SharedBatchScheduler::QueueOptions::max_batch_size" title='tensorflow::serving::SharedBatchScheduler::QueueOptions::max_batch_size' data-ref="tensorflow::serving::SharedBatchScheduler::QueueOptions::max_batch_size">max_batch_size</dfn> = <var>1000</var>;</td></tr>
<tr><th id="139">139</th><td></td></tr>
<tr><th id="140">140</th><td>    <i>// If a task has been enqueued for this amount of time (in microseconds),</i></td></tr>
<tr><th id="141">141</th><td><i>    // and a thread is available, the scheduler will immediately form a batch</i></td></tr>
<tr><th id="142">142</th><td><i>    // from enqueued tasks and assign the batch to the thread for processing,</i></td></tr>
<tr><th id="143">143</th><td><i>    // even if the batch's size is below 'max_batch_size'.</i></td></tr>
<tr><th id="144">144</th><td><i>    //</i></td></tr>
<tr><th id="145">145</th><td><i>    // This parameter offers a way to bound queue latency, so that a task isn't</i></td></tr>
<tr><th id="146">146</th><td><i>    // stuck in the queue indefinitely waiting for enough tasks to arrive to</i></td></tr>
<tr><th id="147">147</th><td><i>    // make a full batch. (The latency bound is given in the class documentation</i></td></tr>
<tr><th id="148">148</th><td><i>    // above.)</i></td></tr>
<tr><th id="149">149</th><td><i>    //</i></td></tr>
<tr><th id="150">150</th><td><i>    // The goal is to smooth out batch sizes under low request rates, and thus</i></td></tr>
<tr><th id="151">151</th><td><i>    // avoid latency spikes.</i></td></tr>
<tr><th id="152">152</th><td>    <a class="typedef" href="../../platform/default/integral_types.h.html#tensorflow::int64" title='tensorflow::int64' data-type='long long' data-ref="tensorflow::int64">int64</a> <dfn class="decl" id="tensorflow::serving::SharedBatchScheduler::QueueOptions::batch_timeout_micros" title='tensorflow::serving::SharedBatchScheduler::QueueOptions::batch_timeout_micros' data-ref="tensorflow::serving::SharedBatchScheduler::QueueOptions::batch_timeout_micros">batch_timeout_micros</dfn> = <var>0</var>;</td></tr>
<tr><th id="153">153</th><td></td></tr>
<tr><th id="154">154</th><td>    <i>// The maximum allowable number of enqueued (accepted by Schedule() but</i></td></tr>
<tr><th id="155">155</th><td><i>    // not yet being processed on a batch thread) tasks in terms of batches.</i></td></tr>
<tr><th id="156">156</th><td><i>    // If this limit is reached, Schedule() will return an UNAVAILABLE error.</i></td></tr>
<tr><th id="157">157</th><td><i>    // See the class documentation above for guidelines on how to tune this</i></td></tr>
<tr><th id="158">158</th><td><i>    // parameter.</i></td></tr>
<tr><th id="159">159</th><td>    <em>int</em> <dfn class="decl" id="tensorflow::serving::SharedBatchScheduler::QueueOptions::max_enqueued_batches" title='tensorflow::serving::SharedBatchScheduler::QueueOptions::max_enqueued_batches' data-ref="tensorflow::serving::SharedBatchScheduler::QueueOptions::max_enqueued_batches">max_enqueued_batches</dfn> = <var>10</var>;</td></tr>
<tr><th id="160">160</th><td>  };</td></tr>
<tr><th id="161">161</th><td>  <a class="type" href="../../lib/core/status.h.html#tensorflow::Status" title='tensorflow::Status' data-ref="tensorflow::Status">Status</a> <a class="decl" href="#_ZN10tensorflow7serving20SharedBatchScheduler8AddQueueERKNS1_12QueueOptionsESt8functionIFvSt10unique_ptrINS0_5BatchIT_EESt14default_deleteIS9_EEEEPS6_13470146" title='tensorflow::serving::SharedBatchScheduler::AddQueue' data-ref="_ZN10tensorflow7serving20SharedBatchScheduler8AddQueueERKNS1_12QueueOptionsESt8functionIFvSt10unique_ptrINS0_5BatchIT_EESt14default_deleteIS9_EEEEPS6_13470146">AddQueue</a>(<em>const</em> <a class="type" href="#tensorflow::serving::SharedBatchScheduler::QueueOptions" title='tensorflow::serving::SharedBatchScheduler::QueueOptions' data-ref="tensorflow::serving::SharedBatchScheduler::QueueOptions">QueueOptions</a>&amp; <dfn class="local col2 decl" id="22options" title='options' data-type='const tensorflow::serving::SharedBatchScheduler::QueueOptions &amp;' data-ref="22options">options</dfn>,</td></tr>
<tr><th id="162">162</th><td>                  <span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/functional.html#std::function" title='std::function' data-ref="std::function">function</a>&lt;<em>void</em>(<span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/unique_ptr.h.html#std::unique_ptr" title='std::unique_ptr' data-ref="std::unique_ptr">unique_ptr</a>&lt;<a class="type" href="batch_scheduler.h.html#tensorflow::serving::Batch" title='tensorflow::serving::Batch' data-ref="tensorflow::serving::Batch">Batch</a>&lt;TaskType&gt;&gt;)&gt;</td></tr>
<tr><th id="163">163</th><td>                      <dfn class="local col3 decl" id="23process_batch_callback" title='process_batch_callback' data-type='std::function&lt;void (std::unique_ptr&lt;Batch&lt;TaskType&gt; &gt;)&gt;' data-ref="23process_batch_callback">process_batch_callback</dfn>,</td></tr>
<tr><th id="164">164</th><td>                  <span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/unique_ptr.h.html#std::unique_ptr" title='std::unique_ptr' data-ref="std::unique_ptr">unique_ptr</a>&lt;<a class="type" href="batch_scheduler.h.html#tensorflow::serving::BatchScheduler" title='tensorflow::serving::BatchScheduler' data-ref="tensorflow::serving::BatchScheduler">BatchScheduler</a>&lt;TaskType&gt;&gt;* <dfn class="local col4 decl" id="24queue" title='queue' data-type='std::unique_ptr&lt;BatchScheduler&lt;TaskType&gt; &gt; *' data-ref="24queue">queue</dfn>);</td></tr>
<tr><th id="165">165</th><td></td></tr>
<tr><th id="166">166</th><td> <b>private</b>:</td></tr>
<tr><th id="167">167</th><td>  <b>explicit</b> <a class="decl" href="#_ZN10tensorflow7serving20SharedBatchSchedulerC1ERKNS1_7OptionsE" title='tensorflow::serving::SharedBatchScheduler::SharedBatchScheduler&lt;TaskType&gt;' data-ref="_ZN10tensorflow7serving20SharedBatchSchedulerC1ERKNS1_7OptionsE">SharedBatchScheduler</a>(<em>const</em> <a class="type" href="#tensorflow::serving::SharedBatchScheduler::Options" title='tensorflow::serving::SharedBatchScheduler::Options' data-ref="tensorflow::serving::SharedBatchScheduler::Options">Options</a>&amp; <dfn class="local col5 decl" id="25options" title='options' data-type='const tensorflow::serving::SharedBatchScheduler::Options &amp;' data-ref="25options">options</dfn>);</td></tr>
<tr><th id="168">168</th><td></td></tr>
<tr><th id="169">169</th><td>  <i>// The code executed in 'batch_threads_'. Obtains a batch to process from the</i></td></tr>
<tr><th id="170">170</th><td><i>  // queue pointed to by 'next_queue_to_schedule_', and processes it. If that</i></td></tr>
<tr><th id="171">171</th><td><i>  // queue declines to provide a batch to process, moves onto the next queue. If</i></td></tr>
<tr><th id="172">172</th><td><i>  // no queues provide a batch to process, just sleeps briefly and exits.</i></td></tr>
<tr><th id="173">173</th><td>  <em>void</em> <a class="decl" href="#_ZN10tensorflow7serving20SharedBatchScheduler11ThreadLogicEv" title='tensorflow::serving::SharedBatchScheduler::ThreadLogic' data-ref="_ZN10tensorflow7serving20SharedBatchScheduler11ThreadLogicEv">ThreadLogic</a>();</td></tr>
<tr><th id="174">174</th><td></td></tr>
<tr><th id="175">175</th><td>  <em>const</em> <a class="type" href="#tensorflow::serving::SharedBatchScheduler::Options" title='tensorflow::serving::SharedBatchScheduler::Options' data-ref="tensorflow::serving::SharedBatchScheduler::Options">Options</a> <dfn class="decl" id="tensorflow::serving::SharedBatchScheduler::options_" title='tensorflow::serving::SharedBatchScheduler::options_' data-ref="tensorflow::serving::SharedBatchScheduler::options_">options_</dfn>;</td></tr>
<tr><th id="176">176</th><td></td></tr>
<tr><th id="177">177</th><td>  <a class="type" href="../../platform/default/mutex.h.html#tensorflow::mutex" title='tensorflow::mutex' data-ref="tensorflow::mutex">mutex</a> <dfn class="decl" id="tensorflow::serving::SharedBatchScheduler::mu_" title='tensorflow::serving::SharedBatchScheduler::mu_' data-ref="tensorflow::serving::SharedBatchScheduler::mu_">mu_</dfn>;</td></tr>
<tr><th id="178">178</th><td></td></tr>
<tr><th id="179">179</th><td>  <i>// A list of queues. (We use std::list instead of std::vector to ensure that</i></td></tr>
<tr><th id="180">180</th><td><i>  // iterators are not invalidated by adding/removing elements. It also offers</i></td></tr>
<tr><th id="181">181</th><td><i>  // efficient removal of elements from the middle.)</i></td></tr>
<tr><th id="182">182</th><td>  <b>using</b> <dfn class="typedef" id="tensorflow::serving::SharedBatchScheduler::QueueList" title='tensorflow::serving::SharedBatchScheduler::QueueList' data-type='std::list&lt;std::unique_ptr&lt;internal::Queue&lt;TaskType&gt; &gt; &gt;' data-ref="tensorflow::serving::SharedBatchScheduler::QueueList">QueueList</dfn> = <span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/stl_list.h.html#std::list" title='std::list' data-ref="std::list">list</a>&lt;<span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/unique_ptr.h.html#std::unique_ptr" title='std::unique_ptr' data-ref="std::unique_ptr">unique_ptr</a>&lt;<span class="namespace">internal::</span><a class="type" href="#tensorflow::serving::internal::Queue" title='tensorflow::serving::internal::Queue' data-ref="tensorflow::serving::internal::Queue">Queue</a>&lt;TaskType&gt;&gt;&gt;;</td></tr>
<tr><th id="183">183</th><td></td></tr>
<tr><th id="184">184</th><td>  <i>// All "active" queues, i.e. ones that either:</i></td></tr>
<tr><th id="185">185</th><td><i>  //  - have not been removed, or</i></td></tr>
<tr><th id="186">186</th><td><i>  //  - have been removed but are not yet empty.</i></td></tr>
<tr><th id="187">187</th><td>  <a class="typedef" href="#tensorflow::serving::SharedBatchScheduler::QueueList" title='tensorflow::serving::SharedBatchScheduler::QueueList' data-type='std::list&lt;std::unique_ptr&lt;internal::Queue&lt;TaskType&gt; &gt; &gt;' data-ref="tensorflow::serving::SharedBatchScheduler::QueueList">QueueList</a> <dfn class="decl" id="tensorflow::serving::SharedBatchScheduler::queues_" title='tensorflow::serving::SharedBatchScheduler::queues_' data-ref="tensorflow::serving::SharedBatchScheduler::queues_">queues_</dfn> <a class="macro" href="../../platform/default/thread_annotations.h.html#52" title="__attribute__((guarded_by(mu_)))" data-ref="_M/GUARDED_BY">GUARDED_BY</a>(<a class="ref" href="#tensorflow::serving::SharedBatchScheduler::mu_" title='tensorflow::serving::SharedBatchScheduler::mu_' data-ref="tensorflow::serving::SharedBatchScheduler::mu_">mu_</a>);</td></tr>
<tr><th id="188">188</th><td></td></tr>
<tr><th id="189">189</th><td>  <i>// An iterator over 'queues_', pointing to the queue from which the next</i></td></tr>
<tr><th id="190">190</th><td><i>  // available batch thread should grab work.</i></td></tr>
<tr><th id="191">191</th><td>  <b>typename</b> <a class="typedef" href="#tensorflow::serving::SharedBatchScheduler::QueueList" title='tensorflow::serving::SharedBatchScheduler::QueueList' data-type='std::list&lt;std::unique_ptr&lt;internal::Queue&lt;TaskType&gt; &gt; &gt;' data-ref="tensorflow::serving::SharedBatchScheduler::QueueList">QueueList</a>::iterator <dfn class="decl" id="tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_" title='tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_' data-ref="tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_">next_queue_to_schedule_</dfn> <a class="macro" href="../../platform/default/thread_annotations.h.html#52" title="__attribute__((guarded_by(mu_)))" data-ref="_M/GUARDED_BY">GUARDED_BY</a>(<a class="ref" href="#tensorflow::serving::SharedBatchScheduler::mu_" title='tensorflow::serving::SharedBatchScheduler::mu_' data-ref="tensorflow::serving::SharedBatchScheduler::mu_">mu_</a>);</td></tr>
<tr><th id="192">192</th><td></td></tr>
<tr><th id="193">193</th><td>  <i>// Used by idle batch threads to wait for work to enter the system. Notified</i></td></tr>
<tr><th id="194">194</th><td><i>  // whenever a batch becomes schedulable.</i></td></tr>
<tr><th id="195">195</th><td>  <a class="type" href="../../platform/default/mutex.h.html#tensorflow::condition_variable" title='tensorflow::condition_variable' data-ref="tensorflow::condition_variable">condition_variable</a> <dfn class="decl" id="tensorflow::serving::SharedBatchScheduler::schedulable_batch_cv_" title='tensorflow::serving::SharedBatchScheduler::schedulable_batch_cv_' data-ref="tensorflow::serving::SharedBatchScheduler::schedulable_batch_cv_">schedulable_batch_cv_</dfn>;</td></tr>
<tr><th id="196">196</th><td></td></tr>
<tr><th id="197">197</th><td>  <i>// Threads that process batches obtained from the queues.</i></td></tr>
<tr><th id="198">198</th><td>  <span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/stl_vector.h.html#std::vector" title='std::vector' data-ref="std::vector">vector</a>&lt;<span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/unique_ptr.h.html#std::unique_ptr" title='std::unique_ptr' data-ref="std::unique_ptr">unique_ptr</a>&lt;<a class="type" href="periodic_function.h.html#tensorflow::serving::PeriodicFunction" title='tensorflow::serving::PeriodicFunction' data-ref="tensorflow::serving::PeriodicFunction">PeriodicFunction</a>&gt;&gt; <dfn class="decl" id="tensorflow::serving::SharedBatchScheduler::batch_threads_" title='tensorflow::serving::SharedBatchScheduler::batch_threads_' data-ref="tensorflow::serving::SharedBatchScheduler::batch_threads_">batch_threads_</dfn>;</td></tr>
<tr><th id="199">199</th><td></td></tr>
<tr><th id="200">200</th><td>  <a class="macro" href="../../platform/macros.h.html#91" title="SharedBatchScheduler(const SharedBatchScheduler&amp;) = delete; void operator=(const SharedBatchScheduler&amp;) = delete" data-ref="_M/TF_DISALLOW_COPY_AND_ASSIGN">TF_DISALLOW_COPY_AND_ASSIGN</a>(<dfn class="decl def" id="_ZN10tensorflow7serving20SharedBatchSchedulerC1ERKNS0_20SharedBatchSchedulerIT_EE" title='tensorflow::serving::SharedBatchScheduler::SharedBatchScheduler&lt;TaskType&gt;' data-ref="_ZN10tensorflow7serving20SharedBatchSchedulerC1ERKNS0_20SharedBatchSchedulerIT_EE">SharedBatchScheduler</dfn>);</td></tr>
<tr><th id="201">201</th><td>};</td></tr>
<tr><th id="202">202</th><td></td></tr>
<tr><th id="203">203</th><td><i>//////////</i></td></tr>
<tr><th id="204">204</th><td><i>// Implementation details follow. API users need not read.</i></td></tr>
<tr><th id="205">205</th><td></td></tr>
<tr><th id="206">206</th><td><b>namespace</b> <span class="namespace">internal</span> {</td></tr>
<tr><th id="207">207</th><td></td></tr>
<tr><th id="208">208</th><td><i>// A task queue for SharedBatchScheduler. Accepts tasks and accumulates them</i></td></tr>
<tr><th id="209">209</th><td><i>// into batches, and dispenses those batches to be processed via a "pull"</i></td></tr>
<tr><th id="210">210</th><td><i>// interface. The queue's behavior is governed by maximum batch size, timeout</i></td></tr>
<tr><th id="211">211</th><td><i>// and maximum queue length parameters; see their documentation in</i></td></tr>
<tr><th id="212">212</th><td><i>// SharedBatchScheduler.</i></td></tr>
<tr><th id="213">213</th><td><i>//</i></td></tr>
<tr><th id="214">214</th><td><i>// The queue is implemented as a deque of batches, with these invariants:</i></td></tr>
<tr><th id="215">215</th><td><i>//  - The number of batches is between 1 and 'options_.max_enqueued_batches'.</i></td></tr>
<tr><th id="216">216</th><td><i>//  - The back-most batch is open; the rest are closed.</i></td></tr>
<tr><th id="217">217</th><td><i>//</i></td></tr>
<tr><th id="218">218</th><td><i>// Submitted tasks are added to the open batch. If that batch doesn't have room</i></td></tr>
<tr><th id="219">219</th><td><i>// but the queue isn't full, then that batch is closed and a new open batch is</i></td></tr>
<tr><th id="220">220</th><td><i>// started.</i></td></tr>
<tr><th id="221">221</th><td><i>//</i></td></tr>
<tr><th id="222">222</th><td><i>// Batch pull requests are handled by dequeuing the front-most batch if it is</i></td></tr>
<tr><th id="223">223</th><td><i>// closed. If the front-most batch is open (i.e. the queue contains only one</i></td></tr>
<tr><th id="224">224</th><td><i>// batch) and has reached the timeout, it is immediately closed and returned;</i></td></tr>
<tr><th id="225">225</th><td><i>// otherwise no batch is returned for the request.</i></td></tr>
<tr><th id="226">226</th><td><b>template</b> &lt;<b>typename</b> TaskType&gt;</td></tr>
<tr><th id="227">227</th><td><b>class</b> <dfn class="type def" id="tensorflow::serving::internal::Queue" title='tensorflow::serving::internal::Queue' data-ref="tensorflow::serving::internal::Queue">Queue</dfn> {</td></tr>
<tr><th id="228">228</th><td> <b>public</b>:</td></tr>
<tr><th id="229">229</th><td>  <b>using</b> <dfn class="typedef" id="tensorflow::serving::internal::Queue::ProcessBatchCallback" title='tensorflow::serving::internal::Queue::ProcessBatchCallback' data-type='std::function&lt;void (std::unique_ptr&lt;Batch&lt;TaskType&gt; &gt;)&gt;' data-ref="tensorflow::serving::internal::Queue::ProcessBatchCallback">ProcessBatchCallback</dfn> =</td></tr>
<tr><th id="230">230</th><td>      <span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/functional.html#std::function" title='std::function' data-ref="std::function">function</a>&lt;<em>void</em>(<span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/unique_ptr.h.html#std::unique_ptr" title='std::unique_ptr' data-ref="std::unique_ptr">unique_ptr</a>&lt;<a class="type" href="batch_scheduler.h.html#tensorflow::serving::Batch" title='tensorflow::serving::Batch' data-ref="tensorflow::serving::Batch">Batch</a>&lt;TaskType&gt;&gt;)&gt;;</td></tr>
<tr><th id="231">231</th><td>  <b>using</b> <dfn class="typedef" id="tensorflow::serving::internal::Queue::SchedulableBatchCallback" title='tensorflow::serving::internal::Queue::SchedulableBatchCallback' data-type='std::function&lt;void ()&gt;' data-ref="tensorflow::serving::internal::Queue::SchedulableBatchCallback">SchedulableBatchCallback</dfn> = <span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/functional.html#std::function" title='std::function' data-ref="std::function">function</a>&lt;<em>void</em>()&gt;;</td></tr>
<tr><th id="232">232</th><td>  <a class="decl" href="#_ZN10tensorflow7serving8internal5QueueC1ERKNS0_20SharedBatchSchedulerIT_E12QueueOptionsEPNS_3EnvESt8functionIFvSt10unique_ptrINS0_5BatchIS4_EESt14defa4067582" title='tensorflow::serving::internal::Queue::Queue&lt;TaskType&gt;' data-ref="_ZN10tensorflow7serving8internal5QueueC1ERKNS0_20SharedBatchSchedulerIT_E12QueueOptionsEPNS_3EnvESt8functionIFvSt10unique_ptrINS0_5BatchIS4_EESt14defa4067582">Queue</a>(<em>const</em> <b>typename</b> <a class="type" href="#tensorflow::serving::SharedBatchScheduler" title='tensorflow::serving::SharedBatchScheduler' data-ref="tensorflow::serving::SharedBatchScheduler">SharedBatchScheduler</a>&lt;TaskType&gt;::QueueOptions&amp; <dfn class="local col6 decl" id="26options" title='options' data-type='const typename SharedBatchScheduler&lt;TaskType&gt;::QueueOptions &amp;' data-ref="26options">options</dfn>,</td></tr>
<tr><th id="233">233</th><td>        <a class="type" href="../../platform/env.h.html#tensorflow::Env" title='tensorflow::Env' data-ref="tensorflow::Env">Env</a>* <dfn class="local col7 decl" id="27env" title='env' data-type='tensorflow::Env *' data-ref="27env">env</dfn>, <a class="typedef" href="#tensorflow::serving::internal::Queue::ProcessBatchCallback" title='tensorflow::serving::internal::Queue::ProcessBatchCallback' data-type='std::function&lt;void (std::unique_ptr&lt;Batch&lt;TaskType&gt; &gt;)&gt;' data-ref="tensorflow::serving::internal::Queue::ProcessBatchCallback">ProcessBatchCallback</a> <dfn class="local col8 decl" id="28process_batch_callback" title='process_batch_callback' data-type='ProcessBatchCallback' data-ref="28process_batch_callback">process_batch_callback</dfn>,</td></tr>
<tr><th id="234">234</th><td>        <a class="typedef" href="#tensorflow::serving::internal::Queue::SchedulableBatchCallback" title='tensorflow::serving::internal::Queue::SchedulableBatchCallback' data-type='std::function&lt;void ()&gt;' data-ref="tensorflow::serving::internal::Queue::SchedulableBatchCallback">SchedulableBatchCallback</a> <dfn class="local col9 decl" id="29schdulable_batch_callback" title='schdulable_batch_callback' data-type='SchedulableBatchCallback' data-ref="29schdulable_batch_callback">schdulable_batch_callback</dfn>);</td></tr>
<tr><th id="235">235</th><td></td></tr>
<tr><th id="236">236</th><td>  <i>// Illegal to destruct unless the queue is empty.</i></td></tr>
<tr><th id="237">237</th><td>  <a class="decl" href="#_ZN10tensorflow7serving8internal5QueueD1Ev" title='tensorflow::serving::internal::Queue::~Queue&lt;TaskType&gt;' data-ref="_ZN10tensorflow7serving8internal5QueueD1Ev">~Queue</a>();</td></tr>
<tr><th id="238">238</th><td></td></tr>
<tr><th id="239">239</th><td>  <i>// Submits a task to the queue, with the same semantics as</i></td></tr>
<tr><th id="240">240</th><td><i>  // BatchScheduler::Schedule().</i></td></tr>
<tr><th id="241">241</th><td>  <a class="type" href="../../lib/core/status.h.html#tensorflow::Status" title='tensorflow::Status' data-ref="tensorflow::Status">Status</a> <a class="decl" href="#_ZN10tensorflow7serving8internal5Queue8ScheduleEPSt10unique_ptrIT_St14default_deleteIS4_EE" title='tensorflow::serving::internal::Queue::Schedule' data-ref="_ZN10tensorflow7serving8internal5Queue8ScheduleEPSt10unique_ptrIT_St14default_deleteIS4_EE">Schedule</a>(<span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/unique_ptr.h.html#std::unique_ptr" title='std::unique_ptr' data-ref="std::unique_ptr">unique_ptr</a>&lt;TaskType&gt;* <dfn class="local col0 decl" id="30task" title='task' data-type='std::unique_ptr&lt;TaskType&gt; *' data-ref="30task">task</dfn>);</td></tr>
<tr><th id="242">242</th><td></td></tr>
<tr><th id="243">243</th><td>  <i>// Returns the number of enqueued tasks, with the same semantics as</i></td></tr>
<tr><th id="244">244</th><td><i>  // BatchScheduler::NumEnqueuedTasks().</i></td></tr>
<tr><th id="245">245</th><td>  <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <a class="decl" href="#_ZNK10tensorflow7serving8internal5Queue16NumEnqueuedTasksEv" title='tensorflow::serving::internal::Queue::NumEnqueuedTasks' data-ref="_ZNK10tensorflow7serving8internal5Queue16NumEnqueuedTasksEv">NumEnqueuedTasks</a>() <em>const</em>;</td></tr>
<tr><th id="246">246</th><td></td></tr>
<tr><th id="247">247</th><td>  <i>// Returns the queue capacity, with the same semantics as</i></td></tr>
<tr><th id="248">248</th><td><i>  // BatchScheduler::SchedulingCapacity().</i></td></tr>
<tr><th id="249">249</th><td>  <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <a class="decl" href="#_ZNK10tensorflow7serving8internal5Queue18SchedulingCapacityEv" title='tensorflow::serving::internal::Queue::SchedulingCapacity' data-ref="_ZNK10tensorflow7serving8internal5Queue18SchedulingCapacityEv">SchedulingCapacity</a>() <em>const</em>;</td></tr>
<tr><th id="250">250</th><td></td></tr>
<tr><th id="251">251</th><td>  <i>// Returns the maximum allowed size of tasks submitted to the queue.</i></td></tr>
<tr><th id="252">252</th><td>  <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <dfn class="decl def" id="_ZNK10tensorflow7serving8internal5Queue13max_task_sizeEv" title='tensorflow::serving::internal::Queue::max_task_size' data-ref="_ZNK10tensorflow7serving8internal5Queue13max_task_sizeEv">max_task_size</dfn>() <em>const</em> { <b>return</b> <a class="member" href="#tensorflow::serving::internal::Queue::options_" title='tensorflow::serving::internal::Queue::options_' data-ref="tensorflow::serving::internal::Queue::options_">options_</a>.max_batch_size; }</td></tr>
<tr><th id="253">253</th><td></td></tr>
<tr><th id="254">254</th><td>  <i>// Called by a thread that is ready to process a batch, to request one from</i></td></tr>
<tr><th id="255">255</th><td><i>  // this queue. Either returns a batch that is ready to be processed, or</i></td></tr>
<tr><th id="256">256</th><td><i>  // nullptr if the queue declines to schedule a batch at this time. If it</i></td></tr>
<tr><th id="257">257</th><td><i>  // returns a batch, the batch is guaranteed to be closed.</i></td></tr>
<tr><th id="258">258</th><td>  <span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/unique_ptr.h.html#std::unique_ptr" title='std::unique_ptr' data-ref="std::unique_ptr">unique_ptr</a>&lt;<a class="type" href="batch_scheduler.h.html#tensorflow::serving::Batch" title='tensorflow::serving::Batch' data-ref="tensorflow::serving::Batch">Batch</a>&lt;TaskType&gt;&gt; <a class="decl" href="#_ZN10tensorflow7serving8internal5Queue13ScheduleBatchEv" title='tensorflow::serving::internal::Queue::ScheduleBatch' data-ref="_ZN10tensorflow7serving8internal5Queue13ScheduleBatchEv">ScheduleBatch</a>();</td></tr>
<tr><th id="259">259</th><td></td></tr>
<tr><th id="260">260</th><td>  <i>// Processes a batch that has been returned earlier by ScheduleBatch().</i></td></tr>
<tr><th id="261">261</th><td>  <em>void</em> <a class="decl" href="#_ZN10tensorflow7serving8internal5Queue12ProcessBatchESt10unique_ptrINS0_5BatchIT_EESt14default_deleteIS6_EE" title='tensorflow::serving::internal::Queue::ProcessBatch' data-ref="_ZN10tensorflow7serving8internal5Queue12ProcessBatchESt10unique_ptrINS0_5BatchIT_EESt14default_deleteIS6_EE">ProcessBatch</a>(<span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/unique_ptr.h.html#std::unique_ptr" title='std::unique_ptr' data-ref="std::unique_ptr">unique_ptr</a>&lt;<a class="type" href="batch_scheduler.h.html#tensorflow::serving::Batch" title='tensorflow::serving::Batch' data-ref="tensorflow::serving::Batch">Batch</a>&lt;TaskType&gt;&gt; <dfn class="local col1 decl" id="31batch" title='batch' data-type='std::unique_ptr&lt;Batch&lt;TaskType&gt; &gt;' data-ref="31batch">batch</dfn>);</td></tr>
<tr><th id="262">262</th><td></td></tr>
<tr><th id="263">263</th><td>  <i>// Determines whether the queue is empty, i.e. has no tasks waiting or being</i></td></tr>
<tr><th id="264">264</th><td><i>  // processed.</i></td></tr>
<tr><th id="265">265</th><td>  <em>bool</em> <a class="decl" href="#_ZNK10tensorflow7serving8internal5Queue7IsEmptyEv" title='tensorflow::serving::internal::Queue::IsEmpty' data-ref="_ZNK10tensorflow7serving8internal5Queue7IsEmptyEv">IsEmpty</a>() <em>const</em>;</td></tr>
<tr><th id="266">266</th><td></td></tr>
<tr><th id="267">267</th><td>  <i>// Marks the queue closed, and waits until it is empty.</i></td></tr>
<tr><th id="268">268</th><td>  <em>void</em> <a class="decl" href="#_ZN10tensorflow7serving8internal5Queue22CloseAndWaitUntilEmptyEv" title='tensorflow::serving::internal::Queue::CloseAndWaitUntilEmpty' data-ref="_ZN10tensorflow7serving8internal5Queue22CloseAndWaitUntilEmptyEv">CloseAndWaitUntilEmpty</a>();</td></tr>
<tr><th id="269">269</th><td></td></tr>
<tr><th id="270">270</th><td>  <em>bool</em> <dfn class="decl def" id="_ZNK10tensorflow7serving8internal5Queue6closedEv" title='tensorflow::serving::internal::Queue::closed' data-ref="_ZNK10tensorflow7serving8internal5Queue6closedEv">closed</dfn>() <em>const</em> {</td></tr>
<tr><th id="271">271</th><td>    <a class="type" href="../../platform/default/mutex.h.html#tensorflow::mutex_lock" title='tensorflow::mutex_lock' data-ref="tensorflow::mutex_lock">mutex_lock</a> <dfn class="local col2 decl" id="32l" title='l' data-type='tensorflow::mutex_lock' data-ref="32l">l</dfn>(<a class="member" href="#tensorflow::serving::internal::Queue::mu_" title='tensorflow::serving::internal::Queue::mu_' data-ref="tensorflow::serving::internal::Queue::mu_">mu_</a>);</td></tr>
<tr><th id="272">272</th><td>    <b>return</b> <a class="member" href="#tensorflow::serving::internal::Queue::closed_" title='tensorflow::serving::internal::Queue::closed_' data-ref="tensorflow::serving::internal::Queue::closed_">closed_</a>;</td></tr>
<tr><th id="273">273</th><td>  }</td></tr>
<tr><th id="274">274</th><td></td></tr>
<tr><th id="275">275</th><td> <b>private</b>:</td></tr>
<tr><th id="276">276</th><td>  <i>// Same as IsEmpty(), but assumes the caller already holds a lock on 'mu_'.</i></td></tr>
<tr><th id="277">277</th><td>  <em>bool</em> <a class="decl" href="#_ZNK10tensorflow7serving8internal5Queue15IsEmptyInternalEv" title='tensorflow::serving::internal::Queue::IsEmptyInternal' data-ref="_ZNK10tensorflow7serving8internal5Queue15IsEmptyInternalEv">IsEmptyInternal</a>() <em>const</em> <a class="macro" href="../../platform/default/thread_annotations.h.html#88" title="__attribute__((exclusive_locks_required(mu_)))" data-ref="_M/EXCLUSIVE_LOCKS_REQUIRED">EXCLUSIVE_LOCKS_REQUIRED</a>(<a class="member" href="#tensorflow::serving::internal::Queue::mu_" title='tensorflow::serving::internal::Queue::mu_' data-ref="tensorflow::serving::internal::Queue::mu_">mu_</a>);</td></tr>
<tr><th id="278">278</th><td></td></tr>
<tr><th id="279">279</th><td>  <i>// Closes the open batch residing at the back of 'batches_', and inserts a</i></td></tr>
<tr><th id="280">280</th><td><i>  // fresh open batch behind it.</i></td></tr>
<tr><th id="281">281</th><td>  <em>void</em> <a class="decl" href="#_ZN10tensorflow7serving8internal5Queue13StartNewBatchEv" title='tensorflow::serving::internal::Queue::StartNewBatch' data-ref="_ZN10tensorflow7serving8internal5Queue13StartNewBatchEv">StartNewBatch</a>() <a class="macro" href="../../platform/default/thread_annotations.h.html#88" title="__attribute__((exclusive_locks_required(mu_)))" data-ref="_M/EXCLUSIVE_LOCKS_REQUIRED">EXCLUSIVE_LOCKS_REQUIRED</a>(<a class="member" href="#tensorflow::serving::internal::Queue::mu_" title='tensorflow::serving::internal::Queue::mu_' data-ref="tensorflow::serving::internal::Queue::mu_">mu_</a>);</td></tr>
<tr><th id="282">282</th><td></td></tr>
<tr><th id="283">283</th><td>  <i>// Determines whether the open batch residing at the back of 'batches_' is</i></td></tr>
<tr><th id="284">284</th><td><i>  // currently schedulable.</i></td></tr>
<tr><th id="285">285</th><td>  <em>bool</em> <a class="decl" href="#_ZNK10tensorflow7serving8internal5Queue22IsOpenBatchSchedulableEv" title='tensorflow::serving::internal::Queue::IsOpenBatchSchedulable' data-ref="_ZNK10tensorflow7serving8internal5Queue22IsOpenBatchSchedulableEv">IsOpenBatchSchedulable</a>() <em>const</em> <a class="macro" href="../../platform/default/thread_annotations.h.html#88" title="__attribute__((exclusive_locks_required(mu_)))" data-ref="_M/EXCLUSIVE_LOCKS_REQUIRED">EXCLUSIVE_LOCKS_REQUIRED</a>(<a class="member" href="#tensorflow::serving::internal::Queue::mu_" title='tensorflow::serving::internal::Queue::mu_' data-ref="tensorflow::serving::internal::Queue::mu_">mu_</a>);</td></tr>
<tr><th id="286">286</th><td></td></tr>
<tr><th id="287">287</th><td>  <em>const</em> <b>typename</b> <a class="type" href="#tensorflow::serving::SharedBatchScheduler" title='tensorflow::serving::SharedBatchScheduler' data-ref="tensorflow::serving::SharedBatchScheduler">SharedBatchScheduler</a>&lt;TaskType&gt;::QueueOptions <dfn class="decl" id="tensorflow::serving::internal::Queue::options_" title='tensorflow::serving::internal::Queue::options_' data-ref="tensorflow::serving::internal::Queue::options_">options_</dfn>;</td></tr>
<tr><th id="288">288</th><td></td></tr>
<tr><th id="289">289</th><td>  <i>// The environment to use.</i></td></tr>
<tr><th id="290">290</th><td>  <a class="type" href="../../platform/env.h.html#tensorflow::Env" title='tensorflow::Env' data-ref="tensorflow::Env">Env</a>* <dfn class="decl" id="tensorflow::serving::internal::Queue::env_" title='tensorflow::serving::internal::Queue::env_' data-ref="tensorflow::serving::internal::Queue::env_">env_</dfn>;</td></tr>
<tr><th id="291">291</th><td></td></tr>
<tr><th id="292">292</th><td>  <i>// A callback invoked to processes a batch of work units. Always invoked from</i></td></tr>
<tr><th id="293">293</th><td><i>  // a batch thread.</i></td></tr>
<tr><th id="294">294</th><td>  <a class="typedef" href="#tensorflow::serving::internal::Queue::ProcessBatchCallback" title='tensorflow::serving::internal::Queue::ProcessBatchCallback' data-type='std::function&lt;void (std::unique_ptr&lt;Batch&lt;TaskType&gt; &gt;)&gt;' data-ref="tensorflow::serving::internal::Queue::ProcessBatchCallback">ProcessBatchCallback</a> <dfn class="decl" id="tensorflow::serving::internal::Queue::process_batch_callback_" title='tensorflow::serving::internal::Queue::process_batch_callback_' data-ref="tensorflow::serving::internal::Queue::process_batch_callback_">process_batch_callback_</dfn>;</td></tr>
<tr><th id="295">295</th><td></td></tr>
<tr><th id="296">296</th><td>  <i>// A callback invoked to notify the scheduler that a new batch has become</i></td></tr>
<tr><th id="297">297</th><td><i>  // schedulable.</i></td></tr>
<tr><th id="298">298</th><td>  <a class="typedef" href="#tensorflow::serving::internal::Queue::SchedulableBatchCallback" title='tensorflow::serving::internal::Queue::SchedulableBatchCallback' data-type='std::function&lt;void ()&gt;' data-ref="tensorflow::serving::internal::Queue::SchedulableBatchCallback">SchedulableBatchCallback</a> <dfn class="decl" id="tensorflow::serving::internal::Queue::schedulable_batch_callback_" title='tensorflow::serving::internal::Queue::schedulable_batch_callback_' data-ref="tensorflow::serving::internal::Queue::schedulable_batch_callback_">schedulable_batch_callback_</dfn>;</td></tr>
<tr><th id="299">299</th><td></td></tr>
<tr><th id="300">300</th><td>  <em>mutable</em> <a class="type" href="../../platform/default/mutex.h.html#tensorflow::mutex" title='tensorflow::mutex' data-ref="tensorflow::mutex">mutex</a> <dfn class="decl" id="tensorflow::serving::internal::Queue::mu_" title='tensorflow::serving::internal::Queue::mu_' data-ref="tensorflow::serving::internal::Queue::mu_">mu_</dfn>;</td></tr>
<tr><th id="301">301</th><td></td></tr>
<tr><th id="302">302</th><td>  <i>// Whether this queue can accept new tasks. This variable is monotonic: it</i></td></tr>
<tr><th id="303">303</th><td><i>  // starts as false, and then at some point gets set to true and remains true</i></td></tr>
<tr><th id="304">304</th><td><i>  // for the duration of this object's life.</i></td></tr>
<tr><th id="305">305</th><td>  <em>bool</em> <dfn class="decl" id="tensorflow::serving::internal::Queue::closed_" title='tensorflow::serving::internal::Queue::closed_' data-ref="tensorflow::serving::internal::Queue::closed_">closed_</dfn> <a class="macro" href="../../platform/default/thread_annotations.h.html#52" title="__attribute__((guarded_by(mu_)))" data-ref="_M/GUARDED_BY">GUARDED_BY</a>(<a class="ref" href="#tensorflow::serving::internal::Queue::mu_" title='tensorflow::serving::internal::Queue::mu_' data-ref="tensorflow::serving::internal::Queue::mu_">mu_</a>) = <b>false</b>;</td></tr>
<tr><th id="306">306</th><td></td></tr>
<tr><th id="307">307</th><td>  <i>// The enqueued batches. See the invariants in the class comments above.</i></td></tr>
<tr><th id="308">308</th><td>  <span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/stl_deque.h.html#std::deque" title='std::deque' data-ref="std::deque">deque</a>&lt;<span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/unique_ptr.h.html#std::unique_ptr" title='std::unique_ptr' data-ref="std::unique_ptr">unique_ptr</a>&lt;<a class="type" href="batch_scheduler.h.html#tensorflow::serving::Batch" title='tensorflow::serving::Batch' data-ref="tensorflow::serving::Batch">Batch</a>&lt;TaskType&gt;&gt;&gt; <dfn class="decl" id="tensorflow::serving::internal::Queue::batches_" title='tensorflow::serving::internal::Queue::batches_' data-ref="tensorflow::serving::internal::Queue::batches_">batches_</dfn> <a class="macro" href="../../platform/default/thread_annotations.h.html#52" title="__attribute__((guarded_by(mu_)))" data-ref="_M/GUARDED_BY">GUARDED_BY</a>(<a class="ref" href="#tensorflow::serving::internal::Queue::mu_" title='tensorflow::serving::internal::Queue::mu_' data-ref="tensorflow::serving::internal::Queue::mu_">mu_</a>);</td></tr>
<tr><th id="309">309</th><td></td></tr>
<tr><th id="310">310</th><td>  <i>// The time at which the first task was added to the open (back-most) batch</i></td></tr>
<tr><th id="311">311</th><td><i>  // in 'batches_'. Valid iff that batch contains at least one task.</i></td></tr>
<tr><th id="312">312</th><td>  <a class="typedef" href="../../platform/default/integral_types.h.html#tensorflow::uint64" title='tensorflow::uint64' data-type='unsigned long long' data-ref="tensorflow::uint64">uint64</a> <dfn class="decl" id="tensorflow::serving::internal::Queue::open_batch_start_time_micros_" title='tensorflow::serving::internal::Queue::open_batch_start_time_micros_' data-ref="tensorflow::serving::internal::Queue::open_batch_start_time_micros_">open_batch_start_time_micros_</dfn> <a class="macro" href="../../platform/default/thread_annotations.h.html#52" title="__attribute__((guarded_by(mu_)))" data-ref="_M/GUARDED_BY">GUARDED_BY</a>(<a class="ref" href="#tensorflow::serving::internal::Queue::mu_" title='tensorflow::serving::internal::Queue::mu_' data-ref="tensorflow::serving::internal::Queue::mu_">mu_</a>);</td></tr>
<tr><th id="313">313</th><td></td></tr>
<tr><th id="314">314</th><td>  <i>// Whether this queue contains a batch that is eligible to be scheduled. Used</i></td></tr>
<tr><th id="315">315</th><td><i>  // to keep track of when to call 'schedulable_batch_callback_'.</i></td></tr>
<tr><th id="316">316</th><td>  <em>bool</em> <dfn class="decl" id="tensorflow::serving::internal::Queue::schedulable_batch_" title='tensorflow::serving::internal::Queue::schedulable_batch_' data-ref="tensorflow::serving::internal::Queue::schedulable_batch_">schedulable_batch_</dfn> <a class="macro" href="../../platform/default/thread_annotations.h.html#52" title="__attribute__((guarded_by(mu_)))" data-ref="_M/GUARDED_BY">GUARDED_BY</a>(<a class="ref" href="#tensorflow::serving::internal::Queue::mu_" title='tensorflow::serving::internal::Queue::mu_' data-ref="tensorflow::serving::internal::Queue::mu_">mu_</a>) = <b>false</b>;</td></tr>
<tr><th id="317">317</th><td></td></tr>
<tr><th id="318">318</th><td>  <i>// The number of batches currently being processed by batch threads.</i></td></tr>
<tr><th id="319">319</th><td><i>  // Incremented in ScheduleBatch() and decremented in ProcessBatch().</i></td></tr>
<tr><th id="320">320</th><td>  <em>int</em> <dfn class="decl" id="tensorflow::serving::internal::Queue::num_batches_being_processed_" title='tensorflow::serving::internal::Queue::num_batches_being_processed_' data-ref="tensorflow::serving::internal::Queue::num_batches_being_processed_">num_batches_being_processed_</dfn> <a class="macro" href="../../platform/default/thread_annotations.h.html#52" title="__attribute__((guarded_by(mu_)))" data-ref="_M/GUARDED_BY">GUARDED_BY</a>(<a class="ref" href="#tensorflow::serving::internal::Queue::mu_" title='tensorflow::serving::internal::Queue::mu_' data-ref="tensorflow::serving::internal::Queue::mu_">mu_</a>) = <var>0</var>;</td></tr>
<tr><th id="321">321</th><td></td></tr>
<tr><th id="322">322</th><td>  <i>// Used by CloseAndWaitUntilEmpty() to wait until the queue is empty, for the</i></td></tr>
<tr><th id="323">323</th><td><i>  // case in which the queue is not empty when CloseAndWaitUntilEmpty() starts.</i></td></tr>
<tr><th id="324">324</th><td><i>  // When ProcessBatch() dequeues the last batch and makes the queue empty, if</i></td></tr>
<tr><th id="325">325</th><td><i>  // 'empty_notification_' is non-null it calls 'empty_notification_-&gt;Notify()'.</i></td></tr>
<tr><th id="326">326</th><td>  <a class="type" href="../../platform/default/notification.h.html#tensorflow::Notification" title='tensorflow::Notification' data-ref="tensorflow::Notification">Notification</a>* <dfn class="decl" id="tensorflow::serving::internal::Queue::empty_notification_" title='tensorflow::serving::internal::Queue::empty_notification_' data-ref="tensorflow::serving::internal::Queue::empty_notification_">empty_notification_</dfn> <a class="macro" href="../../platform/default/thread_annotations.h.html#52" title="__attribute__((guarded_by(mu_)))" data-ref="_M/GUARDED_BY">GUARDED_BY</a>(<a class="ref" href="#tensorflow::serving::internal::Queue::mu_" title='tensorflow::serving::internal::Queue::mu_' data-ref="tensorflow::serving::internal::Queue::mu_">mu_</a>) = <b>nullptr</b>;</td></tr>
<tr><th id="327">327</th><td></td></tr>
<tr><th id="328">328</th><td>  <a class="macro" href="../../platform/macros.h.html#91" title="Queue(const Queue&amp;) = delete; void operator=(const Queue&amp;) = delete" data-ref="_M/TF_DISALLOW_COPY_AND_ASSIGN">TF_DISALLOW_COPY_AND_ASSIGN</a>(<dfn class="decl def" id="_ZN10tensorflow7serving8internal5QueueC1ERKNS1_5QueueIT_EE" title='tensorflow::serving::internal::Queue::Queue&lt;TaskType&gt;' data-ref="_ZN10tensorflow7serving8internal5QueueC1ERKNS1_5QueueIT_EE">Queue</dfn>);</td></tr>
<tr><th id="329">329</th><td>};</td></tr>
<tr><th id="330">330</th><td></td></tr>
<tr><th id="331">331</th><td><i>// A RAII-style object that points to a Queue and implements</i></td></tr>
<tr><th id="332">332</th><td><i>// the BatchScheduler API. To be handed out to clients who call AddQueue().</i></td></tr>
<tr><th id="333">333</th><td><b>template</b> &lt;<b>typename</b> TaskType&gt;</td></tr>
<tr><th id="334">334</th><td><b>class</b> <dfn class="type def" id="tensorflow::serving::internal::QueueHandle" title='tensorflow::serving::internal::QueueHandle' data-ref="tensorflow::serving::internal::QueueHandle">QueueHandle</dfn> : <b>public</b> <a class="type" href="batch_scheduler.h.html#tensorflow::serving::BatchScheduler" title='tensorflow::serving::BatchScheduler' data-ref="tensorflow::serving::BatchScheduler">BatchScheduler</a>&lt;TaskType&gt; {</td></tr>
<tr><th id="335">335</th><td> <b>public</b>:</td></tr>
<tr><th id="336">336</th><td>  <a class="decl" href="#_ZN10tensorflow7serving8internal11QueueHandleC1ESt10shared_ptrINS0_20SharedBatchSchedulerIT_EEEPNS1_5QueueIS5_EE" title='tensorflow::serving::internal::QueueHandle::QueueHandle&lt;TaskType&gt;' data-ref="_ZN10tensorflow7serving8internal11QueueHandleC1ESt10shared_ptrINS0_20SharedBatchSchedulerIT_EEEPNS1_5QueueIS5_EE">QueueHandle</a>(<span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/shared_ptr_base.h.html#std::shared_ptr" title='std::shared_ptr' data-ref="std::shared_ptr">shared_ptr</a>&lt;<a class="type" href="#tensorflow::serving::SharedBatchScheduler" title='tensorflow::serving::SharedBatchScheduler' data-ref="tensorflow::serving::SharedBatchScheduler">SharedBatchScheduler</a>&lt;TaskType&gt;&gt; <dfn class="local col3 decl" id="33scheduler" title='scheduler' data-type='std::shared_ptr&lt;SharedBatchScheduler&lt;TaskType&gt; &gt;' data-ref="33scheduler">scheduler</dfn>,</td></tr>
<tr><th id="337">337</th><td>              <a class="type" href="#tensorflow::serving::internal::Queue" title='tensorflow::serving::internal::Queue' data-ref="tensorflow::serving::internal::Queue">Queue</a>&lt;TaskType&gt;* <dfn class="local col4 decl" id="34queue" title='queue' data-type='Queue&lt;TaskType&gt; *' data-ref="34queue">queue</dfn>);</td></tr>
<tr><th id="338">338</th><td>  <a class="decl" href="#_ZN10tensorflow7serving8internal11QueueHandleD1Ev" title='tensorflow::serving::internal::QueueHandle::~QueueHandle&lt;TaskType&gt;' data-ref="_ZN10tensorflow7serving8internal11QueueHandleD1Ev">~QueueHandle</a>() override;</td></tr>
<tr><th id="339">339</th><td></td></tr>
<tr><th id="340">340</th><td>  <a class="type" href="../../lib/core/status.h.html#tensorflow::Status" title='tensorflow::Status' data-ref="tensorflow::Status">Status</a> <a class="decl" href="#_ZN10tensorflow7serving8internal11QueueHandle8ScheduleEPSt10unique_ptrIT_St14default_deleteIS4_EE" title='tensorflow::serving::internal::QueueHandle::Schedule' data-ref="_ZN10tensorflow7serving8internal11QueueHandle8ScheduleEPSt10unique_ptrIT_St14default_deleteIS4_EE">Schedule</a>(<span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/unique_ptr.h.html#std::unique_ptr" title='std::unique_ptr' data-ref="std::unique_ptr">unique_ptr</a>&lt;TaskType&gt;* <dfn class="local col5 decl" id="35task" title='task' data-type='std::unique_ptr&lt;TaskType&gt; *' data-ref="35task">task</dfn>) override;</td></tr>
<tr><th id="341">341</th><td>  <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <a class="decl" href="#_ZNK10tensorflow7serving8internal11QueueHandle16NumEnqueuedTasksEv" title='tensorflow::serving::internal::QueueHandle::NumEnqueuedTasks' data-ref="_ZNK10tensorflow7serving8internal11QueueHandle16NumEnqueuedTasksEv">NumEnqueuedTasks</a>() <em>const</em> override;</td></tr>
<tr><th id="342">342</th><td>  <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <a class="decl" href="#_ZNK10tensorflow7serving8internal11QueueHandle18SchedulingCapacityEv" title='tensorflow::serving::internal::QueueHandle::SchedulingCapacity' data-ref="_ZNK10tensorflow7serving8internal11QueueHandle18SchedulingCapacityEv">SchedulingCapacity</a>() <em>const</em> override;</td></tr>
<tr><th id="343">343</th><td></td></tr>
<tr><th id="344">344</th><td>  <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <dfn class="decl def" id="_ZNK10tensorflow7serving8internal11QueueHandle13max_task_sizeEv" title='tensorflow::serving::internal::QueueHandle::max_task_size' data-ref="_ZNK10tensorflow7serving8internal11QueueHandle13max_task_sizeEv">max_task_size</dfn>() <em>const</em> override { <b>return</b> <a class="member" href="#tensorflow::serving::internal::QueueHandle::queue_" title='tensorflow::serving::internal::QueueHandle::queue_' data-ref="tensorflow::serving::internal::QueueHandle::queue_">queue_</a>-&gt;max_task_size(); }</td></tr>
<tr><th id="345">345</th><td></td></tr>
<tr><th id="346">346</th><td> <b>private</b>:</td></tr>
<tr><th id="347">347</th><td>  <i>// The scheduler that owns 'queue_'.</i></td></tr>
<tr><th id="348">348</th><td>  <span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/shared_ptr_base.h.html#std::shared_ptr" title='std::shared_ptr' data-ref="std::shared_ptr">shared_ptr</a>&lt;<a class="type" href="#tensorflow::serving::SharedBatchScheduler" title='tensorflow::serving::SharedBatchScheduler' data-ref="tensorflow::serving::SharedBatchScheduler">SharedBatchScheduler</a>&lt;TaskType&gt;&gt; <dfn class="decl" id="tensorflow::serving::internal::QueueHandle::scheduler_" title='tensorflow::serving::internal::QueueHandle::scheduler_' data-ref="tensorflow::serving::internal::QueueHandle::scheduler_">scheduler_</dfn>;</td></tr>
<tr><th id="349">349</th><td></td></tr>
<tr><th id="350">350</th><td>  <i>// The queue this handle wraps. Owned by 'scheduler_', which keeps it alive at</i></td></tr>
<tr><th id="351">351</th><td><i>  // least until this class's destructor closes it.</i></td></tr>
<tr><th id="352">352</th><td>  <a class="type" href="#tensorflow::serving::internal::Queue" title='tensorflow::serving::internal::Queue' data-ref="tensorflow::serving::internal::Queue">Queue</a>&lt;TaskType&gt;* <dfn class="decl" id="tensorflow::serving::internal::QueueHandle::queue_" title='tensorflow::serving::internal::QueueHandle::queue_' data-ref="tensorflow::serving::internal::QueueHandle::queue_">queue_</dfn>;</td></tr>
<tr><th id="353">353</th><td></td></tr>
<tr><th id="354">354</th><td>  <a class="macro" href="../../platform/macros.h.html#91" title="QueueHandle(const QueueHandle&amp;) = delete; void operator=(const QueueHandle&amp;) = delete" data-ref="_M/TF_DISALLOW_COPY_AND_ASSIGN">TF_DISALLOW_COPY_AND_ASSIGN</a>(<dfn class="decl def" id="_ZN10tensorflow7serving8internal11QueueHandleC1ERKNS1_11QueueHandleIT_EE" title='tensorflow::serving::internal::QueueHandle::QueueHandle&lt;TaskType&gt;' data-ref="_ZN10tensorflow7serving8internal11QueueHandleC1ERKNS1_11QueueHandleIT_EE">QueueHandle</dfn>);</td></tr>
<tr><th id="355">355</th><td>};</td></tr>
<tr><th id="356">356</th><td></td></tr>
<tr><th id="357">357</th><td>}  <i>// namespace internal</i></td></tr>
<tr><th id="358">358</th><td></td></tr>
<tr><th id="359">359</th><td><b>template</b> &lt;<b>typename</b> TaskType&gt;</td></tr>
<tr><th id="360">360</th><td><a class="type" href="../../lib/core/status.h.html#tensorflow::Status" title='tensorflow::Status' data-ref="tensorflow::Status">Status</a> <a class="type" href="#tensorflow::serving::SharedBatchScheduler" title='tensorflow::serving::SharedBatchScheduler' data-ref="tensorflow::serving::SharedBatchScheduler">SharedBatchScheduler</a>&lt;TaskType&gt;::<dfn class="decl def" id="_ZN10tensorflow7serving20SharedBatchScheduler6CreateERKNS1_7OptionsEPSt10shared_ptrINS0_20SharedBatchSchedulerIT_EEE" title='tensorflow::serving::SharedBatchScheduler::Create' data-ref="_ZN10tensorflow7serving20SharedBatchScheduler6CreateERKNS1_7OptionsEPSt10shared_ptrINS0_20SharedBatchSchedulerIT_EEE">Create</dfn>(</td></tr>
<tr><th id="361">361</th><td>    <em>const</em> <a class="type" href="#tensorflow::serving::SharedBatchScheduler::Options" title='tensorflow::serving::SharedBatchScheduler::Options' data-ref="tensorflow::serving::SharedBatchScheduler::Options">Options</a>&amp; <dfn class="local col6 decl" id="36options" title='options' data-type='const tensorflow::serving::SharedBatchScheduler::Options &amp;' data-ref="36options">options</dfn>,</td></tr>
<tr><th id="362">362</th><td>    <span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/shared_ptr_base.h.html#std::shared_ptr" title='std::shared_ptr' data-ref="std::shared_ptr">shared_ptr</a>&lt;<a class="type" href="#tensorflow::serving::SharedBatchScheduler" title='tensorflow::serving::SharedBatchScheduler' data-ref="tensorflow::serving::SharedBatchScheduler">SharedBatchScheduler</a>&lt;TaskType&gt;&gt;* <dfn class="local col7 decl" id="37scheduler" title='scheduler' data-type='std::shared_ptr&lt;SharedBatchScheduler&lt;TaskType&gt; &gt; *' data-ref="37scheduler">scheduler</dfn>) {</td></tr>
<tr><th id="363">363</th><td>  <b>if</b> (<a class="local col6 ref" href="#36options" title='options' data-ref="36options">options</a>.num_batch_threads &lt; <var>1</var>) {</td></tr>
<tr><th id="364">364</th><td>    <b>return</b> <span class="namespace">errors::</span>InvalidArgument(<q>"num_batch_threads must be positive; was "</q>,</td></tr>
<tr><th id="365">365</th><td>                                   <a class="local col6 ref" href="#36options" title='options' data-ref="36options">options</a>.num_batch_threads);</td></tr>
<tr><th id="366">366</th><td>  }</td></tr>
<tr><th id="367">367</th><td>  <a class="local col7 ref" href="#37scheduler" title='scheduler' data-ref="37scheduler">scheduler</a>-&gt;reset(<b>new</b> <a class="type" href="#tensorflow::serving::SharedBatchScheduler" title='tensorflow::serving::SharedBatchScheduler' data-ref="tensorflow::serving::SharedBatchScheduler">SharedBatchScheduler</a>&lt;TaskType&gt;(<a class="local col6 ref" href="#36options" title='options' data-ref="36options">options</a>));</td></tr>
<tr><th id="368">368</th><td>  <b>return</b> <a class="type" href="../../lib/core/status.h.html#tensorflow::Status" title='tensorflow::Status' data-ref="tensorflow::Status">Status</a>::<a class="ref" href="../../lib/core/status.h.html#_ZN10tensorflow6Status2OKEv" title='tensorflow::Status::OK' data-ref="_ZN10tensorflow6Status2OKEv">OK</a>();</td></tr>
<tr><th id="369">369</th><td>}</td></tr>
<tr><th id="370">370</th><td></td></tr>
<tr><th id="371">371</th><td><b>template</b> &lt;<b>typename</b> TaskType&gt;</td></tr>
<tr><th id="372">372</th><td><a class="type" href="#tensorflow::serving::SharedBatchScheduler" title='tensorflow::serving::SharedBatchScheduler' data-ref="tensorflow::serving::SharedBatchScheduler">SharedBatchScheduler</a>&lt;TaskType&gt;::<dfn class="decl def" id="_ZN10tensorflow7serving20SharedBatchSchedulerD1Ev" title='tensorflow::serving::SharedBatchScheduler::~SharedBatchScheduler&lt;TaskType&gt;' data-ref="_ZN10tensorflow7serving20SharedBatchSchedulerD1Ev">~SharedBatchScheduler</dfn>() {</td></tr>
<tr><th id="373">373</th><td>  <i>// Wait until the batch threads finish clearing out and deleting the closed</i></td></tr>
<tr><th id="374">374</th><td><i>  // queues.</i></td></tr>
<tr><th id="375">375</th><td>  <b>for</b> (;;) {</td></tr>
<tr><th id="376">376</th><td>    {</td></tr>
<tr><th id="377">377</th><td>      <a class="type" href="../../platform/default/mutex.h.html#tensorflow::mutex_lock" title='tensorflow::mutex_lock' data-ref="tensorflow::mutex_lock">mutex_lock</a> <dfn class="local col8 decl" id="38l" title='l' data-type='tensorflow::mutex_lock' data-ref="38l">l</dfn>(<a class="member" href="#tensorflow::serving::SharedBatchScheduler::mu_" title='tensorflow::serving::SharedBatchScheduler::mu_' data-ref="tensorflow::serving::SharedBatchScheduler::mu_">mu_</a>);</td></tr>
<tr><th id="378">378</th><td>      <b>if</b> (<a class="member" href="#tensorflow::serving::SharedBatchScheduler::queues_" title='tensorflow::serving::SharedBatchScheduler::queues_' data-ref="tensorflow::serving::SharedBatchScheduler::queues_">queues_</a>.empty()) {</td></tr>
<tr><th id="379">379</th><td>        <b>break</b>;</td></tr>
<tr><th id="380">380</th><td>      }</td></tr>
<tr><th id="381">381</th><td>    }</td></tr>
<tr><th id="382">382</th><td>    <em>const</em> <a class="typedef" href="../../platform/default/integral_types.h.html#tensorflow::int64" title='tensorflow::int64' data-type='long long' data-ref="tensorflow::int64">int64</a> <dfn class="local col9 decl" id="39kSleepTimeMicros" title='kSleepTimeMicros' data-type='const int64' data-ref="39kSleepTimeMicros">kSleepTimeMicros</dfn> = <var>100</var>;</td></tr>
<tr><th id="383">383</th><td>    <a class="member" href="#tensorflow::serving::SharedBatchScheduler::options_" title='tensorflow::serving::SharedBatchScheduler::options_' data-ref="tensorflow::serving::SharedBatchScheduler::options_">options_</a>.env-&gt;SleepForMicroseconds(<a class="local col9 ref" href="#39kSleepTimeMicros" title='kSleepTimeMicros' data-ref="39kSleepTimeMicros">kSleepTimeMicros</a>);</td></tr>
<tr><th id="384">384</th><td>  }</td></tr>
<tr><th id="385">385</th><td>  <i>// Delete the batch threads before allowing state the threads may access (e.g.</i></td></tr>
<tr><th id="386">386</th><td><i>  // 'mu_') to be deleted.</i></td></tr>
<tr><th id="387">387</th><td>  <a class="member" href="#tensorflow::serving::SharedBatchScheduler::batch_threads_" title='tensorflow::serving::SharedBatchScheduler::batch_threads_' data-ref="tensorflow::serving::SharedBatchScheduler::batch_threads_">batch_threads_</a>.<a class="ref" href="../../../../../include/c++/5/bits/stl_vector.h.html#_ZNSt6vector5clearEv" title='std::vector::clear' data-ref="_ZNSt6vector5clearEv">clear</a>();</td></tr>
<tr><th id="388">388</th><td>}</td></tr>
<tr><th id="389">389</th><td></td></tr>
<tr><th id="390">390</th><td><b>template</b> &lt;<b>typename</b> TaskType&gt;</td></tr>
<tr><th id="391">391</th><td><a class="type" href="../../lib/core/status.h.html#tensorflow::Status" title='tensorflow::Status' data-ref="tensorflow::Status">Status</a> <a class="type" href="#tensorflow::serving::SharedBatchScheduler" title='tensorflow::serving::SharedBatchScheduler' data-ref="tensorflow::serving::SharedBatchScheduler">SharedBatchScheduler</a>&lt;TaskType&gt;::<dfn class="decl def" id="_ZN10tensorflow7serving20SharedBatchScheduler8AddQueueERKNS1_12QueueOptionsESt8functionIFvSt10unique_ptrINS0_5BatchIT_EESt14default_deleteIS9_EEEEPS6_13470146" title='tensorflow::serving::SharedBatchScheduler::AddQueue' data-ref="_ZN10tensorflow7serving20SharedBatchScheduler8AddQueueERKNS1_12QueueOptionsESt8functionIFvSt10unique_ptrINS0_5BatchIT_EESt14default_deleteIS9_EEEEPS6_13470146">AddQueue</dfn>(</td></tr>
<tr><th id="392">392</th><td>    <em>const</em> <a class="type" href="#tensorflow::serving::SharedBatchScheduler::QueueOptions" title='tensorflow::serving::SharedBatchScheduler::QueueOptions' data-ref="tensorflow::serving::SharedBatchScheduler::QueueOptions">QueueOptions</a>&amp; <dfn class="local col0 decl" id="40options" title='options' data-type='const tensorflow::serving::SharedBatchScheduler::QueueOptions &amp;' data-ref="40options">options</dfn>,</td></tr>
<tr><th id="393">393</th><td>    <span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/functional.html#std::function" title='std::function' data-ref="std::function">function</a>&lt;<em>void</em>(<span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/unique_ptr.h.html#std::unique_ptr" title='std::unique_ptr' data-ref="std::unique_ptr">unique_ptr</a>&lt;<a class="type" href="batch_scheduler.h.html#tensorflow::serving::Batch" title='tensorflow::serving::Batch' data-ref="tensorflow::serving::Batch">Batch</a>&lt;TaskType&gt;&gt;)&gt;</td></tr>
<tr><th id="394">394</th><td>        <dfn class="local col1 decl" id="41process_batch_callback" title='process_batch_callback' data-type='std::function&lt;void (std::unique_ptr&lt;Batch&lt;TaskType&gt; &gt;)&gt;' data-ref="41process_batch_callback">process_batch_callback</dfn>,</td></tr>
<tr><th id="395">395</th><td>    <span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/unique_ptr.h.html#std::unique_ptr" title='std::unique_ptr' data-ref="std::unique_ptr">unique_ptr</a>&lt;<a class="type" href="batch_scheduler.h.html#tensorflow::serving::BatchScheduler" title='tensorflow::serving::BatchScheduler' data-ref="tensorflow::serving::BatchScheduler">BatchScheduler</a>&lt;TaskType&gt;&gt;* <dfn class="local col2 decl" id="42queue" title='queue' data-type='std::unique_ptr&lt;BatchScheduler&lt;TaskType&gt; &gt; *' data-ref="42queue">queue</dfn>) {</td></tr>
<tr><th id="396">396</th><td>  <b>if</b> (<a class="local col0 ref" href="#40options" title='options' data-ref="40options">options</a>.max_batch_size &lt;= <var>0</var>) {</td></tr>
<tr><th id="397">397</th><td>    <b>return</b> <span class="namespace">errors::</span>InvalidArgument(<q>"max_batch_size must be positive; was "</q>,</td></tr>
<tr><th id="398">398</th><td>                                   <a class="local col0 ref" href="#40options" title='options' data-ref="40options">options</a>.max_batch_size);</td></tr>
<tr><th id="399">399</th><td>  }</td></tr>
<tr><th id="400">400</th><td>  <b>if</b> (<a class="local col0 ref" href="#40options" title='options' data-ref="40options">options</a>.batch_timeout_micros &lt; <var>0</var>) {</td></tr>
<tr><th id="401">401</th><td>    <b>return</b> <span class="namespace">errors::</span>InvalidArgument(</td></tr>
<tr><th id="402">402</th><td>        <q>"batch_timeout_micros must be non-negative; was "</q>,</td></tr>
<tr><th id="403">403</th><td>        <a class="local col0 ref" href="#40options" title='options' data-ref="40options">options</a>.batch_timeout_micros);</td></tr>
<tr><th id="404">404</th><td>  }</td></tr>
<tr><th id="405">405</th><td>  <b>if</b> (<a class="local col0 ref" href="#40options" title='options' data-ref="40options">options</a>.max_enqueued_batches &lt; <var>0</var>) {</td></tr>
<tr><th id="406">406</th><td>    <b>return</b> <span class="namespace">errors::</span>InvalidArgument(</td></tr>
<tr><th id="407">407</th><td>        <q>"max_enqueued_batches must be non-negative; was "</q>,</td></tr>
<tr><th id="408">408</th><td>        <a class="local col0 ref" href="#40options" title='options' data-ref="40options">options</a>.max_enqueued_batches);</td></tr>
<tr><th id="409">409</th><td>  }</td></tr>
<tr><th id="410">410</th><td></td></tr>
<tr><th id="411">411</th><td>  <em>auto</em> <dfn class="local col3 decl" id="43schedulable_batch_callback" title='schedulable_batch_callback' data-type='auto' data-ref="43schedulable_batch_callback">schedulable_batch_callback</dfn> = [<b>this</b>] {</td></tr>
<tr><th id="412">412</th><td>    <a class="type" href="../../platform/default/mutex.h.html#tensorflow::mutex_lock" title='tensorflow::mutex_lock' data-ref="tensorflow::mutex_lock">mutex_lock</a> <dfn class="local col4 decl" id="44l" title='l' data-type='tensorflow::mutex_lock' data-ref="44l">l</dfn>(<a class="member" href="#tensorflow::serving::SharedBatchScheduler::mu_" title='tensorflow::serving::SharedBatchScheduler::mu_' data-ref="tensorflow::serving::SharedBatchScheduler::mu_">mu_</a>);</td></tr>
<tr><th id="413">413</th><td>    <a class="member" href="#tensorflow::serving::SharedBatchScheduler::schedulable_batch_cv_" title='tensorflow::serving::SharedBatchScheduler::schedulable_batch_cv_' data-ref="tensorflow::serving::SharedBatchScheduler::schedulable_batch_cv_">schedulable_batch_cv_</a>.<a class="ref" href="../../platform/default/mutex.h.html#_ZN10tensorflow18condition_variable10notify_oneEv" title='tensorflow::condition_variable::notify_one' data-ref="_ZN10tensorflow18condition_variable10notify_oneEv">notify_one</a>();</td></tr>
<tr><th id="414">414</th><td>  };</td></tr>
<tr><th id="415">415</th><td>  <em>auto</em> <dfn class="local col5 decl" id="45internal_queue" title='internal_queue' data-type='auto' data-ref="45internal_queue">internal_queue</dfn> =</td></tr>
<tr><th id="416">416</th><td>      <span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/unique_ptr.h.html#std::unique_ptr" title='std::unique_ptr' data-ref="std::unique_ptr">unique_ptr</a>&lt;<span class="namespace">internal::</span><a class="type" href="#tensorflow::serving::internal::Queue" title='tensorflow::serving::internal::Queue' data-ref="tensorflow::serving::internal::Queue">Queue</a>&lt;TaskType&gt;&gt;(<b>new</b> <span class="namespace">internal::</span><a class="type" href="#tensorflow::serving::internal::Queue" title='tensorflow::serving::internal::Queue' data-ref="tensorflow::serving::internal::Queue">Queue</a>&lt;TaskType&gt;(</td></tr>
<tr><th id="417">417</th><td>          <a class="local col0 ref" href="#40options" title='options' data-ref="40options">options</a>, <a class="member" href="#tensorflow::serving::SharedBatchScheduler::options_" title='tensorflow::serving::SharedBatchScheduler::options_' data-ref="tensorflow::serving::SharedBatchScheduler::options_">options_</a>.env, <a class="local col1 ref" href="#41process_batch_callback" title='process_batch_callback' data-ref="41process_batch_callback">process_batch_callback</a>,</td></tr>
<tr><th id="418">418</th><td>          <a class="local col3 ref" href="#43schedulable_batch_callback" title='schedulable_batch_callback' data-ref="43schedulable_batch_callback">schedulable_batch_callback</a>));</td></tr>
<tr><th id="419">419</th><td>  <em>auto</em> <dfn class="local col6 decl" id="46handle" title='handle' data-type='auto' data-ref="46handle">handle</dfn> = <span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/unique_ptr.h.html#std::unique_ptr" title='std::unique_ptr' data-ref="std::unique_ptr">unique_ptr</a>&lt;<a class="type" href="batch_scheduler.h.html#tensorflow::serving::BatchScheduler" title='tensorflow::serving::BatchScheduler' data-ref="tensorflow::serving::BatchScheduler">BatchScheduler</a>&lt;TaskType&gt;&gt;(</td></tr>
<tr><th id="420">420</th><td>      <b>new</b> <span class="namespace">internal::</span><a class="type" href="#tensorflow::serving::internal::QueueHandle" title='tensorflow::serving::internal::QueueHandle' data-ref="tensorflow::serving::internal::QueueHandle">QueueHandle</a>&lt;TaskType&gt;(<b>this</b>-&gt;shared_from_this(),</td></tr>
<tr><th id="421">421</th><td>                                          <a class="local col5 ref" href="#45internal_queue" title='internal_queue' data-ref="45internal_queue">internal_queue</a>.get()));</td></tr>
<tr><th id="422">422</th><td>  {</td></tr>
<tr><th id="423">423</th><td>    <a class="type" href="../../platform/default/mutex.h.html#tensorflow::mutex_lock" title='tensorflow::mutex_lock' data-ref="tensorflow::mutex_lock">mutex_lock</a> <dfn class="local col7 decl" id="47l" title='l' data-type='tensorflow::mutex_lock' data-ref="47l">l</dfn>(<a class="member" href="#tensorflow::serving::SharedBatchScheduler::mu_" title='tensorflow::serving::SharedBatchScheduler::mu_' data-ref="tensorflow::serving::SharedBatchScheduler::mu_">mu_</a>);</td></tr>
<tr><th id="424">424</th><td>    <a class="member" href="#tensorflow::serving::SharedBatchScheduler::queues_" title='tensorflow::serving::SharedBatchScheduler::queues_' data-ref="tensorflow::serving::SharedBatchScheduler::queues_">queues_</a>.push_back(<span class="namespace">std::</span>move(<a class="local col5 ref" href="#45internal_queue" title='internal_queue' data-ref="45internal_queue">internal_queue</a>));</td></tr>
<tr><th id="425">425</th><td>    <b>if</b> (<a class="member" href="#tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_" title='tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_' data-ref="tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_">next_queue_to_schedule_</a> == <a class="member" href="#tensorflow::serving::SharedBatchScheduler::queues_" title='tensorflow::serving::SharedBatchScheduler::queues_' data-ref="tensorflow::serving::SharedBatchScheduler::queues_">queues_</a>.end()) {</td></tr>
<tr><th id="426">426</th><td>      <a class="member" href="#tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_" title='tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_' data-ref="tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_">next_queue_to_schedule_</a> = <a class="member" href="#tensorflow::serving::SharedBatchScheduler::queues_" title='tensorflow::serving::SharedBatchScheduler::queues_' data-ref="tensorflow::serving::SharedBatchScheduler::queues_">queues_</a>.begin();</td></tr>
<tr><th id="427">427</th><td>    }</td></tr>
<tr><th id="428">428</th><td>  }</td></tr>
<tr><th id="429">429</th><td>  *<a class="local col2 ref" href="#42queue" title='queue' data-ref="42queue">queue</a> = <span class="namespace">std::</span>move(<a class="local col6 ref" href="#46handle" title='handle' data-ref="46handle">handle</a>);</td></tr>
<tr><th id="430">430</th><td>  <b>return</b> <a class="type" href="../../lib/core/status.h.html#tensorflow::Status" title='tensorflow::Status' data-ref="tensorflow::Status">Status</a>::<a class="ref" href="../../lib/core/status.h.html#_ZN10tensorflow6Status2OKEv" title='tensorflow::Status::OK' data-ref="_ZN10tensorflow6Status2OKEv">OK</a>();</td></tr>
<tr><th id="431">431</th><td>}</td></tr>
<tr><th id="432">432</th><td></td></tr>
<tr><th id="433">433</th><td><b>template</b> &lt;<b>typename</b> TaskType&gt;</td></tr>
<tr><th id="434">434</th><td><a class="type" href="#tensorflow::serving::SharedBatchScheduler" title='tensorflow::serving::SharedBatchScheduler' data-ref="tensorflow::serving::SharedBatchScheduler">SharedBatchScheduler</a>&lt;TaskType&gt;::<dfn class="decl def" id="_ZN10tensorflow7serving20SharedBatchSchedulerC1ERKNS1_7OptionsE" title='tensorflow::serving::SharedBatchScheduler::SharedBatchScheduler&lt;TaskType&gt;' data-ref="_ZN10tensorflow7serving20SharedBatchSchedulerC1ERKNS1_7OptionsE">SharedBatchScheduler</dfn>(<em>const</em> <a class="type" href="#tensorflow::serving::SharedBatchScheduler::Options" title='tensorflow::serving::SharedBatchScheduler::Options' data-ref="tensorflow::serving::SharedBatchScheduler::Options">Options</a>&amp; <dfn class="local col8 decl" id="48options" title='options' data-type='const tensorflow::serving::SharedBatchScheduler::Options &amp;' data-ref="48options">options</dfn>)</td></tr>
<tr><th id="435">435</th><td>    : <a class="member" href="#tensorflow::serving::SharedBatchScheduler::options_" title='tensorflow::serving::SharedBatchScheduler::options_' data-ref="tensorflow::serving::SharedBatchScheduler::options_">options_</a>(<a class="local col8 ref" href="#48options" title='options' data-ref="48options">options</a>), <a class="member" href="#tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_" title='tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_' data-ref="tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_">next_queue_to_schedule_</a>(<a class="member" href="#tensorflow::serving::SharedBatchScheduler::queues_" title='tensorflow::serving::SharedBatchScheduler::queues_' data-ref="tensorflow::serving::SharedBatchScheduler::queues_">queues_</a>.end()) {</td></tr>
<tr><th id="436">436</th><td>  <i>// Kick off the batch threads.</i></td></tr>
<tr><th id="437">437</th><td>  <a class="type" href="periodic_function.h.html#tensorflow::serving::PeriodicFunction" title='tensorflow::serving::PeriodicFunction' data-ref="tensorflow::serving::PeriodicFunction">PeriodicFunction</a>::<a class="type" href="periodic_function.h.html#tensorflow::serving::PeriodicFunction::Options" title='tensorflow::serving::PeriodicFunction::Options' data-ref="tensorflow::serving::PeriodicFunction::Options">Options</a> <a class="ref fake" href="periodic_function.h.html#_ZN10tensorflow7serving16PeriodicFunction7OptionsC1Ev" title='tensorflow::serving::PeriodicFunction::Options::Options' data-ref="_ZN10tensorflow7serving16PeriodicFunction7OptionsC1Ev"></a><dfn class="local col9 decl" id="49periodic_fn_options" title='periodic_fn_options' data-type='PeriodicFunction::Options' data-ref="49periodic_fn_options">periodic_fn_options</dfn>;</td></tr>
<tr><th id="438">438</th><td>  <a class="local col9 ref" href="#49periodic_fn_options" title='periodic_fn_options' data-ref="49periodic_fn_options">periodic_fn_options</a>.<a class="ref" href="periodic_function.h.html#tensorflow::serving::PeriodicFunction::Options::thread_name_prefix" title='tensorflow::serving::PeriodicFunction::Options::thread_name_prefix' data-ref="tensorflow::serving::PeriodicFunction::Options::thread_name_prefix">thread_name_prefix</a> =</td></tr>
<tr><th id="439">439</th><td>      <span class="namespace">strings::</span>StrCat(<a class="local col8 ref" href="#48options" title='options' data-ref="48options">options</a>.thread_pool_name, <q>"_"</q>);</td></tr>
<tr><th id="440">440</th><td>  <b>for</b> (<em>int</em> <dfn class="local col0 decl" id="50i" title='i' data-type='int' data-ref="50i">i</dfn> = <var>0</var>; <a class="local col0 ref" href="#50i" title='i' data-ref="50i">i</a> &lt; <a class="local col8 ref" href="#48options" title='options' data-ref="48options">options</a>.num_batch_threads; ++<a class="local col0 ref" href="#50i" title='i' data-ref="50i">i</a>) {</td></tr>
<tr><th id="441">441</th><td>    <span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/unique_ptr.h.html#std::unique_ptr" title='std::unique_ptr' data-ref="std::unique_ptr">unique_ptr</a>&lt;<a class="type" href="periodic_function.h.html#tensorflow::serving::PeriodicFunction" title='tensorflow::serving::PeriodicFunction' data-ref="tensorflow::serving::PeriodicFunction">PeriodicFunction</a>&gt; <dfn class="local col1 decl" id="51thread" title='thread' data-type='std::unique_ptr&lt;PeriodicFunction&gt;' data-ref="51thread">thread</dfn><a class="ref" href="../../../../../include/c++/5/bits/unique_ptr.h.html#_ZNSt10unique_ptrC1ENNS_8_PointerE4typeE" title='std::unique_ptr::unique_ptr&lt;_Tp, _Dp&gt;' data-ref="_ZNSt10unique_ptrC1ENNS_8_PointerE4typeE">(</a><b>new</b> <a class="type" href="periodic_function.h.html#tensorflow::serving::PeriodicFunction" title='tensorflow::serving::PeriodicFunction' data-ref="tensorflow::serving::PeriodicFunction">PeriodicFunction</a>(</td></tr>
<tr><th id="442">442</th><td>        [<b>this</b>] { <b>this</b>-&gt;ThreadLogic(); },</td></tr>
<tr><th id="443">443</th><td>        <var>0</var> <i>/* function invocation interval time */</i>, <a class="local col9 ref" href="#49periodic_fn_options" title='periodic_fn_options' data-ref="49periodic_fn_options">periodic_fn_options</a>));</td></tr>
<tr><th id="444">444</th><td>    <a class="member" href="#tensorflow::serving::SharedBatchScheduler::batch_threads_" title='tensorflow::serving::SharedBatchScheduler::batch_threads_' data-ref="tensorflow::serving::SharedBatchScheduler::batch_threads_">batch_threads_</a>.push_back(<span class="namespace">std::</span><a class="ref" href="../../../../../include/c++/5/bits/move.h.html#_ZSt4moveOT_" title='std::move' data-ref="_ZSt4moveOT_">move</a>(<span class='refarg'><a class="local col1 ref" href="#51thread" title='thread' data-ref="51thread">thread</a></span>));</td></tr>
<tr><th id="445">445</th><td>  }</td></tr>
<tr><th id="446">446</th><td>}</td></tr>
<tr><th id="447">447</th><td></td></tr>
<tr><th id="448">448</th><td><b>template</b> &lt;<b>typename</b> TaskType&gt;</td></tr>
<tr><th id="449">449</th><td><em>void</em> <a class="type" href="#tensorflow::serving::SharedBatchScheduler" title='tensorflow::serving::SharedBatchScheduler' data-ref="tensorflow::serving::SharedBatchScheduler">SharedBatchScheduler</a>&lt;TaskType&gt;::<dfn class="decl def" id="_ZN10tensorflow7serving20SharedBatchScheduler11ThreadLogicEv" title='tensorflow::serving::SharedBatchScheduler::ThreadLogic' data-ref="_ZN10tensorflow7serving20SharedBatchScheduler11ThreadLogicEv">ThreadLogic</dfn>() {</td></tr>
<tr><th id="450">450</th><td>  <i>// A batch to process next (or nullptr if no work to do).</i></td></tr>
<tr><th id="451">451</th><td>  <span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/unique_ptr.h.html#std::unique_ptr" title='std::unique_ptr' data-ref="std::unique_ptr">unique_ptr</a>&lt;<a class="type" href="batch_scheduler.h.html#tensorflow::serving::Batch" title='tensorflow::serving::Batch' data-ref="tensorflow::serving::Batch">Batch</a>&lt;TaskType&gt;&gt; <dfn class="local col2 decl" id="52batch_to_process" title='batch_to_process' data-type='std::unique_ptr&lt;Batch&lt;TaskType&gt; &gt;' data-ref="52batch_to_process">batch_to_process</dfn>;</td></tr>
<tr><th id="452">452</th><td>  <i>// The queue with which 'batch_to_process' is associated.</i></td></tr>
<tr><th id="453">453</th><td>  <span class="namespace">internal::</span><a class="type" href="#tensorflow::serving::internal::Queue" title='tensorflow::serving::internal::Queue' data-ref="tensorflow::serving::internal::Queue">Queue</a>&lt;TaskType&gt;* <dfn class="local col3 decl" id="53queue_for_batch" title='queue_for_batch' data-type='internal::Queue&lt;TaskType&gt; *' data-ref="53queue_for_batch">queue_for_batch</dfn> = <b>nullptr</b>;</td></tr>
<tr><th id="454">454</th><td>  {</td></tr>
<tr><th id="455">455</th><td>    <a class="type" href="../../platform/default/mutex.h.html#tensorflow::mutex_lock" title='tensorflow::mutex_lock' data-ref="tensorflow::mutex_lock">mutex_lock</a> <dfn class="local col4 decl" id="54l" title='l' data-type='tensorflow::mutex_lock' data-ref="54l">l</dfn>(<a class="member" href="#tensorflow::serving::SharedBatchScheduler::mu_" title='tensorflow::serving::SharedBatchScheduler::mu_' data-ref="tensorflow::serving::SharedBatchScheduler::mu_">mu_</a>);</td></tr>
<tr><th id="456">456</th><td></td></tr>
<tr><th id="457">457</th><td>    <em>const</em> <em>int</em> <dfn class="local col5 decl" id="55num_queues" title='num_queues' data-type='const int' data-ref="55num_queues">num_queues</dfn> = <a class="member" href="#tensorflow::serving::SharedBatchScheduler::queues_" title='tensorflow::serving::SharedBatchScheduler::queues_' data-ref="tensorflow::serving::SharedBatchScheduler::queues_">queues_</a>.size();</td></tr>
<tr><th id="458">458</th><td>    <b>for</b> (<em>int</em> <dfn class="local col6 decl" id="56num_queues_tried" title='num_queues_tried' data-type='int' data-ref="56num_queues_tried">num_queues_tried</dfn> = <var>0</var>;</td></tr>
<tr><th id="459">459</th><td>         <a class="local col2 ref" href="#52batch_to_process" title='batch_to_process' data-ref="52batch_to_process">batch_to_process</a> == <b>nullptr</b> &amp;&amp; <a class="local col6 ref" href="#56num_queues_tried" title='num_queues_tried' data-ref="56num_queues_tried">num_queues_tried</a> &lt; <a class="local col5 ref" href="#55num_queues" title='num_queues' data-ref="55num_queues">num_queues</a>;</td></tr>
<tr><th id="460">460</th><td>         ++<a class="local col6 ref" href="#56num_queues_tried" title='num_queues_tried' data-ref="56num_queues_tried">num_queues_tried</a>) {</td></tr>
<tr><th id="461">461</th><td>      <a class="macro" href="../../platform/default/logging.h.html#273" title="while (false &amp;&amp; (next_queue_to_schedule_ != queues_.end())) ::tensorflow::internal::LogMessageFatal(&quot;/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/./tensorflow/core/kernels/batching_util/shared_batch_scheduler.h&quot;, 461)" data-ref="_M/DCHECK">DCHECK</a>(<a class="member" href="#tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_" title='tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_' data-ref="tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_">next_queue_to_schedule_</a> != <a class="member" href="#tensorflow::serving::SharedBatchScheduler::queues_" title='tensorflow::serving::SharedBatchScheduler::queues_' data-ref="tensorflow::serving::SharedBatchScheduler::queues_">queues_</a>.end());</td></tr>
<tr><th id="462">462</th><td></td></tr>
<tr><th id="463">463</th><td>      <i>// If a closed queue responds to ScheduleBatch() with nullptr, the queue</i></td></tr>
<tr><th id="464">464</th><td><i>      // will never yield any further batches so we can drop it. To avoid a</i></td></tr>
<tr><th id="465">465</th><td><i>      // race, we take a snapshot of the queue's closedness state *before*</i></td></tr>
<tr><th id="466">466</th><td><i>      // calling ScheduleBatch().</i></td></tr>
<tr><th id="467">467</th><td>      <em>const</em> <em>bool</em> <dfn class="local col7 decl" id="57queue_closed" title='queue_closed' data-type='const bool' data-ref="57queue_closed">queue_closed</dfn> = (*<a class="member" href="#tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_" title='tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_' data-ref="tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_">next_queue_to_schedule_</a>)-&gt;closed();</td></tr>
<tr><th id="468">468</th><td></td></tr>
<tr><th id="469">469</th><td>      <i>// Ask '*next_queue_to_schedule_' if it wants us to process a batch.</i></td></tr>
<tr><th id="470">470</th><td>      <a class="local col2 ref" href="#52batch_to_process" title='batch_to_process' data-ref="52batch_to_process">batch_to_process</a> = (*<a class="member" href="#tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_" title='tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_' data-ref="tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_">next_queue_to_schedule_</a>)-&gt;ScheduleBatch();</td></tr>
<tr><th id="471">471</th><td>      <b>if</b> (<a class="local col2 ref" href="#52batch_to_process" title='batch_to_process' data-ref="52batch_to_process">batch_to_process</a> != <b>nullptr</b>) {</td></tr>
<tr><th id="472">472</th><td>        <a class="local col3 ref" href="#53queue_for_batch" title='queue_for_batch' data-ref="53queue_for_batch">queue_for_batch</a> = <a class="member" href="#tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_" title='tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_' data-ref="tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_">next_queue_to_schedule_</a>-&gt;get();</td></tr>
<tr><th id="473">473</th><td>      }</td></tr>
<tr><th id="474">474</th><td></td></tr>
<tr><th id="475">475</th><td>      <i>// Advance 'next_queue_to_schedule_'.</i></td></tr>
<tr><th id="476">476</th><td>      <b>if</b> (<a class="local col7 ref" href="#57queue_closed" title='queue_closed' data-ref="57queue_closed">queue_closed</a> &amp;&amp; (*<a class="member" href="#tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_" title='tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_' data-ref="tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_">next_queue_to_schedule_</a>)-&gt;IsEmpty() &amp;&amp;</td></tr>
<tr><th id="477">477</th><td>          <a class="local col2 ref" href="#52batch_to_process" title='batch_to_process' data-ref="52batch_to_process">batch_to_process</a> == <b>nullptr</b>) {</td></tr>
<tr><th id="478">478</th><td>        <i>// We've encountered a closed queue with no work to do. Drop it.</i></td></tr>
<tr><th id="479">479</th><td>        <a class="macro" href="../../platform/default/logging.h.html#284" title="while (false &amp;&amp; ((void)(queue_for_batch), (void)(next_queue_to_schedule_-&gt;get()), 0)) ::tensorflow::internal::LogMessageFatal(&quot;/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/./tensorflow/core/kernels/batching_util/shared_batch_scheduler.h&quot;, 479)" data-ref="_M/DCHECK_NE">DCHECK_NE</a>(<a class="local col3 ref" href="#53queue_for_batch" title='queue_for_batch' data-ref="53queue_for_batch">queue_for_batch</a>, <a class="member" href="#tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_" title='tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_' data-ref="tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_">next_queue_to_schedule_</a>-&gt;get());</td></tr>
<tr><th id="480">480</th><td>        <a class="member" href="#tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_" title='tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_' data-ref="tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_">next_queue_to_schedule_</a> = <a class="member" href="#tensorflow::serving::SharedBatchScheduler::queues_" title='tensorflow::serving::SharedBatchScheduler::queues_' data-ref="tensorflow::serving::SharedBatchScheduler::queues_">queues_</a>.erase(<a class="member" href="#tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_" title='tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_' data-ref="tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_">next_queue_to_schedule_</a>);</td></tr>
<tr><th id="481">481</th><td>      } <b>else</b> {</td></tr>
<tr><th id="482">482</th><td>        ++<a class="member" href="#tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_" title='tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_' data-ref="tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_">next_queue_to_schedule_</a>;</td></tr>
<tr><th id="483">483</th><td>      }</td></tr>
<tr><th id="484">484</th><td>      <b>if</b> (<a class="member" href="#tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_" title='tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_' data-ref="tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_">next_queue_to_schedule_</a> == <a class="member" href="#tensorflow::serving::SharedBatchScheduler::queues_" title='tensorflow::serving::SharedBatchScheduler::queues_' data-ref="tensorflow::serving::SharedBatchScheduler::queues_">queues_</a>.end() &amp;&amp; !<a class="member" href="#tensorflow::serving::SharedBatchScheduler::queues_" title='tensorflow::serving::SharedBatchScheduler::queues_' data-ref="tensorflow::serving::SharedBatchScheduler::queues_">queues_</a>.empty()) {</td></tr>
<tr><th id="485">485</th><td>        <i>// We've hit the end. Wrap to the first queue.</i></td></tr>
<tr><th id="486">486</th><td>        <a class="member" href="#tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_" title='tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_' data-ref="tensorflow::serving::SharedBatchScheduler::next_queue_to_schedule_">next_queue_to_schedule_</a> = <a class="member" href="#tensorflow::serving::SharedBatchScheduler::queues_" title='tensorflow::serving::SharedBatchScheduler::queues_' data-ref="tensorflow::serving::SharedBatchScheduler::queues_">queues_</a>.begin();</td></tr>
<tr><th id="487">487</th><td>      }</td></tr>
<tr><th id="488">488</th><td>    }</td></tr>
<tr><th id="489">489</th><td></td></tr>
<tr><th id="490">490</th><td>    <b>if</b> (<a class="local col2 ref" href="#52batch_to_process" title='batch_to_process' data-ref="52batch_to_process">batch_to_process</a> == <b>nullptr</b>) {</td></tr>
<tr><th id="491">491</th><td>      <i>// We couldn't find any work to do. Wait until a new batch becomes</i></td></tr>
<tr><th id="492">492</th><td><i>      // schedulable, or some time has elapsed, before checking again.</i></td></tr>
<tr><th id="493">493</th><td>      <em>const</em> <a class="typedef" href="../../platform/default/integral_types.h.html#tensorflow::int64" title='tensorflow::int64' data-type='long long' data-ref="tensorflow::int64">int64</a> <dfn class="local col8 decl" id="58kTimeoutMillis" title='kTimeoutMillis' data-type='const int64' data-ref="58kTimeoutMillis">kTimeoutMillis</dfn> = <var>1</var>;  <i>// The smallest accepted granule of time.</i></td></tr>
<tr><th id="494">494</th><td>      WaitForMilliseconds(&amp;<a class="local col4 ref" href="#54l" title='l' data-ref="54l">l</a>, &amp;<a class="member" href="#tensorflow::serving::SharedBatchScheduler::schedulable_batch_cv_" title='tensorflow::serving::SharedBatchScheduler::schedulable_batch_cv_' data-ref="tensorflow::serving::SharedBatchScheduler::schedulable_batch_cv_">schedulable_batch_cv_</a>, <a class="local col8 ref" href="#58kTimeoutMillis" title='kTimeoutMillis' data-ref="58kTimeoutMillis">kTimeoutMillis</a>);</td></tr>
<tr><th id="495">495</th><td>      <b>return</b>;</td></tr>
<tr><th id="496">496</th><td>    }</td></tr>
<tr><th id="497">497</th><td>  }</td></tr>
<tr><th id="498">498</th><td></td></tr>
<tr><th id="499">499</th><td>  <a class="local col3 ref" href="#53queue_for_batch" title='queue_for_batch' data-ref="53queue_for_batch">queue_for_batch</a>-&gt;ProcessBatch(<span class="namespace">std::</span>move(<a class="local col2 ref" href="#52batch_to_process" title='batch_to_process' data-ref="52batch_to_process">batch_to_process</a>));</td></tr>
<tr><th id="500">500</th><td>}</td></tr>
<tr><th id="501">501</th><td></td></tr>
<tr><th id="502">502</th><td><b>namespace</b> <span class="namespace">internal</span> {</td></tr>
<tr><th id="503">503</th><td></td></tr>
<tr><th id="504">504</th><td><b>template</b> &lt;<b>typename</b> TaskType&gt;</td></tr>
<tr><th id="505">505</th><td><a class="type" href="#tensorflow::serving::internal::Queue" title='tensorflow::serving::internal::Queue' data-ref="tensorflow::serving::internal::Queue">Queue</a>&lt;TaskType&gt;::<dfn class="decl def" id="_ZN10tensorflow7serving8internal5QueueC1ERKNS0_20SharedBatchSchedulerIT_E12QueueOptionsEPNS_3EnvESt8functionIFvSt10unique_ptrINS0_5BatchIS4_EESt14defa4067582" title='tensorflow::serving::internal::Queue::Queue&lt;TaskType&gt;' data-ref="_ZN10tensorflow7serving8internal5QueueC1ERKNS0_20SharedBatchSchedulerIT_E12QueueOptionsEPNS_3EnvESt8functionIFvSt10unique_ptrINS0_5BatchIS4_EESt14defa4067582">Queue</dfn>(</td></tr>
<tr><th id="506">506</th><td>    <em>const</em> <b>typename</b> <a class="type" href="#tensorflow::serving::SharedBatchScheduler" title='tensorflow::serving::SharedBatchScheduler' data-ref="tensorflow::serving::SharedBatchScheduler">SharedBatchScheduler</a>&lt;TaskType&gt;::QueueOptions&amp; <dfn class="local col9 decl" id="59options" title='options' data-type='const typename SharedBatchScheduler&lt;TaskType&gt;::QueueOptions &amp;' data-ref="59options">options</dfn>,</td></tr>
<tr><th id="507">507</th><td>    <a class="type" href="../../platform/env.h.html#tensorflow::Env" title='tensorflow::Env' data-ref="tensorflow::Env">Env</a>* <dfn class="local col0 decl" id="60env" title='env' data-type='tensorflow::Env *' data-ref="60env">env</dfn>, <a class="typedef" href="#tensorflow::serving::internal::Queue::ProcessBatchCallback" title='tensorflow::serving::internal::Queue::ProcessBatchCallback' data-type='std::function&lt;void (std::unique_ptr&lt;Batch&lt;TaskType&gt; &gt;)&gt;' data-ref="tensorflow::serving::internal::Queue::ProcessBatchCallback">ProcessBatchCallback</a> <dfn class="local col1 decl" id="61process_batch_callback" title='process_batch_callback' data-type='ProcessBatchCallback' data-ref="61process_batch_callback">process_batch_callback</dfn>,</td></tr>
<tr><th id="508">508</th><td>    <a class="typedef" href="#tensorflow::serving::internal::Queue::SchedulableBatchCallback" title='tensorflow::serving::internal::Queue::SchedulableBatchCallback' data-type='std::function&lt;void ()&gt;' data-ref="tensorflow::serving::internal::Queue::SchedulableBatchCallback">SchedulableBatchCallback</a> <dfn class="local col2 decl" id="62schedulable_batch_callback" title='schedulable_batch_callback' data-type='SchedulableBatchCallback' data-ref="62schedulable_batch_callback">schedulable_batch_callback</dfn>)</td></tr>
<tr><th id="509">509</th><td>    : <a class="member" href="#tensorflow::serving::internal::Queue::options_" title='tensorflow::serving::internal::Queue::options_' data-ref="tensorflow::serving::internal::Queue::options_">options_</a>(<a class="local col9 ref" href="#59options" title='options' data-ref="59options">options</a>),</td></tr>
<tr><th id="510">510</th><td>      <a class="member" href="#tensorflow::serving::internal::Queue::env_" title='tensorflow::serving::internal::Queue::env_' data-ref="tensorflow::serving::internal::Queue::env_">env_</a>(<a class="local col0 ref" href="#60env" title='env' data-ref="60env">env</a>),</td></tr>
<tr><th id="511">511</th><td>      <a class="member" href="#tensorflow::serving::internal::Queue::process_batch_callback_" title='tensorflow::serving::internal::Queue::process_batch_callback_' data-ref="tensorflow::serving::internal::Queue::process_batch_callback_">process_batch_callback_</a>(<a class="local col1 ref" href="#61process_batch_callback" title='process_batch_callback' data-ref="61process_batch_callback">process_batch_callback</a>),</td></tr>
<tr><th id="512">512</th><td>      <a class="member" href="#tensorflow::serving::internal::Queue::schedulable_batch_callback_" title='tensorflow::serving::internal::Queue::schedulable_batch_callback_' data-ref="tensorflow::serving::internal::Queue::schedulable_batch_callback_">schedulable_batch_callback_</a><a class="ref" href="../../../../../include/c++/5/functional.html#_ZNSt8functionIFT_DpT0_EEC1ERKS_IS3_E" title='std::function&lt;type-parameter-0-0 (type-parameter-0-1...)&gt;::function&lt;type-parameter-0-0 (type-parameter-0-1...)&gt;' data-ref="_ZNSt8functionIFT_DpT0_EEC1ERKS_IS3_E">(</a><a class="local col2 ref" href="#62schedulable_batch_callback" title='schedulable_batch_callback' data-ref="62schedulable_batch_callback">schedulable_batch_callback</a>) {</td></tr>
<tr><th id="513">513</th><td>  <i>// Create an initial, open batch.</i></td></tr>
<tr><th id="514">514</th><td>  <a class="member" href="#tensorflow::serving::internal::Queue::batches_" title='tensorflow::serving::internal::Queue::batches_' data-ref="tensorflow::serving::internal::Queue::batches_">batches_</a>.emplace_back(<b>new</b> <a class="type" href="batch_scheduler.h.html#tensorflow::serving::Batch" title='tensorflow::serving::Batch' data-ref="tensorflow::serving::Batch">Batch</a>&lt;TaskType&gt;);</td></tr>
<tr><th id="515">515</th><td>}</td></tr>
<tr><th id="516">516</th><td></td></tr>
<tr><th id="517">517</th><td><b>template</b> &lt;<b>typename</b> TaskType&gt;</td></tr>
<tr><th id="518">518</th><td><a class="type" href="#tensorflow::serving::internal::Queue" title='tensorflow::serving::internal::Queue' data-ref="tensorflow::serving::internal::Queue">Queue</a>&lt;TaskType&gt;::<dfn class="decl def" id="_ZN10tensorflow7serving8internal5QueueD1Ev" title='tensorflow::serving::internal::Queue::~Queue&lt;TaskType&gt;' data-ref="_ZN10tensorflow7serving8internal5QueueD1Ev">~Queue</dfn>() {</td></tr>
<tr><th id="519">519</th><td>  <a class="type" href="../../platform/default/mutex.h.html#tensorflow::mutex_lock" title='tensorflow::mutex_lock' data-ref="tensorflow::mutex_lock">mutex_lock</a> <dfn class="local col3 decl" id="63l" title='l' data-type='tensorflow::mutex_lock' data-ref="63l">l</dfn>(<a class="member" href="#tensorflow::serving::internal::Queue::mu_" title='tensorflow::serving::internal::Queue::mu_' data-ref="tensorflow::serving::internal::Queue::mu_">mu_</a>);</td></tr>
<tr><th id="520">520</th><td>  <a class="macro" href="../../platform/default/logging.h.html#273" title="while (false &amp;&amp; (IsEmptyInternal())) ::tensorflow::internal::LogMessageFatal(&quot;/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/./tensorflow/core/kernels/batching_util/shared_batch_scheduler.h&quot;, 520)" data-ref="_M/DCHECK">DCHECK</a>(<a class="member" href="#_ZNK10tensorflow7serving8internal5Queue15IsEmptyInternalEv" title='tensorflow::serving::internal::Queue::IsEmptyInternal' data-ref="_ZNK10tensorflow7serving8internal5Queue15IsEmptyInternalEv">IsEmptyInternal</a>());</td></tr>
<tr><th id="521">521</th><td></td></tr>
<tr><th id="522">522</th><td>  <i>// Close the (empty) open batch, so its destructor doesn't block.</i></td></tr>
<tr><th id="523">523</th><td>  <a class="member" href="#tensorflow::serving::internal::Queue::batches_" title='tensorflow::serving::internal::Queue::batches_' data-ref="tensorflow::serving::internal::Queue::batches_">batches_</a>.back()-&gt;Close();</td></tr>
<tr><th id="524">524</th><td>}</td></tr>
<tr><th id="525">525</th><td></td></tr>
<tr><th id="526">526</th><td><b>template</b> &lt;<b>typename</b> TaskType&gt;</td></tr>
<tr><th id="527">527</th><td><a class="type" href="../../lib/core/status.h.html#tensorflow::Status" title='tensorflow::Status' data-ref="tensorflow::Status">Status</a> <a class="type" href="#tensorflow::serving::internal::Queue" title='tensorflow::serving::internal::Queue' data-ref="tensorflow::serving::internal::Queue">Queue</a>&lt;TaskType&gt;::<dfn class="decl def" id="_ZN10tensorflow7serving8internal5Queue8ScheduleEPSt10unique_ptrIT_St14default_deleteIS4_EE" title='tensorflow::serving::internal::Queue::Schedule' data-ref="_ZN10tensorflow7serving8internal5Queue8ScheduleEPSt10unique_ptrIT_St14default_deleteIS4_EE">Schedule</dfn>(<span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/unique_ptr.h.html#std::unique_ptr" title='std::unique_ptr' data-ref="std::unique_ptr">unique_ptr</a>&lt;TaskType&gt;* <dfn class="local col4 decl" id="64task" title='task' data-type='std::unique_ptr&lt;TaskType&gt; *' data-ref="64task">task</dfn>) {</td></tr>
<tr><th id="528">528</th><td>  <b>if</b> ((*<a class="local col4 ref" href="#64task" title='task' data-ref="64task">task</a>)-&gt;size() &gt; <a class="member" href="#tensorflow::serving::internal::Queue::options_" title='tensorflow::serving::internal::Queue::options_' data-ref="tensorflow::serving::internal::Queue::options_">options_</a>.max_batch_size) {</td></tr>
<tr><th id="529">529</th><td>    <b>return</b> <span class="namespace">errors::</span>InvalidArgument(<q>"Task size "</q>, (*<a class="local col4 ref" href="#64task" title='task' data-ref="64task">task</a>)-&gt;size(),</td></tr>
<tr><th id="530">530</th><td>                                   <q>" is larger than maximum batch size "</q>,</td></tr>
<tr><th id="531">531</th><td>                                   <a class="member" href="#tensorflow::serving::internal::Queue::options_" title='tensorflow::serving::internal::Queue::options_' data-ref="tensorflow::serving::internal::Queue::options_">options_</a>.max_batch_size);</td></tr>
<tr><th id="532">532</th><td>  }</td></tr>
<tr><th id="533">533</th><td></td></tr>
<tr><th id="534">534</th><td>  <em>bool</em> <dfn class="local col5 decl" id="65notify_of_schedulable_batch" title='notify_of_schedulable_batch' data-type='bool' data-ref="65notify_of_schedulable_batch">notify_of_schedulable_batch</dfn> = <b>false</b>;</td></tr>
<tr><th id="535">535</th><td>  {</td></tr>
<tr><th id="536">536</th><td>    <a class="type" href="../../platform/default/mutex.h.html#tensorflow::mutex_lock" title='tensorflow::mutex_lock' data-ref="tensorflow::mutex_lock">mutex_lock</a> <dfn class="local col6 decl" id="66l" title='l' data-type='tensorflow::mutex_lock' data-ref="66l">l</dfn>(<a class="member" href="#tensorflow::serving::internal::Queue::mu_" title='tensorflow::serving::internal::Queue::mu_' data-ref="tensorflow::serving::internal::Queue::mu_">mu_</a>);</td></tr>
<tr><th id="537">537</th><td></td></tr>
<tr><th id="538">538</th><td>    <a class="macro" href="../../platform/default/logging.h.html#273" title="while (false &amp;&amp; (!closed_)) ::tensorflow::internal::LogMessageFatal(&quot;/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/./tensorflow/core/kernels/batching_util/shared_batch_scheduler.h&quot;, 538)" data-ref="_M/DCHECK">DCHECK</a>(!<a class="member" href="#tensorflow::serving::internal::Queue::closed_" title='tensorflow::serving::internal::Queue::closed_' data-ref="tensorflow::serving::internal::Queue::closed_">closed_</a>);</td></tr>
<tr><th id="539">539</th><td></td></tr>
<tr><th id="540">540</th><td>    <b>if</b> (<a class="member" href="#tensorflow::serving::internal::Queue::batches_" title='tensorflow::serving::internal::Queue::batches_' data-ref="tensorflow::serving::internal::Queue::batches_">batches_</a>.back()-&gt;size() + (*<a class="local col4 ref" href="#64task" title='task' data-ref="64task">task</a>)-&gt;size() &gt; <a class="member" href="#tensorflow::serving::internal::Queue::options_" title='tensorflow::serving::internal::Queue::options_' data-ref="tensorflow::serving::internal::Queue::options_">options_</a>.max_batch_size) {</td></tr>
<tr><th id="541">541</th><td>      <b>if</b> (<a class="member" href="#tensorflow::serving::internal::Queue::batches_" title='tensorflow::serving::internal::Queue::batches_' data-ref="tensorflow::serving::internal::Queue::batches_">batches_</a>.size() &gt;= <a class="member" href="#tensorflow::serving::internal::Queue::options_" title='tensorflow::serving::internal::Queue::options_' data-ref="tensorflow::serving::internal::Queue::options_">options_</a>.max_enqueued_batches) {</td></tr>
<tr><th id="542">542</th><td>        <b>return</b> <span class="namespace">errors::</span><a class="ref" href="../../lib/core/errors.h.html#107" title='tensorflow::errors::Unavailable' data-ref="_ZN10tensorflow6errors11UnavailableEDpT_">Unavailable</a>(</td></tr>
<tr><th id="543">543</th><td>            <q>"The batch scheduling queue to which this task was submitted is "</q></td></tr>
<tr><th id="544">544</th><td>            <q>"full"</q>);</td></tr>
<tr><th id="545">545</th><td>      }</td></tr>
<tr><th id="546">546</th><td>      <a class="member" href="#_ZN10tensorflow7serving8internal5Queue13StartNewBatchEv" title='tensorflow::serving::internal::Queue::StartNewBatch' data-ref="_ZN10tensorflow7serving8internal5Queue13StartNewBatchEv">StartNewBatch</a>();</td></tr>
<tr><th id="547">547</th><td>    }</td></tr>
<tr><th id="548">548</th><td>    <b>if</b> (<a class="member" href="#tensorflow::serving::internal::Queue::batches_" title='tensorflow::serving::internal::Queue::batches_' data-ref="tensorflow::serving::internal::Queue::batches_">batches_</a>.back()-&gt;empty()) {</td></tr>
<tr><th id="549">549</th><td>      <a class="member" href="#tensorflow::serving::internal::Queue::open_batch_start_time_micros_" title='tensorflow::serving::internal::Queue::open_batch_start_time_micros_' data-ref="tensorflow::serving::internal::Queue::open_batch_start_time_micros_">open_batch_start_time_micros_</a> = <a class="member" href="#tensorflow::serving::internal::Queue::env_" title='tensorflow::serving::internal::Queue::env_' data-ref="tensorflow::serving::internal::Queue::env_">env_</a>-&gt;<a class="virtual ref" href="../../platform/env.h.html#_ZN10tensorflow3Env9NowMicrosEv" title='tensorflow::Env::NowMicros' data-ref="_ZN10tensorflow3Env9NowMicrosEv">NowMicros</a>();</td></tr>
<tr><th id="550">550</th><td>    }</td></tr>
<tr><th id="551">551</th><td>    <a class="member" href="#tensorflow::serving::internal::Queue::batches_" title='tensorflow::serving::internal::Queue::batches_' data-ref="tensorflow::serving::internal::Queue::batches_">batches_</a>.back()-&gt;AddTask(<span class="namespace">std::</span>move(*<a class="local col4 ref" href="#64task" title='task' data-ref="64task">task</a>));</td></tr>
<tr><th id="552">552</th><td></td></tr>
<tr><th id="553">553</th><td>    <b>if</b> (!<a class="member" href="#tensorflow::serving::internal::Queue::schedulable_batch_" title='tensorflow::serving::internal::Queue::schedulable_batch_' data-ref="tensorflow::serving::internal::Queue::schedulable_batch_">schedulable_batch_</a>) {</td></tr>
<tr><th id="554">554</th><td>      <b>if</b> (<a class="member" href="#tensorflow::serving::internal::Queue::batches_" title='tensorflow::serving::internal::Queue::batches_' data-ref="tensorflow::serving::internal::Queue::batches_">batches_</a>.size() &gt; <var>1</var> || <a class="member" href="#_ZNK10tensorflow7serving8internal5Queue22IsOpenBatchSchedulableEv" title='tensorflow::serving::internal::Queue::IsOpenBatchSchedulable' data-ref="_ZNK10tensorflow7serving8internal5Queue22IsOpenBatchSchedulableEv">IsOpenBatchSchedulable</a>()) {</td></tr>
<tr><th id="555">555</th><td>        <a class="member" href="#tensorflow::serving::internal::Queue::schedulable_batch_" title='tensorflow::serving::internal::Queue::schedulable_batch_' data-ref="tensorflow::serving::internal::Queue::schedulable_batch_">schedulable_batch_</a> = <b>true</b>;</td></tr>
<tr><th id="556">556</th><td>        <a class="local col5 ref" href="#65notify_of_schedulable_batch" title='notify_of_schedulable_batch' data-ref="65notify_of_schedulable_batch">notify_of_schedulable_batch</a> = <b>true</b>;</td></tr>
<tr><th id="557">557</th><td>      }</td></tr>
<tr><th id="558">558</th><td>    }</td></tr>
<tr><th id="559">559</th><td>  }</td></tr>
<tr><th id="560">560</th><td></td></tr>
<tr><th id="561">561</th><td>  <b>if</b> (<a class="local col5 ref" href="#65notify_of_schedulable_batch" title='notify_of_schedulable_batch' data-ref="65notify_of_schedulable_batch">notify_of_schedulable_batch</a>) {</td></tr>
<tr><th id="562">562</th><td>    <a class="member" href="#tensorflow::serving::internal::Queue::schedulable_batch_callback_" title='tensorflow::serving::internal::Queue::schedulable_batch_callback_' data-ref="tensorflow::serving::internal::Queue::schedulable_batch_callback_">schedulable_batch_callback_</a>();</td></tr>
<tr><th id="563">563</th><td>  }</td></tr>
<tr><th id="564">564</th><td></td></tr>
<tr><th id="565">565</th><td>  <b>return</b> <a class="type" href="../../lib/core/status.h.html#tensorflow::Status" title='tensorflow::Status' data-ref="tensorflow::Status">Status</a>::<a class="ref" href="../../lib/core/status.h.html#_ZN10tensorflow6Status2OKEv" title='tensorflow::Status::OK' data-ref="_ZN10tensorflow6Status2OKEv">OK</a>();</td></tr>
<tr><th id="566">566</th><td>}</td></tr>
<tr><th id="567">567</th><td></td></tr>
<tr><th id="568">568</th><td><b>template</b> &lt;<b>typename</b> TaskType&gt;</td></tr>
<tr><th id="569">569</th><td><span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <a class="type" href="#tensorflow::serving::internal::Queue" title='tensorflow::serving::internal::Queue' data-ref="tensorflow::serving::internal::Queue">Queue</a>&lt;TaskType&gt;::<dfn class="decl def" id="_ZNK10tensorflow7serving8internal5Queue16NumEnqueuedTasksEv" title='tensorflow::serving::internal::Queue::NumEnqueuedTasks' data-ref="_ZNK10tensorflow7serving8internal5Queue16NumEnqueuedTasksEv">NumEnqueuedTasks</dfn>() <em>const</em> {</td></tr>
<tr><th id="570">570</th><td>  <a class="type" href="../../platform/default/mutex.h.html#tensorflow::mutex_lock" title='tensorflow::mutex_lock' data-ref="tensorflow::mutex_lock">mutex_lock</a> <dfn class="local col7 decl" id="67l" title='l' data-type='tensorflow::mutex_lock' data-ref="67l">l</dfn>(<a class="member" href="#tensorflow::serving::internal::Queue::mu_" title='tensorflow::serving::internal::Queue::mu_' data-ref="tensorflow::serving::internal::Queue::mu_">mu_</a>);</td></tr>
<tr><th id="571">571</th><td>  <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <dfn class="local col8 decl" id="68num_enqueued_tasks" title='num_enqueued_tasks' data-type='size_t' data-ref="68num_enqueued_tasks">num_enqueued_tasks</dfn> = <var>0</var>;</td></tr>
<tr><th id="572">572</th><td>  <b>for</b> (<em>const</em> <em>auto</em>&amp; <dfn class="local col9 decl" id="69batch" title='batch' data-type='const auto &amp;' data-ref="69batch">batch</dfn> : <a class="member" href="#tensorflow::serving::internal::Queue::batches_" title='tensorflow::serving::internal::Queue::batches_' data-ref="tensorflow::serving::internal::Queue::batches_">batches_</a>) {</td></tr>
<tr><th id="573">573</th><td>    <a class="local col8 ref" href="#68num_enqueued_tasks" title='num_enqueued_tasks' data-ref="68num_enqueued_tasks">num_enqueued_tasks</a> += <a class="local col9 ref" href="#69batch" title='batch' data-ref="69batch">batch</a>-&gt;num_tasks();</td></tr>
<tr><th id="574">574</th><td>  }</td></tr>
<tr><th id="575">575</th><td>  <b>return</b> <a class="local col8 ref" href="#68num_enqueued_tasks" title='num_enqueued_tasks' data-ref="68num_enqueued_tasks">num_enqueued_tasks</a>;</td></tr>
<tr><th id="576">576</th><td>}</td></tr>
<tr><th id="577">577</th><td></td></tr>
<tr><th id="578">578</th><td><b>template</b> &lt;<b>typename</b> TaskType&gt;</td></tr>
<tr><th id="579">579</th><td><span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <a class="type" href="#tensorflow::serving::internal::Queue" title='tensorflow::serving::internal::Queue' data-ref="tensorflow::serving::internal::Queue">Queue</a>&lt;TaskType&gt;::<dfn class="decl def" id="_ZNK10tensorflow7serving8internal5Queue18SchedulingCapacityEv" title='tensorflow::serving::internal::Queue::SchedulingCapacity' data-ref="_ZNK10tensorflow7serving8internal5Queue18SchedulingCapacityEv">SchedulingCapacity</dfn>() <em>const</em> {</td></tr>
<tr><th id="580">580</th><td>  <a class="type" href="../../platform/default/mutex.h.html#tensorflow::mutex_lock" title='tensorflow::mutex_lock' data-ref="tensorflow::mutex_lock">mutex_lock</a> <dfn class="local col0 decl" id="70l" title='l' data-type='tensorflow::mutex_lock' data-ref="70l">l</dfn>(<a class="member" href="#tensorflow::serving::internal::Queue::mu_" title='tensorflow::serving::internal::Queue::mu_' data-ref="tensorflow::serving::internal::Queue::mu_">mu_</a>);</td></tr>
<tr><th id="581">581</th><td>  <em>const</em> <em>int</em> <dfn class="local col1 decl" id="71num_new_batches_schedulable" title='num_new_batches_schedulable' data-type='const int' data-ref="71num_new_batches_schedulable">num_new_batches_schedulable</dfn> =</td></tr>
<tr><th id="582">582</th><td>      <a class="member" href="#tensorflow::serving::internal::Queue::options_" title='tensorflow::serving::internal::Queue::options_' data-ref="tensorflow::serving::internal::Queue::options_">options_</a>.max_enqueued_batches - <a class="member" href="#tensorflow::serving::internal::Queue::batches_" title='tensorflow::serving::internal::Queue::batches_' data-ref="tensorflow::serving::internal::Queue::batches_">batches_</a>.size();</td></tr>
<tr><th id="583">583</th><td>  <em>const</em> <em>int</em> <dfn class="local col2 decl" id="72open_batch_capacity" title='open_batch_capacity' data-type='const int' data-ref="72open_batch_capacity">open_batch_capacity</dfn> =</td></tr>
<tr><th id="584">584</th><td>      <a class="member" href="#tensorflow::serving::internal::Queue::options_" title='tensorflow::serving::internal::Queue::options_' data-ref="tensorflow::serving::internal::Queue::options_">options_</a>.max_batch_size - <a class="member" href="#tensorflow::serving::internal::Queue::batches_" title='tensorflow::serving::internal::Queue::batches_' data-ref="tensorflow::serving::internal::Queue::batches_">batches_</a>.back()-&gt;size();</td></tr>
<tr><th id="585">585</th><td>  <b>return</b> (<a class="local col1 ref" href="#71num_new_batches_schedulable" title='num_new_batches_schedulable' data-ref="71num_new_batches_schedulable">num_new_batches_schedulable</a> * <a class="member" href="#tensorflow::serving::internal::Queue::options_" title='tensorflow::serving::internal::Queue::options_' data-ref="tensorflow::serving::internal::Queue::options_">options_</a>.max_batch_size) +</td></tr>
<tr><th id="586">586</th><td>         <a class="local col2 ref" href="#72open_batch_capacity" title='open_batch_capacity' data-ref="72open_batch_capacity">open_batch_capacity</a>;</td></tr>
<tr><th id="587">587</th><td>}</td></tr>
<tr><th id="588">588</th><td></td></tr>
<tr><th id="589">589</th><td><b>template</b> &lt;<b>typename</b> TaskType&gt;</td></tr>
<tr><th id="590">590</th><td><span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/unique_ptr.h.html#std::unique_ptr" title='std::unique_ptr' data-ref="std::unique_ptr">unique_ptr</a>&lt;<a class="type" href="batch_scheduler.h.html#tensorflow::serving::Batch" title='tensorflow::serving::Batch' data-ref="tensorflow::serving::Batch">Batch</a>&lt;TaskType&gt;&gt; <a class="type" href="#tensorflow::serving::internal::Queue" title='tensorflow::serving::internal::Queue' data-ref="tensorflow::serving::internal::Queue">Queue</a>&lt;TaskType&gt;::<dfn class="decl def" id="_ZN10tensorflow7serving8internal5Queue13ScheduleBatchEv" title='tensorflow::serving::internal::Queue::ScheduleBatch' data-ref="_ZN10tensorflow7serving8internal5Queue13ScheduleBatchEv">ScheduleBatch</dfn>() {</td></tr>
<tr><th id="591">591</th><td>  <i>// The batch to schedule, which we may populate below. (If left as nullptr,</i></td></tr>
<tr><th id="592">592</th><td><i>  // that means we are electing not to schedule a batch at this time.)</i></td></tr>
<tr><th id="593">593</th><td>  <span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/unique_ptr.h.html#std::unique_ptr" title='std::unique_ptr' data-ref="std::unique_ptr">unique_ptr</a>&lt;<a class="type" href="batch_scheduler.h.html#tensorflow::serving::Batch" title='tensorflow::serving::Batch' data-ref="tensorflow::serving::Batch">Batch</a>&lt;TaskType&gt;&gt; <dfn class="local col3 decl" id="73batch_to_schedule" title='batch_to_schedule' data-type='std::unique_ptr&lt;Batch&lt;TaskType&gt; &gt;' data-ref="73batch_to_schedule">batch_to_schedule</dfn>;</td></tr>
<tr><th id="594">594</th><td></td></tr>
<tr><th id="595">595</th><td>  {</td></tr>
<tr><th id="596">596</th><td>    <a class="type" href="../../platform/default/mutex.h.html#tensorflow::mutex_lock" title='tensorflow::mutex_lock' data-ref="tensorflow::mutex_lock">mutex_lock</a> <dfn class="local col4 decl" id="74l" title='l' data-type='tensorflow::mutex_lock' data-ref="74l">l</dfn>(<a class="member" href="#tensorflow::serving::internal::Queue::mu_" title='tensorflow::serving::internal::Queue::mu_' data-ref="tensorflow::serving::internal::Queue::mu_">mu_</a>);</td></tr>
<tr><th id="597">597</th><td></td></tr>
<tr><th id="598">598</th><td>    <i>// Consider closing the open batch at this time, to schedule it.</i></td></tr>
<tr><th id="599">599</th><td>    <b>if</b> (<a class="member" href="#tensorflow::serving::internal::Queue::batches_" title='tensorflow::serving::internal::Queue::batches_' data-ref="tensorflow::serving::internal::Queue::batches_">batches_</a>.size() == <var>1</var> &amp;&amp; <a class="member" href="#_ZNK10tensorflow7serving8internal5Queue22IsOpenBatchSchedulableEv" title='tensorflow::serving::internal::Queue::IsOpenBatchSchedulable' data-ref="_ZNK10tensorflow7serving8internal5Queue22IsOpenBatchSchedulableEv">IsOpenBatchSchedulable</a>()) {</td></tr>
<tr><th id="600">600</th><td>      <a class="member" href="#_ZN10tensorflow7serving8internal5Queue13StartNewBatchEv" title='tensorflow::serving::internal::Queue::StartNewBatch' data-ref="_ZN10tensorflow7serving8internal5Queue13StartNewBatchEv">StartNewBatch</a>();</td></tr>
<tr><th id="601">601</th><td>    }</td></tr>
<tr><th id="602">602</th><td></td></tr>
<tr><th id="603">603</th><td>    <b>if</b> (<a class="member" href="#tensorflow::serving::internal::Queue::batches_" title='tensorflow::serving::internal::Queue::batches_' data-ref="tensorflow::serving::internal::Queue::batches_">batches_</a>.size() &gt;= <var>2</var>) {</td></tr>
<tr><th id="604">604</th><td>      <i>// There is at least one closed batch that is ready to be scheduled.</i></td></tr>
<tr><th id="605">605</th><td>      ++<a class="member" href="#tensorflow::serving::internal::Queue::num_batches_being_processed_" title='tensorflow::serving::internal::Queue::num_batches_being_processed_' data-ref="tensorflow::serving::internal::Queue::num_batches_being_processed_">num_batches_being_processed_</a>;</td></tr>
<tr><th id="606">606</th><td>      <a class="local col3 ref" href="#73batch_to_schedule" title='batch_to_schedule' data-ref="73batch_to_schedule">batch_to_schedule</a> = <span class="namespace">std::</span>move(<a class="member" href="#tensorflow::serving::internal::Queue::batches_" title='tensorflow::serving::internal::Queue::batches_' data-ref="tensorflow::serving::internal::Queue::batches_">batches_</a>.front());</td></tr>
<tr><th id="607">607</th><td>      <a class="member" href="#tensorflow::serving::internal::Queue::batches_" title='tensorflow::serving::internal::Queue::batches_' data-ref="tensorflow::serving::internal::Queue::batches_">batches_</a>.pop_front();</td></tr>
<tr><th id="608">608</th><td>    } <b>else</b> {</td></tr>
<tr><th id="609">609</th><td>      <a class="member" href="#tensorflow::serving::internal::Queue::schedulable_batch_" title='tensorflow::serving::internal::Queue::schedulable_batch_' data-ref="tensorflow::serving::internal::Queue::schedulable_batch_">schedulable_batch_</a> = <b>false</b>;</td></tr>
<tr><th id="610">610</th><td>    }</td></tr>
<tr><th id="611">611</th><td>  }</td></tr>
<tr><th id="612">612</th><td></td></tr>
<tr><th id="613">613</th><td>  <b>return</b> <a class="local col3 ref" href="#73batch_to_schedule" title='batch_to_schedule' data-ref="73batch_to_schedule">batch_to_schedule</a>;</td></tr>
<tr><th id="614">614</th><td>}</td></tr>
<tr><th id="615">615</th><td></td></tr>
<tr><th id="616">616</th><td><b>template</b> &lt;<b>typename</b> TaskType&gt;</td></tr>
<tr><th id="617">617</th><td><em>void</em> <a class="type" href="#tensorflow::serving::internal::Queue" title='tensorflow::serving::internal::Queue' data-ref="tensorflow::serving::internal::Queue">Queue</a>&lt;TaskType&gt;::<dfn class="decl def" id="_ZN10tensorflow7serving8internal5Queue12ProcessBatchESt10unique_ptrINS0_5BatchIT_EESt14default_deleteIS6_EE" title='tensorflow::serving::internal::Queue::ProcessBatch' data-ref="_ZN10tensorflow7serving8internal5Queue12ProcessBatchESt10unique_ptrINS0_5BatchIT_EESt14default_deleteIS6_EE">ProcessBatch</dfn>(<span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/unique_ptr.h.html#std::unique_ptr" title='std::unique_ptr' data-ref="std::unique_ptr">unique_ptr</a>&lt;<a class="type" href="batch_scheduler.h.html#tensorflow::serving::Batch" title='tensorflow::serving::Batch' data-ref="tensorflow::serving::Batch">Batch</a>&lt;TaskType&gt;&gt; <dfn class="local col5 decl" id="75batch" title='batch' data-type='std::unique_ptr&lt;Batch&lt;TaskType&gt; &gt;' data-ref="75batch">batch</dfn>) {</td></tr>
<tr><th id="618">618</th><td>  <a class="member" href="#tensorflow::serving::internal::Queue::process_batch_callback_" title='tensorflow::serving::internal::Queue::process_batch_callback_' data-ref="tensorflow::serving::internal::Queue::process_batch_callback_">process_batch_callback_</a>(<span class="namespace">std::</span>move(<a class="local col5 ref" href="#75batch" title='batch' data-ref="75batch">batch</a>));</td></tr>
<tr><th id="619">619</th><td></td></tr>
<tr><th id="620">620</th><td>  {</td></tr>
<tr><th id="621">621</th><td>    <a class="type" href="../../platform/default/mutex.h.html#tensorflow::mutex_lock" title='tensorflow::mutex_lock' data-ref="tensorflow::mutex_lock">mutex_lock</a> <dfn class="local col6 decl" id="76l" title='l' data-type='tensorflow::mutex_lock' data-ref="76l">l</dfn>(<a class="member" href="#tensorflow::serving::internal::Queue::mu_" title='tensorflow::serving::internal::Queue::mu_' data-ref="tensorflow::serving::internal::Queue::mu_">mu_</a>);</td></tr>
<tr><th id="622">622</th><td>    --<a class="member" href="#tensorflow::serving::internal::Queue::num_batches_being_processed_" title='tensorflow::serving::internal::Queue::num_batches_being_processed_' data-ref="tensorflow::serving::internal::Queue::num_batches_being_processed_">num_batches_being_processed_</a>;</td></tr>
<tr><th id="623">623</th><td>    <b>if</b> (<a class="member" href="#tensorflow::serving::internal::Queue::empty_notification_" title='tensorflow::serving::internal::Queue::empty_notification_' data-ref="tensorflow::serving::internal::Queue::empty_notification_">empty_notification_</a> != <b>nullptr</b> &amp;&amp; <a class="member" href="#_ZNK10tensorflow7serving8internal5Queue15IsEmptyInternalEv" title='tensorflow::serving::internal::Queue::IsEmptyInternal' data-ref="_ZNK10tensorflow7serving8internal5Queue15IsEmptyInternalEv">IsEmptyInternal</a>()) {</td></tr>
<tr><th id="624">624</th><td>      <a class="member" href="#tensorflow::serving::internal::Queue::empty_notification_" title='tensorflow::serving::internal::Queue::empty_notification_' data-ref="tensorflow::serving::internal::Queue::empty_notification_">empty_notification_</a>-&gt;<a class="ref" href="../../platform/default/notification.h.html#_ZN10tensorflow12Notification6NotifyEv" title='tensorflow::Notification::Notify' data-ref="_ZN10tensorflow12Notification6NotifyEv">Notify</a>();</td></tr>
<tr><th id="625">625</th><td>    }</td></tr>
<tr><th id="626">626</th><td>  }</td></tr>
<tr><th id="627">627</th><td>}</td></tr>
<tr><th id="628">628</th><td></td></tr>
<tr><th id="629">629</th><td><b>template</b> &lt;<b>typename</b> TaskType&gt;</td></tr>
<tr><th id="630">630</th><td><em>bool</em> <a class="type" href="#tensorflow::serving::internal::Queue" title='tensorflow::serving::internal::Queue' data-ref="tensorflow::serving::internal::Queue">Queue</a>&lt;TaskType&gt;::<dfn class="decl def" id="_ZNK10tensorflow7serving8internal5Queue7IsEmptyEv" title='tensorflow::serving::internal::Queue::IsEmpty' data-ref="_ZNK10tensorflow7serving8internal5Queue7IsEmptyEv">IsEmpty</dfn>() <em>const</em> {</td></tr>
<tr><th id="631">631</th><td>  <a class="type" href="../../platform/default/mutex.h.html#tensorflow::mutex_lock" title='tensorflow::mutex_lock' data-ref="tensorflow::mutex_lock">mutex_lock</a> <dfn class="local col7 decl" id="77l" title='l' data-type='tensorflow::mutex_lock' data-ref="77l">l</dfn>(<a class="member" href="#tensorflow::serving::internal::Queue::mu_" title='tensorflow::serving::internal::Queue::mu_' data-ref="tensorflow::serving::internal::Queue::mu_">mu_</a>);</td></tr>
<tr><th id="632">632</th><td>  <b>return</b> <a class="member" href="#_ZNK10tensorflow7serving8internal5Queue15IsEmptyInternalEv" title='tensorflow::serving::internal::Queue::IsEmptyInternal' data-ref="_ZNK10tensorflow7serving8internal5Queue15IsEmptyInternalEv">IsEmptyInternal</a>();</td></tr>
<tr><th id="633">633</th><td>}</td></tr>
<tr><th id="634">634</th><td></td></tr>
<tr><th id="635">635</th><td><b>template</b> &lt;<b>typename</b> TaskType&gt;</td></tr>
<tr><th id="636">636</th><td><em>void</em> <a class="type" href="#tensorflow::serving::internal::Queue" title='tensorflow::serving::internal::Queue' data-ref="tensorflow::serving::internal::Queue">Queue</a>&lt;TaskType&gt;::<dfn class="decl def" id="_ZN10tensorflow7serving8internal5Queue22CloseAndWaitUntilEmptyEv" title='tensorflow::serving::internal::Queue::CloseAndWaitUntilEmpty' data-ref="_ZN10tensorflow7serving8internal5Queue22CloseAndWaitUntilEmptyEv">CloseAndWaitUntilEmpty</dfn>() {</td></tr>
<tr><th id="637">637</th><td>  <a class="type" href="../../platform/default/notification.h.html#tensorflow::Notification" title='tensorflow::Notification' data-ref="tensorflow::Notification">Notification</a> <a class="ref fake" href="../../platform/default/notification.h.html#_ZN10tensorflow12NotificationC1Ev" title='tensorflow::Notification::Notification' data-ref="_ZN10tensorflow12NotificationC1Ev"></a><dfn class="local col8 decl" id="78empty" title='empty' data-type='tensorflow::Notification' data-ref="78empty">empty</dfn>;</td></tr>
<tr><th id="638">638</th><td>  {</td></tr>
<tr><th id="639">639</th><td>    <a class="type" href="../../platform/default/mutex.h.html#tensorflow::mutex_lock" title='tensorflow::mutex_lock' data-ref="tensorflow::mutex_lock">mutex_lock</a> <dfn class="local col9 decl" id="79l" title='l' data-type='tensorflow::mutex_lock' data-ref="79l">l</dfn>(<a class="member" href="#tensorflow::serving::internal::Queue::mu_" title='tensorflow::serving::internal::Queue::mu_' data-ref="tensorflow::serving::internal::Queue::mu_">mu_</a>);</td></tr>
<tr><th id="640">640</th><td>    <a class="member" href="#tensorflow::serving::internal::Queue::closed_" title='tensorflow::serving::internal::Queue::closed_' data-ref="tensorflow::serving::internal::Queue::closed_">closed_</a> = <b>true</b>;</td></tr>
<tr><th id="641">641</th><td>    <b>if</b> (<a class="member" href="#_ZNK10tensorflow7serving8internal5Queue15IsEmptyInternalEv" title='tensorflow::serving::internal::Queue::IsEmptyInternal' data-ref="_ZNK10tensorflow7serving8internal5Queue15IsEmptyInternalEv">IsEmptyInternal</a>()) {</td></tr>
<tr><th id="642">642</th><td>      <a class="local col8 ref" href="#78empty" title='empty' data-ref="78empty">empty</a>.<a class="ref" href="../../platform/default/notification.h.html#_ZN10tensorflow12Notification6NotifyEv" title='tensorflow::Notification::Notify' data-ref="_ZN10tensorflow12Notification6NotifyEv">Notify</a>();</td></tr>
<tr><th id="643">643</th><td>    } <b>else</b> {</td></tr>
<tr><th id="644">644</th><td>      <i>// Arrange for ProcessBatch() to notify when the queue becomes empty.</i></td></tr>
<tr><th id="645">645</th><td>      <a class="member" href="#tensorflow::serving::internal::Queue::empty_notification_" title='tensorflow::serving::internal::Queue::empty_notification_' data-ref="tensorflow::serving::internal::Queue::empty_notification_">empty_notification_</a> = &amp;<a class="local col8 ref" href="#78empty" title='empty' data-ref="78empty">empty</a>;</td></tr>
<tr><th id="646">646</th><td>    }</td></tr>
<tr><th id="647">647</th><td>  }</td></tr>
<tr><th id="648">648</th><td>  <a class="local col8 ref" href="#78empty" title='empty' data-ref="78empty">empty</a>.<a class="ref" href="../../platform/default/notification.h.html#_ZN10tensorflow12Notification19WaitForNotificationEv" title='tensorflow::Notification::WaitForNotification' data-ref="_ZN10tensorflow12Notification19WaitForNotificationEv">WaitForNotification</a>();</td></tr>
<tr><th id="649">649</th><td>}</td></tr>
<tr><th id="650">650</th><td></td></tr>
<tr><th id="651">651</th><td><b>template</b> &lt;<b>typename</b> TaskType&gt;</td></tr>
<tr><th id="652">652</th><td><em>bool</em> <a class="type" href="#tensorflow::serving::internal::Queue" title='tensorflow::serving::internal::Queue' data-ref="tensorflow::serving::internal::Queue">Queue</a>&lt;TaskType&gt;::<dfn class="decl def" id="_ZNK10tensorflow7serving8internal5Queue15IsEmptyInternalEv" title='tensorflow::serving::internal::Queue::IsEmptyInternal' data-ref="_ZNK10tensorflow7serving8internal5Queue15IsEmptyInternalEv">IsEmptyInternal</dfn>() <em>const</em> {</td></tr>
<tr><th id="653">653</th><td>  <b>return</b> <a class="member" href="#tensorflow::serving::internal::Queue::num_batches_being_processed_" title='tensorflow::serving::internal::Queue::num_batches_being_processed_' data-ref="tensorflow::serving::internal::Queue::num_batches_being_processed_">num_batches_being_processed_</a> == <var>0</var> &amp;&amp; <a class="member" href="#tensorflow::serving::internal::Queue::batches_" title='tensorflow::serving::internal::Queue::batches_' data-ref="tensorflow::serving::internal::Queue::batches_">batches_</a>.size() == <var>1</var> &amp;&amp;</td></tr>
<tr><th id="654">654</th><td>         <a class="member" href="#tensorflow::serving::internal::Queue::batches_" title='tensorflow::serving::internal::Queue::batches_' data-ref="tensorflow::serving::internal::Queue::batches_">batches_</a>.back()-&gt;empty();</td></tr>
<tr><th id="655">655</th><td>}</td></tr>
<tr><th id="656">656</th><td></td></tr>
<tr><th id="657">657</th><td><b>template</b> &lt;<b>typename</b> TaskType&gt;</td></tr>
<tr><th id="658">658</th><td><em>void</em> <a class="type" href="#tensorflow::serving::internal::Queue" title='tensorflow::serving::internal::Queue' data-ref="tensorflow::serving::internal::Queue">Queue</a>&lt;TaskType&gt;::<dfn class="decl def" id="_ZN10tensorflow7serving8internal5Queue13StartNewBatchEv" title='tensorflow::serving::internal::Queue::StartNewBatch' data-ref="_ZN10tensorflow7serving8internal5Queue13StartNewBatchEv">StartNewBatch</dfn>() {</td></tr>
<tr><th id="659">659</th><td>  <a class="member" href="#tensorflow::serving::internal::Queue::batches_" title='tensorflow::serving::internal::Queue::batches_' data-ref="tensorflow::serving::internal::Queue::batches_">batches_</a>.back()-&gt;Close();</td></tr>
<tr><th id="660">660</th><td>  <a class="member" href="#tensorflow::serving::internal::Queue::batches_" title='tensorflow::serving::internal::Queue::batches_' data-ref="tensorflow::serving::internal::Queue::batches_">batches_</a>.emplace_back(<b>new</b> <a class="type" href="batch_scheduler.h.html#tensorflow::serving::Batch" title='tensorflow::serving::Batch' data-ref="tensorflow::serving::Batch">Batch</a>&lt;TaskType&gt;);</td></tr>
<tr><th id="661">661</th><td>}</td></tr>
<tr><th id="662">662</th><td></td></tr>
<tr><th id="663">663</th><td><b>template</b> &lt;<b>typename</b> TaskType&gt;</td></tr>
<tr><th id="664">664</th><td><em>bool</em> <a class="type" href="#tensorflow::serving::internal::Queue" title='tensorflow::serving::internal::Queue' data-ref="tensorflow::serving::internal::Queue">Queue</a>&lt;TaskType&gt;::<dfn class="decl def" id="_ZNK10tensorflow7serving8internal5Queue22IsOpenBatchSchedulableEv" title='tensorflow::serving::internal::Queue::IsOpenBatchSchedulable' data-ref="_ZNK10tensorflow7serving8internal5Queue22IsOpenBatchSchedulableEv">IsOpenBatchSchedulable</dfn>() <em>const</em> {</td></tr>
<tr><th id="665">665</th><td>  <a class="type" href="batch_scheduler.h.html#tensorflow::serving::Batch" title='tensorflow::serving::Batch' data-ref="tensorflow::serving::Batch">Batch</a>&lt;TaskType&gt;* <dfn class="local col0 decl" id="80open_batch" title='open_batch' data-type='Batch&lt;TaskType&gt; *' data-ref="80open_batch">open_batch</dfn> = <a class="member" href="#tensorflow::serving::internal::Queue::batches_" title='tensorflow::serving::internal::Queue::batches_' data-ref="tensorflow::serving::internal::Queue::batches_">batches_</a>.back().get();</td></tr>
<tr><th id="666">666</th><td>  <b>if</b> (<a class="local col0 ref" href="#80open_batch" title='open_batch' data-ref="80open_batch">open_batch</a>-&gt;empty()) {</td></tr>
<tr><th id="667">667</th><td>    <b>return</b> <b>false</b>;</td></tr>
<tr><th id="668">668</th><td>  }</td></tr>
<tr><th id="669">669</th><td>  <b>return</b> <a class="member" href="#tensorflow::serving::internal::Queue::closed_" title='tensorflow::serving::internal::Queue::closed_' data-ref="tensorflow::serving::internal::Queue::closed_">closed_</a> || <a class="local col0 ref" href="#80open_batch" title='open_batch' data-ref="80open_batch">open_batch</a>-&gt;size() &gt;= <a class="member" href="#tensorflow::serving::internal::Queue::options_" title='tensorflow::serving::internal::Queue::options_' data-ref="tensorflow::serving::internal::Queue::options_">options_</a>.max_batch_size ||</td></tr>
<tr><th id="670">670</th><td>         <a class="member" href="#tensorflow::serving::internal::Queue::env_" title='tensorflow::serving::internal::Queue::env_' data-ref="tensorflow::serving::internal::Queue::env_">env_</a>-&gt;<a class="virtual ref" href="../../platform/env.h.html#_ZN10tensorflow3Env9NowMicrosEv" title='tensorflow::Env::NowMicros' data-ref="_ZN10tensorflow3Env9NowMicrosEv">NowMicros</a>() &gt;=</td></tr>
<tr><th id="671">671</th><td>             <a class="member" href="#tensorflow::serving::internal::Queue::open_batch_start_time_micros_" title='tensorflow::serving::internal::Queue::open_batch_start_time_micros_' data-ref="tensorflow::serving::internal::Queue::open_batch_start_time_micros_">open_batch_start_time_micros_</a> + <a class="member" href="#tensorflow::serving::internal::Queue::options_" title='tensorflow::serving::internal::Queue::options_' data-ref="tensorflow::serving::internal::Queue::options_">options_</a>.batch_timeout_micros;</td></tr>
<tr><th id="672">672</th><td>}</td></tr>
<tr><th id="673">673</th><td></td></tr>
<tr><th id="674">674</th><td><b>template</b> &lt;<b>typename</b> TaskType&gt;</td></tr>
<tr><th id="675">675</th><td><a class="type" href="#tensorflow::serving::internal::QueueHandle" title='tensorflow::serving::internal::QueueHandle' data-ref="tensorflow::serving::internal::QueueHandle">QueueHandle</a>&lt;TaskType&gt;::<dfn class="decl def" id="_ZN10tensorflow7serving8internal11QueueHandleC1ESt10shared_ptrINS0_20SharedBatchSchedulerIT_EEEPNS1_5QueueIS5_EE" title='tensorflow::serving::internal::QueueHandle::QueueHandle&lt;TaskType&gt;' data-ref="_ZN10tensorflow7serving8internal11QueueHandleC1ESt10shared_ptrINS0_20SharedBatchSchedulerIT_EEEPNS1_5QueueIS5_EE">QueueHandle</dfn>(</td></tr>
<tr><th id="676">676</th><td>    <span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/shared_ptr_base.h.html#std::shared_ptr" title='std::shared_ptr' data-ref="std::shared_ptr">shared_ptr</a>&lt;<a class="type" href="#tensorflow::serving::SharedBatchScheduler" title='tensorflow::serving::SharedBatchScheduler' data-ref="tensorflow::serving::SharedBatchScheduler">SharedBatchScheduler</a>&lt;TaskType&gt;&gt; <dfn class="local col1 decl" id="81scheduler" title='scheduler' data-type='std::shared_ptr&lt;SharedBatchScheduler&lt;TaskType&gt; &gt;' data-ref="81scheduler">scheduler</dfn>,</td></tr>
<tr><th id="677">677</th><td>    <a class="type" href="#tensorflow::serving::internal::Queue" title='tensorflow::serving::internal::Queue' data-ref="tensorflow::serving::internal::Queue">Queue</a>&lt;TaskType&gt;* <dfn class="local col2 decl" id="82queue" title='queue' data-type='Queue&lt;TaskType&gt; *' data-ref="82queue">queue</dfn>)</td></tr>
<tr><th id="678">678</th><td>    : <a class="member" href="#tensorflow::serving::internal::QueueHandle::scheduler_" title='tensorflow::serving::internal::QueueHandle::scheduler_' data-ref="tensorflow::serving::internal::QueueHandle::scheduler_">scheduler_</a>(<a class="local col1 ref" href="#81scheduler" title='scheduler' data-ref="81scheduler">scheduler</a>), <a class="member" href="#tensorflow::serving::internal::QueueHandle::queue_" title='tensorflow::serving::internal::QueueHandle::queue_' data-ref="tensorflow::serving::internal::QueueHandle::queue_">queue_</a>(<a class="local col2 ref" href="#82queue" title='queue' data-ref="82queue">queue</a>) {}</td></tr>
<tr><th id="679">679</th><td></td></tr>
<tr><th id="680">680</th><td><b>template</b> &lt;<b>typename</b> TaskType&gt;</td></tr>
<tr><th id="681">681</th><td><a class="type" href="#tensorflow::serving::internal::QueueHandle" title='tensorflow::serving::internal::QueueHandle' data-ref="tensorflow::serving::internal::QueueHandle">QueueHandle</a>&lt;TaskType&gt;::<dfn class="decl def" id="_ZN10tensorflow7serving8internal11QueueHandleD1Ev" title='tensorflow::serving::internal::QueueHandle::~QueueHandle&lt;TaskType&gt;' data-ref="_ZN10tensorflow7serving8internal11QueueHandleD1Ev">~QueueHandle</dfn>() {</td></tr>
<tr><th id="682">682</th><td>  <a class="member" href="#tensorflow::serving::internal::QueueHandle::queue_" title='tensorflow::serving::internal::QueueHandle::queue_' data-ref="tensorflow::serving::internal::QueueHandle::queue_">queue_</a>-&gt;CloseAndWaitUntilEmpty();</td></tr>
<tr><th id="683">683</th><td>}</td></tr>
<tr><th id="684">684</th><td></td></tr>
<tr><th id="685">685</th><td><b>template</b> &lt;<b>typename</b> TaskType&gt;</td></tr>
<tr><th id="686">686</th><td><a class="type" href="../../lib/core/status.h.html#tensorflow::Status" title='tensorflow::Status' data-ref="tensorflow::Status">Status</a> <a class="type" href="#tensorflow::serving::internal::QueueHandle" title='tensorflow::serving::internal::QueueHandle' data-ref="tensorflow::serving::internal::QueueHandle">QueueHandle</a>&lt;TaskType&gt;::<dfn class="decl def" id="_ZN10tensorflow7serving8internal11QueueHandle8ScheduleEPSt10unique_ptrIT_St14default_deleteIS4_EE" title='tensorflow::serving::internal::QueueHandle::Schedule' data-ref="_ZN10tensorflow7serving8internal11QueueHandle8ScheduleEPSt10unique_ptrIT_St14default_deleteIS4_EE">Schedule</dfn>(<span class="namespace">std::</span><a class="type" href="../../../../../include/c++/5/bits/unique_ptr.h.html#std::unique_ptr" title='std::unique_ptr' data-ref="std::unique_ptr">unique_ptr</a>&lt;TaskType&gt;* <dfn class="local col3 decl" id="83task" title='task' data-type='std::unique_ptr&lt;TaskType&gt; *' data-ref="83task">task</dfn>) {</td></tr>
<tr><th id="687">687</th><td>  <b>return</b> <a class="member" href="#tensorflow::serving::internal::QueueHandle::queue_" title='tensorflow::serving::internal::QueueHandle::queue_' data-ref="tensorflow::serving::internal::QueueHandle::queue_">queue_</a>-&gt;Schedule(<a class="local col3 ref" href="#83task" title='task' data-ref="83task">task</a>);</td></tr>
<tr><th id="688">688</th><td>}</td></tr>
<tr><th id="689">689</th><td></td></tr>
<tr><th id="690">690</th><td><b>template</b> &lt;<b>typename</b> TaskType&gt;</td></tr>
<tr><th id="691">691</th><td><span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <a class="type" href="#tensorflow::serving::internal::QueueHandle" title='tensorflow::serving::internal::QueueHandle' data-ref="tensorflow::serving::internal::QueueHandle">QueueHandle</a>&lt;TaskType&gt;::<dfn class="decl def" id="_ZNK10tensorflow7serving8internal11QueueHandle16NumEnqueuedTasksEv" title='tensorflow::serving::internal::QueueHandle::NumEnqueuedTasks' data-ref="_ZNK10tensorflow7serving8internal11QueueHandle16NumEnqueuedTasksEv">NumEnqueuedTasks</dfn>() <em>const</em> {</td></tr>
<tr><th id="692">692</th><td>  <b>return</b> <a class="member" href="#tensorflow::serving::internal::QueueHandle::queue_" title='tensorflow::serving::internal::QueueHandle::queue_' data-ref="tensorflow::serving::internal::QueueHandle::queue_">queue_</a>-&gt;NumEnqueuedTasks();</td></tr>
<tr><th id="693">693</th><td>}</td></tr>
<tr><th id="694">694</th><td></td></tr>
<tr><th id="695">695</th><td><b>template</b> &lt;<b>typename</b> TaskType&gt;</td></tr>
<tr><th id="696">696</th><td><span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <a class="type" href="#tensorflow::serving::internal::QueueHandle" title='tensorflow::serving::internal::QueueHandle' data-ref="tensorflow::serving::internal::QueueHandle">QueueHandle</a>&lt;TaskType&gt;::<dfn class="decl def" id="_ZNK10tensorflow7serving8internal11QueueHandle18SchedulingCapacityEv" title='tensorflow::serving::internal::QueueHandle::SchedulingCapacity' data-ref="_ZNK10tensorflow7serving8internal11QueueHandle18SchedulingCapacityEv">SchedulingCapacity</dfn>() <em>const</em> {</td></tr>
<tr><th id="697">697</th><td>  <b>return</b> <a class="member" href="#tensorflow::serving::internal::QueueHandle::queue_" title='tensorflow::serving::internal::QueueHandle::queue_' data-ref="tensorflow::serving::internal::QueueHandle::queue_">queue_</a>-&gt;SchedulingCapacity();</td></tr>
<tr><th id="698">698</th><td>}</td></tr>
<tr><th id="699">699</th><td></td></tr>
<tr><th id="700">700</th><td>}  <i>// namespace internal</i></td></tr>
<tr><th id="701">701</th><td></td></tr>
<tr><th id="702">702</th><td>}  <i>// namespace serving</i></td></tr>
<tr><th id="703">703</th><td>}  <i>// namespace tensorflow</i></td></tr>
<tr><th id="704">704</th><td></td></tr>
<tr><th id="705">705</th><td><u>#<span data-ppcond="16">endif</span>  // TENSORFLOW_CORE_KERNELS_BATCHING_UTIL_SHARED_BATCH_SCHEDULER_H_</u></td></tr>
<tr><th id="706">706</th><td></td></tr>
</table><hr/><p id='footer'>
Generated while processing <a href='../batch_kernels.cc.html'>tensorflow/tensorflow/core/kernels/batch_kernels.cc</a><br/>Generated on <em>2018-Sep-06</em> from project tensorflow revision <em>v1.8</em><br />Powered by <a href='https://woboq.com'><img alt='Woboq' src='https://code.woboq.org/woboq-16.png' width='41' height='16' /></a> <a href='https://code.woboq.org'>Code Browser</a> 2.1
<br/>Generator usage only permitted with license.</p>
</div></body></html>
