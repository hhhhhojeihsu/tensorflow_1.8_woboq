<!doctype html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0"><title>matmul_op.cc source code [tensorflow/tensorflow/core/kernels/matmul_op.cc] - Woboq Code Browser</title>
<meta name="woboq:interestingDefinitions" content="tensorflow::LaunchMatMul,tensorflow::LaunchMatMulBase,tensorflow::LaunchMatMulCPU,tensorflow::MatMulOp,tensorflow::functor::MatMulFunctor "/>
<link rel="stylesheet" href="https://code.woboq.org/data/qtcreator.css" title="QtCreator"/>
<link rel="alternate stylesheet" href="https://code.woboq.org/data/kdevelop.css" title="KDevelop"/>
<script type="text/javascript" src="https://code.woboq.org/data/jquery/jquery.min.js"></script>
<script type="text/javascript" src="https://code.woboq.org/data/jquery/jquery-ui.min.js"></script>
<script>var file = 'tensorflow/tensorflow/core/kernels/matmul_op.cc'; var root_path = '../../../..'; var data_path = 'https://code.woboq.org/data';</script>
<script src='https://code.woboq.org/data/codebrowser.js'></script>
</head>
<body><div id='header'><h1 id='breadcrumb'><span>Browse the source code of </span><a href='../../..'>tensorflow</a>/<a href='../..'>tensorflow</a>/<a href='..'>core</a>/<a href='./'>kernels</a>/<a href='matmul_op.cc.html'>matmul_op.cc</a></h1></div>
<hr/><div id='content'><table class="code">
<tr><th id="1">1</th><td><i>/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.</i></td></tr>
<tr><th id="2">2</th><td><i></i></td></tr>
<tr><th id="3">3</th><td><i>Licensed under the Apache License, Version 2.0 (the "License");</i></td></tr>
<tr><th id="4">4</th><td><i>you may not use this file except in compliance with the License.</i></td></tr>
<tr><th id="5">5</th><td><i>You may obtain a copy of the License at</i></td></tr>
<tr><th id="6">6</th><td><i></i></td></tr>
<tr><th id="7">7</th><td><i>    <a href="http://www.apache.org/licenses/LICENSE-2.0">http://www.apache.org/licenses/LICENSE-2.0</a></i></td></tr>
<tr><th id="8">8</th><td><i></i></td></tr>
<tr><th id="9">9</th><td><i>Unless required by applicable law or agreed to in writing, software</i></td></tr>
<tr><th id="10">10</th><td><i>distributed under the License is distributed on an "AS IS" BASIS,</i></td></tr>
<tr><th id="11">11</th><td><i>WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</i></td></tr>
<tr><th id="12">12</th><td><i>See the License for the specific language governing permissions and</i></td></tr>
<tr><th id="13">13</th><td><i>limitations under the License.</i></td></tr>
<tr><th id="14">14</th><td><i>==============================================================================*/</i></td></tr>
<tr><th id="15">15</th><td><i></i></td></tr>
<tr><th id="16">16</th><td><i>// See docs in ../ops/math_ops.cc.</i></td></tr>
<tr><th id="17">17</th><td></td></tr>
<tr><th id="18">18</th><td><u>#define <dfn class="macro" id="_M/EIGEN_USE_THREADS" data-ref="_M/EIGEN_USE_THREADS">EIGEN_USE_THREADS</dfn></u></td></tr>
<tr><th id="19">19</th><td></td></tr>
<tr><th id="20">20</th><td><u>#include <a href="matmul_op.h.html">"tensorflow/core/kernels/matmul_op.h"</a></u></td></tr>
<tr><th id="21">21</th><td></td></tr>
<tr><th id="22">22</th><td><u>#include <a href="../framework/op.h.html">"tensorflow/core/framework/op.h"</a></u></td></tr>
<tr><th id="23">23</th><td><u>#include <a href="../framework/op_kernel.h.html">"tensorflow/core/framework/op_kernel.h"</a></u></td></tr>
<tr><th id="24">24</th><td><u>#include <a href="../framework/register_types.h.html">"tensorflow/core/framework/register_types.h"</a></u></td></tr>
<tr><th id="25">25</th><td><u>#include <a href="fill_functor.h.html">"tensorflow/core/kernels/fill_functor.h"</a></u></td></tr>
<tr><th id="26">26</th><td><u>#include <a href="../util/matmul_autotune.h.html">"tensorflow/core/util/matmul_autotune.h"</a></u></td></tr>
<tr><th id="27">27</th><td><u>#<span data-ppcond="27">if</span> GOOGLE_CUDA</u></td></tr>
<tr><th id="28">28</th><td><u>#include "cuda/include/cuda.h"</u></td></tr>
<tr><th id="29">29</th><td><u>#include "tensorflow/core/kernels/gpu_utils.h"</u></td></tr>
<tr><th id="30">30</th><td><u>#include "tensorflow/core/platform/stream_executor.h"</u></td></tr>
<tr><th id="31">31</th><td><u>#<span data-ppcond="27">endif</span>  // GOOGLE_CUDA</u></td></tr>
<tr><th id="32">32</th><td></td></tr>
<tr><th id="33">33</th><td><b>namespace</b> <span class="namespace">tensorflow</span> {</td></tr>
<tr><th id="34">34</th><td></td></tr>
<tr><th id="35">35</th><td><b>typedef</b> <span class="namespace">Eigen::</span><span class='type' title='Eigen::ThreadPoolDevice' data-ref="Eigen::ThreadPoolDevice">ThreadPoolDevice</span> <dfn class="typedef" id="tensorflow::CPUDevice" title='tensorflow::CPUDevice' data-type='Eigen::ThreadPoolDevice' data-ref="tensorflow::CPUDevice">CPUDevice</dfn>;</td></tr>
<tr><th id="36">36</th><td><b>typedef</b> <span class="namespace">Eigen::</span><span class='type' title='Eigen::GpuDevice' data-ref="Eigen::GpuDevice">GpuDevice</span> <dfn class="typedef" id="tensorflow::GPUDevice" title='tensorflow::GPUDevice' data-type='Eigen::GpuDevice' data-ref="tensorflow::GPUDevice">GPUDevice</dfn>;</td></tr>
<tr><th id="37">37</th><td><u>#<span data-ppcond="37">ifdef</span> <span class="macro" data-ref="_M/TENSORFLOW_USE_SYCL">TENSORFLOW_USE_SYCL</span></u></td></tr>
<tr><th id="38">38</th><td><b>typedef</b> Eigen::SyclDevice SYCLDevice;</td></tr>
<tr><th id="39">39</th><td><u>#<span data-ppcond="37">endif</span>  // TENSORFLOW_USE_SYCL</u></td></tr>
<tr><th id="40">40</th><td></td></tr>
<tr><th id="41">41</th><td><b>template</b> &lt;<b>typename</b> Device, <b>typename</b> T, <em>bool</em> USE_CUBLAS&gt;</td></tr>
<tr><th id="42">42</th><td><b>struct</b> <dfn class="type" id="tensorflow::LaunchMatMul" title='tensorflow::LaunchMatMul' data-ref="tensorflow::LaunchMatMul">LaunchMatMul</dfn>;</td></tr>
<tr><th id="43">43</th><td></td></tr>
<tr><th id="44">44</th><td><b>namespace</b> {</td></tr>
<tr><th id="45">45</th><td><i>// Converts a TensorFlow Tensor to an Eigen Matrix.</i></td></tr>
<tr><th id="46">46</th><td><b>template</b> &lt;<b>typename</b> T&gt;</td></tr>
<tr><th id="47">47</th><td><span class="namespace">Eigen::</span><span class='type' title='Eigen::Map' data-ref="Eigen::Map">Map</span>&lt;</td></tr>
<tr><th id="48">48</th><td>    <em>const</em> <span class="namespace">Eigen::</span><span class='type' title='Eigen::Matrix' data-ref="Eigen::Matrix">Matrix</span>&lt;T, <span class="namespace">Eigen::</span><span class='ref' title='Eigen::Dynamic' data-ref="Eigen::Dynamic">Dynamic</span>, <span class="namespace">Eigen::</span><span class='ref' title='Eigen::Dynamic' data-ref="Eigen::Dynamic">Dynamic</span>, <span class="namespace">Eigen::</span><span class='enum' title='Eigen::StorageOptions::RowMajor' data-ref="Eigen::StorageOptions::RowMajor">RowMajor</span>&gt;&gt;</td></tr>
<tr><th id="49">49</th><td><dfn class="tu decl def" id="_ZN10tensorflow12_GLOBAL__N_113ToEigenMatrixERKNS_6TensorE" title='tensorflow::(anonymous namespace)::ToEigenMatrix' data-type='Eigen::Map&lt;const Eigen::Matrix&lt;T, Eigen::Dynamic, Eigen::Dynamic, Eigen::RowMajor&gt; &gt; tensorflow::(anonymous namespace)::ToEigenMatrix(const tensorflow::Tensor &amp; tensor)' data-ref="_ZN10tensorflow12_GLOBAL__N_113ToEigenMatrixERKNS_6TensorE">ToEigenMatrix</dfn>(<em>const</em> <a class="type" href="../framework/tensor.h.html#tensorflow::Tensor" title='tensorflow::Tensor' data-ref="tensorflow::Tensor">Tensor</a>&amp; <dfn class="local col1 decl" id="11tensor" title='tensor' data-type='const tensorflow::Tensor &amp;' data-ref="11tensor">tensor</dfn>) {</td></tr>
<tr><th id="50">50</th><td>  <em>auto</em> <dfn class="local col2 decl" id="12matrix" title='matrix' data-type='auto' data-ref="12matrix">matrix</dfn> = <a class="local col1 ref" href="#11tensor" title='tensor' data-ref="11tensor">tensor</a>.matrix&lt;T&gt;();</td></tr>
<tr><th id="51">51</th><td>  <b>return</b> <span class="namespace">Eigen::</span><span class='type' title='Eigen::Matrix' data-ref="Eigen::Matrix">Matrix</span>&lt;T, <span class="namespace">Eigen::</span><span class='ref' title='Eigen::Dynamic' data-ref="Eigen::Dynamic">Dynamic</span>, <span class="namespace">Eigen::</span><span class='ref' title='Eigen::Dynamic' data-ref="Eigen::Dynamic">Dynamic</span>, <span class="namespace">Eigen::</span><span class='enum' title='Eigen::StorageOptions::RowMajor' data-ref="Eigen::StorageOptions::RowMajor">RowMajor</span>&gt;::Map(</td></tr>
<tr><th id="52">52</th><td>      <a class="local col2 ref" href="#12matrix" title='matrix' data-ref="12matrix">matrix</a>.data(), <a class="local col2 ref" href="#12matrix" title='matrix' data-ref="12matrix">matrix</a>.dimension(<var>0</var>), <a class="local col2 ref" href="#12matrix" title='matrix' data-ref="12matrix">matrix</a>.dimension(<var>1</var>));</td></tr>
<tr><th id="53">53</th><td>}</td></tr>
<tr><th id="54">54</th><td></td></tr>
<tr><th id="55">55</th><td><i>// Converts a TensorFlow Tensor to an Eigen Vector.</i></td></tr>
<tr><th id="56">56</th><td><b>template</b> &lt;<b>typename</b> T&gt;</td></tr>
<tr><th id="57">57</th><td><span class="namespace">Eigen::</span><span class='type' title='Eigen::Map' data-ref="Eigen::Map">Map</span>&lt;<span class="namespace">Eigen::</span><span class='type' title='Eigen::Matrix' data-ref="Eigen::Matrix">Matrix</span>&lt;T, <span class="namespace">Eigen::</span><span class='ref' title='Eigen::Dynamic' data-ref="Eigen::Dynamic">Dynamic</span>, <var>1</var>&gt;&gt; <dfn class="tu decl def" id="_ZN10tensorflow12_GLOBAL__N_113ToEigenVectorEPNS_6TensorE" title='tensorflow::(anonymous namespace)::ToEigenVector' data-type='Eigen::Map&lt;Eigen::Matrix&lt;T, Eigen::Dynamic, 1&gt; &gt; tensorflow::(anonymous namespace)::ToEigenVector(tensorflow::Tensor * tensor)' data-ref="_ZN10tensorflow12_GLOBAL__N_113ToEigenVectorEPNS_6TensorE">ToEigenVector</dfn>(<a class="type" href="../framework/tensor.h.html#tensorflow::Tensor" title='tensorflow::Tensor' data-ref="tensorflow::Tensor">Tensor</a>* <dfn class="local col3 decl" id="13tensor" title='tensor' data-type='tensorflow::Tensor *' data-ref="13tensor">tensor</dfn>) {</td></tr>
<tr><th id="58">58</th><td>  <em>auto</em> <dfn class="local col4 decl" id="14v" title='v' data-type='auto' data-ref="14v">v</dfn> = <a class="local col3 ref" href="#13tensor" title='tensor' data-ref="13tensor">tensor</a>-&gt;flat&lt;T&gt;();</td></tr>
<tr><th id="59">59</th><td>  <b>return</b> <span class="namespace">Eigen::</span><span class='type' title='Eigen::Matrix' data-ref="Eigen::Matrix">Matrix</span>&lt;T, <span class="namespace">Eigen::</span><span class='ref' title='Eigen::Dynamic' data-ref="Eigen::Dynamic">Dynamic</span>, <var>1</var>&gt;::Map(<a class="local col4 ref" href="#14v" title='v' data-ref="14v">v</a>.data(), <a class="local col4 ref" href="#14v" title='v' data-ref="14v">v</a>.dimension(<var>0</var>));</td></tr>
<tr><th id="60">60</th><td>}</td></tr>
<tr><th id="61">61</th><td><b>template</b> &lt;<b>typename</b> T&gt;</td></tr>
<tr><th id="62">62</th><td><span class="namespace">Eigen::</span><span class='type' title='Eigen::Map' data-ref="Eigen::Map">Map</span>&lt;<em>const</em> <span class="namespace">Eigen::</span><span class='type' title='Eigen::Matrix' data-ref="Eigen::Matrix">Matrix</span>&lt;T, <span class="namespace">Eigen::</span><span class='ref' title='Eigen::Dynamic' data-ref="Eigen::Dynamic">Dynamic</span>, <var>1</var>&gt;&gt; <dfn class="tu decl def" id="_ZN10tensorflow12_GLOBAL__N_113ToEigenVectorERKNS_6TensorE" title='tensorflow::(anonymous namespace)::ToEigenVector' data-type='Eigen::Map&lt;const Eigen::Matrix&lt;T, Eigen::Dynamic, 1&gt; &gt; tensorflow::(anonymous namespace)::ToEigenVector(const tensorflow::Tensor &amp; tensor)' data-ref="_ZN10tensorflow12_GLOBAL__N_113ToEigenVectorERKNS_6TensorE">ToEigenVector</dfn>(</td></tr>
<tr><th id="63">63</th><td>    <em>const</em> <a class="type" href="../framework/tensor.h.html#tensorflow::Tensor" title='tensorflow::Tensor' data-ref="tensorflow::Tensor">Tensor</a>&amp; <dfn class="local col5 decl" id="15tensor" title='tensor' data-type='const tensorflow::Tensor &amp;' data-ref="15tensor">tensor</dfn>) {</td></tr>
<tr><th id="64">64</th><td>  <em>auto</em> <dfn class="local col6 decl" id="16v" title='v' data-type='auto' data-ref="16v">v</dfn> = <a class="local col5 ref" href="#15tensor" title='tensor' data-ref="15tensor">tensor</a>.flat&lt;T&gt;();</td></tr>
<tr><th id="65">65</th><td>  <b>return</b> <span class="namespace">Eigen::</span><span class='type' title='Eigen::Matrix' data-ref="Eigen::Matrix">Matrix</span>&lt;T, <span class="namespace">Eigen::</span><span class='ref' title='Eigen::Dynamic' data-ref="Eigen::Dynamic">Dynamic</span>, <var>1</var>&gt;::Map(<a class="local col6 ref" href="#16v" title='v' data-ref="16v">v</a>.data(), <a class="local col6 ref" href="#16v" title='v' data-ref="16v">v</a>.dimension(<var>0</var>));</td></tr>
<tr><th id="66">66</th><td>}</td></tr>
<tr><th id="67">67</th><td>}  <i>// namespace</i></td></tr>
<tr><th id="68">68</th><td></td></tr>
<tr><th id="69">69</th><td><i>// If either side can be represented as a vector, do an explicit vector</i></td></tr>
<tr><th id="70">70</th><td><i>// matrix multiply and return true; else return false.</i></td></tr>
<tr><th id="71">71</th><td><i>//</i></td></tr>
<tr><th id="72">72</th><td><i>// Note: this uses plain Eigen and not Eigen Tensor because it is more</i></td></tr>
<tr><th id="73">73</th><td><i>// efficient.</i></td></tr>
<tr><th id="74">74</th><td><b>template</b> &lt;<b>typename</b> T&gt;</td></tr>
<tr><th id="75">75</th><td><em>bool</em> <dfn class="decl def" id="_ZN10tensorflow32ExplicitVectorMatrixOptimizationERKNS_6TensorES2_RKN5Eigen5arrayINS3_9IndexPairIlEELm1EEEPS0_" title='tensorflow::ExplicitVectorMatrixOptimization' data-ref="_ZN10tensorflow32ExplicitVectorMatrixOptimizationERKNS_6TensorES2_RKN5Eigen5arrayINS3_9IndexPairIlEELm1EEEPS0_">ExplicitVectorMatrixOptimization</dfn>(</td></tr>
<tr><th id="76">76</th><td>    <em>const</em> <a class="type" href="../framework/tensor.h.html#tensorflow::Tensor" title='tensorflow::Tensor' data-ref="tensorflow::Tensor">Tensor</a>&amp; <dfn class="local col7 decl" id="17a" title='a' data-type='const tensorflow::Tensor &amp;' data-ref="17a">a</dfn>, <em>const</em> <a class="type" href="../framework/tensor.h.html#tensorflow::Tensor" title='tensorflow::Tensor' data-ref="tensorflow::Tensor">Tensor</a>&amp; <dfn class="local col8 decl" id="18b" title='b' data-type='const tensorflow::Tensor &amp;' data-ref="18b">b</dfn>,</td></tr>
<tr><th id="77">77</th><td>    <em>const</em> <span class="namespace">Eigen::</span><span class='type' title='Eigen::array' data-ref="Eigen::array">array</span>&lt;<span class="namespace">Eigen::</span><span class='type' title='Eigen::IndexPair' data-ref="Eigen::IndexPair">IndexPair</span>&lt;<span class="namespace">Eigen::</span><span class='typedef' title='Eigen::DenseIndex' data-type='std::ptrdiff_t' data-ref="Eigen::DenseIndex">DenseIndex</span>&gt;, <var>1</var>&gt;&amp; <dfn class="local col9 decl" id="19dim_pair" title='dim_pair' data-type='const Eigen::array&lt;Eigen::IndexPair&lt;Eigen::DenseIndex&gt;, 1&gt; &amp;' data-ref="19dim_pair">dim_pair</dfn>,</td></tr>
<tr><th id="78">78</th><td>    <a class="type" href="../framework/tensor.h.html#tensorflow::Tensor" title='tensorflow::Tensor' data-ref="tensorflow::Tensor">Tensor</a>* <dfn class="local col0 decl" id="20out" title='out' data-type='tensorflow::Tensor *' data-ref="20out">out</dfn>) {</td></tr>
<tr><th id="79">79</th><td>  <b>if</b> (<a class="local col0 ref" href="#20out" title='out' data-ref="20out">out</a>-&gt;<a class="ref" href="../framework/tensor.h.html#_ZNK10tensorflow6Tensor8dim_sizeEi" title='tensorflow::Tensor::dim_size' data-ref="_ZNK10tensorflow6Tensor8dim_sizeEi">dim_size</a>(<var>0</var>) == <var>1</var>) {</td></tr>
<tr><th id="80">80</th><td>    <b>if</b> (<a class="local col9 ref" href="#19dim_pair" title='dim_pair' data-ref="19dim_pair">dim_pair</a><span class='ref' title='Eigen::array::operator[]' data-ref="_ZNK5Eigen5arrayixEm">[<var>0</var>]</span>.<span class='ref' title='Eigen::IndexPair&lt;long&gt;::second' data-ref="Eigen::IndexPair::second">second</span> == <var>0</var>) {</td></tr>
<tr><th id="81">81</th><td>      <i>// Note: this case is optimized in Eigen Tensors.</i></td></tr>
<tr><th id="82">82</th><td>      <b>return</b> <b>false</b>;</td></tr>
<tr><th id="83">83</th><td>    } <b>else</b> {</td></tr>
<tr><th id="84">84</th><td>      <em>auto</em> <dfn class="local col1 decl" id="21out_v" title='out_v' data-type='auto' data-ref="21out_v">out_v</dfn> = ToEigenVector&lt;T&gt;(<a class="local col0 ref" href="#20out" title='out' data-ref="20out">out</a>);</td></tr>
<tr><th id="85">85</th><td>      <em>auto</em> <dfn class="local col2 decl" id="22a_v" title='a_v' data-type='auto' data-ref="22a_v">a_v</dfn> = ToEigenVector&lt;T&gt;(<a class="local col7 ref" href="#17a" title='a' data-ref="17a">a</a>);</td></tr>
<tr><th id="86">86</th><td>      <em>auto</em> <dfn class="local col3 decl" id="23b_m" title='b_m' data-type='auto' data-ref="23b_m">b_m</dfn> = ToEigenMatrix&lt;T&gt;(<a class="local col8 ref" href="#18b" title='b' data-ref="18b">b</a>);</td></tr>
<tr><th id="87">87</th><td>      <a class="local col1 ref" href="#21out_v" title='out_v' data-ref="21out_v">out_v</a>.noalias() = <a class="local col3 ref" href="#23b_m" title='b_m' data-ref="23b_m">b_m</a> * <a class="local col2 ref" href="#22a_v" title='a_v' data-ref="22a_v">a_v</a>;</td></tr>
<tr><th id="88">88</th><td>    }</td></tr>
<tr><th id="89">89</th><td>    <b>return</b> <b>true</b>;</td></tr>
<tr><th id="90">90</th><td>  } <b>else</b> <b>if</b> (<a class="local col0 ref" href="#20out" title='out' data-ref="20out">out</a>-&gt;<a class="ref" href="../framework/tensor.h.html#_ZNK10tensorflow6Tensor8dim_sizeEi" title='tensorflow::Tensor::dim_size' data-ref="_ZNK10tensorflow6Tensor8dim_sizeEi">dim_size</a>(<var>1</var>) == <var>1</var>) {</td></tr>
<tr><th id="91">91</th><td>    <em>auto</em> <dfn class="local col4 decl" id="24out_v" title='out_v' data-type='auto' data-ref="24out_v">out_v</dfn> = ToEigenVector&lt;T&gt;(<a class="local col0 ref" href="#20out" title='out' data-ref="20out">out</a>);</td></tr>
<tr><th id="92">92</th><td>    <em>auto</em> <dfn class="local col5 decl" id="25a_m" title='a_m' data-type='auto' data-ref="25a_m">a_m</dfn> = ToEigenMatrix&lt;T&gt;(<a class="local col7 ref" href="#17a" title='a' data-ref="17a">a</a>);</td></tr>
<tr><th id="93">93</th><td>    <em>auto</em> <dfn class="local col6 decl" id="26b_v" title='b_v' data-type='auto' data-ref="26b_v">b_v</dfn> = ToEigenVector&lt;T&gt;(<a class="local col8 ref" href="#18b" title='b' data-ref="18b">b</a>);</td></tr>
<tr><th id="94">94</th><td>    <b>if</b> (<a class="local col9 ref" href="#19dim_pair" title='dim_pair' data-ref="19dim_pair">dim_pair</a><span class='ref' title='Eigen::array::operator[]' data-ref="_ZNK5Eigen5arrayixEm">[<var>0</var>]</span>.<span class='ref' title='Eigen::IndexPair&lt;long&gt;::first' data-ref="Eigen::IndexPair::first">first</span> == <var>0</var>) {</td></tr>
<tr><th id="95">95</th><td>      <a class="local col4 ref" href="#24out_v" title='out_v' data-ref="24out_v">out_v</a>.noalias() = <a class="local col5 ref" href="#25a_m" title='a_m' data-ref="25a_m">a_m</a>.transpose() * <a class="local col6 ref" href="#26b_v" title='b_v' data-ref="26b_v">b_v</a>;</td></tr>
<tr><th id="96">96</th><td>    } <b>else</b> {</td></tr>
<tr><th id="97">97</th><td>      <a class="local col4 ref" href="#24out_v" title='out_v' data-ref="24out_v">out_v</a>.noalias() = <a class="local col5 ref" href="#25a_m" title='a_m' data-ref="25a_m">a_m</a> * <a class="local col6 ref" href="#26b_v" title='b_v' data-ref="26b_v">b_v</a>;</td></tr>
<tr><th id="98">98</th><td>    }</td></tr>
<tr><th id="99">99</th><td>    <b>return</b> <b>true</b>;</td></tr>
<tr><th id="100">100</th><td>  }</td></tr>
<tr><th id="101">101</th><td>  <b>return</b> <b>false</b>;</td></tr>
<tr><th id="102">102</th><td>}</td></tr>
<tr><th id="103">103</th><td><i>// Half is not supported.</i></td></tr>
<tr><th id="104">104</th><td><b>template</b> &lt;&gt;</td></tr>
<tr><th id="105">105</th><td><em>bool</em> <dfn class="decl def" id="_ZN10tensorflow32ExplicitVectorMatrixOptimizationERKNS_6TensorES2_RKN5Eigen5arrayINS3_9IndexPairIlEELm1EEEPS0_" title='tensorflow::ExplicitVectorMatrixOptimization' data-ref="_ZN10tensorflow32ExplicitVectorMatrixOptimizationERKNS_6TensorES2_RKN5Eigen5arrayINS3_9IndexPairIlEELm1EEEPS0_">ExplicitVectorMatrixOptimization</dfn>&lt;<span class="namespace">Eigen::</span><span class='type' title='Eigen::half' data-ref="Eigen::half">half</span>&gt;(</td></tr>
<tr><th id="106">106</th><td>    <em>const</em> <a class="type" href="../framework/tensor.h.html#tensorflow::Tensor" title='tensorflow::Tensor' data-ref="tensorflow::Tensor">Tensor</a>&amp; <dfn class="local col7 decl" id="27a" title='a' data-type='const tensorflow::Tensor &amp;' data-ref="27a">a</dfn>, <em>const</em> <a class="type" href="../framework/tensor.h.html#tensorflow::Tensor" title='tensorflow::Tensor' data-ref="tensorflow::Tensor">Tensor</a>&amp; <dfn class="local col8 decl" id="28b" title='b' data-type='const tensorflow::Tensor &amp;' data-ref="28b">b</dfn>,</td></tr>
<tr><th id="107">107</th><td>    <em>const</em> <span class="namespace">Eigen::</span><span class='type' title='Eigen::array' data-ref="Eigen::array">array</span>&lt;<span class="namespace">Eigen::</span><span class='type' title='Eigen::IndexPair' data-ref="Eigen::IndexPair">IndexPair</span>&lt;<span class="namespace">Eigen::</span><span class='typedef' title='Eigen::DenseIndex' data-type='std::ptrdiff_t' data-ref="Eigen::DenseIndex">DenseIndex</span>&gt;, <var>1</var>&gt;&amp; <dfn class="local col9 decl" id="29dim_pair" title='dim_pair' data-type='const Eigen::array&lt;Eigen::IndexPair&lt;Eigen::DenseIndex&gt;, 1&gt; &amp;' data-ref="29dim_pair">dim_pair</dfn>,</td></tr>
<tr><th id="108">108</th><td>    <a class="type" href="../framework/tensor.h.html#tensorflow::Tensor" title='tensorflow::Tensor' data-ref="tensorflow::Tensor">Tensor</a>* <dfn class="local col0 decl" id="30out" title='out' data-type='tensorflow::Tensor *' data-ref="30out">out</dfn>) {</td></tr>
<tr><th id="109">109</th><td>  <b>return</b> <b>false</b>;</td></tr>
<tr><th id="110">110</th><td>}</td></tr>
<tr><th id="111">111</th><td></td></tr>
<tr><th id="112">112</th><td><b>template</b> &lt;<b>typename</b> Device, <b>typename</b> T&gt;</td></tr>
<tr><th id="113">113</th><td><b>struct</b> <dfn class="type def" id="tensorflow::LaunchMatMulBase" title='tensorflow::LaunchMatMulBase' data-ref="tensorflow::LaunchMatMulBase">LaunchMatMulBase</dfn> {</td></tr>
<tr><th id="114">114</th><td><u>#<span data-ppcond="114">if</span> GOOGLE_CUDA</u></td></tr>
<tr><th id="115">115</th><td>  <b>typedef</b> perftools::gputools::blas::AlgorithmType AlgorithmType;</td></tr>
<tr><th id="116">116</th><td><u>#<span data-ppcond="114">else</span></u></td></tr>
<tr><th id="117">117</th><td>  <b>typedef</b> <a class="typedef" href="../platform/default/integral_types.h.html#tensorflow::int64" title='tensorflow::int64' data-type='long long' data-ref="tensorflow::int64">int64</a> <dfn class="typedef" id="tensorflow::LaunchMatMulBase::AlgorithmType" title='tensorflow::LaunchMatMulBase::AlgorithmType' data-type='int64' data-ref="tensorflow::LaunchMatMulBase::AlgorithmType">AlgorithmType</dfn>;</td></tr>
<tr><th id="118">118</th><td><u>#<span data-ppcond="114">endif</span>  // GOOGLE_CUDA</u></td></tr>
<tr><th id="119">119</th><td></td></tr>
<tr><th id="120">120</th><td>  <em>static</em> <em>void</em> <dfn class="tu decl def" id="_ZN10tensorflow16LaunchMatMulBase6launchEPNS_15OpKernelContextERKNS_6TensorES5_RKN5Eigen5arrayINS6_9IndexPairIlEELm1EEEPSt6vectorIxSaIxEEbPS3_" title='tensorflow::LaunchMatMulBase::launch' data-type='static void tensorflow::LaunchMatMulBase::launch(tensorflow::OpKernelContext * ctx, const tensorflow::Tensor &amp; a, const tensorflow::Tensor &amp; b, const Eigen::array&lt;Eigen::IndexPair&lt;Eigen::DenseIndex&gt;, 1&gt; &amp; dim_pair, std::vector&lt;AlgorithmType&gt; * algorithms, bool use_aututone, tensorflow::Tensor * out)' data-ref="_ZN10tensorflow16LaunchMatMulBase6launchEPNS_15OpKernelContextERKNS_6TensorES5_RKN5Eigen5arrayINS6_9IndexPairIlEELm1EEEPSt6vectorIxSaIxEEbPS3_">launch</dfn>(</td></tr>
<tr><th id="121">121</th><td>      <a class="type" href="../framework/op_kernel.h.html#tensorflow::OpKernelContext" title='tensorflow::OpKernelContext' data-ref="tensorflow::OpKernelContext">OpKernelContext</a>* <dfn class="local col1 decl" id="31ctx" title='ctx' data-type='tensorflow::OpKernelContext *' data-ref="31ctx">ctx</dfn>, <em>const</em> <a class="type" href="../framework/tensor.h.html#tensorflow::Tensor" title='tensorflow::Tensor' data-ref="tensorflow::Tensor">Tensor</a>&amp; <dfn class="local col2 decl" id="32a" title='a' data-type='const tensorflow::Tensor &amp;' data-ref="32a">a</dfn>, <em>const</em> <a class="type" href="../framework/tensor.h.html#tensorflow::Tensor" title='tensorflow::Tensor' data-ref="tensorflow::Tensor">Tensor</a>&amp; <dfn class="local col3 decl" id="33b" title='b' data-type='const tensorflow::Tensor &amp;' data-ref="33b">b</dfn>,</td></tr>
<tr><th id="122">122</th><td>      <em>const</em> <span class="namespace">Eigen::</span><span class='type' title='Eigen::array' data-ref="Eigen::array">array</span>&lt;<span class="namespace">Eigen::</span><span class='type' title='Eigen::IndexPair' data-ref="Eigen::IndexPair">IndexPair</span>&lt;<span class="namespace">Eigen::</span><span class='typedef' title='Eigen::DenseIndex' data-type='std::ptrdiff_t' data-ref="Eigen::DenseIndex">DenseIndex</span>&gt;, <var>1</var>&gt;&amp; <dfn class="local col4 decl" id="34dim_pair" title='dim_pair' data-type='const Eigen::array&lt;Eigen::IndexPair&lt;Eigen::DenseIndex&gt;, 1&gt; &amp;' data-ref="34dim_pair">dim_pair</dfn>,</td></tr>
<tr><th id="123">123</th><td>      <span class="namespace">std::</span><a class="type" href="../../../../include/c++/5/bits/stl_vector.h.html#std::vector" title='std::vector' data-ref="std::vector">vector</a>&lt;<a class="typedef" href="#tensorflow::LaunchMatMulBase::AlgorithmType" title='tensorflow::LaunchMatMulBase::AlgorithmType' data-type='int64' data-ref="tensorflow::LaunchMatMulBase::AlgorithmType">AlgorithmType</a>&gt;* <dfn class="local col5 decl" id="35algorithms" title='algorithms' data-type='std::vector&lt;AlgorithmType&gt; *' data-ref="35algorithms">algorithms</dfn>, <em>bool</em> <dfn class="local col6 decl" id="36use_aututone" title='use_aututone' data-type='bool' data-ref="36use_aututone">use_aututone</dfn>, <a class="type" href="../framework/tensor.h.html#tensorflow::Tensor" title='tensorflow::Tensor' data-ref="tensorflow::Tensor">Tensor</a>* <dfn class="local col7 decl" id="37out" title='out' data-type='tensorflow::Tensor *' data-ref="37out">out</dfn>) {</td></tr>
<tr><th id="124">124</th><td><u>#<span data-ppcond="124">ifndef</span> <span class="macro" data-ref="_M/TENSORFLOW_USE_SYCL">TENSORFLOW_USE_SYCL</span></u></td></tr>
<tr><th id="125">125</th><td>    <i>// An explicit vector-matrix multiply is much better optimized than an</i></td></tr>
<tr><th id="126">126</th><td><i>    // implicit one and this is a bottleneck during non-batched inference.</i></td></tr>
<tr><th id="127">127</th><td>    <em>bool</em> <dfn class="local col8 decl" id="38was_vector" title='was_vector' data-type='bool' data-ref="38was_vector">was_vector</dfn> = ExplicitVectorMatrixOptimization&lt;T&gt;(<a class="local col2 ref" href="#32a" title='a' data-ref="32a">a</a>, <a class="local col3 ref" href="#33b" title='b' data-ref="33b">b</a>, <a class="local col4 ref" href="#34dim_pair" title='dim_pair' data-ref="34dim_pair">dim_pair</a>, <a class="local col7 ref" href="#37out" title='out' data-ref="37out">out</a>);</td></tr>
<tr><th id="128">128</th><td>    <b>if</b> (!<a class="local col8 ref" href="#38was_vector" title='was_vector' data-ref="38was_vector">was_vector</a>) {</td></tr>
<tr><th id="129">129</th><td><u>#<span data-ppcond="124">endif</span>  // TENSORFLOW_USE_SYCL</u></td></tr>
<tr><th id="130">130</th><td>      <span class="namespace">functor::</span><a class="type" href="matmul_op.h.html#tensorflow::functor::MatMulFunctor" title='tensorflow::functor::MatMulFunctor' data-ref="tensorflow::functor::MatMulFunctor">MatMulFunctor</a>&lt;Device, T&gt;()(<a class="local col1 ref" href="#31ctx" title='ctx' data-ref="31ctx">ctx</a>-&gt;eigen_device&lt;Device&gt;(),</td></tr>
<tr><th id="131">131</th><td>                                          <a class="local col7 ref" href="#37out" title='out' data-ref="37out">out</a>-&gt;matrix&lt;T&gt;(), <a class="local col2 ref" href="#32a" title='a' data-ref="32a">a</a>.matrix&lt;T&gt;(),</td></tr>
<tr><th id="132">132</th><td>                                          <a class="local col3 ref" href="#33b" title='b' data-ref="33b">b</a>.matrix&lt;T&gt;(), <a class="local col4 ref" href="#34dim_pair" title='dim_pair' data-ref="34dim_pair">dim_pair</a>);</td></tr>
<tr><th id="133">133</th><td><u>#<span data-ppcond="133">ifndef</span> <span class="macro" data-ref="_M/TENSORFLOW_USE_SYCL">TENSORFLOW_USE_SYCL</span></u></td></tr>
<tr><th id="134">134</th><td>    }</td></tr>
<tr><th id="135">135</th><td><u>#<span data-ppcond="133">endif</span>  // TENSORFLOW_USE_SYCL</u></td></tr>
<tr><th id="136">136</th><td>  }</td></tr>
<tr><th id="137">137</th><td></td></tr>
<tr><th id="138">138</th><td>  <em>static</em> <em>void</em> <dfn class="tu decl def" id="_ZN10tensorflow16LaunchMatMulBase20GetBlasGemmAlgorithmEPNS_20OpKernelConstructionEPSt6vectorIxSaIxEEPb" title='tensorflow::LaunchMatMulBase::GetBlasGemmAlgorithm' data-type='static void tensorflow::LaunchMatMulBase::GetBlasGemmAlgorithm(tensorflow::OpKernelConstruction * ctx, std::vector&lt;int64&gt; * algorithms, bool * algorithm_set_flag)' data-ref="_ZN10tensorflow16LaunchMatMulBase20GetBlasGemmAlgorithmEPNS_20OpKernelConstructionEPSt6vectorIxSaIxEEPb">GetBlasGemmAlgorithm</dfn>(<a class="type" href="../framework/op_kernel.h.html#tensorflow::OpKernelConstruction" title='tensorflow::OpKernelConstruction' data-ref="tensorflow::OpKernelConstruction">OpKernelConstruction</a>* <dfn class="local col9 decl" id="39ctx" title='ctx' data-type='tensorflow::OpKernelConstruction *' data-ref="39ctx">ctx</dfn>,</td></tr>
<tr><th id="139">139</th><td>                                   <span class="namespace">std::</span><a class="type" href="../../../../include/c++/5/bits/stl_vector.h.html#std::vector" title='std::vector' data-ref="std::vector">vector</a>&lt;<a class="typedef" href="../platform/default/integral_types.h.html#tensorflow::int64" title='tensorflow::int64' data-type='long long' data-ref="tensorflow::int64">int64</a>&gt;* <dfn class="local col0 decl" id="40algorithms" title='algorithms' data-type='std::vector&lt;int64&gt; *' data-ref="40algorithms">algorithms</dfn>,</td></tr>
<tr><th id="140">140</th><td>                                   <em>bool</em>* <dfn class="local col1 decl" id="41algorithm_set_flag" title='algorithm_set_flag' data-type='bool *' data-ref="41algorithm_set_flag">algorithm_set_flag</dfn>) {}</td></tr>
<tr><th id="141">141</th><td>};</td></tr>
<tr><th id="142">142</th><td><i>// On CPUs, we ignore USE_CUBLAS</i></td></tr>
<tr><th id="143">143</th><td><b>template</b> &lt;<b>typename</b> T&gt;</td></tr>
<tr><th id="144">144</th><td><b>struct</b> <dfn class="type def" id="tensorflow::LaunchMatMulCPU" title='tensorflow::LaunchMatMulCPU' data-ref="tensorflow::LaunchMatMulCPU">LaunchMatMulCPU</dfn> : <a class="type" href="#tensorflow::LaunchMatMulBase" title='tensorflow::LaunchMatMulBase' data-ref="tensorflow::LaunchMatMulBase">LaunchMatMulBase</a>&lt;<a class="typedef" href="#tensorflow::CPUDevice" title='tensorflow::CPUDevice' data-type='Eigen::ThreadPoolDevice' data-ref="tensorflow::CPUDevice">CPUDevice</a>, T&gt; {};</td></tr>
<tr><th id="145">145</th><td></td></tr>
<tr><th id="146">146</th><td><b>template</b> &lt;<b>typename</b> T, <em>bool</em> USE_CUBLAS&gt;</td></tr>
<tr><th id="147">147</th><td><b>struct</b> <dfn class="type def" id="tensorflow::LaunchMatMul" title='tensorflow::LaunchMatMul' data-ref="tensorflow::LaunchMatMul">LaunchMatMul</dfn>&lt;<a class="typedef" href="#tensorflow::CPUDevice" title='tensorflow::CPUDevice' data-type='Eigen::ThreadPoolDevice' data-ref="tensorflow::CPUDevice">CPUDevice</a>, T, <a class="tu ref" href="#tensorflow::LaunchMatMul{Eigen::ThreadPoolDevice,type-parameter-0-0,USE_CUBLAS}::USE_CUBLAS" title='tensorflow::LaunchMatMul&lt;Eigen::ThreadPoolDevice, type-parameter-0-0, USE_CUBLAS&gt;::USE_CUBLAS' data-ref="tensorflow::LaunchMatMul{Eigen::ThreadPoolDevice,type-parameter-0-0,USE_CUBLAS}::USE_CUBLAS">USE_CUBLAS</a>&gt; : <b>public</b> <a class="type" href="#tensorflow::LaunchMatMulCPU" title='tensorflow::LaunchMatMulCPU' data-ref="tensorflow::LaunchMatMulCPU">LaunchMatMulCPU</a>&lt;T&gt; {};</td></tr>
<tr><th id="148">148</th><td></td></tr>
<tr><th id="149">149</th><td><u>#<span data-ppcond="149">ifdef</span> <span class="macro" data-ref="_M/TENSORFLOW_USE_SYCL">TENSORFLOW_USE_SYCL</span></u></td></tr>
<tr><th id="150">150</th><td><b>template</b> &lt;<b>typename</b> T&gt;</td></tr>
<tr><th id="151">151</th><td><b>struct</b> LaunchMatMulSYCL : LaunchMatMulBase&lt;SYCLDevice, T&gt; {};</td></tr>
<tr><th id="152">152</th><td></td></tr>
<tr><th id="153">153</th><td><b>template</b> &lt;<b>typename</b> T, <em>bool</em> USE_CUBLAS&gt;</td></tr>
<tr><th id="154">154</th><td><b>struct</b> LaunchMatMul&lt;SYCLDevice, T, USE_CUBLAS&gt; : <b>public</b> LaunchMatMulSYCL&lt;T&gt; {};</td></tr>
<tr><th id="155">155</th><td><u>#<span data-ppcond="149">endif</span>  // TENSORFLOW_USE_SYCL</u></td></tr>
<tr><th id="156">156</th><td></td></tr>
<tr><th id="157">157</th><td><u>#<span data-ppcond="157">if</span> GOOGLE_CUDA</u></td></tr>
<tr><th id="158">158</th><td></td></tr>
<tr><th id="159">159</th><td><b>namespace</b> {</td></tr>
<tr><th id="160">160</th><td></td></tr>
<tr><th id="161">161</th><td><b>template</b> &lt;<b>typename</b> T&gt;</td></tr>
<tr><th id="162">162</th><td><b>struct</b> LaunchBlasGemv {</td></tr>
<tr><th id="163">163</th><td>  <em>static</em> <em>void</em> Compute(</td></tr>
<tr><th id="164">164</th><td>      OpKernelContext* ctx, perftools::gputools::Stream* stream, <em>bool</em> trans,</td></tr>
<tr><th id="165">165</th><td>      uint64 m, uint64 n, <em>const</em> perftools::gputools::DeviceMemory&lt;T&gt;&amp; a,</td></tr>
<tr><th id="166">166</th><td>      <em>const</em> perftools::gputools::DeviceMemory&lt;T&gt;&amp; b,</td></tr>
<tr><th id="167">167</th><td>      perftools::gputools::DeviceMemory&lt;T&gt;* c,</td></tr>
<tr><th id="168">168</th><td>      perftools::gputools::blas::ProfileResult* output_profile) {</td></tr>
<tr><th id="169">169</th><td>    <em>const</em> <em>auto</em> blas_trans =</td></tr>
<tr><th id="170">170</th><td>        trans ? perftools::gputools::blas::Transpose::kTranspose</td></tr>
<tr><th id="171">171</th><td>              : perftools::gputools::blas::Transpose::kNoTranspose;</td></tr>
<tr><th id="172">172</th><td>    <b>if</b> (output_profile == <b>nullptr</b>) {</td></tr>
<tr><th id="173">173</th><td>      <em>bool</em> blas_launch_status =</td></tr>
<tr><th id="174">174</th><td>          stream</td></tr>
<tr><th id="175">175</th><td>              -&gt;ThenBlasGemv(blas_trans, m, n, <b>static_cast</b>&lt;T&gt;(<var>1.0</var>), a, m, b, <var>1</var>,</td></tr>
<tr><th id="176">176</th><td>                             <b>static_cast</b>&lt;T&gt;(<var>0.0</var>), c, <var>1</var>)</td></tr>
<tr><th id="177">177</th><td>              .ok();</td></tr>
<tr><th id="178">178</th><td>      <b>if</b> (!blas_launch_status) {</td></tr>
<tr><th id="179">179</th><td>        ctx-&gt;SetStatus(</td></tr>
<tr><th id="180">180</th><td>            errors::Internal(<q>"Blas GEMV launch failed:  m="</q>, m, <q>", n="</q>, n));</td></tr>
<tr><th id="181">181</th><td>      }</td></tr>
<tr><th id="182">182</th><td>    } <b>else</b> {</td></tr>
<tr><th id="183">183</th><td>      <em>bool</em> blas_launch_status =</td></tr>
<tr><th id="184">184</th><td>          stream</td></tr>
<tr><th id="185">185</th><td>              -&gt;ThenBlasGemvWithProfiling(blas_trans, m, n, <b>static_cast</b>&lt;T&gt;(<var>1.0</var>),</td></tr>
<tr><th id="186">186</th><td>                                          a, m, b, <var>1</var>, <b>static_cast</b>&lt;T&gt;(<var>0.0</var>), c, <var>1</var>,</td></tr>
<tr><th id="187">187</th><td>                                          output_profile)</td></tr>
<tr><th id="188">188</th><td>              .ok();</td></tr>
<tr><th id="189">189</th><td>      <b>if</b> (!blas_launch_status) {</td></tr>
<tr><th id="190">190</th><td>        ctx-&gt;SetStatus(errors::Internal(</td></tr>
<tr><th id="191">191</th><td>            <q>"Blas GEMV with profiling launch failed:  m="</q>, m, <q>", n="</q>, n));</td></tr>
<tr><th id="192">192</th><td>      }</td></tr>
<tr><th id="193">193</th><td>    }</td></tr>
<tr><th id="194">194</th><td>  }</td></tr>
<tr><th id="195">195</th><td></td></tr>
<tr><th id="196">196</th><td>  <em>static</em> <em>bool</em> IsSupported() { <b>return</b> <b>true</b>; }</td></tr>
<tr><th id="197">197</th><td>};</td></tr>
<tr><th id="198">198</th><td></td></tr>
<tr><th id="199">199</th><td><b>template</b> &lt;&gt;</td></tr>
<tr><th id="200">200</th><td><em>void</em> LaunchBlasGemv&lt;Eigen::half&gt;::Compute(</td></tr>
<tr><th id="201">201</th><td>    OpKernelContext* ctx, perftools::gputools::Stream* stream, <em>bool</em> trans,</td></tr>
<tr><th id="202">202</th><td>    uint64 m, uint64 n, <em>const</em> perftools::gputools::DeviceMemory&lt;Eigen::half&gt;&amp; a,</td></tr>
<tr><th id="203">203</th><td>    <em>const</em> perftools::gputools::DeviceMemory&lt;Eigen::half&gt;&amp; b,</td></tr>
<tr><th id="204">204</th><td>    perftools::gputools::DeviceMemory&lt;Eigen::half&gt;* c,</td></tr>
<tr><th id="205">205</th><td>    perftools::gputools::blas::ProfileResult* output_profile) {</td></tr>
<tr><th id="206">206</th><td>  ctx-&gt;SetStatus(errors::Internal(</td></tr>
<tr><th id="207">207</th><td>      <q>"Blas GEMV launch failed: GEMV is not implemented for float16."</q>));</td></tr>
<tr><th id="208">208</th><td>}</td></tr>
<tr><th id="209">209</th><td></td></tr>
<tr><th id="210">210</th><td><b>template</b> &lt;&gt;</td></tr>
<tr><th id="211">211</th><td><em>bool</em> LaunchBlasGemv&lt;Eigen::half&gt;::IsSupported() {</td></tr>
<tr><th id="212">212</th><td>  <b>return</b> <b>false</b>;</td></tr>
<tr><th id="213">213</th><td>}</td></tr>
<tr><th id="214">214</th><td></td></tr>
<tr><th id="215">215</th><td><b>template</b> &lt;<b>typename</b> T&gt;</td></tr>
<tr><th id="216">216</th><td><em>bool</em> ShouldUseGemv(uint64 n) {</td></tr>
<tr><th id="217">217</th><td>  <b>return</b> (LaunchBlasGemv&lt;T&gt;::IsSupported() &amp;&amp; n == <var>1</var>);</td></tr>
<tr><th id="218">218</th><td>}</td></tr>
<tr><th id="219">219</th><td></td></tr>
<tr><th id="220">220</th><td>}  <i>// namespace</i></td></tr>
<tr><th id="221">221</th><td></td></tr>
<tr><th id="222">222</th><td><em>bool</em> GetCublasAutotuneComputationType(</td></tr>
<tr><th id="223">223</th><td>    <em>const</em> DataType&amp; dtype,</td></tr>
<tr><th id="224">224</th><td>    perftools::gputools::blas::ComputationType* compute_type) {</td></tr>
<tr><th id="225">225</th><td>  <b>using</b> perftools::gputools::blas::ComputationType;</td></tr>
<tr><th id="226">226</th><td>  <em>bool</em> use_f32_for_f16_computation = MatmulDoFP32ComputationFP16Input();</td></tr>
<tr><th id="227">227</th><td>  <b>switch</b> (dtype) {</td></tr>
<tr><th id="228">228</th><td>    <b>case</b> DT_HALF:</td></tr>
<tr><th id="229">229</th><td>    <b>case</b> DT_BFLOAT16:</td></tr>
<tr><th id="230">230</th><td>      <b>if</b> (use_f32_for_f16_computation) {</td></tr>
<tr><th id="231">231</th><td>        *compute_type = ComputationType::kF32;</td></tr>
<tr><th id="232">232</th><td>      } <b>else</b> {</td></tr>
<tr><th id="233">233</th><td>        *compute_type = ComputationType::kF16;</td></tr>
<tr><th id="234">234</th><td>      }</td></tr>
<tr><th id="235">235</th><td>      <b>return</b> <b>false</b>;</td></tr>
<tr><th id="236">236</th><td>    <b>case</b> DT_FLOAT:</td></tr>
<tr><th id="237">237</th><td>      *compute_type = ComputationType::kF32;</td></tr>
<tr><th id="238">238</th><td>      <b>return</b> <b>true</b>;</td></tr>
<tr><th id="239">239</th><td>    <b>case</b> DT_DOUBLE:</td></tr>
<tr><th id="240">240</th><td>      *compute_type = ComputationType::kF64;</td></tr>
<tr><th id="241">241</th><td>      <b>return</b> <b>true</b>;</td></tr>
<tr><th id="242">242</th><td>    <b>default</b>:</td></tr>
<tr><th id="243">243</th><td>      <i>// Unsupported compute_type, return false.</i></td></tr>
<tr><th id="244">244</th><td>      <b>return</b> <b>false</b>;</td></tr>
<tr><th id="245">245</th><td>  }</td></tr>
<tr><th id="246">246</th><td>}</td></tr>
<tr><th id="247">247</th><td></td></tr>
<tr><th id="248">248</th><td><i>// A dummy type to group matmul autotune results together.</i></td></tr>
<tr><th id="249">249</th><td><b>struct</b> MatmulAutoTuneGroup {</td></tr>
<tr><th id="250">250</th><td>  <em>static</em> string name() { <b>return</b> <q>"Matmul"</q>; }</td></tr>
<tr><th id="251">251</th><td>};</td></tr>
<tr><th id="252">252</th><td><b>typedef</b> AutoTuneSingleton&lt;MatmulAutoTuneGroup, MatmulParameters,</td></tr>
<tr><th id="253">253</th><td>                          perftools::gputools::blas::AlgorithmConfig&gt;</td></tr>
<tr><th id="254">254</th><td>    AutoTuneMatmul;</td></tr>
<tr><th id="255">255</th><td></td></tr>
<tr><th id="256">256</th><td><b>template</b> &lt;<b>typename</b> T&gt;</td></tr>
<tr><th id="257">257</th><td><b>struct</b> LaunchMatMul&lt;GPUDevice, T, <b>true</b> <i>/* USE_CUBLAS */</i>&gt; {</td></tr>
<tr><th id="258">258</th><td>  <em>static</em> <em>void</em> launch(</td></tr>
<tr><th id="259">259</th><td>      OpKernelContext* ctx, <em>const</em> Tensor&amp; a, <em>const</em> Tensor&amp; b,</td></tr>
<tr><th id="260">260</th><td>      <em>const</em> Eigen::array&lt;Eigen::IndexPair&lt;Eigen::DenseIndex&gt;, <var>1</var>&gt;&amp; dim_pair,</td></tr>
<tr><th id="261">261</th><td>      std::vector&lt;int64&gt;* algorithms, <em>bool</em> use_autotune, Tensor* out) {</td></tr>
<tr><th id="262">262</th><td>    <b>using</b> perftools::gputools::blas::AlgorithmConfig;</td></tr>
<tr><th id="263">263</th><td>    <b>using</b> perftools::gputools::blas::ComputationType;</td></tr>
<tr><th id="264">264</th><td>    <b>using</b> perftools::gputools::blas::kDefaultAlgorithm;</td></tr>
<tr><th id="265">265</th><td>    <b>using</b> perftools::gputools::blas::kDefaultBlasGemm;</td></tr>
<tr><th id="266">266</th><td>    <b>using</b> perftools::gputools::blas::kDefaultBlasGemv;</td></tr>
<tr><th id="267">267</th><td>    <b>using</b> perftools::gputools::blas::kNoAlgorithm;</td></tr>
<tr><th id="268">268</th><td>    <b>using</b> perftools::gputools::blas::ProfileResult;</td></tr>
<tr><th id="269">269</th><td>    <b>using</b> perftools::gputools::blas::Transpose;</td></tr>
<tr><th id="270">270</th><td>    Transpose trans[] = {Transpose::kNoTranspose, Transpose::kTranspose};</td></tr>
<tr><th id="271">271</th><td>    <em>const</em> uint64 m = a.dim_size(<var>1</var> - dim_pair[<var>0</var>].first);</td></tr>
<tr><th id="272">272</th><td>    <em>const</em> uint64 k = a.dim_size(dim_pair[<var>0</var>].first);</td></tr>
<tr><th id="273">273</th><td>    <em>const</em> uint64 n = b.dim_size(<var>1</var> - dim_pair[<var>0</var>].second);</td></tr>
<tr><th id="274">274</th><td>    <em>bool</em> transpose_a = dim_pair[<var>0</var>].first == <var>0</var>;</td></tr>
<tr><th id="275">275</th><td>    <em>bool</em> transpose_b = dim_pair[<var>0</var>].second == <var>1</var>;</td></tr>
<tr><th id="276">276</th><td>    <em>auto</em> blas_transpose_a = trans[transpose_a];</td></tr>
<tr><th id="277">277</th><td>    <em>auto</em> blas_transpose_b = trans[transpose_b];</td></tr>
<tr><th id="278">278</th><td></td></tr>
<tr><th id="279">279</th><td>    <em>auto</em>* stream = ctx-&gt;op_device_context()-&gt;stream();</td></tr>
<tr><th id="280">280</th><td>    OP_REQUIRES(ctx, stream, errors::Internal(<q>"No GPU stream available."</q>));</td></tr>
<tr><th id="281">281</th><td></td></tr>
<tr><th id="282">282</th><td>    <em>auto</em> a_ptr = AsDeviceMemory(a.<b>template</b> flat&lt;T&gt;().data(),</td></tr>
<tr><th id="283">283</th><td>                                a.<b>template</b> flat&lt;T&gt;().size());</td></tr>
<tr><th id="284">284</th><td>    <em>auto</em> b_ptr = AsDeviceMemory(b.<b>template</b> flat&lt;T&gt;().data(),</td></tr>
<tr><th id="285">285</th><td>                                b.<b>template</b> flat&lt;T&gt;().size());</td></tr>
<tr><th id="286">286</th><td>    <em>auto</em> c_ptr = AsDeviceMemory(out-&gt;<b>template</b> flat&lt;T&gt;().data(),</td></tr>
<tr><th id="287">287</th><td>                                out-&gt;<b>template</b> flat&lt;T&gt;().size());</td></tr>
<tr><th id="288">288</th><td>    <em>auto</em> alpha = <b>static_cast</b>&lt;T&gt;(<var>1.0</var>);</td></tr>
<tr><th id="289">289</th><td>    <em>auto</em> beta = <b>static_cast</b>&lt;T&gt;(<var>0.0</var>);</td></tr>
<tr><th id="290">290</th><td></td></tr>
<tr><th id="291">291</th><td>    <em>int</em> device_id = stream-&gt;parent()-&gt;device_ordinal();</td></tr>
<tr><th id="292">292</th><td>    DataType dtype = a.dtype();</td></tr>
<tr><th id="293">293</th><td>    MatmulParameters matmul_parameters = {</td></tr>
<tr><th id="294">294</th><td>        transpose_a, transpose_b, m, n, k, dtype, device_id,</td></tr>
<tr><th id="295">295</th><td>    };</td></tr>
<tr><th id="296">296</th><td>    AlgorithmConfig algorithm_config(kNoAlgorithm);</td></tr>
<tr><th id="297">297</th><td></td></tr>
<tr><th id="298">298</th><td>    ComputationType computation_type;</td></tr>
<tr><th id="299">299</th><td>    <em>bool</em> compute_type_supported =</td></tr>
<tr><th id="300">300</th><td>        GetCublasAutotuneComputationType(dtype, &amp;computation_type);</td></tr>
<tr><th id="301">301</th><td>    <b>if</b> (use_autotune &amp;&amp; compute_type_supported &amp;&amp; !algorithms-&gt;empty()) {</td></tr>
<tr><th id="302">302</th><td>      ProfileResult best_result;</td></tr>
<tr><th id="303">303</th><td>      <i>// TODO(yangzihao): Unify this code with conv autotuning.</i></td></tr>
<tr><th id="304">304</th><td>      <b>if</b> (!AutoTuneMatmul::GetInstance()-&gt;Find(matmul_parameters,</td></tr>
<tr><th id="305">305</th><td>                                               &amp;algorithm_config)) {</td></tr>
<tr><th id="306">306</th><td>        ProfileResult profile_result;</td></tr>
<tr><th id="307">307</th><td>        <b>for</b> (<em>auto</em> profile_algorithm : (*algorithms)) {</td></tr>
<tr><th id="308">308</th><td>          <i>// Cublas does</i></td></tr>
<tr><th id="309">309</th><td><i>          // C = A x B</i></td></tr>
<tr><th id="310">310</th><td><i>          // where A, B and C are assumed to be in column major.</i></td></tr>
<tr><th id="311">311</th><td><i>          // We want the output to be in row-major, so we can compute</i></td></tr>
<tr><th id="312">312</th><td><i>          // C' = B' x A' (' stands for transpose)</i></td></tr>
<tr><th id="313">313</th><td>          <em>bool</em> cublas_launch_status =</td></tr>
<tr><th id="314">314</th><td>              stream</td></tr>
<tr><th id="315">315</th><td>                  -&gt;ThenBlasGemmWithAlgorithm(</td></tr>
<tr><th id="316">316</th><td>                      blas_transpose_b, blas_transpose_a, n, m, k, alpha, b_ptr,</td></tr>
<tr><th id="317">317</th><td>                      transpose_b ? k : n, a_ptr, transpose_a ? m : k, beta,</td></tr>
<tr><th id="318">318</th><td>                      &amp;c_ptr, n, computation_type, profile_algorithm,</td></tr>
<tr><th id="319">319</th><td>                      &amp;profile_result)</td></tr>
<tr><th id="320">320</th><td>                  .ok();</td></tr>
<tr><th id="321">321</th><td>          <b>if</b> (cublas_launch_status) {</td></tr>
<tr><th id="322">322</th><td>            <b>if</b> (profile_result.is_valid()) {</td></tr>
<tr><th id="323">323</th><td>              <b>if</b> (profile_result.elapsed_time_in_ms() &lt;</td></tr>
<tr><th id="324">324</th><td>                  best_result.elapsed_time_in_ms()) {</td></tr>
<tr><th id="325">325</th><td>                best_result = profile_result;</td></tr>
<tr><th id="326">326</th><td>              }</td></tr>
<tr><th id="327">327</th><td>            }</td></tr>
<tr><th id="328">328</th><td>          }</td></tr>
<tr><th id="329">329</th><td>        }</td></tr>
<tr><th id="330">330</th><td>        <i>// Try BlasGemmWithProfiling</i></td></tr>
<tr><th id="331">331</th><td>        <em>bool</em> cublas_launch_status =</td></tr>
<tr><th id="332">332</th><td>            stream</td></tr>
<tr><th id="333">333</th><td>                -&gt;ThenBlasGemmWithProfiling(</td></tr>
<tr><th id="334">334</th><td>                    blas_transpose_b, blas_transpose_a, n, m, k, <var>1.0</var>, b_ptr,</td></tr>
<tr><th id="335">335</th><td>                    transpose_b ? k : n, a_ptr, transpose_a ? m : k, <var>0.0</var>,</td></tr>
<tr><th id="336">336</th><td>                    &amp;c_ptr, n, &amp;profile_result)</td></tr>
<tr><th id="337">337</th><td>                .ok();</td></tr>
<tr><th id="338">338</th><td>        <b>if</b> (cublas_launch_status) {</td></tr>
<tr><th id="339">339</th><td>          <b>if</b> (profile_result.is_valid()) {</td></tr>
<tr><th id="340">340</th><td>            <b>if</b> (profile_result.elapsed_time_in_ms() &lt;</td></tr>
<tr><th id="341">341</th><td>                best_result.elapsed_time_in_ms()) {</td></tr>
<tr><th id="342">342</th><td>              best_result = profile_result;</td></tr>
<tr><th id="343">343</th><td>            }</td></tr>
<tr><th id="344">344</th><td>          }</td></tr>
<tr><th id="345">345</th><td>        }</td></tr>
<tr><th id="346">346</th><td>        <i>// Try BlasGemvWithProfiling</i></td></tr>
<tr><th id="347">347</th><td>        <b>if</b> (ShouldUseGemv&lt;T&gt;(n)) {</td></tr>
<tr><th id="348">348</th><td>          LaunchBlasGemv&lt;T&gt;::Compute(ctx, stream, !transpose_a,</td></tr>
<tr><th id="349">349</th><td>                                     transpose_a ? m : k, transpose_a ? k : m,</td></tr>
<tr><th id="350">350</th><td>                                     a_ptr, b_ptr, &amp;c_ptr, &amp;profile_result);</td></tr>
<tr><th id="351">351</th><td>          <b>if</b> (profile_result.is_valid()) {</td></tr>
<tr><th id="352">352</th><td>            <b>if</b> (profile_result.elapsed_time_in_ms() &lt;</td></tr>
<tr><th id="353">353</th><td>                best_result.elapsed_time_in_ms()) {</td></tr>
<tr><th id="354">354</th><td>              best_result = profile_result;</td></tr>
<tr><th id="355">355</th><td>            }</td></tr>
<tr><th id="356">356</th><td>          }</td></tr>
<tr><th id="357">357</th><td>        }</td></tr>
<tr><th id="358">358</th><td>      }</td></tr>
<tr><th id="359">359</th><td>      <i>// We make sure that each matmul parameter set only gets one pass of</i></td></tr>
<tr><th id="360">360</th><td><i>      // autotune. If the best result is found, assign it to algorithm_type</i></td></tr>
<tr><th id="361">361</th><td><i>      // and insert it to autotune map. If all internal kernels of</i></td></tr>
<tr><th id="362">362</th><td><i>      // cublasGemmEx() returns invalid results, we add kNoAlgorithm to the</i></td></tr>
<tr><th id="363">363</th><td><i>      // autotune map.</i></td></tr>
<tr><th id="364">364</th><td>      <b>if</b> (best_result.is_valid()) {</td></tr>
<tr><th id="365">365</th><td>        algorithm_config.set_algorithm(best_result.algorithm());</td></tr>
<tr><th id="366">366</th><td>      }</td></tr>
<tr><th id="367">367</th><td>      AutoTuneMatmul::GetInstance()-&gt;Insert(matmul_parameters,</td></tr>
<tr><th id="368">368</th><td>                                            algorithm_config);</td></tr>
<tr><th id="369">369</th><td>      <b>if</b> (algorithm_config.algorithm() != kNoAlgorithm &amp;&amp;</td></tr>
<tr><th id="370">370</th><td>          algorithm_config.algorithm() != kDefaultBlasGemm &amp;&amp;</td></tr>
<tr><th id="371">371</th><td>          algorithm_config.algorithm() != kDefaultBlasGemv) {</td></tr>
<tr><th id="372">372</th><td>        <em>bool</em> cublas_launch_status =</td></tr>
<tr><th id="373">373</th><td>            stream</td></tr>
<tr><th id="374">374</th><td>                -&gt;ThenBlasGemmWithAlgorithm(</td></tr>
<tr><th id="375">375</th><td>                    blas_transpose_b, blas_transpose_a, n, m, k, alpha, b_ptr,</td></tr>
<tr><th id="376">376</th><td>                    transpose_b ? k : n, a_ptr, transpose_a ? m : k, beta,</td></tr>
<tr><th id="377">377</th><td>                    &amp;c_ptr, n, computation_type, algorithm_config.algorithm(),</td></tr>
<tr><th id="378">378</th><td>                    <b>nullptr</b>)</td></tr>
<tr><th id="379">379</th><td>                .ok();</td></tr>
<tr><th id="380">380</th><td>        <b>if</b> (!cublas_launch_status) {</td></tr>
<tr><th id="381">381</th><td>          ctx-&gt;SetStatus(errors::Internal(</td></tr>
<tr><th id="382">382</th><td>              <q>"Blas GEMM with algorithm launch failed : a.shape=("</q>,</td></tr>
<tr><th id="383">383</th><td>              a.dim_size(<var>0</var>), <q>", "</q>, a.dim_size(<var>1</var>), <q>"), b.shape=("</q>, b.dim_size(<var>0</var>),</td></tr>
<tr><th id="384">384</th><td>              <q>", "</q>, b.dim_size(<var>1</var>), <q>"), m="</q>, m, <q>", n="</q>, n, <q>", k="</q>, k));</td></tr>
<tr><th id="385">385</th><td>        }</td></tr>
<tr><th id="386">386</th><td>      }</td></tr>
<tr><th id="387">387</th><td>    }</td></tr>
<tr><th id="388">388</th><td>    <i>// For the following case, we use normal BlasGemm():</i></td></tr>
<tr><th id="389">389</th><td><i>    //  1) We didn't set the use_autotune flag;</i></td></tr>
<tr><th id="390">390</th><td><i>    //  2) compute type does not support autotune;</i></td></tr>
<tr><th id="391">391</th><td><i>    //  3) no algorithm is found;</i></td></tr>
<tr><th id="392">392</th><td><i>    //  4) all internal kernels in autotune return invalid results.</i></td></tr>
<tr><th id="393">393</th><td><i>    //  For the following case, we use normal BlasGemv():</i></td></tr>
<tr><th id="394">394</th><td><i>    //  1) We didn't set the use_autotune flag but LaunchBlasGemv is supported</i></td></tr>
<tr><th id="395">395</th><td><i>    //     and n == 1.</i></td></tr>
<tr><th id="396">396</th><td><i>    //  2) We set the use_autotune flag and it picked up BlasGemv() and set the</i></td></tr>
<tr><th id="397">397</th><td><i>    //     algorithm_config.algorithm() to be kDefaultBlasGemv.</i></td></tr>
<tr><th id="398">398</th><td>    <b>if</b> (!use_autotune || !compute_type_supported || algorithms-&gt;empty() ||</td></tr>
<tr><th id="399">399</th><td>        algorithm_config.algorithm() == kNoAlgorithm ||</td></tr>
<tr><th id="400">400</th><td>        algorithm_config.algorithm() == kDefaultBlasGemm ||</td></tr>
<tr><th id="401">401</th><td>        algorithm_config.algorithm() == kDefaultBlasGemv) {</td></tr>
<tr><th id="402">402</th><td>      <b>if</b> (algorithm_config.algorithm() == kDefaultBlasGemv ||</td></tr>
<tr><th id="403">403</th><td>          ShouldUseGemv&lt;T&gt;(n)) {</td></tr>
<tr><th id="404">404</th><td>        <i>// This is a matrix*vector multiply so use GEMV to compute A * b.</i></td></tr>
<tr><th id="405">405</th><td><i>        // Here we are multiplying in the natural order, so we have to flip</i></td></tr>
<tr><th id="406">406</th><td><i>        // the transposition flag to compensate for the tensor being stored</i></td></tr>
<tr><th id="407">407</th><td><i>        // row-major.</i></td></tr>
<tr><th id="408">408</th><td><i>        // TODO(yangzihao): Add Gemv as an autotuning option too.</i></td></tr>
<tr><th id="409">409</th><td>        LaunchBlasGemv&lt;T&gt;::Compute(ctx, stream, !transpose_a,</td></tr>
<tr><th id="410">410</th><td>                                   transpose_a ? m : k, transpose_a ? k : m,</td></tr>
<tr><th id="411">411</th><td>                                   a_ptr, b_ptr, &amp;c_ptr, <b>nullptr</b>);</td></tr>
<tr><th id="412">412</th><td>      } <b>else</b> {</td></tr>
<tr><th id="413">413</th><td>        <i>// Use C' = B' x A' (' stands for transpose)</i></td></tr>
<tr><th id="414">414</th><td>        <em>bool</em> blas_launch_status =</td></tr>
<tr><th id="415">415</th><td>            stream</td></tr>
<tr><th id="416">416</th><td>                -&gt;ThenBlasGemm(blas_transpose_b, blas_transpose_a, n, m, k,</td></tr>
<tr><th id="417">417</th><td>                               <var>1.0f</var>, b_ptr, transpose_b ? k : n, a_ptr,</td></tr>
<tr><th id="418">418</th><td>                               transpose_a ? m : k, <var>0.0f</var>, &amp;c_ptr, n)</td></tr>
<tr><th id="419">419</th><td>                .ok();</td></tr>
<tr><th id="420">420</th><td>        <b>if</b> (!blas_launch_status) {</td></tr>
<tr><th id="421">421</th><td>          ctx-&gt;SetStatus(errors::Internal(</td></tr>
<tr><th id="422">422</th><td>              <q>"Blas GEMM launch failed : a.shape=("</q>, a.dim_size(<var>0</var>), <q>", "</q>,</td></tr>
<tr><th id="423">423</th><td>              a.dim_size(<var>1</var>), <q>"), b.shape=("</q>, b.dim_size(<var>0</var>), <q>", "</q>, b.dim_size(<var>1</var>),</td></tr>
<tr><th id="424">424</th><td>              <q>"), m="</q>, m, <q>", n="</q>, n, <q>", k="</q>, k));</td></tr>
<tr><th id="425">425</th><td>        }</td></tr>
<tr><th id="426">426</th><td>      }</td></tr>
<tr><th id="427">427</th><td>    }</td></tr>
<tr><th id="428">428</th><td>  }</td></tr>
<tr><th id="429">429</th><td></td></tr>
<tr><th id="430">430</th><td>  <em>static</em> <em>void</em> GetBlasGemmAlgorithm(OpKernelConstruction* ctx,</td></tr>
<tr><th id="431">431</th><td>                                   std::vector&lt;int64&gt;* algorithms,</td></tr>
<tr><th id="432">432</th><td>                                   <em>bool</em>* algorithm_set_flag) {</td></tr>
<tr><th id="433">433</th><td>    <b>if</b> (*algorithm_set_flag == <b>false</b>) {</td></tr>
<tr><th id="434">434</th><td>      <em>auto</em>* stream = ctx-&gt;device()-&gt;tensorflow_gpu_device_info()-&gt;stream;</td></tr>
<tr><th id="435">435</th><td>      stream-&gt;parent()-&gt;GetBlasGemmAlgorithms(algorithms);</td></tr>
<tr><th id="436">436</th><td>      *algorithm_set_flag = <b>true</b>;</td></tr>
<tr><th id="437">437</th><td>    }</td></tr>
<tr><th id="438">438</th><td>  }</td></tr>
<tr><th id="439">439</th><td>};</td></tr>
<tr><th id="440">440</th><td></td></tr>
<tr><th id="441">441</th><td><u>#<span data-ppcond="157">endif</span>  // GOOGLE_CUDA</u></td></tr>
<tr><th id="442">442</th><td></td></tr>
<tr><th id="443">443</th><td><b>template</b> &lt;<b>typename</b> Device, <b>typename</b> T, <em>bool</em> USE_CUBLAS&gt;</td></tr>
<tr><th id="444">444</th><td><b>class</b> <dfn class="type def" id="tensorflow::MatMulOp" title='tensorflow::MatMulOp' data-ref="tensorflow::MatMulOp">MatMulOp</dfn> : <b>public</b> <a class="type" href="../framework/op_kernel.h.html#tensorflow::OpKernel" title='tensorflow::OpKernel' data-ref="tensorflow::OpKernel">OpKernel</a> {</td></tr>
<tr><th id="445">445</th><td> <b>public</b>:</td></tr>
<tr><th id="446">446</th><td>  <b>explicit</b> <dfn class="tu decl def" id="_ZN10tensorflow8MatMulOpC1EPNS_20OpKernelConstructionE" title='tensorflow::MatMulOp::MatMulOp&lt;Device, T, USE_CUBLAS&gt;' data-type='void tensorflow::MatMulOp::MatMulOp&lt;Device, T, USE_CUBLAS&gt;(tensorflow::OpKernelConstruction * ctx)' data-ref="_ZN10tensorflow8MatMulOpC1EPNS_20OpKernelConstructionE">MatMulOp</dfn>(<a class="type" href="../framework/op_kernel.h.html#tensorflow::OpKernelConstruction" title='tensorflow::OpKernelConstruction' data-ref="tensorflow::OpKernelConstruction">OpKernelConstruction</a>* <dfn class="local col2 decl" id="42ctx" title='ctx' data-type='tensorflow::OpKernelConstruction *' data-ref="42ctx">ctx</dfn>)</td></tr>
<tr><th id="447">447</th><td>      : <a class="type" href="../framework/op_kernel.h.html#tensorflow::OpKernel" title='tensorflow::OpKernel' data-ref="tensorflow::OpKernel">OpKernel</a>(<a class="local col2 ref" href="#42ctx" title='ctx' data-ref="42ctx">ctx</a>), <a class="tu member" href="#tensorflow::MatMulOp::algorithms_set_already_" title='tensorflow::MatMulOp::algorithms_set_already_' data-use='w' data-ref="tensorflow::MatMulOp::algorithms_set_already_">algorithms_set_already_</a>(<b>false</b>) {</td></tr>
<tr><th id="448">448</th><td>    <a class="macro" href="../framework/op_kernel.h.html#1545" title="do { ::tensorflow::Status _s(ctx-&gt;GetAttr(&quot;transpose_a&quot;, &amp;transpose_a_)); if (!(__builtin_expect(!!(_s.ok()), 1))) { (ctx)-&gt;CtxFailureWithWarning(&quot;/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/tensorflow/core/kernels/matmul_op.cc&quot;, 448, _s); return; } } while (0)" data-ref="_M/OP_REQUIRES_OK">OP_REQUIRES_OK</a>(<a class="local col2 ref" href="#42ctx" title='ctx' data-ref="42ctx">ctx</a>, <a class="local col2 ref" href="#42ctx" title='ctx' data-ref="42ctx">ctx</a>-&gt;GetAttr(<q>"transpose_a"</q>, &amp;<a class="tu member" href="#tensorflow::MatMulOp::transpose_a_" title='tensorflow::MatMulOp::transpose_a_' data-use='a' data-ref="tensorflow::MatMulOp::transpose_a_">transpose_a_</a>));</td></tr>
<tr><th id="449">449</th><td>    <a class="macro" href="../framework/op_kernel.h.html#1545" title="do { ::tensorflow::Status _s(ctx-&gt;GetAttr(&quot;transpose_b&quot;, &amp;transpose_b_)); if (!(__builtin_expect(!!(_s.ok()), 1))) { (ctx)-&gt;CtxFailureWithWarning(&quot;/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/tensorflow/core/kernels/matmul_op.cc&quot;, 449, _s); return; } } while (0)" data-ref="_M/OP_REQUIRES_OK">OP_REQUIRES_OK</a>(<a class="local col2 ref" href="#42ctx" title='ctx' data-ref="42ctx">ctx</a>, <a class="local col2 ref" href="#42ctx" title='ctx' data-ref="42ctx">ctx</a>-&gt;GetAttr(<q>"transpose_b"</q>, &amp;<a class="tu member" href="#tensorflow::MatMulOp::transpose_b_" title='tensorflow::MatMulOp::transpose_b_' data-use='a' data-ref="tensorflow::MatMulOp::transpose_b_">transpose_b_</a>));</td></tr>
<tr><th id="450">450</th><td></td></tr>
<tr><th id="451">451</th><td>    <a class="type" href="#tensorflow::LaunchMatMul" title='tensorflow::LaunchMatMul' data-ref="tensorflow::LaunchMatMul">LaunchMatMul</a>&lt;Device, T, <a class="tu member" href="#tensorflow::MatMulOp::USE_CUBLAS" title='tensorflow::MatMulOp::USE_CUBLAS' data-use='c' data-ref="tensorflow::MatMulOp::USE_CUBLAS">USE_CUBLAS</a>&gt;::GetBlasGemmAlgorithm(</td></tr>
<tr><th id="452">452</th><td>        <a class="local col2 ref" href="#42ctx" title='ctx' data-ref="42ctx">ctx</a>, &amp;<a class="tu member" href="#tensorflow::MatMulOp::algorithms_" title='tensorflow::MatMulOp::algorithms_' data-use='a' data-ref="tensorflow::MatMulOp::algorithms_">algorithms_</a>, &amp;<a class="tu member" href="#tensorflow::MatMulOp::algorithms_set_already_" title='tensorflow::MatMulOp::algorithms_set_already_' data-use='a' data-ref="tensorflow::MatMulOp::algorithms_set_already_">algorithms_set_already_</a>);</td></tr>
<tr><th id="453">453</th><td>    <a class="tu member" href="#tensorflow::MatMulOp::use_autotune_" title='tensorflow::MatMulOp::use_autotune_' data-use='w' data-ref="tensorflow::MatMulOp::use_autotune_">use_autotune_</a> = <a class="ref" href="../util/matmul_autotune.h.html#_ZN10tensorflow20MatmulAutotuneEnableEv" title='tensorflow::MatmulAutotuneEnable' data-ref="_ZN10tensorflow20MatmulAutotuneEnableEv">MatmulAutotuneEnable</a>();</td></tr>
<tr><th id="454">454</th><td>  }</td></tr>
<tr><th id="455">455</th><td></td></tr>
<tr><th id="456">456</th><td>  <em>void</em> <dfn class="virtual decl def" id="_ZN10tensorflow8MatMulOp7ComputeEPNS_15OpKernelContextE" title='tensorflow::MatMulOp::Compute' data-ref="_ZN10tensorflow8MatMulOp7ComputeEPNS_15OpKernelContextE">Compute</dfn>(<a class="type" href="../framework/op_kernel.h.html#tensorflow::OpKernelContext" title='tensorflow::OpKernelContext' data-ref="tensorflow::OpKernelContext">OpKernelContext</a>* <dfn class="local col3 decl" id="43ctx" title='ctx' data-type='tensorflow::OpKernelContext *' data-ref="43ctx">ctx</dfn>) override {</td></tr>
<tr><th id="457">457</th><td>    <em>const</em> <a class="type" href="../framework/tensor.h.html#tensorflow::Tensor" title='tensorflow::Tensor' data-ref="tensorflow::Tensor">Tensor</a>&amp; <dfn class="local col4 decl" id="44a" title='a' data-type='const tensorflow::Tensor &amp;' data-ref="44a">a</dfn> = <a class="local col3 ref" href="#43ctx" title='ctx' data-ref="43ctx">ctx</a>-&gt;<a class="ref" href="../framework/op_kernel.h.html#_ZN10tensorflow15OpKernelContext5inputEi" title='tensorflow::OpKernelContext::input' data-ref="_ZN10tensorflow15OpKernelContext5inputEi">input</a>(<var>0</var>);</td></tr>
<tr><th id="458">458</th><td>    <em>const</em> <a class="type" href="../framework/tensor.h.html#tensorflow::Tensor" title='tensorflow::Tensor' data-ref="tensorflow::Tensor">Tensor</a>&amp; <dfn class="local col5 decl" id="45b" title='b' data-type='const tensorflow::Tensor &amp;' data-ref="45b">b</dfn> = <a class="local col3 ref" href="#43ctx" title='ctx' data-ref="43ctx">ctx</a>-&gt;<a class="ref" href="../framework/op_kernel.h.html#_ZN10tensorflow15OpKernelContext5inputEi" title='tensorflow::OpKernelContext::input' data-ref="_ZN10tensorflow15OpKernelContext5inputEi">input</a>(<var>1</var>);</td></tr>
<tr><th id="459">459</th><td></td></tr>
<tr><th id="460">460</th><td>    <i>// Check that the dimensions of the two matrices are valid.</i></td></tr>
<tr><th id="461">461</th><td>    <a class="macro" href="../framework/op_kernel.h.html#1537" title="do { if (!(__builtin_expect(!!(TensorShapeUtils::IsMatrix(a.shape())), 1))) { (ctx)-&gt;CtxFailure(&quot;/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/tensorflow/core/kernels/matmul_op.cc&quot;, 462, (errors::InvalidArgument(&quot;In[0] is not a matrix&quot;))); return; } } while (0)" data-ref="_M/OP_REQUIRES">OP_REQUIRES</a>(<a class="local col3 ref" href="#43ctx" title='ctx' data-ref="43ctx">ctx</a>, <a class="type" href="../framework/tensor_shape.h.html#tensorflow::TensorShapeUtils" title='tensorflow::TensorShapeUtils' data-ref="tensorflow::TensorShapeUtils">TensorShapeUtils</a>::<a class="ref" href="../framework/tensor_shape.h.html#_ZN10tensorflow16TensorShapeUtils8IsMatrixERKNS_11TensorShapeE" title='tensorflow::TensorShapeUtils::IsMatrix' data-ref="_ZN10tensorflow16TensorShapeUtils8IsMatrixERKNS_11TensorShapeE">IsMatrix</a>(<a class="local col4 ref" href="#44a" title='a' data-ref="44a">a</a>.<a class="ref" href="../framework/tensor.h.html#_ZNK10tensorflow6Tensor5shapeEv" title='tensorflow::Tensor::shape' data-ref="_ZNK10tensorflow6Tensor5shapeEv">shape</a>()),</td></tr>
<tr><th id="462">462</th><td>                errors::<a class="ref" href="../lib/core/errors.h.html#103" title='tensorflow::errors::InvalidArgument' data-ref="_ZN10tensorflow6errors15InvalidArgumentEDpT_">InvalidArgument</a>(<q>"In[0] is not a matrix"</q>));</td></tr>
<tr><th id="463">463</th><td>    <a class="macro" href="../framework/op_kernel.h.html#1537" title="do { if (!(__builtin_expect(!!(TensorShapeUtils::IsMatrix(b.shape())), 1))) { (ctx)-&gt;CtxFailure(&quot;/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/tensorflow/core/kernels/matmul_op.cc&quot;, 464, (errors::InvalidArgument(&quot;In[1] is not a matrix&quot;))); return; } } while (0)" data-ref="_M/OP_REQUIRES">OP_REQUIRES</a>(<a class="local col3 ref" href="#43ctx" title='ctx' data-ref="43ctx">ctx</a>, <a class="type" href="../framework/tensor_shape.h.html#tensorflow::TensorShapeUtils" title='tensorflow::TensorShapeUtils' data-ref="tensorflow::TensorShapeUtils">TensorShapeUtils</a>::<a class="ref" href="../framework/tensor_shape.h.html#_ZN10tensorflow16TensorShapeUtils8IsMatrixERKNS_11TensorShapeE" title='tensorflow::TensorShapeUtils::IsMatrix' data-ref="_ZN10tensorflow16TensorShapeUtils8IsMatrixERKNS_11TensorShapeE">IsMatrix</a>(<a class="local col5 ref" href="#45b" title='b' data-ref="45b">b</a>.<a class="ref" href="../framework/tensor.h.html#_ZNK10tensorflow6Tensor5shapeEv" title='tensorflow::Tensor::shape' data-ref="_ZNK10tensorflow6Tensor5shapeEv">shape</a>()),</td></tr>
<tr><th id="464">464</th><td>                errors::<a class="ref" href="../lib/core/errors.h.html#103" title='tensorflow::errors::InvalidArgument' data-ref="_ZN10tensorflow6errors15InvalidArgumentEDpT_">InvalidArgument</a>(<q>"In[1] is not a matrix"</q>));</td></tr>
<tr><th id="465">465</th><td>    <span class="namespace">Eigen::</span><span class='type' title='Eigen::array' data-ref="Eigen::array">array</span>&lt;<span class="namespace">Eigen::</span><span class='type' title='Eigen::IndexPair' data-ref="Eigen::IndexPair">IndexPair</span>&lt;<span class="namespace">Eigen::</span><span class='typedef' title='Eigen::DenseIndex' data-type='std::ptrdiff_t' data-ref="Eigen::DenseIndex">DenseIndex</span>&gt;, <var>1</var>&gt; <span class='ref fake' title='Eigen::array::array&lt;T, n&gt;' data-ref="_ZN5Eigen5arrayC1Ev"></span><dfn class="local col6 decl" id="46dim_pair" title='dim_pair' data-type='Eigen::array&lt;Eigen::IndexPair&lt;Eigen::DenseIndex&gt;, 1&gt;' data-ref="46dim_pair">dim_pair</dfn>;</td></tr>
<tr><th id="466">466</th><td>    <a class="local col6 ref" href="#46dim_pair" title='dim_pair' data-ref="46dim_pair">dim_pair</a><span class='ref' title='Eigen::array::operator[]' data-ref="_ZN5Eigen5arrayixEm">[<var>0</var>]</span>.<span class='ref' title='Eigen::IndexPair&lt;long&gt;::first' data-ref="Eigen::IndexPair::first">first</span> = <a class="tu member" href="#tensorflow::MatMulOp::transpose_a_" title='tensorflow::MatMulOp::transpose_a_' data-use='r' data-ref="tensorflow::MatMulOp::transpose_a_">transpose_a_</a> ? <var>0</var> : <var>1</var>;</td></tr>
<tr><th id="467">467</th><td>    <a class="local col6 ref" href="#46dim_pair" title='dim_pair' data-ref="46dim_pair">dim_pair</a><span class='ref' title='Eigen::array::operator[]' data-ref="_ZN5Eigen5arrayixEm">[<var>0</var>]</span>.<span class='ref' title='Eigen::IndexPair&lt;long&gt;::second' data-ref="Eigen::IndexPair::second">second</span> = <a class="tu member" href="#tensorflow::MatMulOp::transpose_b_" title='tensorflow::MatMulOp::transpose_b_' data-use='r' data-ref="tensorflow::MatMulOp::transpose_b_">transpose_b_</a> ? <var>1</var> : <var>0</var>;</td></tr>
<tr><th id="468">468</th><td></td></tr>
<tr><th id="469">469</th><td>    <a class="macro" href="../framework/op_kernel.h.html#1537" title="do { if (!(__builtin_expect(!!(a.dim_size(dim_pair[0].first) == b.dim_size(dim_pair[0].second)), 1))) { (ctx)-&gt;CtxFailure(&quot;/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/tensorflow/core/kernels/matmul_op.cc&quot;, 473, (errors::InvalidArgument( &quot;Matrix size-incompatible: In[0]: &quot;, a.shape().DebugString(), &quot;, In[1]: &quot;, b.shape().DebugString()))); return; } } while (0)" data-ref="_M/OP_REQUIRES">OP_REQUIRES</a>(</td></tr>
<tr><th id="470">470</th><td>        <a class="local col3 ref" href="#43ctx" title='ctx' data-ref="43ctx">ctx</a>, <a class="local col4 ref" href="#44a" title='a' data-ref="44a">a</a>.<a class="ref" href="../framework/tensor.h.html#_ZNK10tensorflow6Tensor8dim_sizeEi" title='tensorflow::Tensor::dim_size' data-ref="_ZNK10tensorflow6Tensor8dim_sizeEi">dim_size</a>(<a class="local col6 ref" href="#46dim_pair" title='dim_pair' data-ref="46dim_pair">dim_pair</a>[<var>0</var>].<span class='ref' title='Eigen::IndexPair&lt;long&gt;::first' data-ref="Eigen::IndexPair::first">first</span>) == <a class="local col5 ref" href="#45b" title='b' data-ref="45b">b</a>.<a class="ref" href="../framework/tensor.h.html#_ZNK10tensorflow6Tensor8dim_sizeEi" title='tensorflow::Tensor::dim_size' data-ref="_ZNK10tensorflow6Tensor8dim_sizeEi">dim_size</a>(<a class="local col6 ref" href="#46dim_pair" title='dim_pair' data-ref="46dim_pair">dim_pair</a>[<var>0</var>].<span class='ref' title='Eigen::IndexPair&lt;long&gt;::second' data-ref="Eigen::IndexPair::second">second</span>),</td></tr>
<tr><th id="471">471</th><td>        errors::<a class="ref" href="../lib/core/errors.h.html#103" title='tensorflow::errors::InvalidArgument' data-ref="_ZN10tensorflow6errors15InvalidArgumentEDpT_">InvalidArgument</a>(</td></tr>
<tr><th id="472">472</th><td>            <q>"Matrix size-incompatible: In[0]: "</q>, <a class="local col4 ref" href="#44a" title='a' data-ref="44a">a</a>.<a class="ref" href="../framework/tensor.h.html#_ZNK10tensorflow6Tensor5shapeEv" title='tensorflow::Tensor::shape' data-ref="_ZNK10tensorflow6Tensor5shapeEv">shape</a>().<a class="ref" href="../framework/tensor_shape.h.html#_ZNK10tensorflow14TensorShapeRep11DebugStringEv" title='tensorflow::TensorShapeRep::DebugString' data-ref="_ZNK10tensorflow14TensorShapeRep11DebugStringEv">DebugString</a>(),</td></tr>
<tr><th id="473">473</th><td>            <q>", In[1]: "</q>, <a class="local col5 ref" href="#45b" title='b' data-ref="45b">b</a>.<a class="ref" href="../framework/tensor.h.html#_ZNK10tensorflow6Tensor5shapeEv" title='tensorflow::Tensor::shape' data-ref="_ZNK10tensorflow6Tensor5shapeEv">shape</a>().<a class="ref" href="../framework/tensor_shape.h.html#_ZNK10tensorflow14TensorShapeRep11DebugStringEv" title='tensorflow::TensorShapeRep::DebugString' data-ref="_ZNK10tensorflow14TensorShapeRep11DebugStringEv">DebugString</a>()));</td></tr>
<tr><th id="474">474</th><td>    <em>int</em> <dfn class="local col7 decl" id="47a_dim_remaining" title='a_dim_remaining' data-type='int' data-ref="47a_dim_remaining">a_dim_remaining</dfn> = <var>1</var> - <a class="local col6 ref" href="#46dim_pair" title='dim_pair' data-ref="46dim_pair">dim_pair</a><span class='ref' title='Eigen::array::operator[]' data-ref="_ZN5Eigen5arrayixEm">[<var>0</var>]</span>.<span class='ref' title='Eigen::IndexPair&lt;long&gt;::first' data-ref="Eigen::IndexPair::first">first</span>;</td></tr>
<tr><th id="475">475</th><td>    <em>int</em> <dfn class="local col8 decl" id="48b_dim_remaining" title='b_dim_remaining' data-type='int' data-ref="48b_dim_remaining">b_dim_remaining</dfn> = <var>1</var> - <a class="local col6 ref" href="#46dim_pair" title='dim_pair' data-ref="46dim_pair">dim_pair</a><span class='ref' title='Eigen::array::operator[]' data-ref="_ZN5Eigen5arrayixEm">[<var>0</var>]</span>.<span class='ref' title='Eigen::IndexPair&lt;long&gt;::second' data-ref="Eigen::IndexPair::second">second</span>;</td></tr>
<tr><th id="476">476</th><td>    <a class="type" href="../framework/tensor_shape.h.html#tensorflow::TensorShape" title='tensorflow::TensorShape' data-ref="tensorflow::TensorShape">TensorShape</a> <dfn class="local col9 decl" id="49out_shape" title='out_shape' data-type='tensorflow::TensorShape' data-ref="49out_shape">out_shape</dfn><a class="ref" href="../framework/tensor_shape.h.html#291" title='tensorflow::TensorShape::TensorShape' data-ref="_ZN10tensorflow11TensorShapeC1ESt16initializer_listIxE">(</a></td></tr>
<tr><th id="477">477</th><td>        {<a class="local col4 ref" href="#44a" title='a' data-ref="44a">a</a>.<a class="ref" href="../framework/tensor.h.html#_ZNK10tensorflow6Tensor8dim_sizeEi" title='tensorflow::Tensor::dim_size' data-ref="_ZNK10tensorflow6Tensor8dim_sizeEi">dim_size</a>(<a class="local col7 ref" href="#47a_dim_remaining" title='a_dim_remaining' data-ref="47a_dim_remaining">a_dim_remaining</a>), <a class="local col5 ref" href="#45b" title='b' data-ref="45b">b</a>.<a class="ref" href="../framework/tensor.h.html#_ZNK10tensorflow6Tensor8dim_sizeEi" title='tensorflow::Tensor::dim_size' data-ref="_ZNK10tensorflow6Tensor8dim_sizeEi">dim_size</a>(<a class="local col8 ref" href="#48b_dim_remaining" title='b_dim_remaining' data-ref="48b_dim_remaining">b_dim_remaining</a>)});</td></tr>
<tr><th id="478">478</th><td>    <a class="type" href="../framework/tensor.h.html#tensorflow::Tensor" title='tensorflow::Tensor' data-ref="tensorflow::Tensor">Tensor</a>* <dfn class="local col0 decl" id="50out" title='out' data-type='tensorflow::Tensor *' data-ref="50out">out</dfn> = <b>nullptr</b>;</td></tr>
<tr><th id="479">479</th><td>    <a class="macro" href="../framework/op_kernel.h.html#1545" title="do { ::tensorflow::Status _s(ctx-&gt;allocate_output(0, out_shape, &amp;out)); if (!(__builtin_expect(!!(_s.ok()), 1))) { (ctx)-&gt;CtxFailureWithWarning(&quot;/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/tensorflow/core/kernels/matmul_op.cc&quot;, 479, _s); return; } } while (0)" data-ref="_M/OP_REQUIRES_OK">OP_REQUIRES_OK</a>(<a class="local col3 ref" href="#43ctx" title='ctx' data-ref="43ctx">ctx</a>, <a class="local col3 ref" href="#43ctx" title='ctx' data-ref="43ctx">ctx</a>-&gt;<a class="ref" href="../framework/op_kernel.h.html#_ZN10tensorflow15OpKernelContext15allocate_outputEiRKNS_11TensorShapeEPPNS_6TensorE" title='tensorflow::OpKernelContext::allocate_output' data-ref="_ZN10tensorflow15OpKernelContext15allocate_outputEiRKNS_11TensorShapeEPPNS_6TensorE">allocate_output</a>(<var>0</var>, <a class="local col9 ref" href="#49out_shape" title='out_shape' data-ref="49out_shape">out_shape</a>, &amp;<a class="local col0 ref" href="#50out" title='out' data-ref="50out">out</a>));</td></tr>
<tr><th id="480">480</th><td></td></tr>
<tr><th id="481">481</th><td>    <b>if</b> (<a class="local col0 ref" href="#50out" title='out' data-ref="50out">out</a>-&gt;<a class="ref" href="../framework/tensor.h.html#_ZNK10tensorflow6Tensor11NumElementsEv" title='tensorflow::Tensor::NumElements' data-ref="_ZNK10tensorflow6Tensor11NumElementsEv">NumElements</a>() == <var>0</var>) {</td></tr>
<tr><th id="482">482</th><td>      <i>// If a has shape [0, x] or b has shape [x, 0], the output shape</i></td></tr>
<tr><th id="483">483</th><td><i>      // is a 0-element matrix, so there is nothing to do.</i></td></tr>
<tr><th id="484">484</th><td>      <b>return</b>;</td></tr>
<tr><th id="485">485</th><td>    }</td></tr>
<tr><th id="486">486</th><td></td></tr>
<tr><th id="487">487</th><td>    <b>if</b> (<a class="local col4 ref" href="#44a" title='a' data-ref="44a">a</a>.<a class="ref" href="../framework/tensor.h.html#_ZNK10tensorflow6Tensor11NumElementsEv" title='tensorflow::Tensor::NumElements' data-ref="_ZNK10tensorflow6Tensor11NumElementsEv">NumElements</a>() == <var>0</var> || <a class="local col5 ref" href="#45b" title='b' data-ref="45b">b</a>.<a class="ref" href="../framework/tensor.h.html#_ZNK10tensorflow6Tensor11NumElementsEv" title='tensorflow::Tensor::NumElements' data-ref="_ZNK10tensorflow6Tensor11NumElementsEv">NumElements</a>() == <var>0</var>) {</td></tr>
<tr><th id="488">488</th><td>      <i>// If a has shape [x, 0] and b has shape [0, y], the</i></td></tr>
<tr><th id="489">489</th><td><i>      // output shape is [x, y] where x and y are non-zero, so we fill</i></td></tr>
<tr><th id="490">490</th><td><i>      // the output with zeros.</i></td></tr>
<tr><th id="491">491</th><td>      <span class="namespace">functor::</span><a class="type" href="fill_functor.h.html#tensorflow::functor::SetZeroFunctor" title='tensorflow::functor::SetZeroFunctor' data-ref="tensorflow::functor::SetZeroFunctor">SetZeroFunctor</a>&lt;Device, T&gt; <dfn class="local col1 decl" id="51f" title='f' data-type='functor::SetZeroFunctor&lt;Device, T&gt;' data-ref="51f">f</dfn>;</td></tr>
<tr><th id="492">492</th><td>      <a class="local col1 ref" href="#51f" title='f' data-ref="51f">f</a>(<a class="local col3 ref" href="#43ctx" title='ctx' data-ref="43ctx">ctx</a>-&gt;eigen_device&lt;Device&gt;(), <a class="local col0 ref" href="#50out" title='out' data-ref="50out">out</a>-&gt;flat&lt;T&gt;());</td></tr>
<tr><th id="493">493</th><td>      <b>return</b>;</td></tr>
<tr><th id="494">494</th><td>    }</td></tr>
<tr><th id="495">495</th><td></td></tr>
<tr><th id="496">496</th><td>    <a class="type" href="#tensorflow::LaunchMatMul" title='tensorflow::LaunchMatMul' data-ref="tensorflow::LaunchMatMul">LaunchMatMul</a>&lt;Device, T, <a class="tu member" href="#tensorflow::MatMulOp::USE_CUBLAS" title='tensorflow::MatMulOp::USE_CUBLAS' data-use='c' data-ref="tensorflow::MatMulOp::USE_CUBLAS">USE_CUBLAS</a>&gt;::launch(</td></tr>
<tr><th id="497">497</th><td>        <a class="local col3 ref" href="#43ctx" title='ctx' data-ref="43ctx">ctx</a>, <a class="local col4 ref" href="#44a" title='a' data-ref="44a">a</a>, <a class="local col5 ref" href="#45b" title='b' data-ref="45b">b</a>, <a class="local col6 ref" href="#46dim_pair" title='dim_pair' data-ref="46dim_pair">dim_pair</a>, &amp;<a class="tu member" href="#tensorflow::MatMulOp::algorithms_" title='tensorflow::MatMulOp::algorithms_' data-use='a' data-ref="tensorflow::MatMulOp::algorithms_">algorithms_</a>, <a class="tu member" href="#tensorflow::MatMulOp::use_autotune_" title='tensorflow::MatMulOp::use_autotune_' data-ref="tensorflow::MatMulOp::use_autotune_">use_autotune_</a>, <a class="local col0 ref" href="#50out" title='out' data-ref="50out">out</a>);</td></tr>
<tr><th id="498">498</th><td>  }</td></tr>
<tr><th id="499">499</th><td></td></tr>
<tr><th id="500">500</th><td> <b>private</b>:</td></tr>
<tr><th id="501">501</th><td>  <span class="namespace">std::</span><a class="type" href="../../../../include/c++/5/bits/stl_vector.h.html#std::vector" title='std::vector' data-ref="std::vector">vector</a>&lt;<a class="typedef" href="../platform/default/integral_types.h.html#tensorflow::int64" title='tensorflow::int64' data-type='long long' data-ref="tensorflow::int64">int64</a>&gt; <dfn class="tu decl" id="tensorflow::MatMulOp::algorithms_" title='tensorflow::MatMulOp::algorithms_' data-type='std::vector&lt;int64&gt;' data-ref="tensorflow::MatMulOp::algorithms_">algorithms_</dfn>;</td></tr>
<tr><th id="502">502</th><td>  <em>bool</em> <dfn class="tu decl" id="tensorflow::MatMulOp::algorithms_set_already_" title='tensorflow::MatMulOp::algorithms_set_already_' data-type='bool' data-ref="tensorflow::MatMulOp::algorithms_set_already_">algorithms_set_already_</dfn>;</td></tr>
<tr><th id="503">503</th><td>  <em>bool</em> <dfn class="tu decl" id="tensorflow::MatMulOp::use_autotune_" title='tensorflow::MatMulOp::use_autotune_' data-type='bool' data-ref="tensorflow::MatMulOp::use_autotune_">use_autotune_</dfn>;</td></tr>
<tr><th id="504">504</th><td>  <em>bool</em> <dfn class="tu decl" id="tensorflow::MatMulOp::transpose_a_" title='tensorflow::MatMulOp::transpose_a_' data-type='bool' data-ref="tensorflow::MatMulOp::transpose_a_">transpose_a_</dfn>;</td></tr>
<tr><th id="505">505</th><td>  <em>bool</em> <dfn class="tu decl" id="tensorflow::MatMulOp::transpose_b_" title='tensorflow::MatMulOp::transpose_b_' data-type='bool' data-ref="tensorflow::MatMulOp::transpose_b_">transpose_b_</dfn>;</td></tr>
<tr><th id="506">506</th><td>};</td></tr>
<tr><th id="507">507</th><td></td></tr>
<tr><th id="508">508</th><td><b>namespace</b> <span class="namespace">functor</span> {</td></tr>
<tr><th id="509">509</th><td></td></tr>
<tr><th id="510">510</th><td><i>// Partial specialization MatMulFunctor&lt;Device=CPUDevice, T&gt;.</i></td></tr>
<tr><th id="511">511</th><td><b>template</b> &lt;<b>typename</b> T&gt;</td></tr>
<tr><th id="512">512</th><td><b>struct</b> <dfn class="type def" id="tensorflow::functor::MatMulFunctor" title='tensorflow::functor::MatMulFunctor' data-ref="tensorflow::functor::MatMulFunctor">MatMulFunctor</dfn>&lt;<a class="typedef" href="#tensorflow::CPUDevice" title='tensorflow::CPUDevice' data-type='Eigen::ThreadPoolDevice' data-ref="tensorflow::CPUDevice">CPUDevice</a>, T&gt; {</td></tr>
<tr><th id="513">513</th><td>  <em>void</em> <dfn class="tu decl def" id="_ZN10tensorflow7functor13MatMulFunctorIN5Eigen16ThreadPoolDeviceET_EclERKS3_NS0_11MatMulTypesIS4_E8out_typeENS9_7in_typeESB_RKNS2_5arrayINS2_9IndexPairIlEELm1EEE" title='tensorflow::functor::MatMulFunctor&lt;Eigen::ThreadPoolDevice, type-parameter-0-0&gt;::operator()' data-type='void tensorflow::functor::MatMulFunctor&lt;Eigen::ThreadPoolDevice, type-parameter-0-0&gt;::operator()(const CPUDevice &amp; d, typename MatMulTypes&lt;T&gt;::out_type out, typename MatMulTypes&lt;T&gt;::in_type in0, typename MatMulTypes&lt;T&gt;::in_type in1, const Eigen::array&lt;Eigen::IndexPair&lt;Eigen::DenseIndex&gt;, 1&gt; &amp; dim_pair)' data-ref="_ZN10tensorflow7functor13MatMulFunctorIN5Eigen16ThreadPoolDeviceET_EclERKS3_NS0_11MatMulTypesIS4_E8out_typeENS9_7in_typeESB_RKNS2_5arrayINS2_9IndexPairIlEELm1EEE"><b>operator</b>()</dfn>(</td></tr>
<tr><th id="514">514</th><td>      <em>const</em> <a class="typedef" href="#tensorflow::CPUDevice" title='tensorflow::CPUDevice' data-type='Eigen::ThreadPoolDevice' data-ref="tensorflow::CPUDevice">CPUDevice</a>&amp; <dfn class="local col2 decl" id="52d" title='d' data-type='const CPUDevice &amp;' data-ref="52d">d</dfn>, <b>typename</b> <a class="type" href="matmul_op.h.html#tensorflow::functor::MatMulTypes" title='tensorflow::functor::MatMulTypes' data-ref="tensorflow::functor::MatMulTypes">MatMulTypes</a>&lt;T&gt;::out_type <dfn class="local col3 decl" id="53out" title='out' data-type='typename MatMulTypes&lt;T&gt;::out_type' data-ref="53out">out</dfn>,</td></tr>
<tr><th id="515">515</th><td>      <b>typename</b> <a class="type" href="matmul_op.h.html#tensorflow::functor::MatMulTypes" title='tensorflow::functor::MatMulTypes' data-ref="tensorflow::functor::MatMulTypes">MatMulTypes</a>&lt;T&gt;::in_type <dfn class="local col4 decl" id="54in0" title='in0' data-type='typename MatMulTypes&lt;T&gt;::in_type' data-ref="54in0">in0</dfn>,</td></tr>
<tr><th id="516">516</th><td>      <b>typename</b> <a class="type" href="matmul_op.h.html#tensorflow::functor::MatMulTypes" title='tensorflow::functor::MatMulTypes' data-ref="tensorflow::functor::MatMulTypes">MatMulTypes</a>&lt;T&gt;::in_type <dfn class="local col5 decl" id="55in1" title='in1' data-type='typename MatMulTypes&lt;T&gt;::in_type' data-ref="55in1">in1</dfn>,</td></tr>
<tr><th id="517">517</th><td>      <em>const</em> <span class="namespace">Eigen::</span><span class='type' title='Eigen::array' data-ref="Eigen::array">array</span>&lt;<span class="namespace">Eigen::</span><span class='type' title='Eigen::IndexPair' data-ref="Eigen::IndexPair">IndexPair</span>&lt;<span class="namespace">Eigen::</span><span class='typedef' title='Eigen::DenseIndex' data-type='std::ptrdiff_t' data-ref="Eigen::DenseIndex">DenseIndex</span>&gt;, <var>1</var>&gt;&amp; <dfn class="local col6 decl" id="56dim_pair" title='dim_pair' data-type='const Eigen::array&lt;Eigen::IndexPair&lt;Eigen::DenseIndex&gt;, 1&gt; &amp;' data-ref="56dim_pair">dim_pair</dfn>) {</td></tr>
<tr><th id="518">518</th><td>    MatMul&lt;<a class="typedef" href="#tensorflow::CPUDevice" title='tensorflow::CPUDevice' data-type='Eigen::ThreadPoolDevice' data-ref="tensorflow::CPUDevice">CPUDevice</a>&gt;(<a class="local col2 ref" href="#52d" title='d' data-ref="52d">d</a>, <a class="local col3 ref" href="#53out" title='out' data-ref="53out">out</a>, <a class="local col4 ref" href="#54in0" title='in0' data-ref="54in0">in0</a>, <a class="local col5 ref" href="#55in1" title='in1' data-ref="55in1">in1</a>, <a class="local col6 ref" href="#56dim_pair" title='dim_pair' data-ref="56dim_pair">dim_pair</a>);</td></tr>
<tr><th id="519">519</th><td>  }</td></tr>
<tr><th id="520">520</th><td>};</td></tr>
<tr><th id="521">521</th><td></td></tr>
<tr><th id="522">522</th><td><u>#<span data-ppcond="522">ifdef</span> <span class="macro" data-ref="_M/TENSORFLOW_USE_SYCL">TENSORFLOW_USE_SYCL</span></u></td></tr>
<tr><th id="523">523</th><td><i>// Partial specialization MatMulFunctor&lt;Device=SYCLDevice, T&gt;.</i></td></tr>
<tr><th id="524">524</th><td><b>template</b> &lt;<b>typename</b> T&gt;</td></tr>
<tr><th id="525">525</th><td><b>struct</b> MatMulFunctor&lt;SYCLDevice, T&gt; {</td></tr>
<tr><th id="526">526</th><td>  <em>void</em> <b>operator</b>()(</td></tr>
<tr><th id="527">527</th><td>      <em>const</em> SYCLDevice&amp; d, <b>typename</b> MatMulTypes&lt;T&gt;::out_type out,</td></tr>
<tr><th id="528">528</th><td>      <b>typename</b> MatMulTypes&lt;T&gt;::in_type in0,</td></tr>
<tr><th id="529">529</th><td>      <b>typename</b> MatMulTypes&lt;T&gt;::in_type in1,</td></tr>
<tr><th id="530">530</th><td>      <em>const</em> Eigen::array&lt;Eigen::IndexPair&lt;Eigen::DenseIndex&gt;, <var>1</var>&gt;&amp; dim_pair) {</td></tr>
<tr><th id="531">531</th><td>    MatMul&lt;SYCLDevice&gt;(d, out, in0, in1, dim_pair);</td></tr>
<tr><th id="532">532</th><td>  }</td></tr>
<tr><th id="533">533</th><td>};</td></tr>
<tr><th id="534">534</th><td><u>#<span data-ppcond="522">endif</span>  // TENSORFLOW_USE_SYCL</u></td></tr>
<tr><th id="535">535</th><td></td></tr>
<tr><th id="536">536</th><td>}  <i>// end namespace functor</i></td></tr>
<tr><th id="537">537</th><td></td></tr>
<tr><th id="538">538</th><td><u>#define <dfn class="macro" id="_M/REGISTER_CPU_EIGEN" data-ref="_M/REGISTER_CPU_EIGEN">REGISTER_CPU_EIGEN</dfn>(T)                                                  \</u></td></tr>
<tr><th id="539">539</th><td><u>  REGISTER_KERNEL_BUILDER(                                                     \</u></td></tr>
<tr><th id="540">540</th><td><u>      <a class="type" href="../framework/op_kernel.h.html#tensorflow::register_kernel::Name" title='tensorflow::register_kernel::Name' data-ref="tensorflow::register_kernel::Name">Name</a><a class="ref" href="../framework/op_kernel.h.html#_ZN10tensorflow15register_kernel4NameC1EPKc" title='tensorflow::register_kernel::Name::Name' data-ref="_ZN10tensorflow15register_kernel4NameC1EPKc">(</a>"MatMul").<a class="ref" href="../framework/kernel_def_builder.h.html#_ZN10tensorflow16KernelDefBuilder6DeviceEPKc" title='tensorflow::KernelDefBuilder::Device' data-ref="_ZN10tensorflow16KernelDefBuilder6DeviceEPKc">Device</a>(<a class="ref" href="../framework/types.h.html#tensorflow::DEVICE_CPU" title='tensorflow::DEVICE_CPU' data-ref="tensorflow::DEVICE_CPU">DEVICE_CPU</a>).<a class="ref" href="../framework/kernel_def_builder.h.html#_ZN10tensorflow16KernelDefBuilder14TypeConstraintEPKc" title='tensorflow::KernelDefBuilder::TypeConstraint' data-ref="_ZN10tensorflow16KernelDefBuilder14TypeConstraintEPKc">TypeConstraint</a>&lt;T&gt;("T").<a class="ref" href="../framework/kernel_def_builder.h.html#_ZN10tensorflow16KernelDefBuilder5LabelEPKc" title='tensorflow::KernelDefBuilder::Label' data-ref="_ZN10tensorflow16KernelDefBuilder5LabelEPKc">Label</a>("eigen"), \</u></td></tr>
<tr><th id="541">541</th><td><u>      <a class="type" href="#tensorflow::MatMulOp" title='tensorflow::MatMulOp' data-ref="tensorflow::MatMulOp">MatMulOp</a>&lt;<a class="typedef" href="#tensorflow::CPUDevice" title='tensorflow::CPUDevice' data-type='Eigen::ThreadPoolDevice' data-ref="tensorflow::CPUDevice">CPUDevice</a>, T, false /* cublas, ignored for CPU */&gt;);</u></td></tr>
<tr><th id="542">542</th><td></td></tr>
<tr><th id="543">543</th><td><u>#define <dfn class="macro" id="_M/REGISTER_CPU" data-ref="_M/REGISTER_CPU">REGISTER_CPU</dfn>(T)                                             \</u></td></tr>
<tr><th id="544">544</th><td><u>  REGISTER_KERNEL_BUILDER(                                          \</u></td></tr>
<tr><th id="545">545</th><td><u>      <a class="type" href="../framework/op_kernel.h.html#tensorflow::register_kernel::Name" title='tensorflow::register_kernel::Name' data-ref="tensorflow::register_kernel::Name">Name</a><a class="ref" href="../framework/op_kernel.h.html#_ZN10tensorflow15register_kernel4NameC1EPKc" title='tensorflow::register_kernel::Name::Name' data-ref="_ZN10tensorflow15register_kernel4NameC1EPKc">(</a>"MatMul").<a class="ref" href="../framework/kernel_def_builder.h.html#_ZN10tensorflow16KernelDefBuilder6DeviceEPKc" title='tensorflow::KernelDefBuilder::Device' data-ref="_ZN10tensorflow16KernelDefBuilder6DeviceEPKc">Device</a>(<a class="ref" href="../framework/types.h.html#tensorflow::DEVICE_CPU" title='tensorflow::DEVICE_CPU' data-ref="tensorflow::DEVICE_CPU">DEVICE_CPU</a>).<a class="ref" href="../framework/kernel_def_builder.h.html#_ZN10tensorflow16KernelDefBuilder14TypeConstraintEPKc" title='tensorflow::KernelDefBuilder::TypeConstraint' data-ref="_ZN10tensorflow16KernelDefBuilder14TypeConstraintEPKc">TypeConstraint</a>&lt;T&gt;("T"),     \</u></td></tr>
<tr><th id="546">546</th><td><u>      <a class="type" href="#tensorflow::MatMulOp" title='tensorflow::MatMulOp' data-ref="tensorflow::MatMulOp">MatMulOp</a>&lt;<a class="typedef" href="#tensorflow::CPUDevice" title='tensorflow::CPUDevice' data-type='Eigen::ThreadPoolDevice' data-ref="tensorflow::CPUDevice">CPUDevice</a>, T, false /* cublas, ignored for CPU */&gt;); \</u></td></tr>
<tr><th id="547">547</th><td><u>  REGISTER_CPU_EIGEN(T);</u></td></tr>
<tr><th id="548">548</th><td></td></tr>
<tr><th id="549">549</th><td><u>#define <dfn class="macro" id="_M/REGISTER_GPU" data-ref="_M/REGISTER_GPU">REGISTER_GPU</dfn>(T)                                            \</u></td></tr>
<tr><th id="550">550</th><td><u>  REGISTER_KERNEL_BUILDER(                                         \</u></td></tr>
<tr><th id="551">551</th><td><u>      Name("MatMul").Device(DEVICE_GPU).TypeConstraint&lt;T&gt;("T"),    \</u></td></tr>
<tr><th id="552">552</th><td><u>      MatMulOp&lt;GPUDevice, T, true /* cublas, true by default */&gt;); \</u></td></tr>
<tr><th id="553">553</th><td><u>  REGISTER_KERNEL_BUILDER(Name("MatMul")                           \</u></td></tr>
<tr><th id="554">554</th><td><u>                              .Device(DEVICE_GPU)                  \</u></td></tr>
<tr><th id="555">555</th><td><u>                              .TypeConstraint&lt;T&gt;("T")              \</u></td></tr>
<tr><th id="556">556</th><td><u>                              .Label("cublas"),                    \</u></td></tr>
<tr><th id="557">557</th><td><u>                          MatMulOp&lt;GPUDevice, T, true /* cublas */&gt;)</u></td></tr>
<tr><th id="558">558</th><td></td></tr>
<tr><th id="559">559</th><td><u>#<span data-ppcond="559">if</span> defined(<span class="macro" data-ref="_M/INTEL_MKL">INTEL_MKL</span>)</u></td></tr>
<tr><th id="560">560</th><td><i>// MKL does not support half and int32 types for matrix-multiplication, so</i></td></tr>
<tr><th id="561">561</th><td><i>// register the kernel to use default Eigen based implementations for these</i></td></tr>
<tr><th id="562">562</th><td><i>// types. Registration for NO-LABEL version is in mkl_matmul_op.cc</i></td></tr>
<tr><th id="563">563</th><td>TF_CALL_float(REGISTER_CPU_EIGEN);</td></tr>
<tr><th id="564">564</th><td>TF_CALL_double(REGISTER_CPU_EIGEN);</td></tr>
<tr><th id="565">565</th><td>TF_CALL_half(REGISTER_CPU);</td></tr>
<tr><th id="566">566</th><td></td></tr>
<tr><th id="567">567</th><td>TF_CALL_int32(REGISTER_CPU);</td></tr>
<tr><th id="568">568</th><td>TF_CALL_complex64(REGISTER_CPU_EIGEN);</td></tr>
<tr><th id="569">569</th><td>TF_CALL_complex128(REGISTER_CPU_EIGEN);</td></tr>
<tr><th id="570">570</th><td><u>#<span data-ppcond="559">else</span></u></td></tr>
<tr><th id="571">571</th><td><a class="macro" href="../framework/register_types.h.html#62" title="constexpr bool should_register_0__flag = true; static ::tensorflow::kernel_factory::OpKernelRegistrar registrar__body__0__object( should_register_0__flag ? ::tensorflow::register_kernel::Name(&quot;MatMul&quot;).Device(DEVICE_CPU).TypeConstraint&lt;float&gt;(&quot;T&quot;).Build() : nullptr, &quot;MatMulOp&lt;CPUDevice, float, false &gt;&quot;, [](::tensorflow::OpKernelConstruction* context) -&gt; ::tensorflow::OpKernel* { return new MatMulOp&lt;CPUDevice, float, false &gt;(context); });; constexpr bool should_register_1__flag = true; static ::tensorflow::kernel_factory::OpKernelRegistrar registrar__body__1__object( should_register_1__flag ? ::tensorflow::register_kernel::Name(&quot;MatMul&quot;).Device(DEVICE_CPU).TypeConstraint&lt;float&gt;(&quot;T&quot;).Label(&quot;eigen&quot;).Build() : nullptr, &quot;MatMulOp&lt;CPUDevice, float, false &gt;&quot;, [](::tensorflow::OpKernelConstruction* context) -&gt; ::tensorflow::OpKernel* { return new MatMulOp&lt;CPUDevice, float, false &gt;(context); });;;" data-ref="_M/TF_CALL_float">TF_CALL_float</a>(REGISTER_CPU);</td></tr>
<tr><th id="572">572</th><td><a class="macro" href="../framework/register_types.h.html#63" title="constexpr bool should_register_4__flag = true; static ::tensorflow::kernel_factory::OpKernelRegistrar registrar__body__4__object( should_register_4__flag ? ::tensorflow::register_kernel::Name(&quot;MatMul&quot;).Device(DEVICE_CPU).TypeConstraint&lt;double&gt;(&quot;T&quot;).Build() : nullptr, &quot;MatMulOp&lt;CPUDevice, double, false &gt;&quot;, [](::tensorflow::OpKernelConstruction* context) -&gt; ::tensorflow::OpKernel* { return new MatMulOp&lt;CPUDevice, double, false &gt;(context); });; constexpr bool should_register_5__flag = true; static ::tensorflow::kernel_factory::OpKernelRegistrar registrar__body__5__object( should_register_5__flag ? ::tensorflow::register_kernel::Name(&quot;MatMul&quot;).Device(DEVICE_CPU).TypeConstraint&lt;double&gt;(&quot;T&quot;).Label(&quot;eigen&quot;).Build() : nullptr, &quot;MatMulOp&lt;CPUDevice, double, false &gt;&quot;, [](::tensorflow::OpKernelConstruction* context) -&gt; ::tensorflow::OpKernel* { return new MatMulOp&lt;CPUDevice, double, false &gt;(context); });;;" data-ref="_M/TF_CALL_double">TF_CALL_double</a>(REGISTER_CPU);</td></tr>
<tr><th id="573">573</th><td><a class="macro" href="../framework/register_types.h.html#87" title="constexpr bool should_register_8__flag = true; static ::tensorflow::kernel_factory::OpKernelRegistrar registrar__body__8__object( should_register_8__flag ? ::tensorflow::register_kernel::Name(&quot;MatMul&quot;).Device(DEVICE_CPU).TypeConstraint&lt;Eigen::half&gt;(&quot;T&quot;).Build() : nullptr, &quot;MatMulOp&lt;CPUDevice, Eigen::half, false &gt;&quot;, [](::tensorflow::OpKernelConstruction* context) -&gt; ::tensorflow::OpKernel* { return new MatMulOp&lt;CPUDevice, Eigen::half, false &gt;(context); });; constexpr bool should_register_9__flag = true; static ::tensorflow::kernel_factory::OpKernelRegistrar registrar__body__9__object( should_register_9__flag ? ::tensorflow::register_kernel::Name(&quot;MatMul&quot;).Device(DEVICE_CPU).TypeConstraint&lt;Eigen::half&gt;(&quot;T&quot;).Label(&quot;eigen&quot;).Build() : nullptr, &quot;MatMulOp&lt;CPUDevice, Eigen::half, false &gt;&quot;, [](::tensorflow::OpKernelConstruction* context) -&gt; ::tensorflow::OpKernel* { return new MatMulOp&lt;CPUDevice, Eigen::half, false &gt;(context); });;;" data-ref="_M/TF_CALL_half">TF_CALL_half</a>(REGISTER_CPU);</td></tr>
<tr><th id="574">574</th><td></td></tr>
<tr><th id="575">575</th><td><a class="macro" href="../framework/register_types.h.html#64" title="constexpr bool should_register_12__flag = true; static ::tensorflow::kernel_factory::OpKernelRegistrar registrar__body__12__object( should_register_12__flag ? ::tensorflow::register_kernel::Name(&quot;MatMul&quot;).Device(DEVICE_CPU).TypeConstraint&lt;::tensorflow::int32&gt;(&quot;T&quot;).Build() : nullptr, &quot;MatMulOp&lt;CPUDevice, ::tensorflow::int32, false &gt;&quot;, [](::tensorflow::OpKernelConstruction* context) -&gt; ::tensorflow::OpKernel* { return new MatMulOp&lt;CPUDevice, ::tensorflow::int32, false &gt;(context); });; constexpr bool should_register_13__flag = true; static ::tensorflow::kernel_factory::OpKernelRegistrar registrar__body__13__object( should_register_13__flag ? ::tensorflow::register_kernel::Name(&quot;MatMul&quot;).Device(DEVICE_CPU).TypeConstraint&lt;::tensorflow::int32&gt;(&quot;T&quot;).Label(&quot;eigen&quot;).Build() : nullptr, &quot;MatMulOp&lt;CPUDevice, ::tensorflow::int32, false &gt;&quot;, [](::tensorflow::OpKernelConstruction* context) -&gt; ::tensorflow::OpKernel* { return new MatMulOp&lt;CPUDevice, ::tensorflow::int32, false &gt;(context); });;;" data-ref="_M/TF_CALL_int32">TF_CALL_int32</a>(REGISTER_CPU);</td></tr>
<tr><th id="576">576</th><td><a class="macro" href="../framework/register_types.h.html#73" title="constexpr bool should_register_16__flag = true; static ::tensorflow::kernel_factory::OpKernelRegistrar registrar__body__16__object( should_register_16__flag ? ::tensorflow::register_kernel::Name(&quot;MatMul&quot;).Device(DEVICE_CPU).TypeConstraint&lt;::tensorflow::complex64&gt;(&quot;T&quot;).Build() : nullptr, &quot;MatMulOp&lt;CPUDevice, ::tensorflow::complex64, false &gt;&quot;, [](::tensorflow::OpKernelConstruction* context) -&gt; ::tensorflow::OpKernel* { return new MatMulOp&lt;CPUDevice, ::tensorflow::complex64, false &gt;(context); });; constexpr bool should_register_17__flag = true; static ::tensorflow::kernel_factory::OpKernelRegistrar registrar__body__17__object( should_register_17__flag ? ::tensorflow::register_kernel::Name(&quot;MatMul&quot;).Device(DEVICE_CPU).TypeConstraint&lt;::tensorflow::complex64&gt;(&quot;T&quot;).Label(&quot;eigen&quot;).Build() : nullptr, &quot;MatMulOp&lt;CPUDevice, ::tensorflow::complex64, false &gt;&quot;, [](::tensorflow::OpKernelConstruction* context) -&gt; ::tensorflow::OpKernel* { return new MatMulOp&lt;CPUDevice, ::tensorflow::complex64, false &gt;(context); });;;" data-ref="_M/TF_CALL_complex64">TF_CALL_complex64</a>(REGISTER_CPU);</td></tr>
<tr><th id="577">577</th><td><a class="macro" href="../framework/register_types.h.html#86" title="constexpr bool should_register_20__flag = true; static ::tensorflow::kernel_factory::OpKernelRegistrar registrar__body__20__object( should_register_20__flag ? ::tensorflow::register_kernel::Name(&quot;MatMul&quot;).Device(DEVICE_CPU).TypeConstraint&lt;::tensorflow::complex128&gt;(&quot;T&quot;).Build() : nullptr, &quot;MatMulOp&lt;CPUDevice, ::tensorflow::complex128, false &gt;&quot;, [](::tensorflow::OpKernelConstruction* context) -&gt; ::tensorflow::OpKernel* { return new MatMulOp&lt;CPUDevice, ::tensorflow::complex128, false &gt;(context); });; constexpr bool should_register_21__flag = true; static ::tensorflow::kernel_factory::OpKernelRegistrar registrar__body__21__object( should_register_21__flag ? ::tensorflow::register_kernel::Name(&quot;MatMul&quot;).Device(DEVICE_CPU).TypeConstraint&lt;::tensorflow::complex128&gt;(&quot;T&quot;).Label(&quot;eigen&quot;).Build() : nullptr, &quot;MatMulOp&lt;CPUDevice, ::tensorflow::complex128, false &gt;&quot;, [](::tensorflow::OpKernelConstruction* context) -&gt; ::tensorflow::OpKernel* { return new MatMulOp&lt;CPUDevice, ::tensorflow::complex128, false &gt;(context); });;;" data-ref="_M/TF_CALL_complex128">TF_CALL_complex128</a>(REGISTER_CPU);</td></tr>
<tr><th id="578">578</th><td><u>#<span data-ppcond="559">endif</span></u></td></tr>
<tr><th id="579">579</th><td></td></tr>
<tr><th id="580">580</th><td><u>#<span data-ppcond="580">if</span> GOOGLE_CUDA</u></td></tr>
<tr><th id="581">581</th><td>TF_CALL_float(REGISTER_GPU);</td></tr>
<tr><th id="582">582</th><td>TF_CALL_double(REGISTER_GPU);</td></tr>
<tr><th id="583">583</th><td>TF_CALL_complex64(REGISTER_GPU);</td></tr>
<tr><th id="584">584</th><td>TF_CALL_complex128(REGISTER_GPU);</td></tr>
<tr><th id="585">585</th><td><u>#if CUDA_VERSION &gt;= 7050</u></td></tr>
<tr><th id="586">586</th><td>TF_CALL_half(REGISTER_GPU);</td></tr>
<tr><th id="587">587</th><td><u>#endif</u></td></tr>
<tr><th id="588">588</th><td><u>#<span data-ppcond="580">endif</span>  // GOOGLE_CUDA</u></td></tr>
<tr><th id="589">589</th><td></td></tr>
<tr><th id="590">590</th><td><u>#<span data-ppcond="590">ifdef</span> <span class="macro" data-ref="_M/TENSORFLOW_USE_SYCL">TENSORFLOW_USE_SYCL</span></u></td></tr>
<tr><th id="591">591</th><td><u>#define REGISTER_SYCL(T)                                         \</u></td></tr>
<tr><th id="592">592</th><td><u>  REGISTER_KERNEL_BUILDER(                                       \</u></td></tr>
<tr><th id="593">593</th><td><u>      Name("MatMul").Device(DEVICE_SYCL).TypeConstraint&lt;T&gt;("T"), \</u></td></tr>
<tr><th id="594">594</th><td><u>      MatMulOp&lt;SYCLDevice, T, false /* xxblas */&gt;);              \</u></td></tr>
<tr><th id="595">595</th><td><u>  REGISTER_KERNEL_BUILDER(Name("MatMul")                         \</u></td></tr>
<tr><th id="596">596</th><td><u>                              .Device(DEVICE_SYCL)               \</u></td></tr>
<tr><th id="597">597</th><td><u>                              .TypeConstraint&lt;T&gt;("T")            \</u></td></tr>
<tr><th id="598">598</th><td><u>                              .Label("eigen"),                   \</u></td></tr>
<tr><th id="599">599</th><td><u>                          MatMulOp&lt;SYCLDevice, T, false /* xxblas */&gt;)</u></td></tr>
<tr><th id="600">600</th><td>TF_CALL_float(REGISTER_SYCL);</td></tr>
<tr><th id="601">601</th><td>TF_CALL_double(REGISTER_SYCL);</td></tr>
<tr><th id="602">602</th><td></td></tr>
<tr><th id="603">603</th><td><u>#<span data-ppcond="590">endif</span>  // TENSORFLOW_USE_SYCL</u></td></tr>
<tr><th id="604">604</th><td>}  <i>// namespace tensorflow</i></td></tr>
<tr><th id="605">605</th><td></td></tr>
</table><hr/><p id='footer'>
Generated on <em>2018-Sep-06</em> from project tensorflow revision <em>v1.8</em><br />Powered by <a href='https://woboq.com'><img alt='Woboq' src='https://code.woboq.org/woboq-16.png' width='41' height='16' /></a> <a href='https://code.woboq.org'>Code Browser</a> 2.1
<br/>Generator usage only permitted with license.</p>
</div></body></html>
