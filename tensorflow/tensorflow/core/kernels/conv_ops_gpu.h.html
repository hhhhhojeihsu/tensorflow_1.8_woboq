<!doctype html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0"><title>conv_ops_gpu.h source code [tensorflow/tensorflow/core/kernels/conv_ops_gpu.h] - Woboq Code Browser</title>
<link rel="stylesheet" href="https://code.woboq.org/data/qtcreator.css" title="QtCreator"/>
<link rel="alternate stylesheet" href="https://code.woboq.org/data/kdevelop.css" title="KDevelop"/>
<script type="text/javascript" src="https://code.woboq.org/data/jquery/jquery.min.js"></script>
<script type="text/javascript" src="https://code.woboq.org/data/jquery/jquery-ui.min.js"></script>
<script>var file = 'tensorflow/tensorflow/core/kernels/conv_ops_gpu.h'; var root_path = '../../../..'; var data_path = 'https://code.woboq.org/data';</script>
<script src='https://code.woboq.org/data/codebrowser.js'></script>
</head>
<body><div id='header'><h1 id='breadcrumb'><span>Browse the source code of </span><a href='../../..'>tensorflow</a>/<a href='../..'>tensorflow</a>/<a href='..'>core</a>/<a href='./'>kernels</a>/<a href='conv_ops_gpu.h.html'>conv_ops_gpu.h</a></h1></div>
<hr/><div id='content'><table class="code">
<tr><th id="1">1</th><td><i>/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.</i></td></tr>
<tr><th id="2">2</th><td><i></i></td></tr>
<tr><th id="3">3</th><td><i>Licensed under the Apache License, Version 2.0 (the "License");</i></td></tr>
<tr><th id="4">4</th><td><i>you may not use this file except in compliance with the License.</i></td></tr>
<tr><th id="5">5</th><td><i>You may obtain a copy of the License at</i></td></tr>
<tr><th id="6">6</th><td><i></i></td></tr>
<tr><th id="7">7</th><td><i>    <a href="http://www.apache.org/licenses/LICENSE-2.0">http://www.apache.org/licenses/LICENSE-2.0</a></i></td></tr>
<tr><th id="8">8</th><td><i></i></td></tr>
<tr><th id="9">9</th><td><i>Unless required by applicable law or agreed to in writing, software</i></td></tr>
<tr><th id="10">10</th><td><i>distributed under the License is distributed on an "AS IS" BASIS,</i></td></tr>
<tr><th id="11">11</th><td><i>WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</i></td></tr>
<tr><th id="12">12</th><td><i>See the License for the specific language governing permissions and</i></td></tr>
<tr><th id="13">13</th><td><i>limitations under the License.</i></td></tr>
<tr><th id="14">14</th><td><i>==============================================================================*/</i></td></tr>
<tr><th id="15">15</th><td></td></tr>
<tr><th id="16">16</th><td><u>#<span data-ppcond="16">ifndef</span> <span class="macro" data-ref="_M/TENSORFLOW_CORE_KERNELS_CONV_OPS_GPU_H_">TENSORFLOW_CORE_KERNELS_CONV_OPS_GPU_H_</span></u></td></tr>
<tr><th id="17">17</th><td><u>#define <dfn class="macro" id="_M/TENSORFLOW_CORE_KERNELS_CONV_OPS_GPU_H_" data-ref="_M/TENSORFLOW_CORE_KERNELS_CONV_OPS_GPU_H_">TENSORFLOW_CORE_KERNELS_CONV_OPS_GPU_H_</dfn></u></td></tr>
<tr><th id="18">18</th><td></td></tr>
<tr><th id="19">19</th><td><u>#<span data-ppcond="19">if</span> GOOGLE_CUDA</u></td></tr>
<tr><th id="20">20</th><td></td></tr>
<tr><th id="21">21</th><td><u>#include &lt;tuple&gt;</u></td></tr>
<tr><th id="22">22</th><td><u>#include &lt;unordered_map&gt;</u></td></tr>
<tr><th id="23">23</th><td><u>#include "tensorflow/core/framework/op_kernel.h"</u></td></tr>
<tr><th id="24">24</th><td><u>#include "tensorflow/core/kernels/gpu_utils.h"</u></td></tr>
<tr><th id="25">25</th><td><u>#include "tensorflow/core/lib/gtl/inlined_vector.h"</u></td></tr>
<tr><th id="26">26</th><td><u>#include "tensorflow/core/lib/hash/hash.h"</u></td></tr>
<tr><th id="27">27</th><td></td></tr>
<tr><th id="28">28</th><td><b>namespace</b> tensorflow {</td></tr>
<tr><th id="29">29</th><td></td></tr>
<tr><th id="30">30</th><td><i>// Get the Cudnn workspace limit from the environment variable, which is in MB.</i></td></tr>
<tr><th id="31">31</th><td><i>// Return the workspace memory limit in bytes. If no value is set, return the</i></td></tr>
<tr><th id="32">32</th><td><i>// default value.</i></td></tr>
<tr><th id="33">33</th><td>int64 GetCudnnWorkspaceLimit(<em>const</em> string&amp; envvar_in_mb,</td></tr>
<tr><th id="34">34</th><td>                             int64 default_value_in_bytes);</td></tr>
<tr><th id="35">35</th><td></td></tr>
<tr><th id="36">36</th><td><i>// A class to provide scratch-space allocator for Stream-Executor Cudnn</i></td></tr>
<tr><th id="37">37</th><td><i>// callback. TensorFlow is responsible for releasing the temporary buffers after</i></td></tr>
<tr><th id="38">38</th><td><i>// the kernel finishes.</i></td></tr>
<tr><th id="39">39</th><td><b>class</b> CudnnScratchAllocator : <b>public</b> perftools::gputools::ScratchAllocator {</td></tr>
<tr><th id="40">40</th><td> <b>public</b>:</td></tr>
<tr><th id="41">41</th><td>  <b>virtual</b> ~CudnnScratchAllocator() {}</td></tr>
<tr><th id="42">42</th><td>  CudnnScratchAllocator(int64 memory_limit, OpKernelContext* context)</td></tr>
<tr><th id="43">43</th><td>      : memory_limit_(memory_limit), total_byte_size_(<var>0</var>), context_(context) {}</td></tr>
<tr><th id="44">44</th><td>  int64 GetMemoryLimitInBytes(perftools::gputools::Stream* stream) override {</td></tr>
<tr><th id="45">45</th><td>    <b>return</b> memory_limit_;</td></tr>
<tr><th id="46">46</th><td>  }</td></tr>
<tr><th id="47">47</th><td>  perftools::gputools::port::StatusOr&lt;perftools::gputools::DeviceMemory&lt;uint8&gt;&gt;</td></tr>
<tr><th id="48">48</th><td>  AllocateBytes(perftools::gputools::Stream* stream, int64 byte_size) override {</td></tr>
<tr><th id="49">49</th><td>    Tensor temporary_memory;</td></tr>
<tr><th id="50">50</th><td>    <b>if</b> (byte_size &lt; <var>0</var>) {</td></tr>
<tr><th id="51">51</th><td>      <b>return</b> perftools::gputools::port::Status{</td></tr>
<tr><th id="52">52</th><td>          perftools::gputools::port::error::INVALID_ARGUMENT,</td></tr>
<tr><th id="53">53</th><td>          <q>"Requested negative byte size!"</q>};</td></tr>
<tr><th id="54">54</th><td>    }</td></tr>
<tr><th id="55">55</th><td>    <b>if</b> (byte_size &gt; memory_limit_) {</td></tr>
<tr><th id="56">56</th><td>      <b>return</b> perftools::gputools::port::StatusOr&lt;</td></tr>
<tr><th id="57">57</th><td>          perftools::gputools::DeviceMemory&lt;uint8&gt;&gt;();</td></tr>
<tr><th id="58">58</th><td>    }</td></tr>
<tr><th id="59">59</th><td>    AllocationAttributes allocation_attr;</td></tr>
<tr><th id="60">60</th><td>    allocation_attr.no_retry_on_failure = <b>true</b>;</td></tr>
<tr><th id="61">61</th><td>    Status allocation_status(context_-&gt;allocate_temp(</td></tr>
<tr><th id="62">62</th><td>        DT_UINT8, TensorShape({byte_size}), &amp;temporary_memory,</td></tr>
<tr><th id="63">63</th><td>        AllocatorAttributes(), allocation_attr));</td></tr>
<tr><th id="64">64</th><td>    <b>if</b> (!allocation_status.ok()) {</td></tr>
<tr><th id="65">65</th><td>      <b>return</b> perftools::gputools::port::StatusOr&lt;</td></tr>
<tr><th id="66">66</th><td>          perftools::gputools::DeviceMemory&lt;uint8&gt;&gt;();</td></tr>
<tr><th id="67">67</th><td>    }</td></tr>
<tr><th id="68">68</th><td>    <i>// Hold the reference of the allocated tensors until the end of the</i></td></tr>
<tr><th id="69">69</th><td><i>    // allocator.</i></td></tr>
<tr><th id="70">70</th><td>    allocated_tensors_.push_back(temporary_memory);</td></tr>
<tr><th id="71">71</th><td>    total_byte_size_ += byte_size;</td></tr>
<tr><th id="72">72</th><td>    <b>return</b> perftools::gputools::port::StatusOr&lt;</td></tr>
<tr><th id="73">73</th><td>        perftools::gputools::DeviceMemory&lt;uint8&gt;&gt;(</td></tr>
<tr><th id="74">74</th><td>        AsDeviceMemory(temporary_memory.flat&lt;uint8&gt;().data(),</td></tr>
<tr><th id="75">75</th><td>                       temporary_memory.flat&lt;uint8&gt;().size()));</td></tr>
<tr><th id="76">76</th><td>  }</td></tr>
<tr><th id="77">77</th><td>  int64 TotalByteSize() { <b>return</b> total_byte_size_; }</td></tr>
<tr><th id="78">78</th><td></td></tr>
<tr><th id="79">79</th><td> <b>private</b>:</td></tr>
<tr><th id="80">80</th><td>  int64 memory_limit_;</td></tr>
<tr><th id="81">81</th><td>  int64 total_byte_size_;</td></tr>
<tr><th id="82">82</th><td>  OpKernelContext* context_;</td></tr>
<tr><th id="83">83</th><td>  std::vector&lt;Tensor&gt; allocated_tensors_;</td></tr>
<tr><th id="84">84</th><td>};</td></tr>
<tr><th id="85">85</th><td></td></tr>
<tr><th id="86">86</th><td><i>// Encapsulate all the shape information that is used in both forward and</i></td></tr>
<tr><th id="87">87</th><td><i>// backward conv operations.</i></td></tr>
<tr><th id="88">88</th><td><b>class</b> ConvParameters {</td></tr>
<tr><th id="89">89</th><td> <b>public</b>:</td></tr>
<tr><th id="90">90</th><td>  <b>using</b> SpatialArray = gtl::InlinedVector&lt;int64, <var>3</var>&gt;;</td></tr>
<tr><th id="91">91</th><td>  ConvParameters(int64 batch, int64 in_depths, <em>const</em> SpatialArray&amp; in,</td></tr>
<tr><th id="92">92</th><td>                 int64 out_depths, <em>const</em> SpatialArray&amp; filter,</td></tr>
<tr><th id="93">93</th><td>                 <em>const</em> SpatialArray&amp; dilation, <em>const</em> SpatialArray&amp; stride,</td></tr>
<tr><th id="94">94</th><td>                 <em>const</em> SpatialArray&amp; padding, DataType dtype, <em>int</em> device_id)</td></tr>
<tr><th id="95">95</th><td>      : batch_(batch),</td></tr>
<tr><th id="96">96</th><td>        in_depths_(in_depths),</td></tr>
<tr><th id="97">97</th><td>        out_depths_(out_depths),</td></tr>
<tr><th id="98">98</th><td>        in_(in),</td></tr>
<tr><th id="99">99</th><td>        filter_(filter),</td></tr>
<tr><th id="100">100</th><td>        dilation_(dilation),</td></tr>
<tr><th id="101">101</th><td>        stride_(stride),</td></tr>
<tr><th id="102">102</th><td>        padding_(padding),</td></tr>
<tr><th id="103">103</th><td>        dtype_(dtype),</td></tr>
<tr><th id="104">104</th><td>        device_id_(device_id) {</td></tr>
<tr><th id="105">105</th><td>    hash_code_ = batch;</td></tr>
<tr><th id="106">106</th><td>    hash_code_ = Hash64Combine(hash_code_, in_depths);</td></tr>
<tr><th id="107">107</th><td>    <b>for</b> (int64 val : in) hash_code_ = Hash64Combine(hash_code_, val);</td></tr>
<tr><th id="108">108</th><td>    hash_code_ = Hash64Combine(hash_code_, out_depths);</td></tr>
<tr><th id="109">109</th><td>    <b>for</b> (int64 val : filter) hash_code_ = Hash64Combine(hash_code_, val);</td></tr>
<tr><th id="110">110</th><td>    <b>for</b> (int64 val : dilation) hash_code_ = Hash64Combine(hash_code_, val);</td></tr>
<tr><th id="111">111</th><td>    <b>for</b> (int64 val : stride) hash_code_ = Hash64Combine(hash_code_, val);</td></tr>
<tr><th id="112">112</th><td>    <b>for</b> (int64 val : padding) hash_code_ = Hash64Combine(hash_code_, val);</td></tr>
<tr><th id="113">113</th><td>    hash_code_ = Hash64Combine(hash_code_, dtype);</td></tr>
<tr><th id="114">114</th><td>    hash_code_ = Hash64Combine(hash_code_, device_id);</td></tr>
<tr><th id="115">115</th><td>  }</td></tr>
<tr><th id="116">116</th><td>  <em>bool</em> <b>operator</b>==(<em>const</em> ConvParameters&amp; other) <em>const</em> {</td></tr>
<tr><th id="117">117</th><td>    <b>return</b> <b>this</b>-&gt;get_data_as_tuple() == other.get_data_as_tuple();</td></tr>
<tr><th id="118">118</th><td>  }</td></tr>
<tr><th id="119">119</th><td></td></tr>
<tr><th id="120">120</th><td>  <em>bool</em> <b>operator</b>!=(<em>const</em> ConvParameters&amp; other) <em>const</em> {</td></tr>
<tr><th id="121">121</th><td>    <b>return</b> !(*<b>this</b> == other);</td></tr>
<tr><th id="122">122</th><td>  }</td></tr>
<tr><th id="123">123</th><td>  uint64 hash() <em>const</em> { <b>return</b> hash_code_; }</td></tr>
<tr><th id="124">124</th><td></td></tr>
<tr><th id="125">125</th><td>  string ToString() <em>const</em> {</td></tr>
<tr><th id="126">126</th><td>    <i>// clang-format off</i></td></tr>
<tr><th id="127">127</th><td>    <b>return</b> strings::StrCat(</td></tr>
<tr><th id="128">128</th><td>        batch_, <q>", "</q>, in_depths_, <q>", "</q>,</td></tr>
<tr><th id="129">129</th><td>        <q>"("</q>, str_util::Join(in_, <q>", "</q>), <q>"), "</q>,</td></tr>
<tr><th id="130">130</th><td>        out_depths_, <q>", "</q>,</td></tr>
<tr><th id="131">131</th><td>        <q>"("</q>, str_util::Join(filter_, <q>", "</q>), <q>"), "</q>,</td></tr>
<tr><th id="132">132</th><td>        <q>"("</q>, str_util::Join(dilation_, <q>", "</q>), <q>"), "</q>,</td></tr>
<tr><th id="133">133</th><td>        <q>"("</q>, str_util::Join(stride_, <q>", "</q>), <q>"), "</q>,</td></tr>
<tr><th id="134">134</th><td>        <q>"("</q>, str_util::Join(padding_, <q>", "</q>), <q>"), "</q>,</td></tr>
<tr><th id="135">135</th><td>        dtype_, <q>", "</q>,</td></tr>
<tr><th id="136">136</th><td>        device_id_);</td></tr>
<tr><th id="137">137</th><td>    <i>// clang-format on</i></td></tr>
<tr><th id="138">138</th><td>  }</td></tr>
<tr><th id="139">139</th><td></td></tr>
<tr><th id="140">140</th><td>  <i>// TODO(yangzihao): The purpose of this function is to disable winograd</i></td></tr>
<tr><th id="141">141</th><td><i>  // nonfused conv algorithm for certain input parameters so as to avoid a bug</i></td></tr>
<tr><th id="142">142</th><td><i>  // in cuDNNv5 and cuDNNv6. Remove this once switch to cuDNNv7.</i></td></tr>
<tr><th id="143">143</th><td>  <b>template</b> &lt;<b>typename</b> T&gt;</td></tr>
<tr><th id="144">144</th><td>  <em>bool</em> ShouldIncludeWinogradNonfusedAlgo() <em>const</em> {</td></tr>
<tr><th id="145">145</th><td>    int64 total_size = <var>16</var> * std::ceil(batch_ / <var>16.0</var>) *</td></tr>
<tr><th id="146">146</th><td>                       std::max(in_depths_, out_depths_) * in_[<var>0</var>] * in_[<var>1</var>] *</td></tr>
<tr><th id="147">147</th><td>                       <b>sizeof</b>(T);</td></tr>
<tr><th id="148">148</th><td>    int64 threshold = <var>1LL</var> &lt;&lt; <var>31</var>;</td></tr>
<tr><th id="149">149</th><td>    <b>if</b> (total_size &gt;= threshold) {</td></tr>
<tr><th id="150">150</th><td>      <b>return</b> <b>false</b>;</td></tr>
<tr><th id="151">151</th><td>    } <b>else</b> {</td></tr>
<tr><th id="152">152</th><td>      <b>return</b> <b>true</b>;</td></tr>
<tr><th id="153">153</th><td>    }</td></tr>
<tr><th id="154">154</th><td>  }</td></tr>
<tr><th id="155">155</th><td></td></tr>
<tr><th id="156">156</th><td> <b>protected</b>:</td></tr>
<tr><th id="157">157</th><td>  <b>using</b> ParameterDataType =</td></tr>
<tr><th id="158">158</th><td>      std::tuple&lt;int64, int64, SpatialArray, int64, SpatialArray, SpatialArray,</td></tr>
<tr><th id="159">159</th><td>                 SpatialArray, SpatialArray, DataType, <em>int</em>&gt;;</td></tr>
<tr><th id="160">160</th><td></td></tr>
<tr><th id="161">161</th><td>  ParameterDataType get_data_as_tuple() <em>const</em> {</td></tr>
<tr><th id="162">162</th><td>    <b>return</b> std::make_tuple(batch_, in_depths_, in_, out_depths_, filter_,</td></tr>
<tr><th id="163">163</th><td>                           dilation_, stride_, padding_, dtype_, device_id_);</td></tr>
<tr><th id="164">164</th><td>  }</td></tr>
<tr><th id="165">165</th><td></td></tr>
<tr><th id="166">166</th><td>  uint64 hash_code_;</td></tr>
<tr><th id="167">167</th><td></td></tr>
<tr><th id="168">168</th><td> <b>private</b>:</td></tr>
<tr><th id="169">169</th><td>  int64 batch_;</td></tr>
<tr><th id="170">170</th><td>  int64 in_depths_;</td></tr>
<tr><th id="171">171</th><td>  int64 out_depths_;</td></tr>
<tr><th id="172">172</th><td>  SpatialArray in_;</td></tr>
<tr><th id="173">173</th><td>  SpatialArray filter_;</td></tr>
<tr><th id="174">174</th><td>  SpatialArray dilation_;</td></tr>
<tr><th id="175">175</th><td>  SpatialArray stride_;</td></tr>
<tr><th id="176">176</th><td>  SpatialArray padding_;</td></tr>
<tr><th id="177">177</th><td>  DataType dtype_;</td></tr>
<tr><th id="178">178</th><td>  <em>int</em> device_id_;</td></tr>
<tr><th id="179">179</th><td>};</td></tr>
<tr><th id="180">180</th><td></td></tr>
<tr><th id="181">181</th><td><b>typedef</b> Eigen::GpuDevice GPUDevice;</td></tr>
<tr><th id="182">182</th><td></td></tr>
<tr><th id="183">183</th><td>}  <i>// namespace tensorflow</i></td></tr>
<tr><th id="184">184</th><td></td></tr>
<tr><th id="185">185</th><td><u>#<span data-ppcond="19">endif</span>  // GOOGLE_CUDA</u></td></tr>
<tr><th id="186">186</th><td></td></tr>
<tr><th id="187">187</th><td><u>#<span data-ppcond="16">endif</span>  // TENSORFLOW_CORE_KERNELS_CONV_OPS_GPU_H_</u></td></tr>
<tr><th id="188">188</th><td></td></tr>
</table><hr/><p id='footer'>
Generated while processing <a href='conv_grad_ops_3d.cc.html'>tensorflow/tensorflow/core/kernels/conv_grad_ops_3d.cc</a><br/>Generated on <em>2018-Aug-09</em> from project tensorflow revision <em>v1.8</em><br />Powered by <a href='https://woboq.com'><img alt='Woboq' src='https://code.woboq.org/woboq-16.png' width='41' height='16' /></a> <a href='https://code.woboq.org'>Code Browser</a> 2.1
<br/>Generator usage only permitted with license.</p>
</div></body></html>
