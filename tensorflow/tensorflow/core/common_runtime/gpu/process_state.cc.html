<!doctype html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0"><title>process_state.cc source code [tensorflow/tensorflow/core/common_runtime/gpu/process_state.cc] - Woboq Code Browser</title>
<link rel="stylesheet" href="https://code.woboq.org/data/qtcreator.css" title="QtCreator"/>
<link rel="alternate stylesheet" href="https://code.woboq.org/data/kdevelop.css" title="KDevelop"/>
<script type="text/javascript" src="https://code.woboq.org/data/jquery/jquery.min.js"></script>
<script type="text/javascript" src="https://code.woboq.org/data/jquery/jquery-ui.min.js"></script>
<script>var file = 'tensorflow/tensorflow/core/common_runtime/gpu/process_state.cc'; var root_path = '../../../../..'; var data_path = 'https://code.woboq.org/data';</script>
<script src='https://code.woboq.org/data/codebrowser.js'></script>
</head>
<body><div id='header'><h1 id='breadcrumb'><span>Browse the source code of </span><a href='../../../..'>tensorflow</a>/<a href='../../..'>tensorflow</a>/<a href='../..'>core</a>/<a href='..'>common_runtime</a>/<a href='./'>gpu</a>/<a href='process_state.cc.html'>process_state.cc</a></h1></div>
<hr/><div id='content'><table class="code">
<tr><th id="1">1</th><td><i>/* Copyright 2015 The TensorFlow Authors. All Rights Reserved.</i></td></tr>
<tr><th id="2">2</th><td><i></i></td></tr>
<tr><th id="3">3</th><td><i>Licensed under the Apache License, Version 2.0 (the "License");</i></td></tr>
<tr><th id="4">4</th><td><i>you may not use this file except in compliance with the License.</i></td></tr>
<tr><th id="5">5</th><td><i>You may obtain a copy of the License at</i></td></tr>
<tr><th id="6">6</th><td><i></i></td></tr>
<tr><th id="7">7</th><td><i>    <a href="http://www.apache.org/licenses/LICENSE-2.0">http://www.apache.org/licenses/LICENSE-2.0</a></i></td></tr>
<tr><th id="8">8</th><td><i></i></td></tr>
<tr><th id="9">9</th><td><i>Unless required by applicable law or agreed to in writing, software</i></td></tr>
<tr><th id="10">10</th><td><i>distributed under the License is distributed on an "AS IS" BASIS,</i></td></tr>
<tr><th id="11">11</th><td><i>WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</i></td></tr>
<tr><th id="12">12</th><td><i>See the License for the specific language governing permissions and</i></td></tr>
<tr><th id="13">13</th><td><i>limitations under the License.</i></td></tr>
<tr><th id="14">14</th><td><i>==============================================================================*/</i></td></tr>
<tr><th id="15">15</th><td></td></tr>
<tr><th id="16">16</th><td><u>#include <a href="process_state.h.html">"tensorflow/core/common_runtime/gpu/process_state.h"</a></u></td></tr>
<tr><th id="17">17</th><td></td></tr>
<tr><th id="18">18</th><td><u>#include <a href="../../../../../include/c++/5/cstring.html">&lt;cstring&gt;</a></u></td></tr>
<tr><th id="19">19</th><td><u>#include <a href="../../../../../include/c++/5/vector.html">&lt;vector&gt;</a></u></td></tr>
<tr><th id="20">20</th><td></td></tr>
<tr><th id="21">21</th><td><u>#include <a href="gpu_bfc_allocator.h.html">"tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.h"</a></u></td></tr>
<tr><th id="22">22</th><td><u>#include <a href="gpu_cudamalloc_allocator.h.html">"tensorflow/core/common_runtime/gpu/gpu_cudamalloc_allocator.h"</a></u></td></tr>
<tr><th id="23">23</th><td><u>#include <a href="gpu_debug_allocator.h.html">"tensorflow/core/common_runtime/gpu/gpu_debug_allocator.h"</a></u></td></tr>
<tr><th id="24">24</th><td><u>#include <a href="gpu_id.h.html">"tensorflow/core/common_runtime/gpu/gpu_id.h"</a></u></td></tr>
<tr><th id="25">25</th><td><u>#include <a href="gpu_id_manager.h.html">"tensorflow/core/common_runtime/gpu/gpu_id_manager.h"</a></u></td></tr>
<tr><th id="26">26</th><td><u>#include <a href="gpu_id_utils.h.html">"tensorflow/core/common_runtime/gpu/gpu_id_utils.h"</a></u></td></tr>
<tr><th id="27">27</th><td><u>#include <a href="gpu_init.h.html">"tensorflow/core/common_runtime/gpu/gpu_init.h"</a></u></td></tr>
<tr><th id="28">28</th><td><u>#include <a href="pool_allocator.h.html">"tensorflow/core/common_runtime/gpu/pool_allocator.h"</a></u></td></tr>
<tr><th id="29">29</th><td><u>#include <a href="../../framework/allocator.h.html">"tensorflow/core/framework/allocator.h"</a></u></td></tr>
<tr><th id="30">30</th><td><u>#include <a href="../../framework/log_memory.h.html">"tensorflow/core/framework/log_memory.h"</a></u></td></tr>
<tr><th id="31">31</th><td><u>#include <a href="../../framework/tracking_allocator.h.html">"tensorflow/core/framework/tracking_allocator.h"</a></u></td></tr>
<tr><th id="32">32</th><td><u>#include <a href="../../lib/gtl/stl_util.h.html">"tensorflow/core/lib/gtl/stl_util.h"</a></u></td></tr>
<tr><th id="33">33</th><td><u>#include <a href="../../lib/strings/strcat.h.html">"tensorflow/core/lib/strings/strcat.h"</a></u></td></tr>
<tr><th id="34">34</th><td><u>#include <a href="../../platform/logging.h.html">"tensorflow/core/platform/logging.h"</a></u></td></tr>
<tr><th id="35">35</th><td><u>#include <a href="../../platform/mutex.h.html">"tensorflow/core/platform/mutex.h"</a></u></td></tr>
<tr><th id="36">36</th><td><u>#include <a href="../../platform/stream_executor.h.html">"tensorflow/core/platform/stream_executor.h"</a></u></td></tr>
<tr><th id="37">37</th><td><u>#include <a href="../../platform/types.h.html">"tensorflow/core/platform/types.h"</a></u></td></tr>
<tr><th id="38">38</th><td><u>#include <a href="../../util/env_var.h.html">"tensorflow/core/util/env_var.h"</a></u></td></tr>
<tr><th id="39">39</th><td></td></tr>
<tr><th id="40">40</th><td><i  data-doc="FLAGS_brain_mem_reg_cuda_dma">// If these flags need to be runtime configurable, consider adding</i></td></tr>
<tr><th id="41">41</th><td><i  data-doc="FLAGS_brain_mem_reg_cuda_dma">// options to ConfigProto.</i></td></tr>
<tr><th id="42">42</th><td><i  data-doc="FLAGS_brain_mem_reg_cuda_dma"></i></td></tr>
<tr><th id="43">43</th><td><i  data-doc="FLAGS_brain_mem_reg_cuda_dma">// If true, register CPU RAM used to copy to/from GPU RAM with the</i></td></tr>
<tr><th id="44">44</th><td><i  data-doc="FLAGS_brain_mem_reg_cuda_dma">// CUDA driver.</i></td></tr>
<tr><th id="45">45</th><td><em>const</em> <em>bool</em> <dfn class="tu decl def" id="FLAGS_brain_mem_reg_cuda_dma" title='FLAGS_brain_mem_reg_cuda_dma' data-type='const bool' data-ref="FLAGS_brain_mem_reg_cuda_dma">FLAGS_brain_mem_reg_cuda_dma</dfn> = <b>true</b>;</td></tr>
<tr><th id="46">46</th><td></td></tr>
<tr><th id="47">47</th><td><i  data-doc="FLAGS_brain_gpu_record_mem_types">// If true, record attributes of memory allocations and</i></td></tr>
<tr><th id="48">48</th><td><i  data-doc="FLAGS_brain_gpu_record_mem_types">// dynamically check for appropriate use of registered memory.</i></td></tr>
<tr><th id="49">49</th><td><i  data-doc="FLAGS_brain_gpu_record_mem_types">// Should only be true for debugging or diagnosis of</i></td></tr>
<tr><th id="50">50</th><td><i  data-doc="FLAGS_brain_gpu_record_mem_types">// performance issues.</i></td></tr>
<tr><th id="51">51</th><td><em>const</em> <em>bool</em> <dfn class="tu decl def" id="FLAGS_brain_gpu_record_mem_types" title='FLAGS_brain_gpu_record_mem_types' data-type='const bool' data-ref="FLAGS_brain_gpu_record_mem_types">FLAGS_brain_gpu_record_mem_types</dfn> = <b>false</b>;</td></tr>
<tr><th id="52">52</th><td></td></tr>
<tr><th id="53">53</th><td><b>namespace</b> <span class="namespace">tensorflow</span> {</td></tr>
<tr><th id="54">54</th><td><b>namespace</b> {</td></tr>
<tr><th id="55">55</th><td></td></tr>
<tr><th id="56">56</th><td><em>bool</em> <dfn class="tu decl def" id="_ZN10tensorflow12_GLOBAL__N_122useCudaMallocAllocatorEv" title='tensorflow::(anonymous namespace)::useCudaMallocAllocator' data-type='bool tensorflow::(anonymous namespace)::useCudaMallocAllocator()' data-ref="_ZN10tensorflow12_GLOBAL__N_122useCudaMallocAllocatorEv">useCudaMallocAllocator</dfn>() {</td></tr>
<tr><th id="57">57</th><td>  <em>const</em> <em>char</em>* <dfn class="local col1 decl" id="1debug_allocator_str" title='debug_allocator_str' data-type='const char *' data-ref="1debug_allocator_str">debug_allocator_str</dfn> = <span class="namespace">std::</span><a class="ref" href="../../../../../include/stdlib.h.html#getenv" title='getenv' data-ref="getenv">getenv</a>(<q>"TF_GPU_ALLOCATOR"</q>);</td></tr>
<tr><th id="58">58</th><td>  <b>return</b> <a class="local col1 ref" href="#1debug_allocator_str" title='debug_allocator_str' data-ref="1debug_allocator_str">debug_allocator_str</a> != <b>nullptr</b> &amp;&amp;</td></tr>
<tr><th id="59">59</th><td>         <span class="namespace">std::</span><a class="ref" href="../../../../../include/string.h.html#strcmp" title='strcmp' data-ref="strcmp">strcmp</a>(<a class="local col1 ref" href="#1debug_allocator_str" title='debug_allocator_str' data-ref="1debug_allocator_str">debug_allocator_str</a>, <q>"cuda_malloc"</q>) == <var>0</var>;</td></tr>
<tr><th id="60">60</th><td>}</td></tr>
<tr><th id="61">61</th><td></td></tr>
<tr><th id="62">62</th><td><em>bool</em> <dfn class="tu decl def" id="_ZN10tensorflow12_GLOBAL__N_127useCudaMemoryGuardAllocatorEv" title='tensorflow::(anonymous namespace)::useCudaMemoryGuardAllocator' data-type='bool tensorflow::(anonymous namespace)::useCudaMemoryGuardAllocator()' data-ref="_ZN10tensorflow12_GLOBAL__N_127useCudaMemoryGuardAllocatorEv">useCudaMemoryGuardAllocator</dfn>() {</td></tr>
<tr><th id="63">63</th><td>  <em>const</em> <em>char</em>* <dfn class="local col2 decl" id="2debug_allocator_str" title='debug_allocator_str' data-type='const char *' data-ref="2debug_allocator_str">debug_allocator_str</dfn> = <span class="namespace">std::</span><a class="ref" href="../../../../../include/stdlib.h.html#getenv" title='getenv' data-ref="getenv">getenv</a>(<q>"TF_GPU_ALLOCATOR"</q>);</td></tr>
<tr><th id="64">64</th><td>  <b>return</b> <a class="local col2 ref" href="#2debug_allocator_str" title='debug_allocator_str' data-ref="2debug_allocator_str">debug_allocator_str</a> != <b>nullptr</b> &amp;&amp;</td></tr>
<tr><th id="65">65</th><td>         <span class="namespace">std::</span><a class="ref" href="../../../../../include/string.h.html#strcmp" title='strcmp' data-ref="strcmp">strcmp</a>(<a class="local col2 ref" href="#2debug_allocator_str" title='debug_allocator_str' data-ref="2debug_allocator_str">debug_allocator_str</a>, <q>"memory_guard"</q>) == <var>0</var>;</td></tr>
<tr><th id="66">66</th><td>}</td></tr>
<tr><th id="67">67</th><td></td></tr>
<tr><th id="68">68</th><td>}  <i>// namespace</i></td></tr>
<tr><th id="69">69</th><td></td></tr>
<tr><th id="70">70</th><td><a class="type" href="process_state.h.html#tensorflow::ProcessState" title='tensorflow::ProcessState' data-ref="tensorflow::ProcessState">ProcessState</a>* <a class="type" href="process_state.h.html#tensorflow::ProcessState" title='tensorflow::ProcessState' data-ref="tensorflow::ProcessState">ProcessState</a>::<dfn class="decl def" id="tensorflow::ProcessState::instance_" title='tensorflow::ProcessState::instance_' data-ref="tensorflow::ProcessState::instance_">instance_</dfn> = <b>nullptr</b>;</td></tr>
<tr><th id="71">71</th><td></td></tr>
<tr><th id="72">72</th><td><i>/*static*/</i> <a class="type" href="process_state.h.html#tensorflow::ProcessState" title='tensorflow::ProcessState' data-ref="tensorflow::ProcessState">ProcessState</a>* <a class="type" href="process_state.h.html#tensorflow::ProcessState" title='tensorflow::ProcessState' data-ref="tensorflow::ProcessState">ProcessState</a>::<dfn class="decl def" id="_ZN10tensorflow12ProcessState9singletonEv" title='tensorflow::ProcessState::singleton' data-ref="_ZN10tensorflow12ProcessState9singletonEv">singleton</dfn>() {</td></tr>
<tr><th id="73">73</th><td>  <b>if</b> (<a class="member" href="process_state.h.html#tensorflow::ProcessState::instance_" title='tensorflow::ProcessState::instance_' data-ref="tensorflow::ProcessState::instance_">instance_</a> == <b>nullptr</b>) {</td></tr>
<tr><th id="74">74</th><td>    <a class="member" href="process_state.h.html#tensorflow::ProcessState::instance_" title='tensorflow::ProcessState::instance_' data-ref="tensorflow::ProcessState::instance_">instance_</a> = <b>new</b> <a class="ref fake" href="#_ZN10tensorflow12ProcessStateC1Ev" title='tensorflow::ProcessState::ProcessState' data-ref="_ZN10tensorflow12ProcessStateC1Ev"></a><a class="type" href="process_state.h.html#tensorflow::ProcessState" title='tensorflow::ProcessState' data-ref="tensorflow::ProcessState">ProcessState</a>;</td></tr>
<tr><th id="75">75</th><td>  }</td></tr>
<tr><th id="76">76</th><td></td></tr>
<tr><th id="77">77</th><td>  <b>return</b> <a class="member" href="process_state.h.html#tensorflow::ProcessState::instance_" title='tensorflow::ProcessState::instance_' data-ref="tensorflow::ProcessState::instance_">instance_</a>;</td></tr>
<tr><th id="78">78</th><td>}</td></tr>
<tr><th id="79">79</th><td></td></tr>
<tr><th id="80">80</th><td><a class="type" href="process_state.h.html#tensorflow::ProcessState" title='tensorflow::ProcessState' data-ref="tensorflow::ProcessState">ProcessState</a>::<dfn class="decl def" id="_ZN10tensorflow12ProcessStateC1Ev" title='tensorflow::ProcessState::ProcessState' data-ref="_ZN10tensorflow12ProcessStateC1Ev">ProcessState</dfn>() : <a class="member" href="process_state.h.html#tensorflow::ProcessState::gpu_device_enabled_" title='tensorflow::ProcessState::gpu_device_enabled_' data-ref="tensorflow::ProcessState::gpu_device_enabled_">gpu_device_enabled_</a>(<b>false</b>) {</td></tr>
<tr><th id="81">81</th><td>  <a class="macro" href="../../platform/default/logging.h.html#97" title="if ((__builtin_expect(!(instance_ == nullptr), 0))) ::tensorflow::internal::LogMessageFatal(&quot;/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/tensorflow/core/common_runtime/gpu/process_state.cc&quot;, 81) &lt;&lt; &quot;Check failed: &quot; &quot;instance_ == nullptr&quot; &quot; &quot;" data-ref="_M/CHECK">CHECK</a>(<a class="member" href="process_state.h.html#tensorflow::ProcessState::instance_" title='tensorflow::ProcessState::instance_' data-ref="tensorflow::ProcessState::instance_">instance_</a> == <b>nullptr</b>);</td></tr>
<tr><th id="82">82</th><td>  <a class="member" href="process_state.h.html#tensorflow::ProcessState::instance_" title='tensorflow::ProcessState::instance_' data-ref="tensorflow::ProcessState::instance_">instance_</a> = <b>this</b>;</td></tr>
<tr><th id="83">83</th><td>}</td></tr>
<tr><th id="84">84</th><td></td></tr>
<tr><th id="85">85</th><td><a class="type" href="process_state.h.html#tensorflow::ProcessState" title='tensorflow::ProcessState' data-ref="tensorflow::ProcessState">ProcessState</a>::<dfn class="virtual decl def" id="_ZN10tensorflow12ProcessStateD1Ev" title='tensorflow::ProcessState::~ProcessState' data-ref="_ZN10tensorflow12ProcessStateD1Ev">~ProcessState</dfn>() {</td></tr>
<tr><th id="86">86</th><td>  <b>for</b> (<em>auto</em> <dfn class="local col3 decl" id="3p" title='p' data-type='tensorflow::VisitableAllocator *' data-ref="3p">p</dfn> : <a class="member" href="process_state.h.html#tensorflow::ProcessState::gpu_allocators_" title='tensorflow::ProcessState::gpu_allocators_' data-ref="tensorflow::ProcessState::gpu_allocators_">gpu_allocators_</a>) {</td></tr>
<tr><th id="87">87</th><td>    <b>delete</b> <a class="local col3 ref" href="#3p" title='p' data-ref="3p">p</a>;</td></tr>
<tr><th id="88">88</th><td>  }</td></tr>
<tr><th id="89">89</th><td>  <a class="member" href="process_state.h.html#tensorflow::ProcessState::instance_" title='tensorflow::ProcessState::instance_' data-ref="tensorflow::ProcessState::instance_">instance_</a> = <b>nullptr</b>;</td></tr>
<tr><th id="90">90</th><td>}</td></tr>
<tr><th id="91">91</th><td></td></tr>
<tr><th id="92">92</th><td><a class="typedef" href="../../../../../include/c++/5/bits/stringfwd.h.html#std::string" title='std::string' data-type='basic_string&lt;char&gt;' data-ref="std::string">string</a> <a class="type" href="process_state.h.html#tensorflow::ProcessState" title='tensorflow::ProcessState' data-ref="tensorflow::ProcessState">ProcessState</a>::<a class="type" href="process_state.h.html#tensorflow::ProcessState::MemDesc" title='tensorflow::ProcessState::MemDesc' data-ref="tensorflow::ProcessState::MemDesc">MemDesc</a>::<dfn class="decl def" id="_ZN10tensorflow12ProcessState7MemDesc11DebugStringEv" title='tensorflow::ProcessState::MemDesc::DebugString' data-ref="_ZN10tensorflow12ProcessState7MemDesc11DebugStringEv">DebugString</dfn>() {</td></tr>
<tr><th id="93">93</th><td>  <b>return</b> <span class="namespace">strings::</span><a class="ref" href="../../lib/strings/strcat.h.html#_ZN10tensorflow7strings6StrCatERKNS0_8AlphaNumES3_S3_S3_S3_DpRKT_" title='tensorflow::strings::StrCat' data-ref="_ZN10tensorflow7strings6StrCatERKNS0_8AlphaNumES3_S3_S3_S3_DpRKT_">StrCat</a>(<a class="ref fake" href="../../lib/strings/strcat.h.html#_ZN10tensorflow7strings8AlphaNumC1EPKc" title='tensorflow::strings::AlphaNum::AlphaNum' data-ref="_ZN10tensorflow7strings8AlphaNumC1EPKc"></a>(<a class="member" href="process_state.h.html#tensorflow::ProcessState::MemDesc::loc" title='tensorflow::ProcessState::MemDesc::loc' data-ref="tensorflow::ProcessState::MemDesc::loc">loc</a> == <a class="enum" href="process_state.h.html#tensorflow::ProcessState::MemDesc::MemLoc::CPU" title='tensorflow::ProcessState::MemDesc::MemLoc::CPU' data-ref="tensorflow::ProcessState::MemDesc::MemLoc::CPU">CPU</a> ? <q>"CPU "</q> : <q>"GPU "</q>), <a class="ref fake" href="../../lib/strings/strcat.h.html#_ZN10tensorflow7strings8AlphaNumC1Ei" title='tensorflow::strings::AlphaNum::AlphaNum' data-ref="_ZN10tensorflow7strings8AlphaNumC1Ei"></a><a class="member" href="process_state.h.html#tensorflow::ProcessState::MemDesc::dev_index" title='tensorflow::ProcessState::MemDesc::dev_index' data-ref="tensorflow::ProcessState::MemDesc::dev_index">dev_index</a>,</td></tr>
<tr><th id="94">94</th><td>                         <a class="ref fake" href="../../lib/strings/strcat.h.html#_ZN10tensorflow7strings8AlphaNumC1EPKc" title='tensorflow::strings::AlphaNum::AlphaNum' data-ref="_ZN10tensorflow7strings8AlphaNumC1EPKc"></a><q>", dma: "</q>, <a class="ref fake" href="../../lib/strings/strcat.h.html#_ZN10tensorflow7strings8AlphaNumC1Ei" title='tensorflow::strings::AlphaNum::AlphaNum' data-ref="_ZN10tensorflow7strings8AlphaNumC1Ei"></a><a class="member" href="process_state.h.html#tensorflow::ProcessState::MemDesc::gpu_registered" title='tensorflow::ProcessState::MemDesc::gpu_registered' data-ref="tensorflow::ProcessState::MemDesc::gpu_registered">gpu_registered</a>, <a class="ref fake" href="../../lib/strings/strcat.h.html#_ZN10tensorflow7strings8AlphaNumC1EPKc" title='tensorflow::strings::AlphaNum::AlphaNum' data-ref="_ZN10tensorflow7strings8AlphaNumC1EPKc"></a><q>", nic: "</q>, <a class="member" href="process_state.h.html#tensorflow::ProcessState::MemDesc::nic_registered" title='tensorflow::ProcessState::MemDesc::nic_registered' data-ref="tensorflow::ProcessState::MemDesc::nic_registered">nic_registered</a>);</td></tr>
<tr><th id="95">95</th><td>}</td></tr>
<tr><th id="96">96</th><td></td></tr>
<tr><th id="97">97</th><td><a class="type" href="process_state.h.html#tensorflow::ProcessState" title='tensorflow::ProcessState' data-ref="tensorflow::ProcessState">ProcessState</a>::<a class="type" href="process_state.h.html#tensorflow::ProcessState::MemDesc" title='tensorflow::ProcessState::MemDesc' data-ref="tensorflow::ProcessState::MemDesc">MemDesc</a> <a class="type" href="process_state.h.html#tensorflow::ProcessState" title='tensorflow::ProcessState' data-ref="tensorflow::ProcessState">ProcessState</a>::<dfn class="decl def" id="_ZN10tensorflow12ProcessState7PtrTypeEPKv" title='tensorflow::ProcessState::PtrType' data-ref="_ZN10tensorflow12ProcessState7PtrTypeEPKv">PtrType</dfn>(<em>const</em> <em>void</em>* <dfn class="local col4 decl" id="4ptr" title='ptr' data-type='const void *' data-ref="4ptr">ptr</dfn>) {</td></tr>
<tr><th id="98">98</th><td>  <b>if</b> (<a class="tu ref" href="#FLAGS_brain_gpu_record_mem_types" title='FLAGS_brain_gpu_record_mem_types' data-use='r' data-ref="FLAGS_brain_gpu_record_mem_types">FLAGS_brain_gpu_record_mem_types</a>) {</td></tr>
<tr><th id="99">99</th><td>    <em>auto</em> <dfn class="local col5 decl" id="5iter" title='iter' data-type='std::__detail::_Node_iterator&lt;std::pair&lt;const void *const, tensorflow::ProcessState::MemDesc&gt;, false, false&gt;' data-ref="5iter">iter</dfn> = <a class="member" href="process_state.h.html#tensorflow::ProcessState::mem_desc_map_" title='tensorflow::ProcessState::mem_desc_map_' data-ref="tensorflow::ProcessState::mem_desc_map_">mem_desc_map_</a>.<a class="ref" href="../../../../../include/c++/5/bits/unordered_map.h.html#_ZNSt13unordered_map4findERKNSt10_HashtableIT_St4pairIKS1_T0_ET3_NSt8__detail10_Select1stET2_T1_NS7_18_Mod_range_hashingENS7_20_Default_ranged_hashENS12423071" title='std::unordered_map::find' data-ref="_ZNSt13unordered_map4findERKNSt10_HashtableIT_St4pairIKS1_T0_ET3_NSt8__detail10_Select1stET2_T1_NS7_18_Mod_range_hashingENS7_20_Default_ranged_hashENS12423071">find</a>(<a class="local col4 ref" href="#4ptr" title='ptr' data-ref="4ptr">ptr</a>);</td></tr>
<tr><th id="100">100</th><td>    <b>if</b> (<a class="local col5 ref" href="#5iter" title='iter' data-ref="5iter">iter</a> <a class="ref" href="../../../../../include/c++/5/bits/hashtable_policy.h.html#_ZNSt8__detailneERKNS_19_Node_iterator_baseIT_XT0_EEES4_" title='std::__detail::operator!=' data-ref="_ZNSt8__detailneERKNS_19_Node_iterator_baseIT_XT0_EEES4_">!=</a> <a class="member" href="process_state.h.html#tensorflow::ProcessState::mem_desc_map_" title='tensorflow::ProcessState::mem_desc_map_' data-ref="tensorflow::ProcessState::mem_desc_map_">mem_desc_map_</a>.<a class="ref" href="../../../../../include/c++/5/bits/unordered_map.h.html#_ZNSt13unordered_map3endEv" title='std::unordered_map::end' data-ref="_ZNSt13unordered_map3endEv">end</a>()) {</td></tr>
<tr><th id="101">101</th><td>      <b>return</b> <a class="ref fake" href="process_state.h.html#45" title='tensorflow::ProcessState::MemDesc::MemDesc' data-ref="_ZN10tensorflow12ProcessState7MemDescC1ERKS1_"></a><a class="local col5 ref" href="#5iter" title='iter' data-ref="5iter">iter</a><a class="ref" href="../../../../../include/c++/5/bits/hashtable_policy.h.html#_ZNKSt8__detail14_Node_iteratorptEv" title='std::__detail::_Node_iterator::operator-&gt;' data-ref="_ZNKSt8__detail14_Node_iteratorptEv">-&gt;</a><a class="ref" href="../../../../../include/c++/5/bits/stl_pair.h.html#std::pair::second" title='std::pair&lt;const void *const, tensorflow::ProcessState::MemDesc&gt;::second' data-ref="std::pair::second">second</a>;</td></tr>
<tr><th id="102">102</th><td>    }</td></tr>
<tr><th id="103">103</th><td>  }</td></tr>
<tr><th id="104">104</th><td>  <b>return</b> <a class="type" href="process_state.h.html#tensorflow::ProcessState::MemDesc" title='tensorflow::ProcessState::MemDesc' data-ref="tensorflow::ProcessState::MemDesc">MemDesc</a><a class="ref" href="process_state.h.html#_ZN10tensorflow12ProcessState7MemDescC1Ev" title='tensorflow::ProcessState::MemDesc::MemDesc' data-ref="_ZN10tensorflow12ProcessState7MemDescC1Ev">(</a>);</td></tr>
<tr><th id="105">105</th><td>}</td></tr>
<tr><th id="106">106</th><td></td></tr>
<tr><th id="107">107</th><td><a class="type" href="../../framework/allocator.h.html#tensorflow::Allocator" title='tensorflow::Allocator' data-ref="tensorflow::Allocator">Allocator</a>* <a class="type" href="process_state.h.html#tensorflow::ProcessState" title='tensorflow::ProcessState' data-ref="tensorflow::ProcessState">ProcessState</a>::<dfn class="virtual decl def" id="_ZN10tensorflow12ProcessState15GetGPUAllocatorERKNS_10GPUOptionsENS_3gtl7IntTypeINS_12TfGpuId_tag_EiEEm" title='tensorflow::ProcessState::GetGPUAllocator' data-ref="_ZN10tensorflow12ProcessState15GetGPUAllocatorERKNS_10GPUOptionsENS_3gtl7IntTypeINS_12TfGpuId_tag_EiEEm">GetGPUAllocator</dfn>(<em>const</em> <span class='type' title='tensorflow::GPUOptions' data-ref="tensorflow::GPUOptions">GPUOptions</span>&amp; <dfn class="local col6 decl" id="6options" title='options' data-type='const tensorflow::GPUOptions &amp;' data-ref="6options">options</dfn>,</td></tr>
<tr><th id="108">108</th><td>                                         <a class="typedef" href="gpu_id.h.html#83" title='tensorflow::TfGpuId' data-type='::tensorflow::gtl::IntType&lt;TfGpuId_tag_, int32&gt;' data-ref="tensorflow::TfGpuId">TfGpuId</a> <dfn class="local col7 decl" id="7tf_gpu_id" title='tf_gpu_id' data-type='TfGpuId' data-ref="7tf_gpu_id">tf_gpu_id</dfn>,</td></tr>
<tr><th id="109">109</th><td>                                         <span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span> <dfn class="local col8 decl" id="8total_bytes" title='total_bytes' data-type='size_t' data-ref="8total_bytes">total_bytes</dfn>) {</td></tr>
<tr><th id="110">110</th><td><u>#<span data-ppcond="110">if</span> GOOGLE_CUDA</u></td></tr>
<tr><th id="111">111</th><td>  <em>const</em> string&amp; allocator_type = options.allocator_type();</td></tr>
<tr><th id="112">112</th><td>  mutex_lock lock(mu_);</td></tr>
<tr><th id="113">113</th><td>  GpuIdUtil::CheckValidTfGpuId(tf_gpu_id);</td></tr>
<tr><th id="114">114</th><td></td></tr>
<tr><th id="115">115</th><td>  <b>if</b> (tf_gpu_id.value() &gt;= <b>static_cast</b>&lt;int64&gt;(gpu_allocators_.size())) {</td></tr>
<tr><th id="116">116</th><td>    gpu_allocators_.resize(tf_gpu_id.value() + <var>1</var>);</td></tr>
<tr><th id="117">117</th><td>    <b>if</b> (FLAGS_brain_gpu_record_mem_types) gpu_al_.resize(tf_gpu_id.value() + <var>1</var>);</td></tr>
<tr><th id="118">118</th><td>  }</td></tr>
<tr><th id="119">119</th><td></td></tr>
<tr><th id="120">120</th><td>  <b>if</b> (gpu_allocators_[tf_gpu_id.value()] == <b>nullptr</b>) {</td></tr>
<tr><th id="121">121</th><td>    VisitableAllocator* gpu_allocator;</td></tr>
<tr><th id="122">122</th><td></td></tr>
<tr><th id="123">123</th><td>    <i>// Validate allocator types.</i></td></tr>
<tr><th id="124">124</th><td>    <b>if</b> (!allocator_type.empty() &amp;&amp; allocator_type != <q>"BFC"</q>) {</td></tr>
<tr><th id="125">125</th><td>      LOG(ERROR) &lt;&lt; <q>"Invalid allocator type: "</q> &lt;&lt; allocator_type;</td></tr>
<tr><th id="126">126</th><td>      <b>return</b> <b>nullptr</b>;</td></tr>
<tr><th id="127">127</th><td>    }</td></tr>
<tr><th id="128">128</th><td></td></tr>
<tr><th id="129">129</th><td>    <em>const</em> CudaGpuId cuda_gpu_id = GpuIdManager::TfToCudaGpuId(tf_gpu_id);</td></tr>
<tr><th id="130">130</th><td>    gpu_allocator =</td></tr>
<tr><th id="131">131</th><td>        <b>new</b> GPUBFCAllocator(cuda_gpu_id, total_bytes, options,</td></tr>
<tr><th id="132">132</th><td>                            strings::StrCat(<q>"GPU_"</q>, tf_gpu_id.value(), <q>"_bfc"</q>));</td></tr>
<tr><th id="133">133</th><td></td></tr>
<tr><th id="134">134</th><td>    <i>// If true, checks for memory overwrites by writing</i></td></tr>
<tr><th id="135">135</th><td><i>    // distinctive patterns on both ends of allocated memory.</i></td></tr>
<tr><th id="136">136</th><td>    <b>if</b> (useCudaMemoryGuardAllocator()) {</td></tr>
<tr><th id="137">137</th><td>      gpu_allocator = <b>new</b> GPUDebugAllocator(gpu_allocator, cuda_gpu_id);</td></tr>
<tr><th id="138">138</th><td>      gpu_allocator = <b>new</b> GPUNanResetAllocator(gpu_allocator, cuda_gpu_id);</td></tr>
<tr><th id="139">139</th><td>    } <b>else</b> <b>if</b> (useCudaMallocAllocator()) {</td></tr>
<tr><th id="140">140</th><td>      <i>// If true, passes all allocation requests through to cudaMalloc</i></td></tr>
<tr><th id="141">141</th><td><i>      // useful for doing memory debugging with tools like cuda-memcheck</i></td></tr>
<tr><th id="142">142</th><td><i>      // **WARNING** probably will not work in a multi-gpu scenario</i></td></tr>
<tr><th id="143">143</th><td>      gpu_allocator = <b>new</b> GPUcudaMallocAllocator(gpu_allocator, cuda_gpu_id);</td></tr>
<tr><th id="144">144</th><td>    }</td></tr>
<tr><th id="145">145</th><td>    gpu_allocators_[tf_gpu_id.value()] = gpu_allocator;</td></tr>
<tr><th id="146">146</th><td></td></tr>
<tr><th id="147">147</th><td>    <i>// If there are any pending AllocVisitors for this bus, add</i></td></tr>
<tr><th id="148">148</th><td><i>    // them now.</i></td></tr>
<tr><th id="149">149</th><td>    gpu::StreamExecutor* se =</td></tr>
<tr><th id="150">150</th><td>        GpuIdUtil::ExecutorForTfGpuId(tf_gpu_id).ValueOrDie();</td></tr>
<tr><th id="151">151</th><td>    <em>int</em> bus_id = se-&gt;GetDeviceDescription().numa_node();</td></tr>
<tr><th id="152">152</th><td>    <b>if</b> (bus_id &gt;= <var>0</var> &amp;&amp; bus_id &lt; <b>static_cast</b>&lt;int64&gt;(gpu_visitors_.size())) {</td></tr>
<tr><th id="153">153</th><td>      <b>for</b> (<em>const</em> <em>auto</em>&amp; v : gpu_visitors_[bus_id]) {</td></tr>
<tr><th id="154">154</th><td>        gpu_allocator-&gt;AddAllocVisitor(v);</td></tr>
<tr><th id="155">155</th><td>      }</td></tr>
<tr><th id="156">156</th><td>    }</td></tr>
<tr><th id="157">157</th><td>    <b>if</b> (FLAGS_brain_gpu_record_mem_types) {</td></tr>
<tr><th id="158">158</th><td>      MemDesc md;</td></tr>
<tr><th id="159">159</th><td>      md.loc = MemDesc::GPU;</td></tr>
<tr><th id="160">160</th><td>      md.dev_index = cuda_gpu_id.value();</td></tr>
<tr><th id="161">161</th><td>      md.gpu_registered = <b>false</b>;</td></tr>
<tr><th id="162">162</th><td>      md.nic_registered = <b>true</b>;</td></tr>
<tr><th id="163">163</th><td>      <b>if</b> (<b>static_cast</b>&lt;int64&gt;(gpu_al_.size()) &lt;= tf_gpu_id.value()) {</td></tr>
<tr><th id="164">164</th><td>        gpu_al_.resize(tf_gpu_id.value() + <var>1</var>);</td></tr>
<tr><th id="165">165</th><td>      }</td></tr>
<tr><th id="166">166</th><td>      gpu_al_[tf_gpu_id.value()] = <b>new</b> internal::RecordingAllocator(</td></tr>
<tr><th id="167">167</th><td>          &amp;mem_desc_map_, gpu_allocator, md, &amp;mu_);</td></tr>
<tr><th id="168">168</th><td>    }</td></tr>
<tr><th id="169">169</th><td>  }</td></tr>
<tr><th id="170">170</th><td>  <b>if</b> (FLAGS_brain_gpu_record_mem_types) <b>return</b> gpu_al_[tf_gpu_id.value()];</td></tr>
<tr><th id="171">171</th><td>  <b>return</b> gpu_allocators_[tf_gpu_id.value()];</td></tr>
<tr><th id="172">172</th><td><u>#<span data-ppcond="110">else</span></u></td></tr>
<tr><th id="173">173</th><td>  <a class="macro" href="../../platform/default/logging.h.html#77" title="::tensorflow::internal::LogMessageFatal(&quot;/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/tensorflow/core/common_runtime/gpu/process_state.cc&quot;, 173)" data-ref="_M/LOG">LOG</a>(FATAL) <a class="ref" href="../../../../../include/c++/5/ostream.html#_ZStlsOSt13basic_ostreamIT_T0_ERKT1_" title='std::operator&lt;&lt;' data-ref="_ZStlsOSt13basic_ostreamIT_T0_ERKT1_">&lt;&lt;</a> <q>"GPUAllocator unavailable. Not compiled with --config=cuda."</q>;</td></tr>
<tr><th id="174">174</th><td>  <b>return</b> <b>nullptr</b>;</td></tr>
<tr><th id="175">175</th><td><u>#<span data-ppcond="110">endif</span>  // GOOGLE_CUDA</u></td></tr>
<tr><th id="176">176</th><td>}</td></tr>
<tr><th id="177">177</th><td></td></tr>
<tr><th id="178">178</th><td><a class="type" href="../../framework/allocator.h.html#tensorflow::Allocator" title='tensorflow::Allocator' data-ref="tensorflow::Allocator">Allocator</a>* <a class="type" href="process_state.h.html#tensorflow::ProcessState" title='tensorflow::ProcessState' data-ref="tensorflow::ProcessState">ProcessState</a>::<dfn class="decl def" id="_ZN10tensorflow12ProcessState15GetCPUAllocatorEi" title='tensorflow::ProcessState::GetCPUAllocator' data-ref="_ZN10tensorflow12ProcessState15GetCPUAllocatorEi">GetCPUAllocator</dfn>(<em>int</em> <dfn class="local col9 decl" id="9numa_node" title='numa_node' data-type='int' data-ref="9numa_node">numa_node</dfn>) {</td></tr>
<tr><th id="179">179</th><td>  <i>// Although we're temporarily ignoring numa_node, check for legality.</i></td></tr>
<tr><th id="180">180</th><td>  <a class="macro" href="../../platform/default/logging.h.html#255" title="while (::tensorflow::internal::CheckOpString _result = ::tensorflow::internal::Check_GEImpl( ::tensorflow::internal::GetReferenceableValue(numa_node), ::tensorflow::internal::GetReferenceableValue(0), &quot;numa_node&quot; &quot; &quot; &quot;&gt;=&quot; &quot; &quot; &quot;0&quot;)) ::tensorflow::internal::LogMessageFatal(&quot;/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/tensorflow/core/common_runtime/gpu/process_state.cc&quot;, 180) &lt;&lt; *(_result.str_)" data-ref="_M/CHECK_GE">CHECK_GE</a>(<a class="local col9 ref" href="#9numa_node" title='numa_node' data-ref="9numa_node">numa_node</a>, <var>0</var>);</td></tr>
<tr><th id="181">181</th><td>  <i>// TODO(tucker): actually maintain separate CPUAllocators for</i></td></tr>
<tr><th id="182">182</th><td><i>  // different numa_nodes.  For now, just one.</i></td></tr>
<tr><th id="183">183</th><td>  <a class="local col9 ref" href="#9numa_node" title='numa_node' data-ref="9numa_node">numa_node</a> = <var>0</var>;</td></tr>
<tr><th id="184">184</th><td>  <a class="type" href="../../platform/default/mutex.h.html#tensorflow::mutex_lock" title='tensorflow::mutex_lock' data-ref="tensorflow::mutex_lock">mutex_lock</a> <dfn class="local col0 decl" id="10lock" title='lock' data-type='tensorflow::mutex_lock' data-ref="10lock">lock</dfn><a class="ref" href="../../platform/default/mutex.h.html#_ZN10tensorflow10mutex_lockC1ERNS_5mutexE" title='tensorflow::mutex_lock::mutex_lock' data-ref="_ZN10tensorflow10mutex_lockC1ERNS_5mutexE">(</a><a class="member" href="process_state.h.html#tensorflow::ProcessState::mu_" title='tensorflow::ProcessState::mu_' data-ref="tensorflow::ProcessState::mu_">mu_</a>);</td></tr>
<tr><th id="185">185</th><td>  <b>while</b> (<a class="member" href="process_state.h.html#tensorflow::ProcessState::cpu_allocators_" title='tensorflow::ProcessState::cpu_allocators_' data-ref="tensorflow::ProcessState::cpu_allocators_">cpu_allocators_</a>.<a class="ref" href="../../../../../include/c++/5/bits/stl_vector.h.html#_ZNKSt6vector4sizeEv" title='std::vector::size' data-ref="_ZNKSt6vector4sizeEv">size</a>() &lt;= <b>static_cast</b>&lt;<span class='typedef' title='size_t' data-type='unsigned long' data-ref="size_t">size_t</span>&gt;(<a class="local col9 ref" href="#9numa_node" title='numa_node' data-ref="9numa_node">numa_node</a>)) {</td></tr>
<tr><th id="186">186</th><td>    <em>bool</em> <dfn class="local col1 decl" id="11use_bfc_allocator" title='use_bfc_allocator' data-type='bool' data-ref="11use_bfc_allocator">use_bfc_allocator</dfn> = <b>false</b>;</td></tr>
<tr><th id="187">187</th><td>    <i>// TODO(reedwm): Switch default to BGFAllocator if it's at least as fast and</i></td></tr>
<tr><th id="188">188</th><td><i>    // efficient.</i></td></tr>
<tr><th id="189">189</th><td>    <a class="type" href="../../lib/core/status.h.html#tensorflow::Status" title='tensorflow::Status' data-ref="tensorflow::Status">Status</a> <dfn class="local col2 decl" id="12status" title='status' data-type='tensorflow::Status' data-ref="12status">status</dfn> = <a class="ref" href="../../util/env_var.h.html#_ZN10tensorflow18ReadBoolFromEnvVarENS_11StringPieceEbPb" title='tensorflow::ReadBoolFromEnvVar' data-ref="_ZN10tensorflow18ReadBoolFromEnvVarENS_11StringPieceEbPb">ReadBoolFromEnvVar</a>(<a class="ref fake" href="../../lib/core/stringpiece.h.html#_ZN10tensorflow11StringPieceC1EPKc" title='tensorflow::StringPiece::StringPiece' data-ref="_ZN10tensorflow11StringPieceC1EPKc"></a><q>"TF_CPU_ALLOCATOR_USE_BFC"</q>, <b>false</b>,</td></tr>
<tr><th id="190">190</th><td>                                       &amp;<a class="local col1 ref" href="#11use_bfc_allocator" title='use_bfc_allocator' data-ref="11use_bfc_allocator">use_bfc_allocator</a>);</td></tr>
<tr><th id="191">191</th><td>    <b>if</b> (!<a class="local col2 ref" href="#12status" title='status' data-ref="12status">status</a>.<a class="ref" href="../../lib/core/status.h.html#_ZNK10tensorflow6Status2okEv" title='tensorflow::Status::ok' data-ref="_ZNK10tensorflow6Status2okEv">ok</a>()) {</td></tr>
<tr><th id="192">192</th><td>      <a class="macro" href="../../platform/default/logging.h.html#77" title="::tensorflow::internal::LogMessage(&quot;/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/tensorflow/core/common_runtime/gpu/process_state.cc&quot;, 192, ::tensorflow::ERROR)" data-ref="_M/LOG">LOG</a>(ERROR) <a class="ref" href="../../../../../include/c++/5/ostream.html#_ZStlsOSt13basic_ostreamIT_T0_ERKT1_" title='std::operator&lt;&lt;' data-ref="_ZStlsOSt13basic_ostreamIT_T0_ERKT1_">&lt;&lt;</a> <q>"GetCPUAllocator: "</q> <a class="ref" href="../../../../../include/c++/5/bits/basic_string.h.html#_ZStlsRSt13basic_ostreamIT_T0_ERKSbIS0_S1_T1_E" title='std::operator&lt;&lt;' data-ref="_ZStlsRSt13basic_ostreamIT_T0_ERKSbIS0_S1_T1_E">&lt;&lt;</a> <a class="local col2 ref" href="#12status" title='status' data-ref="12status">status</a>.<a class="ref" href="../../lib/core/status.h.html#_ZNK10tensorflow6Status13error_messageEv" title='tensorflow::Status::error_message' data-ref="_ZNK10tensorflow6Status13error_messageEv">error_message</a>();</td></tr>
<tr><th id="193">193</th><td>    }</td></tr>
<tr><th id="194">194</th><td>    <a class="type" href="../visitable_allocator.h.html#tensorflow::VisitableAllocator" title='tensorflow::VisitableAllocator' data-ref="tensorflow::VisitableAllocator">VisitableAllocator</a>* <dfn class="local col3 decl" id="13allocator" title='allocator' data-type='tensorflow::VisitableAllocator *' data-ref="13allocator">allocator</dfn>;</td></tr>
<tr><th id="195">195</th><td>    <b>if</b> (<a class="local col1 ref" href="#11use_bfc_allocator" title='use_bfc_allocator' data-ref="11use_bfc_allocator">use_bfc_allocator</a>) {</td></tr>
<tr><th id="196">196</th><td>      <i>// TODO(reedwm): evaluate whether 64GB by default is the best choice.</i></td></tr>
<tr><th id="197">197</th><td>      <a class="typedef" href="../../platform/default/integral_types.h.html#tensorflow::int64" title='tensorflow::int64' data-type='long long' data-ref="tensorflow::int64">int64</a> <dfn class="local col4 decl" id="14cpu_mem_limit_in_mb" title='cpu_mem_limit_in_mb' data-type='int64' data-ref="14cpu_mem_limit_in_mb">cpu_mem_limit_in_mb</dfn> = -<var>1</var>;</td></tr>
<tr><th id="198">198</th><td>      <a class="type" href="../../lib/core/status.h.html#tensorflow::Status" title='tensorflow::Status' data-ref="tensorflow::Status">Status</a> <dfn class="local col5 decl" id="15status" title='status' data-type='tensorflow::Status' data-ref="15status">status</dfn> = <a class="ref" href="../../util/env_var.h.html#_ZN10tensorflow19ReadInt64FromEnvVarENS_11StringPieceExPx" title='tensorflow::ReadInt64FromEnvVar' data-ref="_ZN10tensorflow19ReadInt64FromEnvVarENS_11StringPieceExPx">ReadInt64FromEnvVar</a>(<a class="ref fake" href="../../lib/core/stringpiece.h.html#_ZN10tensorflow11StringPieceC1EPKc" title='tensorflow::StringPiece::StringPiece' data-ref="_ZN10tensorflow11StringPieceC1EPKc"></a><q>"TF_CPU_BFC_MEM_LIMIT_IN_MB"</q>,</td></tr>
<tr><th id="199">199</th><td>                                          <var>1LL</var> &lt;&lt; <var>16</var> <i>/*64GB max by default*/</i>,</td></tr>
<tr><th id="200">200</th><td>                                          &amp;<a class="local col4 ref" href="#14cpu_mem_limit_in_mb" title='cpu_mem_limit_in_mb' data-ref="14cpu_mem_limit_in_mb">cpu_mem_limit_in_mb</a>);</td></tr>
<tr><th id="201">201</th><td>      <b>if</b> (!<a class="local col5 ref" href="#15status" title='status' data-ref="15status">status</a>.<a class="ref" href="../../lib/core/status.h.html#_ZNK10tensorflow6Status2okEv" title='tensorflow::Status::ok' data-ref="_ZNK10tensorflow6Status2okEv">ok</a>()) {</td></tr>
<tr><th id="202">202</th><td>        <a class="macro" href="../../platform/default/logging.h.html#77" title="::tensorflow::internal::LogMessage(&quot;/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/tensorflow/core/common_runtime/gpu/process_state.cc&quot;, 202, ::tensorflow::ERROR)" data-ref="_M/LOG">LOG</a>(ERROR) <a class="ref" href="../../../../../include/c++/5/ostream.html#_ZStlsOSt13basic_ostreamIT_T0_ERKT1_" title='std::operator&lt;&lt;' data-ref="_ZStlsOSt13basic_ostreamIT_T0_ERKT1_">&lt;&lt;</a> <q>"GetCPUAllocator: "</q> <a class="ref" href="../../../../../include/c++/5/bits/basic_string.h.html#_ZStlsRSt13basic_ostreamIT_T0_ERKSbIS0_S1_T1_E" title='std::operator&lt;&lt;' data-ref="_ZStlsRSt13basic_ostreamIT_T0_ERKSbIS0_S1_T1_E">&lt;&lt;</a> <a class="local col5 ref" href="#15status" title='status' data-ref="15status">status</a>.<a class="ref" href="../../lib/core/status.h.html#_ZNK10tensorflow6Status13error_messageEv" title='tensorflow::Status::error_message' data-ref="_ZNK10tensorflow6Status13error_messageEv">error_message</a>();</td></tr>
<tr><th id="203">203</th><td>      }</td></tr>
<tr><th id="204">204</th><td>      <a class="typedef" href="../../platform/default/integral_types.h.html#tensorflow::int64" title='tensorflow::int64' data-type='long long' data-ref="tensorflow::int64">int64</a> <dfn class="local col6 decl" id="16cpu_mem_limit" title='cpu_mem_limit' data-type='int64' data-ref="16cpu_mem_limit">cpu_mem_limit</dfn> = <a class="local col4 ref" href="#14cpu_mem_limit_in_mb" title='cpu_mem_limit_in_mb' data-ref="14cpu_mem_limit_in_mb">cpu_mem_limit_in_mb</a> * (<var>1LL</var> &lt;&lt; <var>20</var>);</td></tr>
<tr><th id="205">205</th><td>      <a class="local col3 ref" href="#13allocator" title='allocator' data-ref="13allocator">allocator</a> = <b>new</b> <a class="type" href="../bfc_allocator.h.html#tensorflow::BFCAllocator" title='tensorflow::BFCAllocator' data-ref="tensorflow::BFCAllocator">BFCAllocator</a><a class="ref" href="../bfc_allocator.h.html#_ZN10tensorflow12BFCAllocatorC1EPNS_12SubAllocatorEmbRKSs" title='tensorflow::BFCAllocator::BFCAllocator' data-ref="_ZN10tensorflow12BFCAllocatorC1EPNS_12SubAllocatorEmbRKSs">(</a><b>new</b> <a class="type" href="pool_allocator.h.html#tensorflow::BasicCPUAllocator" title='tensorflow::BasicCPUAllocator' data-ref="tensorflow::BasicCPUAllocator">BasicCPUAllocator</a><a class="ref" href="pool_allocator.h.html#169" title='tensorflow::BasicCPUAllocator::BasicCPUAllocator' data-ref="_ZN10tensorflow17BasicCPUAllocatorC1Ev">(</a>), <a class="local col6 ref" href="#16cpu_mem_limit" title='cpu_mem_limit' data-ref="16cpu_mem_limit">cpu_mem_limit</a>,</td></tr>
<tr><th id="206">206</th><td>                                   <b>true</b> <i>/*allow_growth*/</i>,</td></tr>
<tr><th id="207">207</th><td>                                   <a class="ref fake" href="../../../../../include/c++/5/bits/basic_string.h.html#_ZNSt12basic_stringC1EPKT_RKT1_" title='std::basic_string::basic_string&lt;_CharT, _Traits, _Alloc&gt;' data-ref="_ZNSt12basic_stringC1EPKT_RKT1_"></a><q>"bfc_cpu_allocator_for_gpu"</q> <i>/*name*/</i>);</td></tr>
<tr><th id="208">208</th><td>      <a class="macro" href="../../platform/default/logging.h.html#89" title="if ((__builtin_expect(((2) &lt;= ::tensorflow::internal::LogMessage::MinVLogLevel()), 0))) ::tensorflow::internal::LogMessage(&quot;/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/tensorflow/core/common_runtime/gpu/process_state.cc&quot;, 208, tensorflow::INFO)" data-ref="_M/VLOG">VLOG</a>(<var>2</var>) <a class="ref" href="../../../../../include/c++/5/ostream.html#_ZStlsOSt13basic_ostreamIT_T0_ERKT1_" title='std::operator&lt;&lt;' data-ref="_ZStlsOSt13basic_ostreamIT_T0_ERKT1_">&lt;&lt;</a> <q>"Using BFCAllocator with memory limit of "</q></td></tr>
<tr><th id="209">209</th><td>              <a class="ref" href="../../../../../include/c++/5/ostream.html#_ZNSt13basic_ostreamlsEx" title='std::basic_ostream::operator&lt;&lt;' data-ref="_ZNSt13basic_ostreamlsEx">&lt;&lt;</a> <a class="local col4 ref" href="#14cpu_mem_limit_in_mb" title='cpu_mem_limit_in_mb' data-ref="14cpu_mem_limit_in_mb">cpu_mem_limit_in_mb</a> <a class="ref" href="../../../../../include/c++/5/ostream.html#_ZStlsRSt13basic_ostreamIcT_EPKc" title='std::operator&lt;&lt;' data-ref="_ZStlsRSt13basic_ostreamIcT_EPKc">&lt;&lt;</a> <q>" MB for ProcessState CPU allocator"</q>;</td></tr>
<tr><th id="210">210</th><td>    } <b>else</b> {</td></tr>
<tr><th id="211">211</th><td>      <a class="local col3 ref" href="#13allocator" title='allocator' data-ref="13allocator">allocator</a> = <b>new</b> <a class="type" href="pool_allocator.h.html#tensorflow::PoolAllocator" title='tensorflow::PoolAllocator' data-ref="tensorflow::PoolAllocator">PoolAllocator</a><a class="ref" href="pool_allocator.h.html#_ZN10tensorflow13PoolAllocatorC1EmbPNS_12SubAllocatorEPNS_16RoundUpInterfaceESs" title='tensorflow::PoolAllocator::PoolAllocator' data-ref="_ZN10tensorflow13PoolAllocatorC1EmbPNS_12SubAllocatorEPNS_16RoundUpInterfaceESs">(</a></td></tr>
<tr><th id="212">212</th><td>          <var>100</var> <i>/*pool_size_limit*/</i>, <b>true</b> <i>/*auto_resize*/</i>,</td></tr>
<tr><th id="213">213</th><td>          <b>new</b> <a class="type" href="pool_allocator.h.html#tensorflow::BasicCPUAllocator" title='tensorflow::BasicCPUAllocator' data-ref="tensorflow::BasicCPUAllocator">BasicCPUAllocator</a><a class="ref" href="pool_allocator.h.html#169" title='tensorflow::BasicCPUAllocator::BasicCPUAllocator' data-ref="_ZN10tensorflow17BasicCPUAllocatorC1Ev">(</a>), <b>new</b> <a class="ref fake" href="pool_allocator.h.html#156" title='tensorflow::NoopRounder::NoopRounder' data-ref="_ZN10tensorflow11NoopRounderC1Ev"></a><a class="type" href="pool_allocator.h.html#tensorflow::NoopRounder" title='tensorflow::NoopRounder' data-ref="tensorflow::NoopRounder">NoopRounder</a>, <a class="ref fake" href="../../../../../include/c++/5/bits/basic_string.h.html#_ZNSt12basic_stringC1EPKT_RKT1_" title='std::basic_string::basic_string&lt;_CharT, _Traits, _Alloc&gt;' data-ref="_ZNSt12basic_stringC1EPKT_RKT1_"></a><q>"cpu_pool"</q>);</td></tr>
<tr><th id="214">214</th><td>      <a class="macro" href="../../platform/default/logging.h.html#89" title="if ((__builtin_expect(((2) &lt;= ::tensorflow::internal::LogMessage::MinVLogLevel()), 0))) ::tensorflow::internal::LogMessage(&quot;/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/tensorflow/core/common_runtime/gpu/process_state.cc&quot;, 214, tensorflow::INFO)" data-ref="_M/VLOG">VLOG</a>(<var>2</var>) <a class="ref" href="../../../../../include/c++/5/ostream.html#_ZStlsOSt13basic_ostreamIT_T0_ERKT1_" title='std::operator&lt;&lt;' data-ref="_ZStlsOSt13basic_ostreamIT_T0_ERKT1_">&lt;&lt;</a> <q>"Using PoolAllocator for ProcessState CPU allocator"</q>;</td></tr>
<tr><th id="215">215</th><td>    }</td></tr>
<tr><th id="216">216</th><td>    <b>if</b> (<a class="type" href="../../framework/log_memory.h.html#tensorflow::LogMemory" title='tensorflow::LogMemory' data-ref="tensorflow::LogMemory">LogMemory</a>::<a class="ref" href="../../framework/log_memory.h.html#_ZN10tensorflow9LogMemory9IsEnabledEv" title='tensorflow::LogMemory::IsEnabled' data-ref="_ZN10tensorflow9LogMemory9IsEnabledEv">IsEnabled</a>()) {</td></tr>
<tr><th id="217">217</th><td>      <i>// Wrap the allocator to track allocation ids for better logging</i></td></tr>
<tr><th id="218">218</th><td><i>      // at the cost of performance.</i></td></tr>
<tr><th id="219">219</th><td>      <a class="local col3 ref" href="#13allocator" title='allocator' data-ref="13allocator">allocator</a> = <b>new</b> <a class="type" href="../visitable_allocator.h.html#tensorflow::TrackingVisitableAllocator" title='tensorflow::TrackingVisitableAllocator' data-ref="tensorflow::TrackingVisitableAllocator">TrackingVisitableAllocator</a><a class="ref" href="../visitable_allocator.h.html#_ZN10tensorflow26TrackingVisitableAllocatorC1EPNS_18VisitableAllocatorEb" title='tensorflow::TrackingVisitableAllocator::TrackingVisitableAllocator' data-ref="_ZN10tensorflow26TrackingVisitableAllocatorC1EPNS_18VisitableAllocatorEb">(</a><a class="local col3 ref" href="#13allocator" title='allocator' data-ref="13allocator">allocator</a>, <b>true</b>);</td></tr>
<tr><th id="220">220</th><td>    }</td></tr>
<tr><th id="221">221</th><td>    <a class="member" href="process_state.h.html#tensorflow::ProcessState::cpu_allocators_" title='tensorflow::ProcessState::cpu_allocators_' data-ref="tensorflow::ProcessState::cpu_allocators_">cpu_allocators_</a>.<a class="ref" href="../../../../../include/c++/5/bits/stl_vector.h.html#_ZNSt6vector9push_backEOT_" title='std::vector::push_back' data-ref="_ZNSt6vector9push_backEOT_">push_back</a>(<a class="local col3 ref" href="#13allocator" title='allocator' data-ref="13allocator">allocator</a>);</td></tr>
<tr><th id="222">222</th><td>  }</td></tr>
<tr><th id="223">223</th><td>  <b>return</b> <a class="member" href="process_state.h.html#tensorflow::ProcessState::cpu_allocators_" title='tensorflow::ProcessState::cpu_allocators_' data-ref="tensorflow::ProcessState::cpu_allocators_">cpu_allocators_</a><a class="ref" href="../../../../../include/c++/5/bits/stl_vector.h.html#_ZNSt6vectorixEm" title='std::vector::operator[]' data-ref="_ZNSt6vectorixEm">[<var>0</var>]</a>;</td></tr>
<tr><th id="224">224</th><td>}</td></tr>
<tr><th id="225">225</th><td></td></tr>
<tr><th id="226">226</th><td><a class="type" href="../../framework/allocator.h.html#tensorflow::Allocator" title='tensorflow::Allocator' data-ref="tensorflow::Allocator">Allocator</a>* <a class="type" href="process_state.h.html#tensorflow::ProcessState" title='tensorflow::ProcessState' data-ref="tensorflow::ProcessState">ProcessState</a>::<dfn class="virtual decl def" id="_ZN10tensorflow12ProcessState20GetCUDAHostAllocatorEi" title='tensorflow::ProcessState::GetCUDAHostAllocator' data-ref="_ZN10tensorflow12ProcessState20GetCUDAHostAllocatorEi">GetCUDAHostAllocator</dfn>(<em>int</em> <dfn class="local col7 decl" id="17numa_node" title='numa_node' data-type='int' data-ref="17numa_node">numa_node</dfn>) {</td></tr>
<tr><th id="227">227</th><td>  <b>if</b> (!<a class="member" href="process_state.h.html#_ZNK10tensorflow12ProcessState12HasGPUDeviceEv" title='tensorflow::ProcessState::HasGPUDevice' data-ref="_ZNK10tensorflow12ProcessState12HasGPUDeviceEv">HasGPUDevice</a>() || !<a class="tu ref" href="#FLAGS_brain_mem_reg_cuda_dma" title='FLAGS_brain_mem_reg_cuda_dma' data-use='r' data-ref="FLAGS_brain_mem_reg_cuda_dma">FLAGS_brain_mem_reg_cuda_dma</a>) {</td></tr>
<tr><th id="228">228</th><td>    <b>return</b> <a class="ref" href="../../framework/allocator.h.html#_ZN10tensorflow13cpu_allocatorEv" title='tensorflow::cpu_allocator' data-ref="_ZN10tensorflow13cpu_allocatorEv">cpu_allocator</a>();</td></tr>
<tr><th id="229">229</th><td>  }</td></tr>
<tr><th id="230">230</th><td>  <i>// Although we're temporarily ignoring numa_node, check for legality.</i></td></tr>
<tr><th id="231">231</th><td>  <a class="macro" href="../../platform/default/logging.h.html#255" title="while (::tensorflow::internal::CheckOpString _result = ::tensorflow::internal::Check_GEImpl( ::tensorflow::internal::GetReferenceableValue(numa_node), ::tensorflow::internal::GetReferenceableValue(0), &quot;numa_node&quot; &quot; &quot; &quot;&gt;=&quot; &quot; &quot; &quot;0&quot;)) ::tensorflow::internal::LogMessageFatal(&quot;/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/tensorflow/core/common_runtime/gpu/process_state.cc&quot;, 231) &lt;&lt; *(_result.str_)" data-ref="_M/CHECK_GE">CHECK_GE</a>(<a class="local col7 ref" href="#17numa_node" title='numa_node' data-ref="17numa_node">numa_node</a>, <var>0</var>);</td></tr>
<tr><th id="232">232</th><td>  <i>// TODO(tucker): actually maintain separate CPUAllocators for</i></td></tr>
<tr><th id="233">233</th><td><i>  // different numa_nodes.  For now, just one.</i></td></tr>
<tr><th id="234">234</th><td>  <a class="local col7 ref" href="#17numa_node" title='numa_node' data-ref="17numa_node">numa_node</a> = <var>0</var>;</td></tr>
<tr><th id="235">235</th><td></td></tr>
<tr><th id="236">236</th><td>  {</td></tr>
<tr><th id="237">237</th><td>    <i>// Here we optimize the most common use case where cuda_host_allocators_</i></td></tr>
<tr><th id="238">238</th><td><i>    // and cuda_al_ have already been populated and since we're only reading</i></td></tr>
<tr><th id="239">239</th><td><i>    // these vectors, we can get by with a shared lock. In the slower case,</i></td></tr>
<tr><th id="240">240</th><td><i>    // we take a unique lock and populate these vectors.</i></td></tr>
<tr><th id="241">241</th><td>    <a class="type" href="../../platform/default/mutex.h.html#tensorflow::tf_shared_lock" title='tensorflow::tf_shared_lock' data-ref="tensorflow::tf_shared_lock">tf_shared_lock</a> <dfn class="local col8 decl" id="18lock" title='lock' data-type='tensorflow::tf_shared_lock' data-ref="18lock">lock</dfn><a class="ref" href="../../platform/default/mutex.h.html#_ZN10tensorflow14tf_shared_lockC1ERNS_5mutexE" title='tensorflow::tf_shared_lock::tf_shared_lock' data-ref="_ZN10tensorflow14tf_shared_lockC1ERNS_5mutexE">(</a><a class="member" href="process_state.h.html#tensorflow::ProcessState::mu_" title='tensorflow::ProcessState::mu_' data-ref="tensorflow::ProcessState::mu_">mu_</a>);</td></tr>
<tr><th id="242">242</th><td></td></tr>
<tr><th id="243">243</th><td>    <b>if</b> (<a class="tu ref" href="#FLAGS_brain_gpu_record_mem_types" title='FLAGS_brain_gpu_record_mem_types' data-use='r' data-ref="FLAGS_brain_gpu_record_mem_types">FLAGS_brain_gpu_record_mem_types</a> &amp;&amp;</td></tr>
<tr><th id="244">244</th><td>        <b>static_cast</b>&lt;<em>int</em>&gt;(<a class="member" href="process_state.h.html#tensorflow::ProcessState::cuda_al_" title='tensorflow::ProcessState::cuda_al_' data-ref="tensorflow::ProcessState::cuda_al_">cuda_al_</a>.<a class="ref" href="../../../../../include/c++/5/bits/stl_vector.h.html#_ZNKSt6vector4sizeEv" title='std::vector::size' data-ref="_ZNKSt6vector4sizeEv">size</a>()) &gt; <var>0</var>) {</td></tr>
<tr><th id="245">245</th><td>      <b>return</b> <a class="member" href="process_state.h.html#tensorflow::ProcessState::cuda_al_" title='tensorflow::ProcessState::cuda_al_' data-ref="tensorflow::ProcessState::cuda_al_">cuda_al_</a><a class="ref" href="../../../../../include/c++/5/bits/stl_vector.h.html#_ZNSt6vectorixEm" title='std::vector::operator[]' data-ref="_ZNSt6vectorixEm">[<var>0</var>]</a>;</td></tr>
<tr><th id="246">246</th><td>    }</td></tr>
<tr><th id="247">247</th><td>    <b>if</b> (<b>static_cast</b>&lt;<em>int</em>&gt;(<a class="member" href="process_state.h.html#tensorflow::ProcessState::cuda_host_allocators_" title='tensorflow::ProcessState::cuda_host_allocators_' data-ref="tensorflow::ProcessState::cuda_host_allocators_">cuda_host_allocators_</a>.<a class="ref" href="../../../../../include/c++/5/bits/stl_vector.h.html#_ZNKSt6vector4sizeEv" title='std::vector::size' data-ref="_ZNKSt6vector4sizeEv">size</a>()) &gt; <a class="local col7 ref" href="#17numa_node" title='numa_node' data-ref="17numa_node">numa_node</a>) {</td></tr>
<tr><th id="248">248</th><td>      <b>return</b> <a class="member" href="process_state.h.html#tensorflow::ProcessState::cuda_host_allocators_" title='tensorflow::ProcessState::cuda_host_allocators_' data-ref="tensorflow::ProcessState::cuda_host_allocators_">cuda_host_allocators_</a><a class="ref" href="../../../../../include/c++/5/bits/stl_vector.h.html#_ZNSt6vectorixEm" title='std::vector::operator[]' data-ref="_ZNSt6vectorixEm">[<var>0</var>]</a>;</td></tr>
<tr><th id="249">249</th><td>    }</td></tr>
<tr><th id="250">250</th><td>  }</td></tr>
<tr><th id="251">251</th><td></td></tr>
<tr><th id="252">252</th><td>  <a class="type" href="../../platform/default/mutex.h.html#tensorflow::mutex_lock" title='tensorflow::mutex_lock' data-ref="tensorflow::mutex_lock">mutex_lock</a> <dfn class="local col9 decl" id="19lock" title='lock' data-type='tensorflow::mutex_lock' data-ref="19lock">lock</dfn><a class="ref" href="../../platform/default/mutex.h.html#_ZN10tensorflow10mutex_lockC1ERNS_5mutexE" title='tensorflow::mutex_lock::mutex_lock' data-ref="_ZN10tensorflow10mutex_lockC1ERNS_5mutexE">(</a><a class="member" href="process_state.h.html#tensorflow::ProcessState::mu_" title='tensorflow::ProcessState::mu_' data-ref="tensorflow::ProcessState::mu_">mu_</a>);</td></tr>
<tr><th id="253">253</th><td>  <i>// Find the first valid StreamExecutor to request CUDA host memory</i></td></tr>
<tr><th id="254">254</th><td><i>  // through, since any will work.</i></td></tr>
<tr><th id="255">255</th><td><i>  //</i></td></tr>
<tr><th id="256">256</th><td><i>  // This search isn't super clean, and it would be nice to use a</i></td></tr>
<tr><th id="257">257</th><td><i>  // better source of information about which executor to use.  For</i></td></tr>
<tr><th id="258">258</th><td><i>  // example, process_state could maybe save the first stream executor</i></td></tr>
<tr><th id="259">259</th><td><i>  // it knows is valid.</i></td></tr>
<tr><th id="260">260</th><td>  <span class="namespace">gpu::</span><a class="type" href="../../../stream_executor/stream_executor_pimpl.h.html#perftools::gputools::StreamExecutor" title='perftools::gputools::StreamExecutor' data-ref="perftools::gputools::StreamExecutor">StreamExecutor</a>* <dfn class="local col0 decl" id="20se" title='se' data-type='gpu::StreamExecutor *' data-ref="20se">se</dfn> = <b>nullptr</b>;</td></tr>
<tr><th id="261">261</th><td>  <b>for</b> (<em>int</em> <dfn class="local col1 decl" id="21i" title='i' data-type='int' data-ref="21i">i</dfn> = <var>0</var>; <a class="local col1 ref" href="#21i" title='i' data-ref="21i">i</a> &lt; <b>static_cast</b>&lt;<em>int</em>&gt;(<a class="member" href="process_state.h.html#tensorflow::ProcessState::gpu_allocators_" title='tensorflow::ProcessState::gpu_allocators_' data-ref="tensorflow::ProcessState::gpu_allocators_">gpu_allocators_</a>.<a class="ref" href="../../../../../include/c++/5/bits/stl_vector.h.html#_ZNKSt6vector4sizeEv" title='std::vector::size' data-ref="_ZNKSt6vector4sizeEv">size</a>()); ++<a class="local col1 ref" href="#21i" title='i' data-ref="21i">i</a>) {</td></tr>
<tr><th id="262">262</th><td>    <b>if</b> (<a class="member" href="process_state.h.html#tensorflow::ProcessState::gpu_allocators_" title='tensorflow::ProcessState::gpu_allocators_' data-ref="tensorflow::ProcessState::gpu_allocators_">gpu_allocators_</a><a class="ref" href="../../../../../include/c++/5/bits/stl_vector.h.html#_ZNSt6vectorixEm" title='std::vector::operator[]' data-ref="_ZNSt6vectorixEm">[<a class="local col1 ref" href="#21i" title='i' data-ref="21i">i</a>]</a> != <b>nullptr</b>) {</td></tr>
<tr><th id="263">263</th><td>      <a class="local col0 ref" href="#20se" title='se' data-ref="20se">se</a> = <a class="type" href="gpu_id_utils.h.html#tensorflow::GpuIdUtil" title='tensorflow::GpuIdUtil' data-ref="tensorflow::GpuIdUtil">GpuIdUtil</a>::<a class="ref" href="gpu_id_utils.h.html#_ZN10tensorflow9GpuIdUtil18ExecutorForTfGpuIdENS_3gtl7IntTypeINS_12TfGpuId_tag_EiEE" title='tensorflow::GpuIdUtil::ExecutorForTfGpuId' data-ref="_ZN10tensorflow9GpuIdUtil18ExecutorForTfGpuIdENS_3gtl7IntTypeINS_12TfGpuId_tag_EiEE">ExecutorForTfGpuId</a>(<a class="typedef" href="gpu_id.h.html#83" title='tensorflow::TfGpuId' data-type='::tensorflow::gtl::IntType&lt;TfGpuId_tag_, int32&gt;' data-ref="tensorflow::TfGpuId">TfGpuId</a><a class="ref" href="../../lib/gtl/int_type.h.html#_ZN10tensorflow3gtl7IntTypeC1ET0_" title='tensorflow::gtl::IntType::IntType&lt;IntTypeName, _ValueType&gt;' data-ref="_ZN10tensorflow3gtl7IntTypeC1ET0_">(</a><a class="local col1 ref" href="#21i" title='i' data-ref="21i">i</a>)).<a class="ref" href="../../../stream_executor/lib/statusor.h.html#_ZN9perftools8gputools4port8StatusOr10ValueOrDieEv" title='perftools::gputools::port::StatusOr::ValueOrDie' data-ref="_ZN9perftools8gputools4port8StatusOr10ValueOrDieEv">ValueOrDie</a>();</td></tr>
<tr><th id="264">264</th><td>      <b>break</b>;</td></tr>
<tr><th id="265">265</th><td>    }</td></tr>
<tr><th id="266">266</th><td>  }</td></tr>
<tr><th id="267">267</th><td></td></tr>
<tr><th id="268">268</th><td>  <a class="macro" href="../../platform/default/logging.h.html#252" title="while (::tensorflow::internal::CheckOpString _result = ::tensorflow::internal::Check_NEImpl( ::tensorflow::internal::GetReferenceableValue(nullptr), ::tensorflow::internal::GetReferenceableValue(se), &quot;nullptr&quot; &quot; &quot; &quot;!=&quot; &quot; &quot; &quot;se&quot;)) ::tensorflow::internal::LogMessageFatal(&quot;/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/tensorflow/core/common_runtime/gpu/process_state.cc&quot;, 268) &lt;&lt; *(_result.str_)" data-ref="_M/CHECK_NE">CHECK_NE</a>(<b>nullptr</b>, <a class="local col0 ref" href="#20se" title='se' data-ref="20se">se</a>);</td></tr>
<tr><th id="269">269</th><td></td></tr>
<tr><th id="270">270</th><td>  <b>while</b> (<b>static_cast</b>&lt;<em>int</em>&gt;(<a class="member" href="process_state.h.html#tensorflow::ProcessState::cuda_host_allocators_" title='tensorflow::ProcessState::cuda_host_allocators_' data-ref="tensorflow::ProcessState::cuda_host_allocators_">cuda_host_allocators_</a>.<a class="ref" href="../../../../../include/c++/5/bits/stl_vector.h.html#_ZNKSt6vector4sizeEv" title='std::vector::size' data-ref="_ZNKSt6vector4sizeEv">size</a>()) &lt;= <a class="local col7 ref" href="#17numa_node" title='numa_node' data-ref="17numa_node">numa_node</a>) {</td></tr>
<tr><th id="271">271</th><td>    <i>// TODO(zheng-xq): evaluate whether 64GB by default is the best choice.</i></td></tr>
<tr><th id="272">272</th><td>    <a class="typedef" href="../../platform/default/integral_types.h.html#tensorflow::int64" title='tensorflow::int64' data-type='long long' data-ref="tensorflow::int64">int64</a> <dfn class="local col2 decl" id="22cuda_host_mem_limit_in_mb" title='cuda_host_mem_limit_in_mb' data-type='int64' data-ref="22cuda_host_mem_limit_in_mb">cuda_host_mem_limit_in_mb</dfn> = -<var>1</var>;</td></tr>
<tr><th id="273">273</th><td>    <a class="type" href="../../lib/core/status.h.html#tensorflow::Status" title='tensorflow::Status' data-ref="tensorflow::Status">Status</a> <dfn class="local col3 decl" id="23status" title='status' data-type='tensorflow::Status' data-ref="23status">status</dfn> = <a class="ref" href="../../util/env_var.h.html#_ZN10tensorflow19ReadInt64FromEnvVarENS_11StringPieceExPx" title='tensorflow::ReadInt64FromEnvVar' data-ref="_ZN10tensorflow19ReadInt64FromEnvVarENS_11StringPieceExPx">ReadInt64FromEnvVar</a>(<a class="ref fake" href="../../lib/core/stringpiece.h.html#_ZN10tensorflow11StringPieceC1EPKc" title='tensorflow::StringPiece::StringPiece' data-ref="_ZN10tensorflow11StringPieceC1EPKc"></a><q>"TF_CUDA_HOST_MEM_LIMIT_IN_MB"</q>,</td></tr>
<tr><th id="274">274</th><td>                                        <var>1LL</var> &lt;&lt; <var>16</var> <i>/*64GB max by default*/</i>,</td></tr>
<tr><th id="275">275</th><td>                                        &amp;<a class="local col2 ref" href="#22cuda_host_mem_limit_in_mb" title='cuda_host_mem_limit_in_mb' data-ref="22cuda_host_mem_limit_in_mb">cuda_host_mem_limit_in_mb</a>);</td></tr>
<tr><th id="276">276</th><td>    <b>if</b> (!<a class="local col3 ref" href="#23status" title='status' data-ref="23status">status</a>.<a class="ref" href="../../lib/core/status.h.html#_ZNK10tensorflow6Status2okEv" title='tensorflow::Status::ok' data-ref="_ZNK10tensorflow6Status2okEv">ok</a>()) {</td></tr>
<tr><th id="277">277</th><td>      <a class="macro" href="../../platform/default/logging.h.html#77" title="::tensorflow::internal::LogMessage(&quot;/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/org_tensorflow/tensorflow/core/common_runtime/gpu/process_state.cc&quot;, 277, ::tensorflow::ERROR)" data-ref="_M/LOG">LOG</a>(ERROR) <a class="ref" href="../../../../../include/c++/5/ostream.html#_ZStlsOSt13basic_ostreamIT_T0_ERKT1_" title='std::operator&lt;&lt;' data-ref="_ZStlsOSt13basic_ostreamIT_T0_ERKT1_">&lt;&lt;</a> <q>"GetCUDAHostAllocator: "</q> <a class="ref" href="../../../../../include/c++/5/bits/basic_string.h.html#_ZStlsRSt13basic_ostreamIT_T0_ERKSbIS0_S1_T1_E" title='std::operator&lt;&lt;' data-ref="_ZStlsRSt13basic_ostreamIT_T0_ERKSbIS0_S1_T1_E">&lt;&lt;</a> <a class="local col3 ref" href="#23status" title='status' data-ref="23status">status</a>.<a class="ref" href="../../lib/core/status.h.html#_ZNK10tensorflow6Status13error_messageEv" title='tensorflow::Status::error_message' data-ref="_ZNK10tensorflow6Status13error_messageEv">error_message</a>();</td></tr>
<tr><th id="278">278</th><td>    }</td></tr>
<tr><th id="279">279</th><td>    <a class="typedef" href="../../platform/default/integral_types.h.html#tensorflow::int64" title='tensorflow::int64' data-type='long long' data-ref="tensorflow::int64">int64</a> <dfn class="local col4 decl" id="24cuda_host_mem_limit" title='cuda_host_mem_limit' data-type='int64' data-ref="24cuda_host_mem_limit">cuda_host_mem_limit</dfn> = <a class="local col2 ref" href="#22cuda_host_mem_limit_in_mb" title='cuda_host_mem_limit_in_mb' data-ref="22cuda_host_mem_limit_in_mb">cuda_host_mem_limit_in_mb</a> * (<var>1LL</var> &lt;&lt; <var>20</var>);</td></tr>
<tr><th id="280">280</th><td>    <a class="type" href="../visitable_allocator.h.html#tensorflow::VisitableAllocator" title='tensorflow::VisitableAllocator' data-ref="tensorflow::VisitableAllocator">VisitableAllocator</a>* <dfn class="local col5 decl" id="25allocator" title='allocator' data-type='tensorflow::VisitableAllocator *' data-ref="25allocator">allocator</dfn> =</td></tr>
<tr><th id="281">281</th><td>        <b>new</b> <a class="type" href="../bfc_allocator.h.html#tensorflow::BFCAllocator" title='tensorflow::BFCAllocator' data-ref="tensorflow::BFCAllocator">BFCAllocator</a><a class="ref" href="../bfc_allocator.h.html#_ZN10tensorflow12BFCAllocatorC1EPNS_12SubAllocatorEmbRKSs" title='tensorflow::BFCAllocator::BFCAllocator' data-ref="_ZN10tensorflow12BFCAllocatorC1EPNS_12SubAllocatorEmbRKSs">(</a><b>new</b> <a class="type" href="pool_allocator.h.html#tensorflow::CUDAHostAllocator" title='tensorflow::CUDAHostAllocator' data-ref="tensorflow::CUDAHostAllocator">CUDAHostAllocator</a><a class="ref" href="pool_allocator.h.html#_ZN10tensorflow17CUDAHostAllocatorC1EPN9perftools8gputools14StreamExecutorE" title='tensorflow::CUDAHostAllocator::CUDAHostAllocator' data-ref="_ZN10tensorflow17CUDAHostAllocatorC1EPN9perftools8gputools14StreamExecutorE">(</a><a class="local col0 ref" href="#20se" title='se' data-ref="20se">se</a>), <a class="local col4 ref" href="#24cuda_host_mem_limit" title='cuda_host_mem_limit' data-ref="24cuda_host_mem_limit">cuda_host_mem_limit</a>,</td></tr>
<tr><th id="282">282</th><td>                         <b>true</b> <i>/*allow_growth*/</i>, <a class="ref fake" href="../../../../../include/c++/5/bits/basic_string.h.html#_ZNSt12basic_stringC1EPKT_RKT1_" title='std::basic_string::basic_string&lt;_CharT, _Traits, _Alloc&gt;' data-ref="_ZNSt12basic_stringC1EPKT_RKT1_"></a><q>"cuda_host_bfc"</q> <i>/*name*/</i>);</td></tr>
<tr><th id="283">283</th><td></td></tr>
<tr><th id="284">284</th><td>    <b>if</b> (<a class="type" href="../../framework/log_memory.h.html#tensorflow::LogMemory" title='tensorflow::LogMemory' data-ref="tensorflow::LogMemory">LogMemory</a>::<a class="ref" href="../../framework/log_memory.h.html#_ZN10tensorflow9LogMemory9IsEnabledEv" title='tensorflow::LogMemory::IsEnabled' data-ref="_ZN10tensorflow9LogMemory9IsEnabledEv">IsEnabled</a>()) {</td></tr>
<tr><th id="285">285</th><td>      <i>// Wrap the allocator to track allocation ids for better logging</i></td></tr>
<tr><th id="286">286</th><td><i>      // at the cost of performance.</i></td></tr>
<tr><th id="287">287</th><td>      <a class="local col5 ref" href="#25allocator" title='allocator' data-ref="25allocator">allocator</a> = <b>new</b> <a class="type" href="../visitable_allocator.h.html#tensorflow::TrackingVisitableAllocator" title='tensorflow::TrackingVisitableAllocator' data-ref="tensorflow::TrackingVisitableAllocator">TrackingVisitableAllocator</a><a class="ref" href="../visitable_allocator.h.html#_ZN10tensorflow26TrackingVisitableAllocatorC1EPNS_18VisitableAllocatorEb" title='tensorflow::TrackingVisitableAllocator::TrackingVisitableAllocator' data-ref="_ZN10tensorflow26TrackingVisitableAllocatorC1EPNS_18VisitableAllocatorEb">(</a><a class="local col5 ref" href="#25allocator" title='allocator' data-ref="25allocator">allocator</a>, <b>true</b>);</td></tr>
<tr><th id="288">288</th><td>    }</td></tr>
<tr><th id="289">289</th><td>    <a class="member" href="process_state.h.html#tensorflow::ProcessState::cuda_host_allocators_" title='tensorflow::ProcessState::cuda_host_allocators_' data-ref="tensorflow::ProcessState::cuda_host_allocators_">cuda_host_allocators_</a>.<a class="ref" href="../../../../../include/c++/5/bits/stl_vector.h.html#_ZNSt6vector9push_backEOT_" title='std::vector::push_back' data-ref="_ZNSt6vector9push_backEOT_">push_back</a>(<a class="local col5 ref" href="#25allocator" title='allocator' data-ref="25allocator">allocator</a>);</td></tr>
<tr><th id="290">290</th><td>    <b>if</b> (<a class="tu ref" href="#FLAGS_brain_gpu_record_mem_types" title='FLAGS_brain_gpu_record_mem_types' data-use='r' data-ref="FLAGS_brain_gpu_record_mem_types">FLAGS_brain_gpu_record_mem_types</a>) {</td></tr>
<tr><th id="291">291</th><td>      <a class="type" href="process_state.h.html#tensorflow::ProcessState::MemDesc" title='tensorflow::ProcessState::MemDesc' data-ref="tensorflow::ProcessState::MemDesc">MemDesc</a> <a class="ref fake" href="process_state.h.html#_ZN10tensorflow12ProcessState7MemDescC1Ev" title='tensorflow::ProcessState::MemDesc::MemDesc' data-ref="_ZN10tensorflow12ProcessState7MemDescC1Ev"></a><dfn class="local col6 decl" id="26md" title='md' data-type='tensorflow::ProcessState::MemDesc' data-ref="26md">md</dfn>;</td></tr>
<tr><th id="292">292</th><td>      <a class="local col6 ref" href="#26md" title='md' data-ref="26md">md</a>.<a class="ref" href="process_state.h.html#tensorflow::ProcessState::MemDesc::loc" title='tensorflow::ProcessState::MemDesc::loc' data-ref="tensorflow::ProcessState::MemDesc::loc">loc</a> = <a class="type" href="process_state.h.html#tensorflow::ProcessState::MemDesc" title='tensorflow::ProcessState::MemDesc' data-ref="tensorflow::ProcessState::MemDesc">MemDesc</a>::<a class="enum" href="process_state.h.html#tensorflow::ProcessState::MemDesc::MemLoc::CPU" title='tensorflow::ProcessState::MemDesc::MemLoc::CPU' data-ref="tensorflow::ProcessState::MemDesc::MemLoc::CPU">CPU</a>;</td></tr>
<tr><th id="293">293</th><td>      <a class="local col6 ref" href="#26md" title='md' data-ref="26md">md</a>.<a class="ref" href="process_state.h.html#tensorflow::ProcessState::MemDesc::dev_index" title='tensorflow::ProcessState::MemDesc::dev_index' data-ref="tensorflow::ProcessState::MemDesc::dev_index">dev_index</a> = <var>0</var>;</td></tr>
<tr><th id="294">294</th><td>      <a class="local col6 ref" href="#26md" title='md' data-ref="26md">md</a>.<a class="ref" href="process_state.h.html#tensorflow::ProcessState::MemDesc::gpu_registered" title='tensorflow::ProcessState::MemDesc::gpu_registered' data-ref="tensorflow::ProcessState::MemDesc::gpu_registered">gpu_registered</a> = <b>true</b>;</td></tr>
<tr><th id="295">295</th><td>      <a class="local col6 ref" href="#26md" title='md' data-ref="26md">md</a>.<a class="ref" href="process_state.h.html#tensorflow::ProcessState::MemDesc::nic_registered" title='tensorflow::ProcessState::MemDesc::nic_registered' data-ref="tensorflow::ProcessState::MemDesc::nic_registered">nic_registered</a> = <b>false</b>;</td></tr>
<tr><th id="296">296</th><td>      <a class="member" href="process_state.h.html#tensorflow::ProcessState::cuda_al_" title='tensorflow::ProcessState::cuda_al_' data-ref="tensorflow::ProcessState::cuda_al_">cuda_al_</a>.<a class="ref" href="../../../../../include/c++/5/bits/stl_vector.h.html#_ZNSt6vector9push_backEOT_" title='std::vector::push_back' data-ref="_ZNSt6vector9push_backEOT_">push_back</a>(<b>new</b> <span class="namespace">internal::</span><a class="type" href="process_state.h.html#tensorflow::internal::RecordingAllocator" title='tensorflow::internal::RecordingAllocator' data-ref="tensorflow::internal::RecordingAllocator">RecordingAllocator</a><a class="ref" href="process_state.h.html#_ZN10tensorflow8internal18RecordingAllocatorC1EPSt13unordered_mapIPKvNS_12ProcessState7MemDescESt4hashIS4_ESt8equal_toIS4_ESaISt4pairIKS4_S6_EEEPNS_9A2258139" title='tensorflow::internal::RecordingAllocator::RecordingAllocator' data-ref="_ZN10tensorflow8internal18RecordingAllocatorC1EPSt13unordered_mapIPKvNS_12ProcessState7MemDescESt4hashIS4_ESt8equal_toIS4_ESaISt4pairIKS4_S6_EEEPNS_9A2258139">(</a></td></tr>
<tr><th id="297">297</th><td>          &amp;<a class="member" href="process_state.h.html#tensorflow::ProcessState::mem_desc_map_" title='tensorflow::ProcessState::mem_desc_map_' data-ref="tensorflow::ProcessState::mem_desc_map_">mem_desc_map_</a>, <a class="member" href="process_state.h.html#tensorflow::ProcessState::cuda_host_allocators_" title='tensorflow::ProcessState::cuda_host_allocators_' data-ref="tensorflow::ProcessState::cuda_host_allocators_">cuda_host_allocators_</a>.<a class="ref" href="../../../../../include/c++/5/bits/stl_vector.h.html#_ZNSt6vector4backEv" title='std::vector::back' data-ref="_ZNSt6vector4backEv">back</a>(), <a class="ref fake" href="process_state.h.html#45" title='tensorflow::ProcessState::MemDesc::MemDesc' data-ref="_ZN10tensorflow12ProcessState7MemDescC1ERKS1_"></a><a class="local col6 ref" href="#26md" title='md' data-ref="26md">md</a>, &amp;<a class="member" href="process_state.h.html#tensorflow::ProcessState::mu_" title='tensorflow::ProcessState::mu_' data-ref="tensorflow::ProcessState::mu_">mu_</a>));</td></tr>
<tr><th id="298">298</th><td>    }</td></tr>
<tr><th id="299">299</th><td>  }</td></tr>
<tr><th id="300">300</th><td>  <b>if</b> (<a class="tu ref" href="#FLAGS_brain_gpu_record_mem_types" title='FLAGS_brain_gpu_record_mem_types' data-use='r' data-ref="FLAGS_brain_gpu_record_mem_types">FLAGS_brain_gpu_record_mem_types</a>) <b>return</b> <a class="member" href="process_state.h.html#tensorflow::ProcessState::cuda_al_" title='tensorflow::ProcessState::cuda_al_' data-ref="tensorflow::ProcessState::cuda_al_">cuda_al_</a><a class="ref" href="../../../../../include/c++/5/bits/stl_vector.h.html#_ZNSt6vectorixEm" title='std::vector::operator[]' data-ref="_ZNSt6vectorixEm">[<var>0</var>]</a>;</td></tr>
<tr><th id="301">301</th><td>  <b>return</b> <a class="member" href="process_state.h.html#tensorflow::ProcessState::cuda_host_allocators_" title='tensorflow::ProcessState::cuda_host_allocators_' data-ref="tensorflow::ProcessState::cuda_host_allocators_">cuda_host_allocators_</a><a class="ref" href="../../../../../include/c++/5/bits/stl_vector.h.html#_ZNSt6vectorixEm" title='std::vector::operator[]' data-ref="_ZNSt6vectorixEm">[<var>0</var>]</a>;</td></tr>
<tr><th id="302">302</th><td>}</td></tr>
<tr><th id="303">303</th><td></td></tr>
<tr><th id="304">304</th><td><em>void</em> <a class="type" href="process_state.h.html#tensorflow::ProcessState" title='tensorflow::ProcessState' data-ref="tensorflow::ProcessState">ProcessState</a>::<dfn class="virtual decl def" id="_ZN10tensorflow12ProcessState18AddGPUAllocVisitorEiSt8functionIFvPvmEE" title='tensorflow::ProcessState::AddGPUAllocVisitor' data-ref="_ZN10tensorflow12ProcessState18AddGPUAllocVisitorEiSt8functionIFvPvmEE">AddGPUAllocVisitor</dfn>(<em>int</em> <dfn class="local col7 decl" id="27bus_id" title='bus_id' data-type='int' data-ref="27bus_id">bus_id</dfn>, <a class="typedef" href="process_state.h.html#tensorflow::ProcessState::AllocVisitor" title='tensorflow::ProcessState::AllocVisitor' data-type='std::function&lt;void (void *, size_t)&gt;' data-ref="tensorflow::ProcessState::AllocVisitor">AllocVisitor</a> <dfn class="local col8 decl" id="28visitor" title='visitor' data-type='AllocVisitor' data-ref="28visitor">visitor</dfn>) {</td></tr>
<tr><th id="305">305</th><td><u>#<span data-ppcond="305">if</span> GOOGLE_CUDA</u></td></tr>
<tr><th id="306">306</th><td>  mutex_lock lock(mu_);</td></tr>
<tr><th id="307">307</th><td>  <b>for</b> (<em>int</em> i = <var>0</var>; i &lt; <b>static_cast</b>&lt;int64&gt;(gpu_allocators_.size()); ++i) {</td></tr>
<tr><th id="308">308</th><td>    gpu::StreamExecutor* se =</td></tr>
<tr><th id="309">309</th><td>        GpuIdUtil::ExecutorForTfGpuId(TfGpuId(i)).ValueOrDie();</td></tr>
<tr><th id="310">310</th><td>    <b>if</b> (gpu_allocators_[i] &amp;&amp;</td></tr>
<tr><th id="311">311</th><td>        (se-&gt;GetDeviceDescription().numa_node() + <var>1</var>) == bus_id) {</td></tr>
<tr><th id="312">312</th><td>      gpu_allocators_[i]-&gt;AddAllocVisitor(visitor);</td></tr>
<tr><th id="313">313</th><td>    }</td></tr>
<tr><th id="314">314</th><td>  }</td></tr>
<tr><th id="315">315</th><td>  <b>while</b> (bus_id &gt;= <b>static_cast</b>&lt;int64&gt;(gpu_visitors_.size())) {</td></tr>
<tr><th id="316">316</th><td>    gpu_visitors_.push_back(std::vector&lt;AllocVisitor&gt;());</td></tr>
<tr><th id="317">317</th><td>  }</td></tr>
<tr><th id="318">318</th><td>  gpu_visitors_[bus_id].push_back(visitor);</td></tr>
<tr><th id="319">319</th><td><u>#<span data-ppcond="305">endif</span>  // GOOGLE_CUDA</u></td></tr>
<tr><th id="320">320</th><td>}</td></tr>
<tr><th id="321">321</th><td></td></tr>
<tr><th id="322">322</th><td><em>void</em> <a class="type" href="process_state.h.html#tensorflow::ProcessState" title='tensorflow::ProcessState' data-ref="tensorflow::ProcessState">ProcessState</a>::<dfn class="virtual decl def" id="_ZN10tensorflow12ProcessState13TestOnlyResetEv" title='tensorflow::ProcessState::TestOnlyReset' data-ref="_ZN10tensorflow12ProcessState13TestOnlyResetEv">TestOnlyReset</dfn>() {</td></tr>
<tr><th id="323">323</th><td>  <a class="type" href="../../platform/default/mutex.h.html#tensorflow::mutex_lock" title='tensorflow::mutex_lock' data-ref="tensorflow::mutex_lock">mutex_lock</a> <dfn class="local col9 decl" id="29lock" title='lock' data-type='tensorflow::mutex_lock' data-ref="29lock">lock</dfn><a class="ref" href="../../platform/default/mutex.h.html#_ZN10tensorflow10mutex_lockC1ERNS_5mutexE" title='tensorflow::mutex_lock::mutex_lock' data-ref="_ZN10tensorflow10mutex_lockC1ERNS_5mutexE">(</a><a class="member" href="process_state.h.html#tensorflow::ProcessState::mu_" title='tensorflow::ProcessState::mu_' data-ref="tensorflow::ProcessState::mu_">mu_</a>);</td></tr>
<tr><th id="324">324</th><td>  <a class="member" href="process_state.h.html#tensorflow::ProcessState::gpu_device_enabled_" title='tensorflow::ProcessState::gpu_device_enabled_' data-ref="tensorflow::ProcessState::gpu_device_enabled_">gpu_device_enabled_</a> = <b>false</b>;</td></tr>
<tr><th id="325">325</th><td>  <a class="member" href="process_state.h.html#tensorflow::ProcessState::gpu_visitors_" title='tensorflow::ProcessState::gpu_visitors_' data-ref="tensorflow::ProcessState::gpu_visitors_">gpu_visitors_</a>.<a class="ref" href="../../../../../include/c++/5/bits/stl_vector.h.html#_ZNSt6vector5clearEv" title='std::vector::clear' data-ref="_ZNSt6vector5clearEv">clear</a>();</td></tr>
<tr><th id="326">326</th><td>  <a class="member" href="process_state.h.html#tensorflow::ProcessState::mem_desc_map_" title='tensorflow::ProcessState::mem_desc_map_' data-ref="tensorflow::ProcessState::mem_desc_map_">mem_desc_map_</a>.<a class="ref" href="../../../../../include/c++/5/bits/unordered_map.h.html#_ZNSt13unordered_map5clearEv" title='std::unordered_map::clear' data-ref="_ZNSt13unordered_map5clearEv">clear</a>();</td></tr>
<tr><th id="327">327</th><td>  <span class="namespace">gtl::</span><a class="ref" href="../../lib/gtl/stl_util.h.html#_ZN10tensorflow3gtl17STLDeleteElementsEPT_" title='tensorflow::gtl::STLDeleteElements' data-ref="_ZN10tensorflow3gtl17STLDeleteElementsEPT_">STLDeleteElements</a>(&amp;<a class="member" href="process_state.h.html#tensorflow::ProcessState::cpu_allocators_" title='tensorflow::ProcessState::cpu_allocators_' data-ref="tensorflow::ProcessState::cpu_allocators_">cpu_allocators_</a>);</td></tr>
<tr><th id="328">328</th><td>  <span class="namespace">gtl::</span><a class="ref" href="../../lib/gtl/stl_util.h.html#_ZN10tensorflow3gtl17STLDeleteElementsEPT_" title='tensorflow::gtl::STLDeleteElements' data-ref="_ZN10tensorflow3gtl17STLDeleteElementsEPT_">STLDeleteElements</a>(&amp;<a class="member" href="process_state.h.html#tensorflow::ProcessState::gpu_allocators_" title='tensorflow::ProcessState::gpu_allocators_' data-ref="tensorflow::ProcessState::gpu_allocators_">gpu_allocators_</a>);</td></tr>
<tr><th id="329">329</th><td>  <span class="namespace">gtl::</span><a class="ref" href="../../lib/gtl/stl_util.h.html#_ZN10tensorflow3gtl17STLDeleteElementsEPT_" title='tensorflow::gtl::STLDeleteElements' data-ref="_ZN10tensorflow3gtl17STLDeleteElementsEPT_">STLDeleteElements</a>(&amp;<a class="member" href="process_state.h.html#tensorflow::ProcessState::cuda_host_allocators_" title='tensorflow::ProcessState::cuda_host_allocators_' data-ref="tensorflow::ProcessState::cuda_host_allocators_">cuda_host_allocators_</a>);</td></tr>
<tr><th id="330">330</th><td>  <span class="namespace">gtl::</span><a class="ref" href="../../lib/gtl/stl_util.h.html#_ZN10tensorflow3gtl17STLDeleteElementsEPT_" title='tensorflow::gtl::STLDeleteElements' data-ref="_ZN10tensorflow3gtl17STLDeleteElementsEPT_">STLDeleteElements</a>(&amp;<a class="member" href="process_state.h.html#tensorflow::ProcessState::cpu_al_" title='tensorflow::ProcessState::cpu_al_' data-ref="tensorflow::ProcessState::cpu_al_">cpu_al_</a>);</td></tr>
<tr><th id="331">331</th><td>  <span class="namespace">gtl::</span><a class="ref" href="../../lib/gtl/stl_util.h.html#_ZN10tensorflow3gtl17STLDeleteElementsEPT_" title='tensorflow::gtl::STLDeleteElements' data-ref="_ZN10tensorflow3gtl17STLDeleteElementsEPT_">STLDeleteElements</a>(&amp;<a class="member" href="process_state.h.html#tensorflow::ProcessState::gpu_al_" title='tensorflow::ProcessState::gpu_al_' data-ref="tensorflow::ProcessState::gpu_al_">gpu_al_</a>);</td></tr>
<tr><th id="332">332</th><td>  <span class="namespace">gtl::</span><a class="ref" href="../../lib/gtl/stl_util.h.html#_ZN10tensorflow3gtl17STLDeleteElementsEPT_" title='tensorflow::gtl::STLDeleteElements' data-ref="_ZN10tensorflow3gtl17STLDeleteElementsEPT_">STLDeleteElements</a>(&amp;<a class="member" href="process_state.h.html#tensorflow::ProcessState::cuda_al_" title='tensorflow::ProcessState::cuda_al_' data-ref="tensorflow::ProcessState::cuda_al_">cuda_al_</a>);</td></tr>
<tr><th id="333">333</th><td>}</td></tr>
<tr><th id="334">334</th><td></td></tr>
<tr><th id="335">335</th><td>}  <i>// namespace tensorflow</i></td></tr>
<tr><th id="336">336</th><td></td></tr>
</table><hr/><p id='footer'>
Generated on <em>2018-Aug-09</em> from project tensorflow revision <em>v1.8</em><br />Powered by <a href='https://woboq.com'><img alt='Woboq' src='https://code.woboq.org/woboq-16.png' width='41' height='16' /></a> <a href='https://code.woboq.org'>Code Browser</a> 2.1
<br/>Generator usage only permitted with license.</p>
</div></body></html>
