<!doctype html>
<html>
<head>
<meta name="viewport" content="width=device-width, initial-scale=1.0"><title>distort_image_ops.cc source code [tensorflow/tensorflow/contrib/image/ops/distort_image_ops.cc] - Woboq Code Browser</title>
<link rel="stylesheet" href="https://code.woboq.org/data/qtcreator.css" title="QtCreator"/>
<link rel="alternate stylesheet" href="https://code.woboq.org/data/kdevelop.css" title="KDevelop"/>
<script type="text/javascript" src="https://code.woboq.org/data/jquery/jquery.min.js"></script>
<script type="text/javascript" src="https://code.woboq.org/data/jquery/jquery-ui.min.js"></script>
<script>var file = 'tensorflow/tensorflow/contrib/image/ops/distort_image_ops.cc'; var root_path = '../../../../..'; var data_path = 'https://code.woboq.org/data';</script>
<script src='https://code.woboq.org/data/codebrowser.js'></script>
</head>
<body><div id='header'><h1 id='breadcrumb'><span>Browse the source code of </span><a href='../../../..'>tensorflow</a>/<a href='../../..'>tensorflow</a>/<a href='../..'>contrib</a>/<a href='..'>image</a>/<a href='./'>ops</a>/<a href='distort_image_ops.cc.html'>distort_image_ops.cc</a></h1></div>
<hr/><div id='content'><table class="code">
<tr><th id="1">1</th><td><i>/* Copyright 2016 The TensorFlow Authors. All Rights Reserved.</i></td></tr>
<tr><th id="2">2</th><td><i></i></td></tr>
<tr><th id="3">3</th><td><i>Licensed under the Apache License, Version 2.0 (the "License");</i></td></tr>
<tr><th id="4">4</th><td><i>you may not use this file except in compliance with the License.</i></td></tr>
<tr><th id="5">5</th><td><i>You may obtain a copy of the License at</i></td></tr>
<tr><th id="6">6</th><td><i></i></td></tr>
<tr><th id="7">7</th><td><i>    <a href="http://www.apache.org/licenses/LICENSE-2.0">http://www.apache.org/licenses/LICENSE-2.0</a></i></td></tr>
<tr><th id="8">8</th><td><i></i></td></tr>
<tr><th id="9">9</th><td><i>Unless required by applicable law or agreed to in writing, software</i></td></tr>
<tr><th id="10">10</th><td><i>distributed under the License is distributed on an "AS IS" BASIS,</i></td></tr>
<tr><th id="11">11</th><td><i>WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</i></td></tr>
<tr><th id="12">12</th><td><i>See the License for the specific language governing permissions and</i></td></tr>
<tr><th id="13">13</th><td><i>limitations under the License.</i></td></tr>
<tr><th id="14">14</th><td><i>==============================================================================*/</i></td></tr>
<tr><th id="15">15</th><td></td></tr>
<tr><th id="16">16</th><td><u>#include <a href="../../../core/framework/common_shape_fns.h.html">"tensorflow/core/framework/common_shape_fns.h"</a></u></td></tr>
<tr><th id="17">17</th><td><u>#include <a href="../../../core/framework/op.h.html">"tensorflow/core/framework/op.h"</a></u></td></tr>
<tr><th id="18">18</th><td><u>#include <a href="../../../core/framework/shape_inference.h.html">"tensorflow/core/framework/shape_inference.h"</a></u></td></tr>
<tr><th id="19">19</th><td></td></tr>
<tr><th id="20">20</th><td><b>namespace</b> <span class="namespace">tensorflow</span> {</td></tr>
<tr><th id="21">21</th><td></td></tr>
<tr><th id="22">22</th><td><b>using</b> <span class="namespace">shape_inference::</span>InferenceContext;</td></tr>
<tr><th id="23">23</th><td></td></tr>
<tr><th id="24">24</th><td><i>// --------------------------------------------------------------------------</i></td></tr>
<tr><th id="25">25</th><td><a class="macro" href="../../../core/framework/op.h.html#290" title="static ::tensorflow::register_op::OpDefBuilderReceiver register_op0 __attribute__((unused)) = ::tensorflow::register_op::OpDefBuilderWrapper&lt;true&gt;(&quot;AdjustHsvInYiq&quot;)" data-ref="_M/REGISTER_OP">REGISTER_OP</a>(<q>"AdjustHsvInYiq"</q>)</td></tr>
<tr><th id="26">26</th><td>    .<a class="ref" href="../../../core/framework/op.h.html#_ZN10tensorflow11register_op19OpDefBuilderWrapperILb1EE5InputENS_11StringPieceE" title='tensorflow::register_op::OpDefBuilderWrapper&lt;true&gt;::Input' data-ref="_ZN10tensorflow11register_op19OpDefBuilderWrapperILb1EE5InputENS_11StringPieceE">Input</a>(<a class="ref fake" href="../../../core/lib/core/stringpiece.h.html#_ZN10tensorflow11StringPieceC1EPKc" title='tensorflow::StringPiece::StringPiece' data-ref="_ZN10tensorflow11StringPieceC1EPKc"></a><q>"images: T"</q>)</td></tr>
<tr><th id="27">27</th><td>    .<a class="ref" href="../../../core/framework/op.h.html#_ZN10tensorflow11register_op19OpDefBuilderWrapperILb1EE5InputENS_11StringPieceE" title='tensorflow::register_op::OpDefBuilderWrapper&lt;true&gt;::Input' data-ref="_ZN10tensorflow11register_op19OpDefBuilderWrapperILb1EE5InputENS_11StringPieceE">Input</a>(<a class="ref fake" href="../../../core/lib/core/stringpiece.h.html#_ZN10tensorflow11StringPieceC1EPKc" title='tensorflow::StringPiece::StringPiece' data-ref="_ZN10tensorflow11StringPieceC1EPKc"></a><q>"delta_h: float"</q>)</td></tr>
<tr><th id="28">28</th><td>    .<a class="ref" href="../../../core/framework/op.h.html#_ZN10tensorflow11register_op19OpDefBuilderWrapperILb1EE5InputENS_11StringPieceE" title='tensorflow::register_op::OpDefBuilderWrapper&lt;true&gt;::Input' data-ref="_ZN10tensorflow11register_op19OpDefBuilderWrapperILb1EE5InputENS_11StringPieceE">Input</a>(<a class="ref fake" href="../../../core/lib/core/stringpiece.h.html#_ZN10tensorflow11StringPieceC1EPKc" title='tensorflow::StringPiece::StringPiece' data-ref="_ZN10tensorflow11StringPieceC1EPKc"></a><q>"scale_s: float"</q>)</td></tr>
<tr><th id="29">29</th><td>    .<a class="ref" href="../../../core/framework/op.h.html#_ZN10tensorflow11register_op19OpDefBuilderWrapperILb1EE5InputENS_11StringPieceE" title='tensorflow::register_op::OpDefBuilderWrapper&lt;true&gt;::Input' data-ref="_ZN10tensorflow11register_op19OpDefBuilderWrapperILb1EE5InputENS_11StringPieceE">Input</a>(<a class="ref fake" href="../../../core/lib/core/stringpiece.h.html#_ZN10tensorflow11StringPieceC1EPKc" title='tensorflow::StringPiece::StringPiece' data-ref="_ZN10tensorflow11StringPieceC1EPKc"></a><q>"scale_v: float"</q>)</td></tr>
<tr><th id="30">30</th><td>    .<a class="ref" href="../../../core/framework/op.h.html#_ZN10tensorflow11register_op19OpDefBuilderWrapperILb1EE6OutputENS_11StringPieceE" title='tensorflow::register_op::OpDefBuilderWrapper&lt;true&gt;::Output' data-ref="_ZN10tensorflow11register_op19OpDefBuilderWrapperILb1EE6OutputENS_11StringPieceE">Output</a>(<a class="ref fake" href="../../../core/lib/core/stringpiece.h.html#_ZN10tensorflow11StringPieceC1EPKc" title='tensorflow::StringPiece::StringPiece' data-ref="_ZN10tensorflow11StringPieceC1EPKc"></a><q>"output: T"</q>)</td></tr>
<tr><th id="31">31</th><td>    .<a class="ref" href="../../../core/framework/op.h.html#_ZN10tensorflow11register_op19OpDefBuilderWrapperILb1EE4AttrENS_11StringPieceE" title='tensorflow::register_op::OpDefBuilderWrapper&lt;true&gt;::Attr' data-ref="_ZN10tensorflow11register_op19OpDefBuilderWrapperILb1EE4AttrENS_11StringPieceE">Attr</a>(<a class="ref fake" href="../../../core/lib/core/stringpiece.h.html#_ZN10tensorflow11StringPieceC1EPKc" title='tensorflow::StringPiece::StringPiece' data-ref="_ZN10tensorflow11StringPieceC1EPKc"></a><q>"T: {uint8, int8, int16, int32, int64, half, float, double}"</q>)</td></tr>
<tr><th id="32">32</th><td>    .<a class="ref" href="../../../core/framework/op.h.html#_ZN10tensorflow11register_op19OpDefBuilderWrapperILb1EE10SetShapeFnEPFNS_6StatusEPNS_15shape_inference16InferenceContextEE" title='tensorflow::register_op::OpDefBuilderWrapper&lt;true&gt;::SetShapeFn' data-ref="_ZN10tensorflow11register_op19OpDefBuilderWrapperILb1EE10SetShapeFnEPFNS_6StatusEPNS_15shape_inference16InferenceContextEE">SetShapeFn</a>([](<a class="type" href="../../../core/framework/shape_inference.h.html#tensorflow::shape_inference::InferenceContext" title='tensorflow::shape_inference::InferenceContext' data-ref="tensorflow::shape_inference::InferenceContext">InferenceContext</a>* <dfn class="local col1 decl" id="1c" title='c' data-type='tensorflow::shape_inference::InferenceContext *' data-ref="1c">c</dfn>) {</td></tr>
<tr><th id="33">33</th><td>      <b>return</b> <span class="namespace">shape_inference::</span><a class="ref" href="../../../core/framework/common_shape_fns.h.html#_ZN10tensorflow15shape_inference29UnchangedShapeWithRankAtLeastEPNS0_16InferenceContextEi" title='tensorflow::shape_inference::UnchangedShapeWithRankAtLeast' data-ref="_ZN10tensorflow15shape_inference29UnchangedShapeWithRankAtLeastEPNS0_16InferenceContextEi">UnchangedShapeWithRankAtLeast</a>(<a class="local col1 ref" href="#1c" title='c' data-ref="1c">c</a>, <var>3</var>);</td></tr>
<tr><th id="34">34</th><td>    })</td></tr>
<tr><th id="35">35</th><td>    .<a class="ref" href="../../../core/framework/op.h.html#_ZN10tensorflow11register_op19OpDefBuilderWrapperILb1EE3DocENS_11StringPieceE" title='tensorflow::register_op::OpDefBuilderWrapper&lt;true&gt;::Doc' data-ref="_ZN10tensorflow11register_op19OpDefBuilderWrapperILb1EE3DocENS_11StringPieceE">Doc</a>(<a class="ref fake" href="../../../core/lib/core/stringpiece.h.html#_ZN10tensorflow11StringPieceC1EPKc" title='tensorflow::StringPiece::StringPiece' data-ref="_ZN10tensorflow11StringPieceC1EPKc"></a><q>R"Doc(</q></td></tr>
<tr><th id="36">36</th><td><q>Adjust the YIQ hue of one or more images.</q></td></tr>
<tr><th id="37">37</th><td><q></q></td></tr>
<tr><th id="38">38</th><td><q>`images` is a tensor of at least 3 dimensions.  The last dimension is</q></td></tr>
<tr><th id="39">39</th><td><q>interpretted as channels, and must be three.</q></td></tr>
<tr><th id="40">40</th><td><q></q></td></tr>
<tr><th id="41">41</th><td><q>We used linear transfomation described in:</q></td></tr>
<tr><th id="42">42</th><td><q> beesbuzz.biz/code/hsv_color_transforms.php</q></td></tr>
<tr><th id="43">43</th><td><q>The input image is considered in the RGB colorspace. Conceptually, the RGB</q></td></tr>
<tr><th id="44">44</th><td><q>colors are first mapped into YIQ space, rotated around the Y channel by</q></td></tr>
<tr><th id="45">45</th><td><q>delta_h in radians, multiplying the chrominance channels (I, Q)  by scale_s,</q></td></tr>
<tr><th id="46">46</th><td><q>multiplying all channels (Y, I, Q)  by scale_v, and then remapped back to RGB</q></td></tr>
<tr><th id="47">47</th><td><q>colorspace. Each operation described above is a linear transformation.</q></td></tr>
<tr><th id="48">48</th><td><q></q></td></tr>
<tr><th id="49">49</th><td><q>images: Images to adjust.  At least 3-D.</q></td></tr>
<tr><th id="50">50</th><td><q>delta_h: A float scale that represents the hue rotation amount, in radians.</q></td></tr>
<tr><th id="51">51</th><td><q>         Although delta_h can be any float value.</q></td></tr>
<tr><th id="52">52</th><td><q>scale_s: A float scale that represents the factor to multiply the saturation by.</q></td></tr>
<tr><th id="53">53</th><td><q>         scale_s needs to be non-negative.</q></td></tr>
<tr><th id="54">54</th><td><q>scale_v: A float scale that represents the factor to multiply the value by.</q></td></tr>
<tr><th id="55">55</th><td><q>         scale_v needs to be non-negative.</q></td></tr>
<tr><th id="56">56</th><td><q>output: The hsv-adjusted image or images. No clipping will be done in this op.</q></td></tr>
<tr><th id="57">57</th><td><q>        The client can clip them using additional ops in their graph.</q></td></tr>
<tr><th id="58">58</th><td><q>)Doc"</q>);</td></tr>
<tr><th id="59">59</th><td></td></tr>
<tr><th id="60">60</th><td>}  <i>// namespace tensorflow</i></td></tr>
<tr><th id="61">61</th><td></td></tr>
</table><hr/><p id='footer'>
Generated on <em>2018-Aug-09</em> from project tensorflow revision <em>v1.8</em><br />Powered by <a href='https://woboq.com'><img alt='Woboq' src='https://code.woboq.org/woboq-16.png' width='41' height='16' /></a> <a href='https://code.woboq.org'>Code Browser</a> 2.1
<br/>Generator usage only permitted with license.</p>
</div></body></html>
