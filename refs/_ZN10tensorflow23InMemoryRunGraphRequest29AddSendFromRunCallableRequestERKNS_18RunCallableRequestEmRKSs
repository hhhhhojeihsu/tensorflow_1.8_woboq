<dec f='tensorflow/tensorflow/core/distributed_runtime/message_wrappers.h' l='340' type='tensorflow::Status tensorflow::InMemoryRunGraphRequest::AddSendFromRunCallableRequest(const tensorflow::RunCallableRequest &amp; run_callable_request, size_t i, const string &amp; send_key)'/>
<inh f='tensorflow/tensorflow/core/distributed_runtime/message_wrappers.h' l='305' c='_ZN10tensorflow29MutableRunGraphRequestWrapper29AddSendFromRunCallableRequestERKNS_18RunCallableRequestEmRKSs'/>
<def f='tensorflow/tensorflow/core/distributed_runtime/message_wrappers.cc' l='332' ll='341' type='tensorflow::Status tensorflow::InMemoryRunGraphRequest::AddSendFromRunCallableRequest(const tensorflow::RunCallableRequest &amp; run_callable_request, size_t i, const string &amp; send_key)'/>
<doc f='tensorflow/tensorflow/core/distributed_runtime/message_wrappers.cc' l='329'>// TODO(b/74355905): Add a specialized implementation that avoids
// copying the tensor when at least two of the {client, master,
// worker} are in the same process.</doc>
