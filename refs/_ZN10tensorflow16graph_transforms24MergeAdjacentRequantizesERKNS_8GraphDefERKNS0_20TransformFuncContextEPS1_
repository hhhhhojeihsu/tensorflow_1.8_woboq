<def f='tensorflow/tensorflow/tools/graph_transforms/quantize_nodes.cc' l='464' ll='526' type='tensorflow::Status tensorflow::graph_transforms::MergeAdjacentRequantizes(const tensorflow::GraphDef &amp; input_graph_def, const tensorflow::graph_transforms::TransformFuncContext &amp; context, tensorflow::GraphDef * output_graph_def)'/>
<use f='tensorflow/tensorflow/tools/graph_transforms/quantize_nodes.cc' l='926' u='c' c='_ZN10tensorflow16graph_transforms13QuantizeNodesERKNS_8GraphDefERKNS0_20TransformFuncContextEPS1_'/>
<doc f='tensorflow/tensorflow/tools/graph_transforms/quantize_nodes.cc' l='458'>// We always generate Requantize ops driven by dynamic RequantizationRange
// calculations when we produce quantized ops like Conv2D or BiasAdd with
// 32-bit results. If there were FakeQuant ops already for those activation
// layers, then there will be a later Requantize op with constant min/max
// inputs, which is preferable for fast inference. This pass looks for those
// later Requantize ops, and replaces the dynamic version with them.</doc>
